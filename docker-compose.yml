version: '3.8'

services:
  # MCP Server - Tool execution layer
  mcp-server:
    build:
      context: .
      dockerfile: docker/Dockerfile.mcp
    container_name: mcp-server
    volumes:
      - ./pdf:/data/pdf
      - ./output:/data/output
    environment:
      - PDF_DIR=/data/pdf
      - OUTPUT_DIR=/data/output
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - PYTHONUNBUFFERED=1
    ports:
      - "8000:8000"
    networks:
      - research-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Agent Client - Reasoning layer
  agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
    container_name: research-agent
    volumes:
      - ./pdf:/data/pdf:ro
      - ./output:/data/output:ro
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - MCP_SERVER_URL=http://mcp-server:8000
      - PYTHONUNBUFFERED=1
    env_file:
      - .env
    networks:
      - research-network
    depends_on:
      mcp-server:
        condition: service_healthy
    stdin_open: true
    tty: true

  # Web UI - Graph visualization
  web:
    build:
      context: .
      dockerfile: docker/Dockerfile.web
    container_name: research-web
    volumes:
      - ./web:/app
      - /app/node_modules
    environment:
      - MCP_SERVER_URL=http://mcp-server:8000
      - NODE_ENV=development
    ports:
      - "3000:3000"
    networks:
      - research-network
    depends_on:
      - mcp-server

networks:
  research-network:
    driver: bridge
