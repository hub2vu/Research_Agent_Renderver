import os
import json
import logging
import re
import time
import arxiv
from pathlib import Path
from typing import Any, Dict, List, Optional
from openai import AsyncOpenAI
from ..base import MCPTool, ToolParameter

# LLM Logging
import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from logs.llm_logger import get_logger as get_llm_logger, SummaryType

# PDF ÎùºÏù¥Î∏åÎü¨Î¶¨
try:
    from pypdf import PdfReader
except ImportError:
    PdfReader = None

logger = logging.getLogger("mcp.tools.report")
logger.setLevel(logging.INFO)
aclient = AsyncOpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# Í≤ΩÎ°ú ÏÑ§Ï†ï
OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", "data/output"))
PDF_DIR = Path(os.getenv("PDF_DIR", "data/pdf"))
NEURIPS_DIR = PDF_DIR / "neurips2025"


class GetReportTool(MCPTool):
    """Ïù¥ÎØ∏ ÏÉùÏÑ±Îêú ÏöîÏïΩ Î¶¨Ìè¨Ìä∏(txt)Î•º ÏùΩÏñ¥ÏòµÎãàÎã§."""

    @property
    def name(self) -> str:
        return "get_report"

    @property
    def description(self) -> str:
        return "Retrieve existing summary report."

    @property
    def parameters(self) -> List[ToolParameter]:
        return [
            ToolParameter(
                name="paper_id", type="string", description="Paper ID", required=True
            )
        ]

    async def execute(self, paper_id: str, **kwargs) -> Dict[str, Any]:
        # 1. Í∏∞Î≥∏ Í≤ΩÎ°ú ÌôïÏù∏
        report_path = OUTPUT_DIR / paper_id / "summary_report.txt"

        # 2. ÏóÜÏúºÎ©¥ fuzzy folder (Ïòà: 115627_Title) ÌôïÏù∏
        if not report_path.exists() and OUTPUT_DIR.exists():
            for folder in OUTPUT_DIR.iterdir():
                if folder.is_dir() and folder.name.startswith(f"{paper_id}_"):
                    candidate = folder / "summary_report.txt"
                    if candidate.exists():
                        report_path = candidate
                        break

        if report_path.exists():
            with open(report_path, "r", encoding="utf-8") as f:
                return {"found": True, "content": f.read()}
        return {"found": False, "message": "Report not found."}


class GenerateReportTool(MCPTool):
    """ÎÖºÎ¨∏ Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±Í∏∞ (NeurIPS Í≤ΩÎ°ú ÏûêÎèô ÌÉêÏÉâ Ìè¨Ìï®)"""

    @property
    def name(self) -> str:
        return "generate_report"

    @property
    def description(self) -> str:
        return "Generate summary report from PDF or text."

    @property
    def parameters(self) -> List[ToolParameter]:
        return [
            ToolParameter(
                name="paper_id", type="string", description="Paper ID", required=True
            )
        ]

    def _resolve_paper_dir(self, paper_id: str) -> Path:
        """IDÎ°ú Ìè¥Îçî Ï∞æÍ∏∞ (Ï†ïÌôïÌûà ÏùºÏπòÌïòÍ±∞ÎÇò, ID_Title ÌòïÌÉú)"""
        exact = OUTPUT_DIR / paper_id
        if exact.exists():
            return exact

        # Fuzzy search in output dir
        if OUTPUT_DIR.exists():
            for folder in OUTPUT_DIR.iterdir():
                if folder.is_dir() and folder.name.startswith(f"{paper_id}_"):
                    return folder

        # ÏóÜÏúºÎ©¥ ÏÉàÎ°ú ÏÉùÏÑ±Ìï† Í∏∞Î≥∏ Í≤ΩÎ°ú
        return exact

    def _get_text_from_file(self, paper_dir: Path) -> str:
        """Ï∂îÏ∂úÎêú ÌÖçÏä§Ìä∏ ÌååÏùº ÏùΩÍ∏∞"""
        for fname in ["extracted_text.json", "extracted_text.txt"]:
            fpath = paper_dir / fname
            if fpath.exists():
                try:
                    with open(fpath, "r", encoding="utf-8") as f:
                        if fname.endswith(".json"):
                            data = json.load(f)
                            return data.get("full_text", "") or ""
                        return f.read()
                except:
                    pass
        return ""

    def _find_pdf_path(self, paper_id: str, paper_dir: Path) -> Optional[Path]:
        """PDF ÌååÏùº ÏúÑÏπò Ï∂îÏ†Å (NeurIPS Ìè¥Îçî Ìè¨Ìï®)"""
        # 1. Output Ìè¥Îçî ÎÇ¥
        if paper_dir.exists():
            pdfs = list(paper_dir.glob("*.pdf"))
            if pdfs:
                return pdfs[0]

        # 2. NeurIPS 2025 Ìè¥Îçî (ID_Title.pdf Ìå®ÌÑ¥)
        if NEURIPS_DIR.exists():
            # Ï†ïÌôïÌïú ID Îß§Ïπ≠
            exact = NEURIPS_DIR / f"{paper_id}.pdf"
            if exact.exists():
                return exact
            # Ï†ëÎëêÏñ¥ Îß§Ïπ≠ (115627_Alternating_Gradient...)
            for f in NEURIPS_DIR.glob(f"{paper_id}_*.pdf"):
                return f

        # 3. Í∏∞Î≥∏ PDF Ìè¥Îçî
        if (PDF_DIR / f"{paper_id}.pdf").exists():
            return PDF_DIR / f"{paper_id}.pdf"

        return None

    def _extract_from_pdf_file(self, pdf_path: Path) -> str:
        """PDF ÌååÏùºÏóêÏÑú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú"""
        if not PdfReader:
            return ""
        try:
            reader = PdfReader(str(pdf_path))
            return "\n".join([page.extract_text() or "" for page in reader.pages])
        except Exception as e:
            logger.error(f"PDF read error: {e}")
            return ""

    def _download_arxiv_pdf(self, paper_id: str, save_dir: Path) -> bool:
        if not arxiv:
            return False
        try:
            clean_id = paper_id.split("v")[0]
            paper = next(arxiv.Search(id_list=[clean_id]).results(), None)
            if paper:
                save_dir.mkdir(parents=True, exist_ok=True)
                paper.download_pdf(dirpath=str(save_dir), filename=f"{paper_id}.pdf")
                return True
        except:
            pass
        return False

    async def execute(self, paper_id: str, **kwargs) -> Dict[str, Any]:
        paper_dir = self._resolve_paper_dir(paper_id)

        # 1. ÌÖçÏä§Ìä∏ ÌôïÏù∏
        full_text = self._get_text_from_file(paper_dir)

        # 2. ÌÖçÏä§Ìä∏ ÏóÜÏúºÎ©¥ PDF Ï∞æÏïÑÏÑú Ï∂îÏ∂ú
        if not full_text:
            pdf_path = self._find_pdf_path(paper_id, paper_dir)

            if pdf_path:
                logger.info(f"Found PDF at {pdf_path}, extracting...")
                full_text = self._extract_from_pdf_file(pdf_path)
            else:
                # PDFÎèÑ ÏóÜÏúºÎ©¥ ArXiv Îã§Ïö¥Î°úÎìú ÏãúÎèÑ (NeurIPSÎäî Ïù¥ÎØ∏ Îã§Ïö¥Î°úÎìú ÎêòÏóàÎã§Í≥† Í∞ÄÏ†ï)
                if "." in paper_id and self._download_arxiv_pdf(paper_id, paper_dir):
                    full_text = self._extract_from_pdf_file(
                        paper_dir / f"{paper_id}.pdf"
                    )

        if not full_text:
            return {
                "success": False,
                "error": f"ÎÖºÎ¨∏ ÌååÏùº(PDF)ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Í≤ΩÎ°ú: {NEURIPS_DIR}/{paper_id}_*.pdf ÌôïÏù∏ ÌïÑÏöî.",
            }

        # 3. Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
        try:
            prompt = f"""
            ÎãπÏã†ÏùÄ AI ÎÖºÎ¨∏ Ï†ÑÎ¨∏ Î∂ÑÏÑùÍ∞ÄÏûÖÎãàÎã§. ÏïÑÎûò ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú [Ï¢ÖÌï© ÏöîÏïΩ Î≥¥Í≥†ÏÑú]Î•º ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.

            [ÎÖºÎ¨∏ ÌÖçÏä§Ìä∏ ÏùºÎ∂Ä]
            {full_text[:50000]}

            [ÏûëÏÑ± ÏñëÏãù]
            1. üìå ÎÖºÎ¨∏ Ï†úÎ™© Î∞è ÌïµÏã¨ Í∏∞Ïó¨ (3Î¨∏Ïû• ÏöîÏïΩ)
            2. üõ† Ï£ºÏöî Î∞©Î≤ïÎ°† (Methodology)
            3. üìä Ïã§Ìóò Í≤∞Í≥º Î∞è ÏÑ±Îä• (Experiments)
            4. üí° Í≤∞Î°† Î∞è ÌïúÍ≥ÑÏ†ê

            Î∞òÎìúÏãú **ÌïúÍµ≠Ïñ¥**Î°ú ÏûëÏÑ±ÌïòÏÑ∏Ïöî.
            """

            start_time = time.time()
            response = await aclient.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )

            latency_ms = (time.time() - start_time) * 1000
            content = response.choices[0].message.content

            # LLM Logging - Log report generation
            try:
                llm_logger = get_llm_logger()

                llm_logger.log_summary(
                    paper_id=paper_id,
                    summary_type=SummaryType.COMPREHENSIVE,
                    summary_prompt=prompt[:5000],
                    summary_response=content,
                    source_text_length=len(full_text),
                    model="gpt-4o",
                    temperature=0.3,
                    metadata={
                        "source_truncated": len(full_text) > 50000
                    }
                )

                llm_logger.log_llm_call(
                    model="gpt-4o",
                    prompt=prompt[:5000],
                    response=content[:5000],
                    tool_name="generate_report",
                    temperature=0.3,
                    latency_ms=latency_ms,
                    paper_id=paper_id
                )
            except Exception as log_error:
                logger.warning(f"Failed to log report generation: {log_error}")

            # Ï†ÄÏû• (Í≤∞Í≥º Ìè¥ÎçîÍ∞Ä ÏóÜÏúºÎ©¥ ÏÉùÏÑ±)
            paper_dir.mkdir(parents=True, exist_ok=True)
            report_file_path = paper_dir / "summary_report.txt"
            with open(report_file_path, "w", encoding="utf-8") as f:
                f.write(content)

            # LLM Logging - Log artifact
            try:
                llm_logger = get_llm_logger()
                llm_logger.log_artifact(
                    artifact_type="summary_report_txt",
                    file_path=str(report_file_path),
                    generation_method="llm",
                    input_sources=[{"type": "full_text", "length": len(full_text)}],
                    paper_id=paper_id
                )
            except Exception as log_error:
                logger.warning(f"Failed to log artifact: {log_error}")

            return {"success": True, "result": {"content": content}}

        except Exception as e:
            logger.error(f"Report gen failed: {e}")
            return {"success": False, "error": str(e)}
