{
  "filename": "119698_The Rise of Parameter Specialization for Knowledge Storage in Large Language Models.pdf",
  "total_pages": 26,
  "full_text": "The Rise of Parameter Specialization for Knowledge\nStorage in Large Language Models\nYihuai Hong1,2∗\nYiran Zhao3\nWei Tang1\nYang Deng4\nYu Rong1\nWenxuan Zhang5†\n1Alibaba DAMO Academy 2New York University\n3National University of Singapore\n4Singapore Management University 5Singapore University of Technology and Design\nyihuaihong@nyu.edu, wxzhang@sutd.edu.sg\nAbstract\nOver time, a growing wave of large language models from various series has been\nintroduced to the community. Researchers are striving to maximize the performance\nof language models with constrained parameter sizes. However, from a microscopic\nperspective, there has been limited research on how to better store knowledge in\nmodel parameters, particularly within MLPs, to enable more effective utilization of\nthis knowledge by the model. In this work, we analyze twenty publicly available\nopen-source large language models to investigate the relationship between their\nstrong performance and the way knowledge is stored in their corresponding MLP\nparameters. Our findings reveal that as language models become more advanced\nand demonstrate stronger knowledge capabilities, their parameters exhibit increased\nspecialization. Specifically, parameters in the MLPs tend to be more focused\non encoding similar types of knowledge. We experimentally validate that this\nspecialized distribution of knowledge contributes to improving the efficiency of\nknowledge utilization in these models. Furthermore, by conducting causal training\nexperiments, we confirm that this specialized knowledge distribution plays a critical\nrole in improving the model’s efficiency in leveraging stored knowledge.\n1\nIntroduction\nAn increasing number of powerful large language models (LLMs) have emerged in recent years\n(Touvron et al., 2023a; Achiam et al., 2023; Groeneveld et al., 2024; Bai et al., 2023; Team, 2025),\noften demonstrating remarkable capabilities across various benchmarks and tests (Hendrycks et al.,\n2021a; Chen et al., 2021a; Cobbe et al., 2021). Thanks to the large parameter space, they have shown\nan exceptional ability to encode vast amounts of knowledge within their parameters, enabling superior\nperformance on knowledge-intensive tasks (Hendrycks et al., 2021a; Zhang et al., 2023).\nTo understand the internal mechanism of knowledge storage, many studies have been conducted. For\nexample, Geva et al. (2021b) interprets the MLP layers of the transformer architecture (Vaswani et al.,\n2017) as key-value memories, where the factual knowledge encoded in the weights is retrieved and\ntransmitted to the output layer during inference (Geva et al., 2023; Meng et al., 2022; Yu et al., 2024).\nFurthermore, researchers have observed that, in the final layer of the MLP, each vector in that value\nmatrix can act as a fundamental unit of knowledge storage (Geva et al., 2022a,b). However, there\nhas been limited research on how to better store and compress knowledge within constrained model\nparameters to enable more effective utilization of that knowledge by the model.\n*Work done during an internship at Alibaba Group, before joining New York University.\n†Corresponding author.\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\nIn this work, we investigate the relationship between language models’ knowledge storage patterns\nand their performance. To identify parameters associated with specific knowledge concepts, we\nanalyze consistently activated parameters in MLP layers when the model processes questions related\nto the particular knowledge concept. Building on the key-value interpretation of the MLP by Geva\net al. (2021b), which treats the up-projection matrix as the key and the down-projection matrix as\nthe value (i.e., stored knowledge), we extract the intermediate representations between these two\nmatrices and treat their absolute value as the activation of corresponding parameters. To support\nempirical analysis, we construct a new encyclopedic knowledge benchmark based on Wikipedia,\ncovering knowledge concepts with varying frequencies. We then apply the knowledge parameter\nidentification method to 20 open-source LLMs across a wide range of model families, enabling us to\nexplore correlations between knowledge storage patterns and overall model performance.\nHarry Potter\nSuper Mario \nBarack Obama\nWhen querying about Super Mario: \nEvolution of Knowledge Distribution in Parameter Vectors during Model Iteration\nLLaMA MLP\nLLaMA2 MLP\nLLaMA3 MLP\nFigure 1: Evolution of knowledge distribution in model pa-\nrameters during three iterations of LLaMA models. Each\nparameter vector corresponds to a column in the value matrix\nof the MLP module, as indicated by the dashed rectangles.\nOur extensive empirical analysis re-\nveals that stronger models exhibit\nhigher parameter specialization for\ndistinct knowledge, whereas weaker\nmodels distribute knowledge more\ndiffusely across parameters. Conse-\nquently, significantly more parameters\nare required to store individual knowl-\nedge in weaker models. As illustrated\nin Figure 1, advancing model capabil-\nity correlated with improved parame-\nter specialization for encoding knowl-\nedge: fewer parameters are allocated\nper knowledge concept, while each pa-\nrameter governs a narrower subset of\nconcepts.\nMotivated by this observation, we fur-\nther conduct four sets of controlled\nexperiments, each involving continued training on the Llama2-7B (Touvron et al., 2023a) and\nQwen2-7B (Yang et al., 2024) models with new knowledge respectively, to validate the strong causal\nrelationship between improved parameter specialization and enhanced performance of the models\non knowledge tasks. Overall, the experiments reveal that encoding similar knowledge into the same\nparameter vectors better aligns with the model’s internal knowledge retrieval mechanism. This\napproach helps the model utilize knowledge more efficiently, improves knowledge compression, and\nreduces hallucination generation.\nOur contributions can be summarized as follows:\n• To the best of our knowledge, this is the first attempt to quantify and compare the degree of\nparameter specialization for knowledge storage across different LLMs.\n• We investigate the relationship between parameter specialization and model performance in LLMs,\nconstructing a dedicated probing dataset for an in-depth analysis on 20 open-source LLMs. Our\nfindings indicate that more capable LLMs exhibit greater parameter specialization.\n• Through controlled training experiments, we provide empirical evidence of a causal link between\nincreased parameter specialization and improved performance on knowledge-intensive tasks.\n2\nRelated Work\nKnowledge Storage in LLMs\nStudying how knowledge is stored and utilized in LLMs has been\nan important area in the research of LLM interpretability (Meng et al., 2022; Geva et al., 2021b;\nSukhbaatar et al., 2015; Geva et al., 2023). Recent studies have shown that MLPs are the primary and\ncrucial components for storing factual knowledge and associations in transformer-based language\nmodels (Geva et al., 2022b; Dar et al., 2023). They can be conceptualized as key-value memories\n(Geva et al., 2021b), where the factual knowledge encoded in the MLP weights is recalled and\ntransmitted to the output layer during inference (Geva et al., 2023; Meng et al., 2022; Yu et al., 2024).\nAdditionally, researchers have found that in the final layer of the MLP, each vector in the value matrix\ncan serve as a fundamental unit for storing knowledge (Geva et al., 2022a,b). They have also verified\n2\nthat by directly manipulating or disrupting these parameter vectors, specific knowledge can be edited\nor unlearned (Hong et al., 2024a,b; Meng et al., 2022), leading to changes in the model’s responses.\nKnowledge Superposition in LLM\nElhage et al. (2022); Olah (2023) propose the concept of\nKnowledge Superposition. It refers to an inevitable phenomenon in neural network models, especially\nlarge language models, during training and data memorization: since the number of data features\ngreatly exceeds the number of parameters in the model, each parameter does not have a simple\none-to-one mapping with the data features or knowledge. Neurons are often involved with multiple\ndata features simultaneously. In our work, we treat each vector in the last layer of MLP as a basic\nunit for storing knowledge and investigate the superposition of knowledge within these vectors.\n3\nParameter Specialization Analysis for Knowledge Storage\n3.1\nPreliminary\nIn transformer-based language models, the MLP is a crucial component for storing the model’s\nfactual knowledge, and its sub-layers can be viewed as key-value memories (Geva et al., 2021b). To\nbe specific, the first layer* of MLP sublayers can be viewed as a matrix WK formed by key vectors\n{k1, k2, . . . , kn}, used to capture a set of patterns in the input sequence, and ultimately outputting\nthe coefficient scores. The second layer can be viewed as a matrix WV formed by value vectors\n{v1, v2, . . . , vn}, with each value vector containing the corresponding factual knowledge.\nFormally, the output of the MLP in the transformer’s ℓ-th layer, given an input hidden state xℓ, can be\ndefined as:\nMℓ= f\n\u0000W ℓ\nK · γ(xℓ+ Aℓ)\n\u0001\nW ℓ\nV = mℓW ℓ\nV ,\n(1)\nwhere W ℓ\nK, W ℓ\nV ∈Rn×d. The function f and γ represent a non-linearity† and layer normalization,\nrespectively. In the transformer’s ℓ-th layer, mℓ∈Rn denotes the coefficient scores, and Aℓ\nrepresents the output of the attention component. The hidden state dimension is d, while the\nintermediate MLP has a dimension of n. Then, by denoting vℓ\nj as the j-th column (which will be\ncalled the value vector or parameter vector in the following sections) of W ℓ\nV and mℓ\nj as the j-th\nelement in the coefficients produced by the first layer of the MLP, we can view MLP’s output Mℓas\na linear combination of the value vectors in W ℓ\nV , with their corresponding coefficients mℓ:\nMℓ=\nXn\nj=1 mℓ\njvℓ\nj,\n(2)\nFinally, the hidden states at the ℓ-th layer of the language model can be defined as:\nXℓ+1 = Xℓ+ Mℓ+ Aℓ,\n(3)\nwhere Xℓ, Mℓand Aℓrepresent the hidden states, MLP’s output, and the attention component’s\noutput in the transformer’s ℓ-th layer, respectively. In this work, we focus on studying the impact of\nthe MLP on the knowledge output of the hidden states.\n3.2\nKnowledge Vectors Masking Procedure\nReferring to Eq. (2), if we aim to ablate the impact of the knowledge contained in the vectors for\na particular subset Sℓof indices in ℓ-th layer, we can directly set the corresponding mℓ\nj values for\nj ∈Sℓto zero. Hence, we have:\nMℓ\nmasked =\nXn\nj=1\nj /∈Sℓmℓ\njvℓ\nj +\nXn\nj=1\nj∈Sℓ0 · vℓ\nj =\nXn\nj=1\nj /∈Sℓmℓ\njvℓ\nj,\n(4)\n*In most decoder-only models, such as GPT-2 (Radford et al., 2019) and GPT-J (Chen et al., 2021b), the MLP\ncomponent consists of two layers, whereas in LLaMA (Touvron et al., 2023b), it comprises three layers. However,\nwe can still regard LLaMA’s first two layers collectively as the key matrices, with their output representing the\ncoefficient scores.\n†For brevity, the bias term is omitted.\n3\nTherefore, given a concept, when we aim to identify which specific value vectors in the model’s\nMLPs are most closely related to the knowledge contained in that concept—while avoiding the\nmasking of vectors associated with the model’s general capabilities‡ (Meng et al., 2022; Geva et al.,\n2023), i.e., determining the appropriate subset Sℓat each layer of the model for this concept—we\nwill run t concept-related questions and t∗irrelevant questions on the selected model. Then we will\ncompute the corresponding coefficients mℓand m∗ℓ, which are the averages of the coefficients for\nthe concept-related questions and irrelevant questions, respectively, at each layer of the model. For\ndetails on the generation of concept-related and irrelevant questions, as well as the selection of t and\nt∗, please refer to §3.4. After obtaining mℓand m∗ℓat each layer, we perform the computation using\nthe following formula:\nSℓ=\n\b\f\fmℓ\nj −m∗ℓ\nj\n\f\f \f\f 1 ≤j ≤n, mℓ\nj ∈mℓ, m∗ℓ\nj ∈m∗ℓ\t\n(5)\nNext, we will sort Sℓin descending order and select the value vectors corresponding to the indices of\nthe top k elements, which will be used as the subset Sℓfor the masking operation. This allows us to\nobserve and analyze the impact of masking these vectors on the model’s knowledge output for certain\nconcepts.\n3.3\nThe Definition of Parameter Specialization\nAfter obtaining the subset of value vectors Sℓthat exhibit specificity to a given concept at each layer\nof the model, as described in §3.2, we apply the masking operation to these value vectors, as shown\nin Eq. (4). We then analyze its impact on the model’s final outputs for the t concept-related questions\nand t∗irrelevant questions. By comparing the model’s responses after masking with the ground truth\nanswers, we compute the accuracy on concept-related questions, referred to as the Concept Specific\nScore after surgery, and the accuracy on irrelevant questions, referred to as the General Score after\nsurgery. To quantify the degrees of specialization of the model’s value vectors with respect to the\nconcept-related knowledge, we define the Parameter Specialization Score (PSS):\nPSS\n△= |General Score after surgery −Concept Specific Score after surgery|\nGeneral Score before surgery\n,\n(6)\nwhich is obtained by taking the absolute difference between the General Score and the Concept\nSpecific Score after surgery, and then dividing by the model’s accuracy on the entire dataset before\nsurgery. A higher PSS indicates that the parameter vectors in the model’s MLP layers exhibit a higher\ndegree of specialization towards specific knowledge. Conversely, a lower PSS suggests more severe\nknowledge superposition phenomena within the parameter vectors, resulting in a lower degree of\nspecialization.\n3.4\nDataset Construction\nTo thoroughly investigate the parameter specialization of knowledge with different frequencies in the\nparameter vectors of LLMs’ MLP, we introduce a dataset named SpecWiki. It includes 525 concepts\nselected from Wikipedia §, a widely recognized high-quality corpus for LLM training. These concepts\nare categorized based on their frequency levels to ensure a diverse distribution. We then design\ntwo distinct question formats—multiple-choice questions and open-ended generation prompts—to\nfacilitate a thorough examination of the models’ knowledge storage.\nConcept Selection\nWe treat each Wikipedia item as a defining concept, typically represented by\nan article focused on a specific subject, indicated by its title. We focus on specific entity concepts,\nsuch as historical figures, events and locations. We began by randomly sampling 2,400 pages (a\n0.01% rate) from the 2019 version of Wikipedia. Subsequently, we performed manual filtering to\nremove overly commonsensical or abstract concepts (such as the letter ’S’ and the word ’Freedom’),\nambiguous concepts (like ’Apple’), and those associated with pages under 1,000 words. Ultimately,\nthis resulted in 525 high-quality concepts spanning specific topics like people, arts, and events.\n‡The term \"general ability\" refers to the model’s fundamental skills, such as processing text inputs correctly\nand generating coherent outputs, rather than encoding knowledge specific to a particular concept.\n§https://en.wikipedia.org/\n4\nGiven that the frequency of knowledge in training datasets significantly influences a model’s ability\nto retain and comprehend it (Allen-Zhu & Li, 2023; Meng et al., 2022; Mallen et al., 2023), we utilize\nWikipedia page views as a proxy for knowledge frequency in the models’ pre-training datasets¶. To\nthis end, we calculated the page views for each concept on Wikipedia between January 1, 2010, and\nDecember 31, 2019||. Based on these statistics, concepts are categorized by page view frequency into\nthree equal tiers: low-frequency (bottom 33% of the distribution), medium-frequency (middle 33%),\nand high-frequency (top 33%). A more detailed distribution of the categories and the corresponding\nexample data of SpecWiki dataset are provided in Table 4 and Table 5, respectively, in the Appendix.\nThis approximation helps estimate the likelihood of a concept’s presence in the models’ pre-training\ndatasets and allows us to explore how knowledge at different frequency levels is stored in models and\nprovides a more comprehensive evaluation.\nQuestion Generation\nTo more precisely assess the retention of knowledge within the model, we\ndesign two sets of question formats.\n• Multi-Choice Questions. Drawing inspiration from the widely used Massive Multitask Language\nUnderstanding (MMLU) dataset (Hendrycks et al., 2021b), which evaluates general knowledge\nacross models, we similarly designed ten multiple-choice questions for each concept, ensuring the\nknowledge and answers could be directly found in the relevant Wikipedia articles. Specifically, we\nprovided GPT-4o (OpenAI et al., 2024) with the appropriate Wikipedia article for each concept\nand instructed it to extract ten questions without overlap, along with the correct answers derived\nfrom the article’s text. Next, it was instructed to generate three additional incorrect answers, aside\nfrom the golden answer, ensuring that none of them overlapped with the correct answer to avoid\nconfusion. The detailed prompt is available in §A.1. We also include sample multiple-choice\nquestions and results of manual verification of the generated data in Appendix §A.2.\n• Open-ended Generation. To more effectively assess the model’s ability to generate knowledge text\nfreely, and to overcome the randomness and lack of depth inherent in the Multi-Choice Question\nevaluation method, we also set up a series of Open-ended Generation questions. For each question\nrelated to a concept, we prompted the model to generate an answer of up to 150 tokens directly\nand used GPT-4o as an evaluator to evaluate whether the generated response correctly matched the\ngolden answer.\n4\nExperiment\n4.1\nExperimental Setup\nEvaluated Models\nTo provide a more comprehensive evaluation of how the degree of parameter\nspecialization evolves across large language models, we assessed 20 open-source models from\nvarious families and sizes in the community. Specifically, we evaluated LLaMA series (Touvron\net al., 2023a,b; Grattafiori et al., 2024), Qwen series (Bai et al., 2023; Yang et al., 2024; Team, 2025),\nGemma series (Team et al., 2024a,b), OLMo series (Groeneveld et al., 2024; OLMo et al., 2025), Yi\nseries (AI et al., 2025), Mistral series (Jiang et al., 2023), GPT-j-6b (Wang & Komatsuzaki, 2021),\nPythia-6.9b (Biderman et al., 2023), Falcon-7b (Almazrouei et al., 2023) and Mpt-7b (Databricks,\n2023). Refer to Appendix §B.1 for the implementation details of these models.\nKnowledge Vectors Masking Setup\nBased on the descriptions in §3.2, in order to obtain mℓand\nm∗ℓfor each concept in SpecWiki at each layer of the model, we set the number of concept-related\nquestions t to 10. Additionally, we randomly select 5 irrelevant concepts with no knowledge overlap\nfrom the benchmark, and gather the corresponding questions associated with these irrelevant concepts,\nresulting in t∗= 50 irrelevant questions. These collected questions will also be directly utilized in\nthe computation of both the Concept-Specific Score and the General Score.\n¶To better support this point, we include experiments in §A.4 of Appendix that validate the strong correlation\nbetween concept popularity and their frequency in the pretraining data.\n||The earliest release date of the evaluated models, such as GPT-J, is 2019. Therefore, their pretraining\ndatasets could not include knowledge or concepts that emerged after this period. To ensure a fair evaluation\nacross all models, any knowledge introduced post-2019, including the COVID-19 pandemic, was excluded from\nthe benchmark.\n5\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nSpecWiki Performance (Multi-Choice Questions)\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\n0.16\nParameter Specialization Score(PSS)\nQwen1.5-7B\nQwen2-7B\nQwen2.5-7B\nLLaMA-7B\nLLaMA2-7B\nLLaMA3-8B\nOLMo-7B\nOLMo-2-7B\nGemma-7B\nGemma2-9B\nMistral-7B-v0.1\nMistral-7B-v0.2\nMistral-7B-v0.3\nYi-6B\nYi-1.5-6B\nFalcon-7B\nGPT-J-6B\nPythia-6.9B\nMpt-7B\nQwen3-8B\nPearson R: 0.92 (p=1.41e-08)\nSpearman : 0.93 (p=4.87e-09)\nSpecWiki Performance vs Parameter Specialization Score\nTrendline\n2021-06-09\n2022-05-30\n2023-05-20\n2024-05-09\n2025-04-29\nRelease Date\nFigure 2: Correlation between the performance on SpecWiki and parameter specialization score\n(PSS) in 20 language models. We use a color gradient to distinguish the release times of the models,\nwith cooler colors indicating earlier release dates and warmer colors representing later releases.\nAdditionally, the size of each circle reflects the model’s performance on MMLU, with larger circles\nindicating better performance. The blue trendline, obtained through linear regression fitting of the\ndata points, suggests a strong correlation between a model’s performance on SpecWiki and its degree\nof Parameter Specialization.\nRegarding the selection of model layers for masking, since the initial layers of a model typically\nhandle fundamental capabilities like basic text processing (Meng et al., 2022; Geva et al., 2023),\nmasking these layers could severely impair the model’s basic text generation abilities. Therefore, for\nall models in our study, we preserve the first 5 layers without masking and only apply vector masking\noperations to all subsequent layers.\nFor the PSS computation of each model, we selected five different fixed k values—10%, 20%, 30%,\n40%, and 50%—which represent the proportion of value vectors in the model’s MLP layers that were\nmasked. For each k, we calculated the corresponding PSS following 6, and then averaged the results\nto obtain the final PSS score for each model. This criterion was applied consistently across both the\nMultiple-Choice Questions (MCQ) and Open-ended Generation (OEG) tasks.\n4.2\nMain Results\nThe main results for the Multiple-Choice Questions setting can be seen in Figure 2. We observe a\nstrong correlation between the degree of Parameter Specialization (measured by PSS) and model\nperformance on SpecWiki across 20 models, with Pearson and Spearman coefficients of 0.92 and\n0.93, respectively. Models achieving better performance on SpecWiki exhibit higher Parameter\nSpecialization Scores. Furthermore, models with higher PSS are often those released more recently\n(warmer color) and exhibit stronger general abilities, as measured by their MMLU performance\n(larger circle). The corresponding results for the Open-ended Generation setting can be found in\nFigure 6 in §B.2, which exhibit similar patterns and trends.\nTo better analyze the variations in Parameter Specialization across models within the same family,\nwe selected eight models from four model families: LLaMA, Qwen, Mistral, and Gemma. We\nexamined how the difference between the General Score, which represents the model’s ability to\nhandle irrelevant knowledge, and the Concept Specific Score, which reflects the model’s ability to\nhandle task-specific knowledge, changes under different masking ratios of parameter vectors. The\nresults are shown in Figure 3.\nFrom the figure, we can observe a very similar pattern across models from the four families:\n1. Among models within the same family, more advanced models tend to achieve higher peaks in the\nGeneral Score - Concept Specific Score difference. This indicates that more advanced models\ngenerally exhibit higher levels of Parameter Specialization.\n6\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nLLaMA Series Models\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nQwen Series Models\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nMistral Series Models\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nGemma Series Models\nLLaMA-7B\nLLaMA3-8B\nQwen1.5-7B\nQwen2.5-7B\nMistral-7B-v1\nMistral-7B-v3\nGemma-7B\nGemma2-9B\nFigure 3: Analysis of Parameter Specialization variations across models within the same family. We\nselected eight models from four model families: LLaMA, Qwen, Mistral, and Gemma. The figure\nshows how the difference between the General Score (representing the model’s ability to handle\nirrelevant knowledge) and the Concept Specific Score (representing the model’s ability to handle\ntask-specific knowledge) changes under different masking ratios of parameter vectors.\n2. As the masking ratio of parameter vectors increases, from approximately 5% to 20%, the difference\nbetween the General Score and the Concept Specific Score gradually increases to a peak. This\nindicates that we are removing parameter vectors that are highly specific to the target knowledge.\nAfter reaching the peak, as the masking ratio continues to increase, the difference gradually\ndecreases to zero. This suggests that parameter vectors with lower activation are often those that\nhave a higher degree of knowledge superposition and are less specialized in the target knowledge.\nAdditionally, we unexpectedly found that when a small proportion of concept-related vectors (ranging\nfrom 5% to 10%) were masked, the performance of the masked models on unrelated questions\neven surpassed that of the original models. This observation is consistent across various models\nand indicates the positive impact of reducing irrelevant information interference in the model’s\nrepresentation, leading to improved performance.\nIn §5, we will further validate the causal relationship between the degree of model parameter\nspecialization and its ability to better utilize target knowledge through the finetuning experiments on\nadditional data.\n4.3\nImpact of Model Scale on Parameter Specialization\nModel\nAccuracyMCQ ↑\nPSS ↑\nQwen1.5-0.5B\n0.61 (±0.2)\n0.019 (±0.01)\nQwen1.5-1.8B\n0.61 (±0.3)\n0.044 (±0.02)\nQwen1.5-4B\n0.73 (±0.2)\n0.075 (±0.02)\nQwen1.5-7B\n0.75 (±0.2)\n0.121 (±0.04)\nQwen1.5-14B\n0.82 (±0.2)\n0.184 (±0.03)\nGemma2-2B\n0.72 (±0.3)\n0.057 (±0.02)\nGemma2-9B\n0.86 (±0.1)\n0.138 (±0.03)\nTable 1: Performance comparison of language models\nwith varying sizes on Multiple-Choice Question and\nParameter Specialization Score. Both the Qwen1.5 and\nGemma2 series models show improved Parameter Spe-\ncialization as the model scale increases, accompanied\nby better performance on the MCQ testing in SpceWiki.\nIn this section, to better explore the dif-\nferences in the degree of parameter spe-\ncialization across models of different sizes,\nwe conducted Knowledge Vectors Mask-\ning experiments on five Qwen1.5 models\nof varying sizes (0.5B, 1.8B, 4B, 7B, and\n14B) and on 2 Gemma2 models (2B and\n9B). The results are shown in Table 1. We\nobserve that in both the Qwen and Gemma\nmodel families, as the model size increases,\nthe corresponding Parameter Specializa-\ntion Score also increases. This trend is\naccompanied by improved performance on\nSpecWiki.\nThis suggests that in larger-\nscale models, the degree of superposition\nfor specific knowledge decreases and it\ntends to be distinctly represented across\ndesignated parameter vectors.\n4.4\nEvolution of Parameter Specialization During Pretraining\nTo better investigate the development of Parameter Specialization in the model from the perspective\nof model training dynamics, we analyzed 10 checkpoints from the OLMo-2-1124-7B (OLMo et al.,\n2025) pretraining process by using our SpecWiki. The results are shown in Figure 4 below.\n7\nstep10000\nstep100000\nstep210000\nstep310000\nstep410000\nstep510000\nstep610000\nstep810000\nstep910000\nOLMo-2-1124-7B Training Checkpoints\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\nParameter Specialization Score(PSS)\nParameter Specialization Score(PSS)\nSpecWiki Accuracy\n0.0\n0.2\n0.4\n0.6\n0.8\nSpecWiki Accuracy\nParameter Specialization Score(PSS) in OLMo2's Training Checkpoints\nFigure 4: Development of Parameter Specializa-\ntion in OLMo-2-1124-7B over the pretraining\nprocess.\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09\n0.10\nParameter Specialization Score (PSS)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nSpecWiki Performance (MCQ)\nLow frequency\nMid frequency\nHigh frequency\nLLaMA2-7B-base\n0.09\n0.10\n0.11\n0.12\n0.13\n0.14\n0.15\n0.16\nParameter Specialization Score (PSS)\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nLow frequency\nMid frequency\nHigh frequency\nQwen2-7B-base\nFigure 5: Relationship between concept popu-\nlarity, model accuracy on MCQ, and Parameter\nSpecialization Score in LLaMA2-7B and Qwen2-\n7B models.\nModel\nAccuracyMCQ ↑\nAccuracyOEG ↑\nPSS ↑\nSemantic Entropy ↓\nLocal Intrinsic Dimension ↓\nLLaMA2-7B\n0.60 (±0.2)\n0.51 (±0.1)\n0.67 (±0.1)\n0.67 (±0.1)\n11.23 (±2.1)\nLLaMA2-7BF T −F V\n0.63 (±0.3)\n0.54 (±0.2)\n0.65 (±0.2)\n0.62 (±0.1)\n11.12 (±1.4)\nLLaMA2-7BF T −P V\n0.67 (±0.3)\n0.59 (±0.2)\n0.72 (±0.1)\n0.50 (±0.2)\n7.89 (±2.1)\nLLaMA2-7BF T −CV\n0.62 (±0.1)\n0.51 (±0.1)\n0.63 (±0.2)\n0.62 (±0.1)\n11.12 (±1.4)\nLLaMA2-7BF T −RV\n0.58 (±0.2)\n0.49 (±0.2)\n0.65 (±0.2)\n0.65 (±0.2)\n11.07(±2.7)\nQwen2-7B\n0.72 (±0.3)\n0.63 (±0.1)\n0.124 (±0.03)\n0.56 (±0.1)\n9.78 (±1.9)\nQwen2-7BF T −F V\n0.73 (±0.2)\n0.67 (±0.2)\n0.110 (±0.02)\n0.59 (±0.2)\n8.53 (±1.1)\nQwen2-7BF T −P V\n0.77 (±0.1)\n0.70 (±0.1)\n0.133 (±0.03)\n0.39 (±0.1)\n6.92 (±1.3)\nQwen2-7BF T −CV\n0.73 (±0.2)\n0.65 (±0.2)\n0.114 (±0.03)\n0.55 (±0.2)\n8.78 (±1.6)\nQwen2-7BF T −RV\n0.71 (±0.2)\n0.63 (±0.1)\n0.122 (±0.02)\n0.59 (±0.2)\n9.65 (±1.4)\nTable 2: The performance of both the original LLaMA2-7B-base and Qwen2-7B-base models,\nalong with their FT-FV, FT-PV, FT-CV and FT-RV variants, was assessed on a selection of 10 high-\nfrequency concepts from SpecWiki. Five metrics were used to evaluate their performance, including\ntheir general effectiveness, Parameter Specialization, and the degree of hallucination present in their\noutput.\nFrom the results, we observe that during the early training steps (step 10,000 to step 210,000), both\nthe PSS and the accuracy on SpeciWiki remain nearly unchanged and close to zero. In the subsequent\nphase (step 310,000 to step 510,000), although the model begins to show noticeable gains in accuracy\non SpeciWiki, the PSS are still under 0.1. However, it is during the later training steps (step 610,000\nto step 910,000) that parameter specialization begins to emerge, accompanied by a more substantial\nimprovement in accuracy. These findings suggest that parameter specialization does not occur in the\nearly stages of training, but rather emerges after a certain amount of data exposure. Furthermore, as\ntraining continues and the model sees more data, the degree of parameter specialization increases\naccordingly.\n4.5\nParameter Specialization in Relation to Concept Popularity\nIn this section, we analyze how the popularity of concepts themselves, which is roughly equivalent\nto their frequency in the pretraining data, will affect the level of parameter specialization for the\ncorresponding knowledge. We follow the classification method for concepts as outlined in §3.4,\ndividing them into high-frequency, mid-frequency, and low-frequency categories. The impact on their\nPSS scores is measured on two example models, LLaMA2-7B, and Qwen2.5-7B, which are shown in\nFigure 5.\nFrom the figure, it is clear that in both the LLaMA2-7B and Qwen2-7B models, as the popularity of\na concept decreases, the model’s accuracy on that specific knowledge declines, accompanied by a\nlower Parameter Specialization Score. This suggests that the degree of Parameter Specialization for a\nparticular knowledge in the model’s parameters is likely directly correlated with the frequency of that\nknowledge in the model’s pretraining dataset. The higher the frequency, the greater the Parameter\nSpecialization for that knowledge in the model.\n5\nValidation of Parameter Specialization Benefits for Knowledge Tasks\nIn this section, we conducted four sets of controlled training experiments, each involving continued\nfine-tuning on the Llama2-7B-base (Touvron et al., 2023a) and Qwen2-7B-base (Yang et al., 2024)\n8\nmodels with additional knowledge data. These experiments aim to validate the causal relationship\nbetween improved parameter specialization and enhanced model performance on knowledge tasks.\n5.1\nFinetuning Setup\nWe randomly selected 10 high-frequency concepts from the SpecWiki benchmark. For each concept,\nwe gathered relevant textual material from the top 10 most popular Google search results, including\nthe corresponding Wikipedia article, and compiled this into an additional finetuning training dataset.\nNext, we will validate whether the improvement in Parameter Specialization and the enhanced\nefficiency in the model’s use of knowledge truly exhibit a causal relationship through four distinct\nfinetuning experiments. The experimental setups are detailed below:\nFT-FV(Full Vectors) Perform full finetuning (FT) on all parameter vectors of the MLPs across all\nlayers in the model, while keeping the other parameters frozen.\nFT-PV(Partial Vectors) Perform partial finetuning on a subset of the parameter vectors in the MLPs\nwhile keeping the other parameters frozen. Specifically, for each model, we apply finetuning\n(FT) to the top k\n8 most highly activated parameter vectors**. For the selection of k, please\nrefer to the description in §4.1.\nFT-CV(Complementary Vectors) Perform finetuning only on the complementary set of parameter\nvectors, excluding the target vectors.\nFT-RV(Random Vectors) Perform finetuning on a subset of parameter vectors randomly selected\nfrom the MLP, ensuring the same quantity as in the FT-PV setting.\n5.2\nFinetuning Results\nIn addition to evaluating the model’s performance on SpecWiki’s Multi-choice Question and Open-\nended Generation tests, as well as the Parameter Specialization scores, we also report two other\nmetrics, Semantic Entropy (Kuhn et al., 2022) and Local Intrinsic Dimension (LID) (Yin et al.,\n2024), for measuring the extent of hallucination in the model’s output. These metrics help evaluate\nwhether training strategies that enhance Parameter Specialization—by aligning better with the\nmodel’s knowledge retrieval mechanisms through a data-encoded strategy—can effectively reduce\nthe unintended side effect of hallucination. For a detailed introduction to these two hallucination\nmeasurements, please refer to §B.3.\nThe final results are presented in Table 2. From the results, we can see that the FT-PV method, which\nfinetunes only a small subset of the highly activated knowledge parameters, not only further enhances\nthe model’s Parameter Specialization compared to the three other finetuning setups, but also greatly\nimproves the model’s utilization of specific knowledge. As a result, it achieves the best performance\non the benchmark Multi-Choice questions and Open-ended generation tasks. Additionally, by\nreducing the influence of irrelevant information in the model’s key parameter vectors, FT-PV helps to\nsignificantly reduce the level of hallucination in the generated text.\nAlthough FT-FV and FT-CV does improve the model’s performance on both the Multi-Choice\nquestions and Open-ended generation tasks to some extent, compared to FT-PV, it does not lead\nto a better increase in Parameter Specialization. Additionally, the degree of hallucination in the\ngenerated text is not effectively reduced. FT-RV, serving as a counterpart to FT-PV, demonstrates\nthat fine-tuning the same number of arbitrary value vectors in the model’s MLP can not result in a\ndesirable knowledge enhancement.\n6\nConclusion\nThis study reveals that enhanced parameter specialization—where related knowledge is encoded in\nfocused parameter vectors—correlates with superior performance in large language models. Analyz-\ning 20 open-source models, we observed stronger models increasingly consolidate similar knowledge\ninto fewer parameters, while weaker models distribute it diffusely. Controlled experiments confirmed\n**We experimented with k\n2 , k\n4 , k\n8 , and\nk\n16, and found that finetuning only k\n8 of the parameter vectors was\nsufficient to achieve excellent performance.\n9\nthat optimizing this specialization improves task performance and reduces hallucination. These\nfindings highlight the importance of aligning knowledge storage with models’ retrieval mechanisms\nfor efficiency and accuracy. Future work should explore dynamic knowledge updates and scalability,\nadvancing both interpretability and performance in LLM design.\n7\nLimitations and Future Work\nIn our work, we have only examined and validated knowledge parameter specialization within the\nMLP, and this was done by treating vectors in the MLP as units of analysis. However, at least this\nremains one of the knowledge storage methods that has been extensively validated so far (Geva et al.,\n2021a; Meng et al., 2022; Geva et al., 2023). In fact, knowledge may also reside within the attention\nmodule of transformer models (Geva et al., 2023).\nAdditionally, due to GPU limitations, all the models we tested are smaller than or equal to 14B\nparameters, so we were unable to validate our conclusions on larger models, such as those with 35B\nparameters or more.\nIn future work, we will progressively narrow the focus of our research to individual neurons in\nlanguage models, aiming to measure and validate more precise Parameter Specialization and Pa-\nrameter Superposition. In addition, we will extend this concept to the study of other related model\narchitectures, including Mixture of Experts (Fedus et al., 2022), which similarly enhances model\nperformance by specializing expert parameters, as well as Sparse Auto-Encoders (Huben et al., 2024),\nwhich help clarify the model’s representations by leveraging a larger parameter space and mitigating\nthe superposition of these features.\nAcknowledgment\nThis research is supported by the Ministry of Education, Singapore, under its Academic Research\nFund (AcRF) Tier 1 grant, and funded through the SUTD Assistant Professorship Scheme (SAP\n2025_001).\nReferences\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt,\nJ., Altman, S., Anadkat, S., et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\nAI, ., :, Young, A., Chen, B., Li, C., Huang, C., Zhang, G., Zhang, G., Wang, G., Li, H., Zhu, J.,\nChen, J., Chang, J., Yu, K., Liu, P., Liu, Q., Yue, S., Yang, S., Yang, S., Xie, W., Huang, W., Hu,\nX., Ren, X., Niu, X., Nie, P., Li, Y., Xu, Y., Liu, Y., Wang, Y., Cai, Y., Gu, Z., Liu, Z., and Dai, Z.\nYi: Open foundation models by 01.ai, 2025. URL https://arxiv.org/abs/2403.04652.\nAllen-Zhu, Z. and Li, Y. Physics of language models: Part 3.1, knowledge storage and extraction,\n2023.\nAlmazrouei, E., Alobeidli, H., Alshamsi, A., Cappelli, A., Cojocaru, R., Debbah, M., Étienne Goffinet,\nHesslow, D., Launay, J., Malartic, Q., Mazzotta, D., Noune, B., Pannier, B., and Penedo, G. The\nfalcon series of open language models, 2023. URL https://arxiv.org/abs/2311.16867.\nBai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B.,\nJi, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren,\nX., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A.,\nYang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang,\nY., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T. Qwen technical report, 2023. URL\nhttps://arxiv.org/abs/2309.16609.\nBiderman, S., Schoelkopf, H., Anthony, Q., Bradley, H., O’Brien, K., Hallahan, E., Khan, M. A.,\nPurohit, S., Prashanth, U. S., Raff, E., Skowron, A., Sutawika, L., and van der Wal, O. Pythia:\nA suite for analyzing large language models across training and scaling, 2023. URL https:\n//arxiv.org/abs/2304.01373.\n10\nChen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda,\nY., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G.,\nMishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter,\nC., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss,\nA., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S.,\nSaunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford,\nA., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D.,\nMcCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code,\n2021a. URL https://arxiv.org/abs/2107.03374.\nChen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y.,\nJoseph, N., Brockman, G., et al. Evaluating large language models trained on code. arXiv preprint\narXiv:2107.03374, 2021b.\nCobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton,\nJ., Nakano, R., Hesse, C., and Schulman, J. Training verifiers to solve math word problems, 2021.\nURL https://arxiv.org/abs/2110.14168.\nDar, G., Geva, M., Gupta, A., and Berant, J. Analyzing transformers in embedding space. In\nRogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers), pp. 16124–16170, Toronto,\nCanada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.\n893. URL https://aclanthology.org/2023.acl-long.893.\nDatabricks. Introducing mpt-7b: A new standard for open-source, commercially usable llms, May\n2023. URL https://www.databricks.com/blog/mpt-7b. Accessed: Jan 29, 2025.\nElazar, Y., Bhagia, A., Magnusson, I. H., Ravichander, A., Schwenk, D., Suhr, A., Walsh, E. P.,\nGroeneveld, D., Soldaini, L., Singh, S., Hajishirzi, H., Smith, N. A., and Dodge, J. What’s in\nmy big data? In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=RvfPnOkPV4.\nElhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., Hatfield-Dodds, Z., Lasenby,\nR., Drain, D., Chen, C., et al. Toy models of superposition. arXiv preprint arXiv:2209.10652,\n2022.\nFedus, W., Zoph, B., and Shazeer, N. Switch transformers: Scaling to trillion parameter models with\nsimple and efficient sparsity, 2022. URL https://arxiv.org/abs/2101.03961.\nGao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A.,\nNabeshima, N., Presser, S., and Leahy, C. The pile: An 800gb dataset of diverse text for language\nmodeling, 2020. URL https://arxiv.org/abs/2101.00027.\nGeva, M., Schuster, R., Berant, J., and Levy, O. Transformer feed-forward layers are key-value\nmemories. In Moens, M.-F., Huang, X., Specia, L., and Yih, S. W.-t. (eds.), Proceedings of\nthe 2021 Conference on Empirical Methods in Natural Language Processing, pp. 5484–5495,\nOnline and Punta Cana, Dominican Republic, November 2021a. Association for Computational\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.446. URL https://aclanthology.org/2021.\nemnlp-main.446.\nGeva, M., Schuster, R., Berant, J., and Levy, O. Transformer feed-forward layers are key-value\nmemories. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, pp. 5484–5495, 2021b.\nGeva, M., Caciularu, A., Dar, G., Roit, P., Sadde, S., Shlain, M., Tamir, B., and Goldberg, Y. LM-\ndebugger: An interactive tool for inspection and intervention in transformer-based language models.\nIn Che, W. and Shutova, E. (eds.), Proceedings of the 2022 Conference on Empirical Methods in\nNatural Language Processing: System Demonstrations, pp. 12–21, Abu Dhabi, UAE, December\n2022a. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-demos.2. URL\nhttps://aclanthology.org/2022.emnlp-demos.2.\n11\nGeva, M., Caciularu, A., Wang, K., and Goldberg, Y. Transformer feed-forward layers build\npredictions by promoting concepts in the vocabulary space. In Goldberg, Y., Kozareva, Z.,\nand Zhang, Y. (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural\nLanguage Processing, pp. 30–45, Abu Dhabi, United Arab Emirates, December 2022b. Asso-\nciation for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.3. URL https:\n//aclanthology.org/2022.emnlp-main.3.\nGeva, M., Bastings, J., Filippova, K., and Globerson, A. Dissecting recall of factual associations in\nauto-regressive language models. In Proceedings of the 2023 Conference on Empirical Methods in\nNatural Language Processing, pp. 12216–12235, 2023.\nGrattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur,\nA., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra,\nA., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson,\nA., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C.,\nMarra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C.,\nAllonsius, D., Song, D., Pintz, D., Livshits, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan,\nD., Garcia-Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan,\nE., Smith, E. M., Radenovic, F., Guzmán, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G. L.,\nThattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H.,\nTouvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee,\nJ., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J., Hong, J.,\nLee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca, J.,\nJohnstun, J., Saxe, J., Jia, J., Alwala, K. V., Prasad, K., Upasani, K., Plawiak, K., Li, K., Heafield,\nK., Stone, K., El-Arini, K., Iyer, K., Malik, K., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary,\nL., van der Maaten, L., Chen, L., Tan, L., Jenkins, L., Martin, L., Madaan, L., Malo, L., Blecher,\nL., Landzaat, L., de Oliveira, L., Muzzi, M., Pasupuleti, M., Singh, M., Paluri, M., Kardas, M.,\nTsimpoukelli, M., Oldham, M., Rita, M., Pavlova, M., Kambadur, M., Lewis, M., Si, M., Singh,\nM. K., Hassan, M., Goyal, N., Torabi, N., Bashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N.,\nDuchenne, O., Çelebi, O., Alrassy, P., Zhang, P., Li, P., Vasic, P., Weng, P., Bhargava, P., Dubal,\nP., Krishnan, P., Koura, P. S., Xu, P., He, Q., Dong, Q., Srinivasan, R., Ganapathy, R., Calderer,\nR., Cabral, R. S., Stojnic, R., Raileanu, R., Maheswari, R., Girdhar, R., Patel, R., Sauvestre, R.,\nPolidoro, R., Sumbaly, R., Taylor, R., Silva, R., Hou, R., Wang, R., Hosseini, S., Chennabasappa,\nS., Singh, S., Bell, S., Kim, S. S., Edunov, S., Nie, S., Narang, S., Raparthy, S., Shen, S., Wan, S.,\nBhosale, S., Zhang, S., Vandenhende, S., Batra, S., Whitman, S., Sootla, S., Collot, S., Gururangan,\nS., Borodinsky, S., Herman, T., Fowler, T., Sheasha, T., Georgiou, T., Scialom, T., Speckbacher, T.,\nMihaylov, T., Xiao, T., Karn, U., Goswami, V., Gupta, V., Ramanathan, V., Kerkez, V., Gonguet,\nV., Do, V., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong, W., Fu, W., Meers, W., Martinet,\nX., Wang, X., Wang, X., Tan, X. E., Xia, X., Xie, X., Jia, X., Wang, X., Goldschlag, Y., Gaur,\nY., Babaei, Y., Wen, Y., Song, Y., Zhang, Y., Li, Y., Mao, Y., Coudert, Z. D., Yan, Z., Chen, Z.,\nPapakipos, Z., Singh, A., Srivastava, A., Jain, A., Kelsey, A., Shajnfeld, A., Gangidi, A., Victoria,\nA., Goldstand, A., Menon, A., Sharma, A., Boesenberg, A., Baevski, A., Feinstein, A., Kallet, A.,\nSangani, A., Teo, A., Yunus, A., Lupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poulton, A.,\nRyan, A., Ramchandani, A., Dong, A., Franco, A., Goyal, A., Saraf, A., Chowdhury, A., Gabriel,\nA., Bharambe, A., Eisenman, A., Yazdan, A., James, B., Maurer, B., Leonhardi, B., Huang, B.,\nLoyd, B., Paola, B. D., Paranjape, B., Liu, B., Wu, B., Ni, B., Hancock, B., Wasti, B., Spence, B.,\nStojkovic, B., Gamido, B., Montalvo, B., Parker, C., Burton, C., Mejia, C., Liu, C., Wang, C., Kim,\nC., Zhou, C., Hu, C., Chu, C.-H., Cai, C., Tindal, C., Feichtenhofer, C., Gao, C., Civin, D., Beaty,\nD., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine, D., David, D., Parikh, D., Liskovich, D.,\nFoss, D., Wang, D., Le, D., Holland, D., Dowling, E., Jamil, E., Montgomery, E., Presani, E., Hahn,\nE., Wood, E., Le, E.-T., Brinkman, E., Arcaute, E., Dunbar, E., Smothers, E., Sun, F., Kreuk, F.,\nTian, F., Kokkinos, F., Ozgenel, F., Caggioni, F., Kanayet, F., Seide, F., Florez, G. M., Schwarz, G.,\nBadeer, G., Swee, G., Halpern, G., Herman, G., Sizov, G., Guangyi, Zhang, Lakshminarayanan, G.,\nInan, H., Shojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H., Rudolph, H., Suk, H., Aspegren,\nH., Goldman, H., Zhan, H., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I., Veliche, I.-E., Gat,\nI., Weissman, J., Geboski, J., Kohli, J., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J., Chan, J.,\nZhen, J., Reizenstein, J., Teboul, J., Zhong, J., Jin, J., Yang, J., Cummings, J., Carvill, J., Shepard,\nJ., McPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U, K. H., Saxena, K., Khandelwal, K.,\nZand, K., Matosich, K., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh, K., Huang, K.,\nChawla, K., Huang, K., Chen, L., Garg, L., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L.,\n12\nMoshkovich, L., Wehrstedt, L., Khabsa, M., Avalani, M., Bhatt, M., Mankus, M., Hasson, M.,\nLennie, M., Reso, M., Groshev, M., Naumov, M., Lathi, M., Keneally, M., Liu, M., Seltzer, M. L.,\nValko, M., Restrepo, M., Patel, M., Vyatskov, M., Samvelyan, M., Clark, M., Macey, M., Wang,\nM., Hermoso, M. J., Metanat, M., Rastegari, M., Bansal, M., Santhanam, N., Parks, N., White,\nN., Bawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta, N., Laptev, N. P., Dong, N., Cheng, N.,\nChernoguz, O., Hart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P., Saab, P., Balaji, P., Rittner,\nP., Bontrager, P., Roux, P., Dollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P., Liang, Q., Alao,\nR., Rodriguez, R., Ayub, R., Murthy, R., Nayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan,\nR., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta, S., Siby, S., Bondu, S. J., Datta, S., Chugh,\nS., Hunt, S., Dhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma, S., Yamamoto, S., Ramaswamy,\nS., Lindsay, S., Lindsay, S., Feng, S., Lin, S., Zha, S. C., Patil, S., Shankar, S., Zhang, S., Zhang,\nS., Wang, S., Agarwal, S., Sajuyigbe, S., Chintala, S., Max, S., Chen, S., Kehoe, S., Satterfield,\nS., Govindaprasad, S., Gupta, S., Deng, S., Cho, S., Virk, S., Subramanian, S., Choudhury, S.,\nGoldman, S., Remez, T., Glaser, T., Best, T., Koehler, T., Robinson, T., Li, T., Zhang, T., Matthews,\nT., Chou, T., Shaked, T., Vontimitta, V., Ajayi, V., Montanez, V., Mohan, V., Kumar, V. S., Mangla,\nV., Ionescu, V., Poenaru, V., Mihailescu, V. T., Ivanov, V., Li, W., Wang, W., Jiang, W., Bouaziz,\nW., Constable, W., Tang, X., Wu, X., Wang, X., Wu, X., Gao, X., Kleinman, Y., Chen, Y., Hu, Y.,\nJia, Y., Qi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu, Wang, Zhao, Y., Hao, Y., Qian,\nY., Li, Y., He, Y., Rait, Z., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao, Z., and Ma, Z. The\nllama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783.\nGroeneveld, D., Beltagy, I., Walsh, P., Bhagia, A., Kinney, R., Tafjord, O., Jha, A. H., Ivison, H.,\nMagnusson, I., Wang, Y., Arora, S., Atkinson, D., Authur, R., Chandu, K. R., Cohan, A., Dumas, J.,\nElazar, Y., Gu, Y., Hessel, J., Khot, T., Merrill, W., Morrison, J., Muennighoff, N., Naik, A., Nam,\nC., Peters, M. E., Pyatkin, V., Ravichander, A., Schwenk, D., Shah, S., Smith, W., Strubell, E.,\nSubramani, N., Wortsman, M., Dasigi, P., Lambert, N., Richardson, K., Zettlemoyer, L., Dodge, J.,\nLo, K., Soldaini, L., Smith, N. A., and Hajishirzi, H. Olmo: Accelerating the science of language\nmodels. arXiv preprint arXiv:2402.00838, 2024.\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring\nmassive multitask language understanding. In International Conference on Learning Representa-\ntions, 2021a. URL https://openreview.net/forum?id=d7KBjmI3GmQ.\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring\nmassive multitask language understanding. Proceedings of the International Conference on\nLearning Representations (ICLR), 2021b.\nHong, Y., Yu, L., Yang, H., Ravfogel, S., and Geva, M. Intrinsic evaluation of unlearning using\nparametric knowledge traces. arXiv preprint arXiv:2406.11614, 2024a.\nHong, Y., Zou, Y., Hu, L., Zeng, Z., Wang, D., and Yang, H. Dissecting fine-tuning unlearning in\nlarge language models. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Proceedings of the\n2024 Conference on Empirical Methods in Natural Language Processing, pp. 3933–3941, Miami,\nFlorida, USA, November 2024b. Association for Computational Linguistics. doi: 10.18653/v1/\n2024.emnlp-main.228. URL https://aclanthology.org/2024.emnlp-main.228/.\nHuben, R., Cunningham, H., Smith, L. R., Ewart, A., and Sharkey, L. Sparse autoencoders find highly\ninterpretable features in language models. In The Twelfth International Conference on Learning\nRepresentations, 2024. URL https://openreview.net/forum?id=F76bwRSLeK.\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de las Casas, D., Bressand,\nF., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L. R., Lachaux, M.-A., Stock, P., Scao,\nT. L., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. Mistral 7b, 2023. URL https:\n//arxiv.org/abs/2310.06825.\nKuhn, L., Gal, Y., and Farquhar, S. Semantic uncertainty: Linguistic invariances for uncertainty\nestimation in natural language generation. In The Eleventh International Conference on Learning\nRepresentations, 2022.\nMallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., and Hajishirzi, H. When not to trust language\nmodels: Investigating effectiveness of parametric and non-parametric memories. In Rogers, A.,\nBoyd-Graber, J., and Okazaki, N. (eds.), Proceedings of the 61st Annual Meeting of the Association\n13\nfor Computational Linguistics (Volume 1: Long Papers), pp. 9802–9822, Toronto, Canada, July\n2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.546. URL\nhttps://aclanthology.org/2023.acl-long.546/.\nMeng, K., Bau, D., Andonian, A. J., and Belinkov, Y. Locating and editing factual associations in\nGPT. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information\nProcessing Systems, 2022. URL https://openreview.net/forum?id=-h6WAS6eE4.\nOlah,\nC.\nDistributed\nrepresentations:\nComposition\n&\nsuperposition.\nhttps:\n//transformer-circuits.pub/2023/superposition-composition/index.html,\n2023. Published May 4th, 2023.\nOLMo, T., Walsh, P., Soldaini, L., Groeneveld, D., Lo, K., Arora, S., Bhagia, A., Gu, Y., Huang,\nS., Jordan, M., Lambert, N., Schwenk, D., Tafjord, O., Anderson, T., Atkinson, D., Brahman, F.,\nClark, C., Dasigi, P., Dziri, N., Guerquin, M., Ivison, H., Koh, P. W., Liu, J., Malik, S., Merrill,\nW., Miranda, L. J. V., Morrison, J., Murray, T., Nam, C., Pyatkin, V., Rangapur, A., Schmitz, M.,\nSkjonsberg, S., Wadden, D., Wilhelm, C., Wilson, M., Zettlemoyer, L., Farhadi, A., Smith, N. A.,\nand Hajishirzi, H. 2 olmo 2 furious, 2025. URL https://arxiv.org/abs/2501.00656.\nOpenAI, :, Hurst, A., Lerer, A., Goucher, A. P., Perelman, A., Ramesh, A., Clark, A., Ostrow, A.,\nWelihinda, A., Hayes, A., Radford, A., M ˛adry, A., Baker-Whitcomb, A., Beutel, A., Borzunov, A.,\nCarney, A., Chow, A., Kirillov, A., Nichol, A., Paino, A., Renzin, A., Passos, A. T., Kirillov, A.,\nChristakis, A., Conneau, A., Kamali, A., Jabri, A., Moyer, A., Tam, A., Crookes, A., Tootoochian,\nA., Tootoonchian, A., Kumar, A., Vallone, A., Karpathy, A., Braunstein, A., Cann, A., Codispoti,\nA., Galu, A., Kondrich, A., Tulloch, A., Mishchenko, A., Baek, A., Jiang, A., Pelisse, A., Woodford,\nA., Gosalia, A., Dhar, A., Pantuliano, A., Nayak, A., Oliver, A., Zoph, B., Ghorbani, B., Leimberger,\nB., Rossen, B., Sokolowsky, B., Wang, B., Zweig, B., Hoover, B., Samic, B., McGrew, B., Spero,\nB., Giertler, B., Cheng, B., Lightcap, B., Walkin, B., Quinn, B., Guarraci, B., Hsu, B., Kellogg, B.,\nEastman, B., Lugaresi, C., Wainwright, C., Bassin, C., Hudson, C., Chu, C., Nelson, C., Li, C.,\nShern, C. J., Conger, C., Barette, C., Voss, C., Ding, C., Lu, C., Zhang, C., Beaumont, C., Hallacy,\nC., Koch, C., Gibson, C., Kim, C., Choi, C., McLeavey, C., Hesse, C., Fischer, C., Winter, C.,\nCzarnecki, C., Jarvis, C., Wei, C., Koumouzelis, C., Sherburn, D., Kappler, D., Levin, D., Levy,\nD., Carr, D., Farhi, D., Mely, D., Robinson, D., Sasaki, D., Jin, D., Valladares, D., Tsipras, D., Li,\nD., Nguyen, D. P., Findlay, D., Oiwoh, E., Wong, E., Asdar, E., Proehl, E., Yang, E., Antonow,\nE., Kramer, E., Peterson, E., Sigler, E., Wallace, E., Brevdo, E., Mays, E., Khorasani, F., Such,\nF. P., Raso, F., Zhang, F., von Lohmann, F., Sulit, F., Goh, G., Oden, G., Salmon, G., Starace,\nG., Brockman, G., Salman, H., Bao, H., Hu, H., Wong, H., Wang, H., Schmidt, H., Whitney, H.,\nJun, H., Kirchner, H., de Oliveira Pinto, H. P., Ren, H., Chang, H., Chung, H. W., Kivlichan, I.,\nO’Connell, I., O’Connell, I., Osband, I., Silber, I., Sohl, I., Okuyucu, I., Lan, I., Kostrikov, I.,\nSutskever, I., Kanitscheider, I., Gulrajani, I., Coxon, J., Menick, J., Pachocki, J., Aung, J., Betker,\nJ., Crooks, J., Lennon, J., Kiros, J., Leike, J., Park, J., Kwon, J., Phang, J., Teplitz, J., Wei, J.,\nWolfe, J., Chen, J., Harris, J., Varavva, J., Lee, J. G., Shieh, J., Lin, J., Yu, J., Weng, J., Tang, J., Yu,\nJ., Jang, J., Candela, J. Q., Beutler, J., Landers, J., Parish, J., Heidecke, J., Schulman, J., Lachman,\nJ., McKay, J., Uesato, J., Ward, J., Kim, J. W., Huizinga, J., Sitkin, J., Kraaijeveld, J., Gross, J.,\nKaplan, J., Snyder, J., Achiam, J., Jiao, J., Lee, J., Zhuang, J., Harriman, J., Fricke, K., Hayashi,\nK., Singhal, K., Shi, K., Karthik, K., Wood, K., Rimbach, K., Hsu, K., Nguyen, K., Gu-Lemberg,\nK., Button, K., Liu, K., Howe, K., Muthukumar, K., Luther, K., Ahmad, L., Kai, L., Itow, L.,\nWorkman, L., Pathak, L., Chen, L., Jing, L., Guy, L., Fedus, L., Zhou, L., Mamitsuka, L., Weng, L.,\nMcCallum, L., Held, L., Ouyang, L., Feuvrier, L., Zhang, L., Kondraciuk, L., Kaiser, L., Hewitt, L.,\nMetz, L., Doshi, L., Aflak, M., Simens, M., Boyd, M., Thompson, M., Dukhan, M., Chen, M., Gray,\nM., Hudnall, M., Zhang, M., Aljubeh, M., Litwin, M., Zeng, M., Johnson, M., Shetty, M., Gupta,\nM., Shah, M., Yatbaz, M., Yang, M. J., Zhong, M., Glaese, M., Chen, M., Janner, M., Lampe, M.,\nPetrov, M., Wu, M., Wang, M., Fradin, M., Pokrass, M., Castro, M., de Castro, M. O. T., Pavlov,\nM., Brundage, M., Wang, M., Khan, M., Murati, M., Bavarian, M., Lin, M., Yesildal, M., Soto, N.,\nGimelshein, N., Cone, N., Staudacher, N., Summers, N., LaFontaine, N., Chowdhury, N., Ryder,\nN., Stathas, N., Turley, N., Tezak, N., Felix, N., Kudige, N., Keskar, N., Deutsch, N., Bundick,\nN., Puckett, N., Nachum, O., Okelola, O., Boiko, O., Murk, O., Jaffe, O., Watkins, O., Godement,\nO., Campbell-Moore, O., Chao, P., McMillan, P., Belov, P., Su, P., Bak, P., Bakkum, P., Deng, P.,\nDolan, P., Hoeschele, P., Welinder, P., Tillet, P., Pronin, P., Tillet, P., Dhariwal, P., Yuan, Q., Dias,\nR., Lim, R., Arora, R., Troll, R., Lin, R., Lopes, R. G., Puri, R., Miyara, R., Leike, R., Gaubert, R.,\n14\nZamani, R., Wang, R., Donnelly, R., Honsby, R., Smith, R., Sahai, R., Ramchandani, R., Huet,\nR., Carmichael, R., Zellers, R., Chen, R., Chen, R., Nigmatullin, R., Cheu, R., Jain, S., Altman,\nS., Schoenholz, S., Toizer, S., Miserendino, S., Agarwal, S., Culver, S., Ethersmith, S., Gray, S.,\nGrove, S., Metzger, S., Hermani, S., Jain, S., Zhao, S., Wu, S., Jomoto, S., Wu, S., Shuaiqi, Xia,\nPhene, S., Papay, S., Narayanan, S., Coffey, S., Lee, S., Hall, S., Balaji, S., Broda, T., Stramer, T.,\nXu, T., Gogineni, T., Christianson, T., Sanders, T., Patwardhan, T., Cunninghman, T., Degry, T.,\nDimson, T., Raoux, T., Shadwell, T., Zheng, T., Underwood, T., Markov, T., Sherbakov, T., Rubin,\nT., Stasi, T., Kaftan, T., Heywood, T., Peterson, T., Walters, T., Eloundou, T., Qi, V., Moeller, V.,\nMonaco, V., Kuo, V., Fomenko, V., Chang, W., Zheng, W., Zhou, W., Manassra, W., Sheu, W.,\nZaremba, W., Patil, Y., Qian, Y., Kim, Y., Cheng, Y., Zhang, Y., He, Y., Zhang, Y., Jin, Y., Dai, Y.,\nand Malkov, Y. Gpt-4o system card, 2024. URL https://arxiv.org/abs/2410.21276.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. Language models are\nunsupervised multitask learners. OpenAI blog, 2019.\nSukhbaatar, S., Weston, J., Fergus, R., et al. End-to-end memory networks. Advances in neural\ninformation processing systems, 28, 2015.\nTeam, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivière, M.,\nKale, M. S., Love, J., Tafti, P., Hussenot, L., Sessa, P. G., Chowdhery, A., Roberts, A., Barua,\nA., Botev, A., Castro-Ros, A., Slone, A., Héliou, A., Tacchetti, A., Bulanova, A., Paterson, A.,\nTsai, B., Shahriari, B., Lan, C. L., Choquette-Choo, C. A., Crepy, C., Cer, D., Ippolito, D., Reid,\nD., Buchatskaya, E., Ni, E., Noland, E., Yan, G., Tucker, G., Muraru, G.-C., Rozhdestvenskiy,\nG., Michalewski, H., Tenney, I., Grishchenko, I., Austin, J., Keeling, J., Labanowski, J., Lespiau,\nJ.-B., Stanway, J., Brennan, J., Chen, J., Ferret, J., Chiu, J., Mao-Jones, J., Lee, K., Yu, K.,\nMillican, K., Sjoesund, L. L., Lee, L., Dixon, L., Reid, M., Mikuła, M., Wirth, M., Sharman, M.,\nChinaev, N., Thain, N., Bachem, O., Chang, O., Wahltinez, O., Bailey, P., Michel, P., Yotov, P.,\nChaabouni, R., Comanescu, R., Jana, R., Anil, R., McIlroy, R., Liu, R., Mullins, R., Smith, S. L.,\nBorgeaud, S., Girgin, S., Douglas, S., Pandya, S., Shakeri, S., De, S., Klimenko, T., Hennigan,\nT., Feinberg, V., Stokowiec, W., hui Chen, Y., Ahmed, Z., Gong, Z., Warkentin, T., Peran, L.,\nGiang, M., Farabet, C., Vinyals, O., Dean, J., Kavukcuoglu, K., Hassabis, D., Ghahramani, Z.,\nEck, D., Barral, J., Pereira, F., Collins, E., Joulin, A., Fiedel, N., Senter, E., Andreev, A., and\nKenealy, K. Gemma: Open models based on gemini research and technology, 2024a. URL\nhttps://arxiv.org/abs/2403.08295.\nTeam, G., Riviere, M., Pathak, S., Sessa, P. G., Hardin, C., Bhupatiraju, S., Hussenot, L., Mesnard, T.,\nShahriari, B., Ramé, A., Ferret, J., Liu, P., Tafti, P., Friesen, A., Casbon, M., Ramos, S., Kumar, R.,\nLan, C. L., Jerome, S., Tsitsulin, A., Vieillard, N., Stanczyk, P., Girgin, S., Momchev, N., Hoffman,\nM., Thakoor, S., Grill, J.-B., Neyshabur, B., Bachem, O., Walton, A., Severyn, A., Parrish, A.,\nAhmad, A., Hutchison, A., Abdagic, A., Carl, A., Shen, A., Brock, A., Coenen, A., Laforge, A.,\nPaterson, A., Bastian, B., Piot, B., Wu, B., Royal, B., Chen, C., Kumar, C., Perry, C., Welty,\nC., Choquette-Choo, C. A., Sinopalnikov, D., Weinberger, D., Vijaykumar, D., Rogozi´nska, D.,\nHerbison, D., Bandy, E., Wang, E., Noland, E., Moreira, E., Senter, E., Eltyshev, E., Visin, F.,\nRasskin, G., Wei, G., Cameron, G., Martins, G., Hashemi, H., Klimczak-Pluci´nska, H., Batra,\nH., Dhand, H., Nardini, I., Mein, J., Zhou, J., Svensson, J., Stanway, J., Chan, J., Zhou, J. P.,\nCarrasqueira, J., Iljazi, J., Becker, J., Fernandez, J., van Amersfoort, J., Gordon, J., Lipschultz,\nJ., Newlan, J., yeong Ji, J., Mohamed, K., Badola, K., Black, K., Millican, K., McDonell, K.,\nNguyen, K., Sodhia, K., Greene, K., Sjoesund, L. L., Usui, L., Sifre, L., Heuermann, L., Lago, L.,\nMcNealus, L., Soares, L. B., Kilpatrick, L., Dixon, L., Martins, L., Reid, M., Singh, M., Iverson,\nM., Görner, M., Velloso, M., Wirth, M., Davidow, M., Miller, M., Rahtz, M., Watson, M., Risdal,\nM., Kazemi, M., Moynihan, M., Zhang, M., Kahng, M., Park, M., Rahman, M., Khatwani, M.,\nDao, N., Bardoliwalla, N., Devanathan, N., Dumai, N., Chauhan, N., Wahltinez, O., Botarda, P.,\nBarnes, P., Barham, P., Michel, P., Jin, P., Georgiev, P., Culliton, P., Kuppala, P., Comanescu, R.,\nMerhej, R., Jana, R., Rokni, R. A., Agarwal, R., Mullins, R., Saadat, S., Carthy, S. M., Cogan,\nS., Perrin, S., Arnold, S. M. R., Krause, S., Dai, S., Garg, S., Sheth, S., Ronstrom, S., Chan, S.,\nJordan, T., Yu, T., Eccles, T., Hennigan, T., Kocisky, T., Doshi, T., Jain, V., Yadav, V., Meshram, V.,\nDharmadhikari, V., Barkley, W., Wei, W., Ye, W., Han, W., Kwon, W., Xu, X., Shen, Z., Gong,\nZ., Wei, Z., Cotruta, V., Kirk, P., Rao, A., Giang, M., Peran, L., Warkentin, T., Collins, E., Barral,\nJ., Ghahramani, Z., Hadsell, R., Sculley, D., Banks, J., Dragan, A., Petrov, S., Vinyals, O., Dean,\nJ., Hassabis, D., Kavukcuoglu, K., Farabet, C., Buchatskaya, E., Borgeaud, S., Fiedel, N., Joulin,\n15\nA., Kenealy, K., Dadashi, R., and Andreev, A. Gemma 2: Improving open language models at a\npractical size, 2024b. URL https://arxiv.org/abs/2408.00118.\nTeam, Q. Qwen3: Think deeper, act faster. https://qwenlm.github.io/blog/qwen3/, 2025.\nAccessed: 2025-04-29.\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal,\nN., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G. Llama: Open and\nefficient foundation language models, 2023a. URL https://arxiv.org/abs/2302.13971.\nTouvron, H., Martin, L., Stone, K. R., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S.,\nBhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D.,\nFernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini,\nS., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I. M., Korenev, A., Koura,\nP. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov,\nT., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten,\nA., Silva, R., Smith, E. M., Subramanian, R., Tan, X., Tang, B., Taylor, R., Williams, A., Kuan,\nJ. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A.,\nStojnic, R., Edunov, S., and Scialom, T. Llama 2: Open foundation and fine-tuned chat models.\narXiv preprint arXiv:2307.09288, 2023b.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and\nPolosukhin, I. Attention is all you need. Advances in neural information processing systems, 30,\n2017.\nWang, B. and Komatsuzaki, A. Gpt-j-6b: A 6 billion parameter autoregressive language model, May\n2021. URL https://github.com/kingoflolz/mesh-transformer-jax. Accessed: Jan 29,\n2025.\nYang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li, C., Li, C., Liu, D., Huang, F., Dong,\nG., Wei, H., Lin, H., Tang, J., Wang, J., Yang, J., Tu, J., Zhang, J., Ma, J., Yang, J., Xu, J., Zhou,\nJ., Bai, J., He, J., Lin, J., Dang, K., Lu, K., Chen, K., Yang, K., Li, M., Xue, M., Ni, N., Zhang,\nP., Wang, P., Peng, R., Men, R., Gao, R., Lin, R., Wang, S., Bai, S., Tan, S., Zhu, T., Li, T., Liu,\nT., Ge, W., Deng, X., Zhou, X., Ren, X., Zhang, X., Wei, X., Ren, X., Liu, X., Fan, Y., Yao, Y.,\nZhang, Y., Wan, Y., Chu, Y., Liu, Y., Cui, Z., Zhang, Z., Guo, Z., and Fan, Z. Qwen2 technical\nreport, 2024. URL https://arxiv.org/abs/2407.10671.\nYin, F., Srinivasa, J., and Chang, K.-W.\nCharacterizing truthfulness in large language model\ngenerations with local intrinsic dimension. In ICML, 2024. URL https://openreview.net/\nforum?id=7DbIyQlfaO.\nYu, L., Cao, M., Cheung, J. C. K., and Dong, Y. Mechanisms of non-factual hallucinations in\nlanguage models. arXiv preprint arXiv:2403.18167, 2024.\nZhang, W., Aljunied, M., Gao, C., Chia, Y. K., and Bing, L. M3exam: A multilingual, multimodal,\nmultilevel benchmark for examining large language models. Advances in Neural Information\nProcessing Systems, 36:5484–5505, 2023.\n16\nA\nDetails of Dataset\nA.1\nDataset Construction Prompts\nBelow is our prompt for querying GPT-4o to generate the options for Multi-Choice questions of each\nconcept:\nPlease provide four answer options (A, B, C, D) for the following\nquestion, and indicate the correct answer.\nExample:\nQuestion:\n’When\nwas Costa Coffee founded?’\nOptions:\nA) 1971 B) 1985 C) 1992 D) 2000\nCorrect Answer:\nA) 1971\nNow, please answer the following question:\nQuestion:\nQuestion\nOptions:\nBelow is our prompt for querying the model to generate the answers for Multi-choice questions in\nthree-shot setting:\n**Question:** What is the capital city of France?\n**Options:** A.\nBerlin B. Madrid C. Paris D. Rome **Answer:** C\n**Question:** What is the largest planet in our solar system?\n**Options:** A. Earth B. Jupiter C. Mars D. Venus **Answer:** B\n**Question:** Which element has the chemical symbol \"O\"?\n**Options:**\nA. Oxygen B. Gold C. Silver D. Iron **Answer:** A\n**Question:** question **Options:** A. option a B. option b C. option\nc D. option d\nBelow is our prompt for collecting the coefficients in model when querying about concept-reated\nknowledge:\nQuestion:\nquestion Answer:\nanswer:\nA.2\nManual Verification\nHere, we describe the manual verification process used in constructing SpecWiki, including the\nvalidation of model-generated data:\nSpecifically, we analyze a subset of 524 (10%) questions from SpecWiki, by sampling 50% of the\nconcepts and randomly selecting 2 questions per concept. Then, we manually verify that the questions\nare about the given concept and that they are simple and reasonable. In addition, we review all the\ngenerated questions for 200 sampled concepts and verify they are not repetitive. We find that all\nanalyzed questions were about the given concept and that 522 (99%) of them are reasonable simple\nquestions. Moreover, we observe that questions are generally diverse, with only 1 out of 20 concepts\nhaving 2 (out of 10) similar questions. This shows that our data generation process produces valid\nand diverse instances for evaluation.\nA.3\nDataset Categories and Examples\nHere, we provided a more detailed distribution of the categories and the corresponding example data\nof SpecWiki dataset in Table 4 and Table 5, respectively.\nA.4\nValidation of Popularity-Frequency Correlation\nWe included a simple experiment to validate the strong correlation between the popularity of concepts\nand their frequency in the pretraining data. To be specific, we used The Pile(Gao et al., 2020),\nwhich currently serves as a significant portion of the pretraining dataset for most large language\nmodels(Touvron et al., 2023a; Groeneveld et al., 2024; Team et al., 2024a), as an example of a\npretraining corpus. We then counted the frequency with which each of the 525 concepts from\nSpecWiki appeared in all text segments of The Pile dataset via the Elasticsearch API(Elazar et al.,\n2024). Subsequently, we compared these frequencies with the popularity metrics for each concept and\n17\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nSpecWiki Performance (Open-ended Generations)\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\n0.16\nParameter Specialization Score(PSS)\nQwen1.5-7B\nQwen2-7B\nQwen2.5-7B\nLLaMA-7B\nLLaMA2-7B\nLLaMA3-8B\nOLMo-7B\nOLMo-2-7B\nGemma-7B\nGemma2-9B\nMistral-7B-v0.1\nMistral-7B-v0.2\nMistral-7B-v0.3\nYi-6B\nYi-1.5-6B\nFalcon-7B\nGPT-J-6B\nPythia-6.9B\nMpt-7B\nQwen3-8B\nPearson R: 0.88 (p=3.75e-07)\nSpearman : 0.84 (p=3.29e-06)\nSpecWiki Performance vs Parameter Specialization Score\nTrendline\n2021-06-09\n2022-05-30\n2023-05-20\n2024-05-09\n2025-04-29\nRelease Date\nFigure 6: Performance across 20 models on Parameter Specialization Scores on Open-ended Genera-\ntion Setting.\ncomputed the corresponding Spearman’s rank correlation coefficient. The result is 0.814, indicating a\nstrong correlation.\nAdditionally, Table 3 presents the top 3 most popular and the bottom 3 least popular concept examples\nin SpecWiki, along with their occurrence counts in The Pile dataset and their corresponding popularity\nscores.\nTop 3 High Popularity Example Concept\nFrequency\nPopularity\nWikipedia\n911708\n1414686\nBarack Obama\n984586\n1128538\nIndia\n3839241\n1024513\nBottom 3 Low Popularity Example Concept\nFrequency\nPopularity\nDark Souls (video game)\n49\n27\nCulture of Latin America\n251\n90\nArray (data structure)\n1164\n94\nTable 3: Top and bottom 3 concepts ranked by popularity and their corresponding frequencies.\nB\nDetails of Experiments\nB.1\nThe implementation of the models\nFor all models, the inference is performed in a text completion/generation mode, without the addition\nof any instruction tokens, to better assess the knowledge present in the model. For the Multi-Choice\nQuestions task, we use a three-shot setup for each model and search for the answer within the next\n30 tokens generated by the model. For the open-ended generation task, we prompt the model in a\nzero-shot setting to produce an answer no longer than 150 tokens.\nAll the experiments in this work were conducted on four 80GB NVIDIA A800 GPUs.\nB.2\nParameter Specialization Scores on OEG Setting\nIn Figure 6 we provided the performance across 20 models on Parameter Specialization Scores on\nOpen-ended Generation Setting.\n18\nHigh Frequency\nMedium Frequency\nLow Frequency\n(Number of Concepts: 181)\n(Number of Concepts: 191)\n(Number of Concepts: 153)\nCountry\n13.3%\nTechnology\n7.6%\nTechnology\n19.9%\nMathematics\n4.4%\nPerson\n21.9%\nBrand/Product\n6.3%\nCulture\n9.5%\nBrand/Product\n7.6%\nArt and Entertainment\n11.1%\nPolitics\n4.4%\nHistory\n10.6%\nMedical\n5.5%\nLocation\n8.6%\nPerson\n6.7%\nNatural Sciences\n10.5%\nLocation\n4.4%\nEntertainment\n8.6%\nCulture\n2.9%\nHistory\n8.6%\nMedical\n6.7%\nMedical/Biology\n7.7%\nCountry\n3.9%\nCompany/Organization\n7.3%\nOthers\n2.3%\nSports\n7.6%\nEntertainment\n6.7%\nCulture\n7.2%\nCompany/Organization\n3.3%\nOthers\n6.3%\nNatural Sciences\n2.1%\nTable 4: Ten most frequent concept categories of SpecWiki in high frequency, medium frequency,\nand low frequency levels.\nExample Concept\nFrequency Level\nCategory\nExample Multi-Choice QA\nExample Open-ended Generation\nThe Lord of the Rings\nHigh\nMonthly Views: 177540\nArt and Enter-\ntainment\nQuestion: \"Who is the main protagonist of ’The Lord of the Rings’?\",\nOptions: A: \"Frodo Baggins\", B: \"Gandalf the Grey\", C: \"Aragorn\", D:\n\"Legolas\".\nAnswer: A\nQuestion: \"Who is the author of ’The Lord of\nthe Rings’ trilogy?\"\nAnswer: \"J.R.R. Tolkien.\"\nDetritivore\nMedium\nMonthly Views: 11810\nBiology\nQuestion: \"What do detritivores consume to obtain nutrients?\",\nOptions: A: \"Fresh, living plants and animals\", B: \"Detritus, including\ndecomposing plant and animal parts and feces\", C: \"Sunlight and water\",\nD: \"Inorganic minerals and metals\".\nAnswer: B\nQuestion: \"What term is used for the consump-\ntion of dead wood by detritivores?\"\nAnswer: \"Sapro-xylophagy.\"\nMaluma\nLow\nMonthly Views: 2252\nPerson\nQuestion: \"In which city was Maluma born and raised?\"\nOptions: A: \"Bogotá\", B: \"Cali\", C: \"Medellín\", D: \"Cartagena\".\nAnswer: C\nQuestion: \"What is the name of Maluma’s 2023\nalbum?\"\nAnswer: \"Don Juan\"\nTable 5: Example data from the SpecWiki dataset.\nB.3\nHallucination Metric Descriptions\nIn this experiment, we additionally incorporate two metrics, Semantic Entropy (Kuhn et al., 2022)\nand Local Intrinsic Dimension (LID) (Yin et al., 2024), to assess hallucination. This helps evaluate\nwhether the finetuning methods that enhance Parameter Specialization also effectively mitigate the\nunintended side effect of hallucination in the model’s output.\nSemantic Entropy\nSemantic entropy is defined as a measure of uncertainty based on the distri-\nbution of semantically equivalent outputs. In this method, the outputs are grouped into clusters of\nsemantically similar responses, and the entropy is calculated among these groups. Formally, it is\nexpressed as:\nSemantic Entropy =\n1\n|C|\n|C|\nX\ni=1\nlog p(Ci|x)\nwhere Ci represents the summed likelihood of outputs in the i-th group, and |C| is the total number\nof such groups. The measure captures the uncertainty not in individual responses but within clusters\nof semantically similar outputs. This approach accounts for semantic equivalence among different\nresponses, providing a more robust evaluation of entropy in generative tasks.\nLocal Intrinsic Dimension\nThe Local Intrinsic Dimension (LID) method detects hallucinations\nin Large Language Models by measuring the discrepancy in the local intrinsic dimension of model\nactivations. This approach is grounded in the principle that LID represents the minimal number of\nactivations required to characterize a data point, with truthful outputs exhibiting lower LID values\ndue to their closer alignment with natural language structure, while hallucinated outputs tend to\nshow higher LID values due to mixing human prompt and model distributions. Technically, the\nmethod employs Maximum Likelihood Estimation (MLE) using a Poisson process to approximate\nthe count of neighbors surrounding sample points, computed through the formula m(Xi) = (1/(T −\n1) ∗P(log(QT /Qj)))−1, where T represents the number of nearest neighbors and Qj denotes the\nEuclidean distance to the j-th nearest neighbor. For more details about the Local Intrinsic Dimension\nmetric, please refer to the work (Yin et al., 2024).\n19\nNeurIPS Paper Checklist\n1. Claims\nQuestion: Do the main claims made in the abstract and introduction accurately reflect the\npaper’s contributions and scope?\nAnswer: [Yes]\nJustification: The abstract and the introduction in the paper clearly state the claims, contri-\nbutions and scope of our work.\nGuidelines:\n• The answer NA means that the abstract and introduction do not include the claims\nmade in the paper.\n• The abstract and/or introduction should clearly state the claims made, including the\ncontributions made in the paper and important assumptions and limitations. A No or\nNA answer to this question will not be perceived well by the reviewers.\n• The claims made should match theoretical and experimental results, and reflect how\nmuch the results can be expected to generalize to other settings.\n• It is fine to include aspirational goals as motivation as long as it is clear that these goals\nare not attained by the paper.\n2. Limitations\nQuestion: Does the paper discuss the limitations of the work performed by the authors?\nAnswer: [Yes]\nJustification: We discuss the limitations of the work in §7.\nGuidelines:\n• The answer NA means that the paper has no limitation while the answer No means that\nthe paper has limitations, but those are not discussed in the paper.\n• The authors are encouraged to create a separate \"Limitations\" section in their paper.\n• The paper should point out any strong assumptions and how robust the results are to\nviolations of these assumptions (e.g., independence assumptions, noiseless settings,\nmodel well-specification, asymptotic approximations only holding locally). The authors\nshould reflect on how these assumptions might be violated in practice and what the\nimplications would be.\n• The authors should reflect on the scope of the claims made, e.g., if the approach was\nonly tested on a few datasets or with a few runs. In general, empirical results often\ndepend on implicit assumptions, which should be articulated.\n• The authors should reflect on the factors that influence the performance of the approach.\nFor example, a facial recognition algorithm may perform poorly when image resolution\nis low or images are taken in low lighting. Or a speech-to-text system might not be\nused reliably to provide closed captions for online lectures because it fails to handle\ntechnical jargon.\n• The authors should discuss the computational efficiency of the proposed algorithms\nand how they scale with dataset size.\n• If applicable, the authors should discuss possible limitations of their approach to\naddress problems of privacy and fairness.\n• While the authors might fear that complete honesty about limitations might be used by\nreviewers as grounds for rejection, a worse outcome might be that reviewers discover\nlimitations that aren’t acknowledged in the paper. The authors should use their best\njudgment and recognize that individual actions in favor of transparency play an impor-\ntant role in developing norms that preserve the integrity of the community. Reviewers\nwill be specifically instructed to not penalize honesty concerning limitations.\n3. Theory assumptions and proofs\nQuestion: For each theoretical result, does the paper provide the full set of assumptions and\na complete (and correct) proof?\nAnswer: [NA]\n20\nJustification: Our work does not include any theoretical analysis or formal results.\nGuidelines:\n• The answer NA means that the paper does not include theoretical results.\n• All the theorems, formulas, and proofs in the paper should be numbered and cross-\nreferenced.\n• All assumptions should be clearly stated or referenced in the statement of any theorems.\n• The proofs can either appear in the main paper or the supplemental material, but if\nthey appear in the supplemental material, the authors are encouraged to provide a short\nproof sketch to provide intuition.\n• Inversely, any informal proof provided in the core of the paper should be complemented\nby formal proofs provided in appendix or supplemental material.\n• Theorems and Lemmas that the proof relies upon should be properly referenced.\n4. Experimental result reproducibility\nQuestion: Does the paper fully disclose all the information needed to reproduce the main ex-\nperimental results of the paper to the extent that it affects the main claims and/or conclusions\nof the paper (regardless of whether the code and data are provided or not)?\nAnswer: [Yes]\nJustification: We provide sufficient details in §3.4 and §4 to ensure that our datasets and\nexperiments are fully reproducible.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• If the paper includes experiments, a No answer to this question will not be perceived\nwell by the reviewers: Making the paper reproducible is important, regardless of\nwhether the code and data are provided or not.\n• If the contribution is a dataset and/or model, the authors should describe the steps taken\nto make their results reproducible or verifiable.\n• Depending on the contribution, reproducibility can be accomplished in various ways.\nFor example, if the contribution is a novel architecture, describing the architecture fully\nmight suffice, or if the contribution is a specific model and empirical evaluation, it may\nbe necessary to either make it possible for others to replicate the model with the same\ndataset, or provide access to the model. In general. releasing code and data is often\none good way to accomplish this, but reproducibility can also be provided via detailed\ninstructions for how to replicate the results, access to a hosted model (e.g., in the case\nof a large language model), releasing of a model checkpoint, or other means that are\nappropriate to the research performed.\n• While NeurIPS does not require releasing code, the conference does require all submis-\nsions to provide some reasonable avenue for reproducibility, which may depend on the\nnature of the contribution. For example\n(a) If the contribution is primarily a new algorithm, the paper should make it clear how\nto reproduce that algorithm.\n(b) If the contribution is primarily a new model architecture, the paper should describe\nthe architecture clearly and fully.\n(c) If the contribution is a new model (e.g., a large language model), then there should\neither be a way to access this model for reproducing the results or a way to reproduce\nthe model (e.g., with an open-source dataset or instructions for how to construct\nthe dataset).\n(d) We recognize that reproducibility may be tricky in some cases, in which case\nauthors are welcome to describe the particular way they provide for reproducibility.\nIn the case of closed-source models, it may be that access to the model is limited in\nsome way (e.g., to registered users), but it should be possible for other researchers\nto have some path to reproducing or verifying the results.\n5. Open access to data and code\nQuestion: Does the paper provide open access to the data and code, with sufficient instruc-\ntions to faithfully reproduce the main experimental results, as described in supplemental\nmaterial?\n21\nAnswer: [Yes]\nJustification: We release the code and datasets in the supplementary materials submitted\nalongside the main paper.\nGuidelines:\n• The answer NA means that paper does not include experiments requiring code.\n• Please see the NeurIPS code and data submission guidelines (https://nips.cc/\npublic/guides/CodeSubmissionPolicy) for more details.\n• While we encourage the release of code and data, we understand that this might not be\npossible, so “No” is an acceptable answer. Papers cannot be rejected simply for not\nincluding code, unless this is central to the contribution (e.g., for a new open-source\nbenchmark).\n• The instructions should contain the exact command and environment needed to run to\nreproduce the results. See the NeurIPS code and data submission guidelines (https:\n//nips.cc/public/guides/CodeSubmissionPolicy) for more details.\n• The authors should provide instructions on data access and preparation, including how\nto access the raw data, preprocessed data, intermediate data, and generated data, etc.\n• The authors should provide scripts to reproduce all experimental results for the new\nproposed method and baselines. If only a subset of experiments are reproducible, they\nshould state which ones are omitted from the script and why.\n• At submission time, to preserve anonymity, the authors should release anonymized\nversions (if applicable).\n• Providing as much information as possible in supplemental material (appended to the\npaper) is recommended, but including URLs to data and code is permitted.\n6. Experimental setting/details\nQuestion: Does the paper specify all the training and test details (e.g., data splits, hyper-\nparameters, how they were chosen, type of optimizer, etc.) necessary to understand the\nresults?\nAnswer: [Yes]\nJustification: We provide detailed specifications of all training and evaluation settings in\n§4.1 and §B.1.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The experimental setting should be presented in the core of the paper to a level of detail\nthat is necessary to appreciate the results and make sense of them.\n• The full details can be provided either with the code, in appendix, or as supplemental\nmaterial.\n7. Experiment statistical significance\nQuestion: Does the paper report error bars suitably and correctly defined or other appropriate\ninformation about the statistical significance of the experiments?\nAnswer: [Yes]\nJustification: We include error analysis to support the main experiments in our paper,\nspecifically in §4.3 and §5.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The authors should answer \"Yes\" if the results are accompanied by error bars, confi-\ndence intervals, or statistical significance tests, at least for the experiments that support\nthe main claims of the paper.\n• The factors of variability that the error bars are capturing should be clearly stated (for\nexample, train/test split, initialization, random drawing of some parameter, or overall\nrun with given experimental conditions).\n• The method for calculating the error bars should be explained (closed form formula,\ncall to a library function, bootstrap, etc.)\n22\n• The assumptions made should be given (e.g., Normally distributed errors).\n• It should be clear whether the error bar is the standard deviation or the standard error\nof the mean.\n• It is OK to report 1-sigma error bars, but one should state it. The authors should\npreferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis\nof Normality of errors is not verified.\n• For asymmetric distributions, the authors should be careful not to show in tables or\nfigures symmetric error bars that would yield results that are out of range (e.g. negative\nerror rates).\n• If error bars are reported in tables or plots, The authors should explain in the text how\nthey were calculated and reference the corresponding figures or tables in the text.\n8. Experiments compute resources\nQuestion: For each experiment, does the paper provide sufficient information on the com-\nputer resources (type of compute workers, memory, time of execution) needed to reproduce\nthe experiments?\nAnswer: [Yes]\nJustification: We provide sufficient details on the replication of the experiments in §B.1 in\nAppendix.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The paper should indicate the type of compute workers CPU or GPU, internal cluster,\nor cloud provider, including relevant memory and storage.\n• The paper should provide the amount of compute required for each of the individual\nexperimental runs as well as estimate the total compute.\n• The paper should disclose whether the full research project required more compute\nthan the experiments reported in the paper (e.g., preliminary or failed experiments that\ndidn’t make it into the paper).\n9. Code of ethics\nQuestion: Does the research conducted in the paper conform, in every respect, with the\nNeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?\nAnswer: [Yes]\nJustification: We affirm that our research fully complies with the NeurIPS Code of Ethics.\nGuidelines:\n• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.\n• If the authors answer No, they should explain the special circumstances that require a\ndeviation from the Code of Ethics.\n• The authors should make sure to preserve anonymity (e.g., if there is a special consid-\neration due to laws or regulations in their jurisdiction).\n10. Broader impacts\nQuestion: Does the paper discuss both potential positive societal impacts and negative\nsocietal impacts of the work performed?\nAnswer: [NA]\nJustification: Our research focuses on the interpretability of internal model parameters and\ndoes not have direct societal impact.\nGuidelines:\n• The answer NA means that there is no societal impact of the work performed.\n• If the authors answer NA or No, they should explain why their work has no societal\nimpact or why the paper does not address societal impact.\n• Examples of negative societal impacts include potential malicious or unintended uses\n(e.g., disinformation, generating fake profiles, surveillance), fairness considerations\n(e.g., deployment of technologies that could make decisions that unfairly impact specific\ngroups), privacy considerations, and security considerations.\n23\n• The conference expects that many papers will be foundational research and not tied\nto particular applications, let alone deployments. However, if there is a direct path to\nany negative applications, the authors should point it out. For example, it is legitimate\nto point out that an improvement in the quality of generative models could be used to\ngenerate deepfakes for disinformation. On the other hand, it is not needed to point out\nthat a generic algorithm for optimizing neural networks could enable people to train\nmodels that generate Deepfakes faster.\n• The authors should consider possible harms that could arise when the technology is\nbeing used as intended and functioning correctly, harms that could arise when the\ntechnology is being used as intended but gives incorrect results, and harms following\nfrom (intentional or unintentional) misuse of the technology.\n• If there are negative societal impacts, the authors could also discuss possible mitigation\nstrategies (e.g., gated release of models, providing defenses in addition to attacks,\nmechanisms for monitoring misuse, mechanisms to monitor how a system learns from\nfeedback over time, improving the efficiency and accessibility of ML).\n11. Safeguards\nQuestion: Does the paper describe safeguards that have been put in place for responsible\nrelease of data or models that have a high risk for misuse (e.g., pretrained language models,\nimage generators, or scraped datasets)?\nAnswer: [NA]\nJustification: The paper poses no such risks.\nGuidelines:\n• The answer NA means that the paper poses no such risks.\n• Released models that have a high risk for misuse or dual-use should be released with\nnecessary safeguards to allow for controlled use of the model, for example by requiring\nthat users adhere to usage guidelines or restrictions to access the model or implementing\nsafety filters.\n• Datasets that have been scraped from the Internet could pose safety risks. The authors\nshould describe how they avoided releasing unsafe images.\n• We recognize that providing effective safeguards is challenging, and many papers do\nnot require this, but we encourage authors to take this into account and make a best\nfaith effort.\n12. Licenses for existing assets\nQuestion: Are the creators or original owners of assets (e.g., code, data, models), used in\nthe paper, properly credited and are the license and terms of use explicitly mentioned and\nproperly respected?\nAnswer: [Yes]\nJustification: For the usage of other assets, we clearly cite their original sources and indicate\nthe corresponding versions and licenses.\nGuidelines:\n• The answer NA means that the paper does not use existing assets.\n• The authors should cite the original paper that produced the code package or dataset.\n• The authors should state which version of the asset is used and, if possible, include a\nURL.\n• The name of the license (e.g., CC-BY 4.0) should be included for each asset.\n• For scraped data from a particular source (e.g., website), the copyright and terms of\nservice of that source should be provided.\n• If assets are released, the license, copyright information, and terms of use in the\npackage should be provided. For popular datasets, paperswithcode.com/datasets\nhas curated licenses for some datasets. Their licensing guide can help determine the\nlicense of a dataset.\n• For existing datasets that are re-packaged, both the original license and the license of\nthe derived asset (if it has changed) should be provided.\n24\n• If this information is not available online, the authors are encouraged to reach out to\nthe asset’s creators.\n13. New assets\nQuestion: Are new assets introduced in the paper well documented and is the documentation\nprovided alongside the assets?\nAnswer: [Yes]\nJustification: We include the complete dataset in the supplementary materials, and provide\ndetailed information about its construction in §3.4.\nGuidelines:\n• The answer NA means that the paper does not release new assets.\n• Researchers should communicate the details of the dataset/code/model as part of their\nsubmissions via structured templates. This includes details about training, license,\nlimitations, etc.\n• The paper should discuss whether and how consent was obtained from people whose\nasset is used.\n• At submission time, remember to anonymize your assets (if applicable). You can either\ncreate an anonymized URL or include an anonymized zip file.\n14. Crowdsourcing and research with human subjects\nQuestion: For crowdsourcing experiments and research with human subjects, does the paper\ninclude the full text of instructions given to participants and screenshots, if applicable, as\nwell as details about compensation (if any)?\nAnswer: [NA]\nJustification: The paper does not involve crowdsourcing nor research with human subjects.\nGuidelines:\n• The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n• Including this information in the supplemental material is fine, but if the main contribu-\ntion of the paper involves human subjects, then as much detail as possible should be\nincluded in the main paper.\n• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,\nor other labor should be paid at least the minimum wage in the country of the data\ncollector.\n15. Institutional review board (IRB) approvals or equivalent for research with human\nsubjects\nQuestion: Does the paper describe potential risks incurred by study participants, whether\nsuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)\napprovals (or an equivalent approval/review based on the requirements of your country or\ninstitution) were obtained?\nAnswer: [NA]\nJustification: The paper does not involve crowdsourcing nor research with human subjects.\nGuidelines:\n• The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n• Depending on the country in which research is conducted, IRB approval (or equivalent)\nmay be required for any human subjects research. If you obtained IRB approval, you\nshould clearly state this in the paper.\n• We recognize that the procedures for this may vary significantly between institutions\nand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the\nguidelines for their institution.\n• For initial submissions, do not include any information that would break anonymity (if\napplicable), such as the institution conducting the review.\n25\n16. Declaration of LLM usage\nQuestion: Does the paper describe the usage of LLMs if it is an important, original, or\nnon-standard component of the core methods in this research? Note that if the LLM is used\nonly for writing, editing, or formatting purposes and does not impact the core methodology,\nscientific rigorousness, or originality of the research, declaration is not required.\nAnswer: [Yes]\nJustification: We only used GPT-4o to assist in generating evaluation questions for the\ndataset, and included manually verified results in §A.2 of Appendix.\nGuidelines:\n• The answer NA means that the core method development in this research does not\ninvolve LLMs as any important, original, or non-standard components.\n• Please refer to our LLM policy (https://neurips.cc/Conferences/2025/LLM)\nfor what should or should not be described.\n26\n",
  "pages": [
    {
      "page_number": 1,
      "text": "The Rise of Parameter Specialization for Knowledge\nStorage in Large Language Models\nYihuai Hong1,2∗\nYiran Zhao3\nWei Tang1\nYang Deng4\nYu Rong1\nWenxuan Zhang5†\n1Alibaba DAMO Academy 2New York University\n3National University of Singapore\n4Singapore Management University 5Singapore University of Technology and Design\nyihuaihong@nyu.edu, wxzhang@sutd.edu.sg\nAbstract\nOver time, a growing wave of large language models from various series has been\nintroduced to the community. Researchers are striving to maximize the performance\nof language models with constrained parameter sizes. However, from a microscopic\nperspective, there has been limited research on how to better store knowledge in\nmodel parameters, particularly within MLPs, to enable more effective utilization of\nthis knowledge by the model. In this work, we analyze twenty publicly available\nopen-source large language models to investigate the relationship between their\nstrong performance and the way knowledge is stored in their corresponding MLP\nparameters. Our findings reveal that as language models become more advanced\nand demonstrate stronger knowledge capabilities, their parameters exhibit increased\nspecialization. Specifically, parameters in the MLPs tend to be more focused\non encoding similar types of knowledge. We experimentally validate that this\nspecialized distribution of knowledge contributes to improving the efficiency of\nknowledge utilization in these models. Furthermore, by conducting causal training\nexperiments, we confirm that this specialized knowledge distribution plays a critical\nrole in improving the model’s efficiency in leveraging stored knowledge.\n1\nIntroduction\nAn increasing number of powerful large language models (LLMs) have emerged in recent years\n(Touvron et al., 2023a; Achiam et al., 2023; Groeneveld et al., 2024; Bai et al., 2023; Team, 2025),\noften demonstrating remarkable capabilities across various benchmarks and tests (Hendrycks et al.,\n2021a; Chen et al., 2021a; Cobbe et al., 2021). Thanks to the large parameter space, they have shown\nan exceptional ability to encode vast amounts of knowledge within their parameters, enabling superior\nperformance on knowledge-intensive tasks (Hendrycks et al., 2021a; Zhang et al., 2023).\nTo understand the internal mechanism of knowledge storage, many studies have been conducted. For\nexample, Geva et al. (2021b) interprets the MLP layers of the transformer architecture (Vaswani et al.,\n2017) as key-value memories, where the factual knowledge encoded in the weights is retrieved and\ntransmitted to the output layer during inference (Geva et al., 2023; Meng et al., 2022; Yu et al., 2024).\nFurthermore, researchers have observed that, in the final layer of the MLP, each vector in that value\nmatrix can act as a fundamental unit of knowledge storage (Geva et al., 2022a,b). However, there\nhas been limited research on how to better store and compress knowledge within constrained model\nparameters to enable more effective utilization of that knowledge by the model.\n*Work done during an internship at Alibaba Group, before joining New York University.\n†Corresponding author.\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\n"
    },
    {
      "page_number": 2,
      "text": "In this work, we investigate the relationship between language models’ knowledge storage patterns\nand their performance. To identify parameters associated with specific knowledge concepts, we\nanalyze consistently activated parameters in MLP layers when the model processes questions related\nto the particular knowledge concept. Building on the key-value interpretation of the MLP by Geva\net al. (2021b), which treats the up-projection matrix as the key and the down-projection matrix as\nthe value (i.e., stored knowledge), we extract the intermediate representations between these two\nmatrices and treat their absolute value as the activation of corresponding parameters. To support\nempirical analysis, we construct a new encyclopedic knowledge benchmark based on Wikipedia,\ncovering knowledge concepts with varying frequencies. We then apply the knowledge parameter\nidentification method to 20 open-source LLMs across a wide range of model families, enabling us to\nexplore correlations between knowledge storage patterns and overall model performance.\nHarry Potter\nSuper Mario \nBarack Obama\nWhen querying about Super Mario: \nEvolution of Knowledge Distribution in Parameter Vectors during Model Iteration\nLLaMA MLP\nLLaMA2 MLP\nLLaMA3 MLP\nFigure 1: Evolution of knowledge distribution in model pa-\nrameters during three iterations of LLaMA models. Each\nparameter vector corresponds to a column in the value matrix\nof the MLP module, as indicated by the dashed rectangles.\nOur extensive empirical analysis re-\nveals that stronger models exhibit\nhigher parameter specialization for\ndistinct knowledge, whereas weaker\nmodels distribute knowledge more\ndiffusely across parameters. Conse-\nquently, significantly more parameters\nare required to store individual knowl-\nedge in weaker models. As illustrated\nin Figure 1, advancing model capabil-\nity correlated with improved parame-\nter specialization for encoding knowl-\nedge: fewer parameters are allocated\nper knowledge concept, while each pa-\nrameter governs a narrower subset of\nconcepts.\nMotivated by this observation, we fur-\nther conduct four sets of controlled\nexperiments, each involving continued training on the Llama2-7B (Touvron et al., 2023a) and\nQwen2-7B (Yang et al., 2024) models with new knowledge respectively, to validate the strong causal\nrelationship between improved parameter specialization and enhanced performance of the models\non knowledge tasks. Overall, the experiments reveal that encoding similar knowledge into the same\nparameter vectors better aligns with the model’s internal knowledge retrieval mechanism. This\napproach helps the model utilize knowledge more efficiently, improves knowledge compression, and\nreduces hallucination generation.\nOur contributions can be summarized as follows:\n• To the best of our knowledge, this is the first attempt to quantify and compare the degree of\nparameter specialization for knowledge storage across different LLMs.\n• We investigate the relationship between parameter specialization and model performance in LLMs,\nconstructing a dedicated probing dataset for an in-depth analysis on 20 open-source LLMs. Our\nfindings indicate that more capable LLMs exhibit greater parameter specialization.\n• Through controlled training experiments, we provide empirical evidence of a causal link between\nincreased parameter specialization and improved performance on knowledge-intensive tasks.\n2\nRelated Work\nKnowledge Storage in LLMs\nStudying how knowledge is stored and utilized in LLMs has been\nan important area in the research of LLM interpretability (Meng et al., 2022; Geva et al., 2021b;\nSukhbaatar et al., 2015; Geva et al., 2023). Recent studies have shown that MLPs are the primary and\ncrucial components for storing factual knowledge and associations in transformer-based language\nmodels (Geva et al., 2022b; Dar et al., 2023). They can be conceptualized as key-value memories\n(Geva et al., 2021b), where the factual knowledge encoded in the MLP weights is recalled and\ntransmitted to the output layer during inference (Geva et al., 2023; Meng et al., 2022; Yu et al., 2024).\nAdditionally, researchers have found that in the final layer of the MLP, each vector in the value matrix\ncan serve as a fundamental unit for storing knowledge (Geva et al., 2022a,b). They have also verified\n2\n"
    },
    {
      "page_number": 3,
      "text": "that by directly manipulating or disrupting these parameter vectors, specific knowledge can be edited\nor unlearned (Hong et al., 2024a,b; Meng et al., 2022), leading to changes in the model’s responses.\nKnowledge Superposition in LLM\nElhage et al. (2022); Olah (2023) propose the concept of\nKnowledge Superposition. It refers to an inevitable phenomenon in neural network models, especially\nlarge language models, during training and data memorization: since the number of data features\ngreatly exceeds the number of parameters in the model, each parameter does not have a simple\none-to-one mapping with the data features or knowledge. Neurons are often involved with multiple\ndata features simultaneously. In our work, we treat each vector in the last layer of MLP as a basic\nunit for storing knowledge and investigate the superposition of knowledge within these vectors.\n3\nParameter Specialization Analysis for Knowledge Storage\n3.1\nPreliminary\nIn transformer-based language models, the MLP is a crucial component for storing the model’s\nfactual knowledge, and its sub-layers can be viewed as key-value memories (Geva et al., 2021b). To\nbe specific, the first layer* of MLP sublayers can be viewed as a matrix WK formed by key vectors\n{k1, k2, . . . , kn}, used to capture a set of patterns in the input sequence, and ultimately outputting\nthe coefficient scores. The second layer can be viewed as a matrix WV formed by value vectors\n{v1, v2, . . . , vn}, with each value vector containing the corresponding factual knowledge.\nFormally, the output of the MLP in the transformer’s ℓ-th layer, given an input hidden state xℓ, can be\ndefined as:\nMℓ= f\n\u0000W ℓ\nK · γ(xℓ+ Aℓ)\n\u0001\nW ℓ\nV = mℓW ℓ\nV ,\n(1)\nwhere W ℓ\nK, W ℓ\nV ∈Rn×d. The function f and γ represent a non-linearity† and layer normalization,\nrespectively. In the transformer’s ℓ-th layer, mℓ∈Rn denotes the coefficient scores, and Aℓ\nrepresents the output of the attention component. The hidden state dimension is d, while the\nintermediate MLP has a dimension of n. Then, by denoting vℓ\nj as the j-th column (which will be\ncalled the value vector or parameter vector in the following sections) of W ℓ\nV and mℓ\nj as the j-th\nelement in the coefficients produced by the first layer of the MLP, we can view MLP’s output Mℓas\na linear combination of the value vectors in W ℓ\nV , with their corresponding coefficients mℓ:\nMℓ=\nXn\nj=1 mℓ\njvℓ\nj,\n(2)\nFinally, the hidden states at the ℓ-th layer of the language model can be defined as:\nXℓ+1 = Xℓ+ Mℓ+ Aℓ,\n(3)\nwhere Xℓ, Mℓand Aℓrepresent the hidden states, MLP’s output, and the attention component’s\noutput in the transformer’s ℓ-th layer, respectively. In this work, we focus on studying the impact of\nthe MLP on the knowledge output of the hidden states.\n3.2\nKnowledge Vectors Masking Procedure\nReferring to Eq. (2), if we aim to ablate the impact of the knowledge contained in the vectors for\na particular subset Sℓof indices in ℓ-th layer, we can directly set the corresponding mℓ\nj values for\nj ∈Sℓto zero. Hence, we have:\nMℓ\nmasked =\nXn\nj=1\nj /∈Sℓmℓ\njvℓ\nj +\nXn\nj=1\nj∈Sℓ0 · vℓ\nj =\nXn\nj=1\nj /∈Sℓmℓ\njvℓ\nj,\n(4)\n*In most decoder-only models, such as GPT-2 (Radford et al., 2019) and GPT-J (Chen et al., 2021b), the MLP\ncomponent consists of two layers, whereas in LLaMA (Touvron et al., 2023b), it comprises three layers. However,\nwe can still regard LLaMA’s first two layers collectively as the key matrices, with their output representing the\ncoefficient scores.\n†For brevity, the bias term is omitted.\n3\n"
    },
    {
      "page_number": 4,
      "text": "Therefore, given a concept, when we aim to identify which specific value vectors in the model’s\nMLPs are most closely related to the knowledge contained in that concept—while avoiding the\nmasking of vectors associated with the model’s general capabilities‡ (Meng et al., 2022; Geva et al.,\n2023), i.e., determining the appropriate subset Sℓat each layer of the model for this concept—we\nwill run t concept-related questions and t∗irrelevant questions on the selected model. Then we will\ncompute the corresponding coefficients mℓand m∗ℓ, which are the averages of the coefficients for\nthe concept-related questions and irrelevant questions, respectively, at each layer of the model. For\ndetails on the generation of concept-related and irrelevant questions, as well as the selection of t and\nt∗, please refer to §3.4. After obtaining mℓand m∗ℓat each layer, we perform the computation using\nthe following formula:\nSℓ=\n\b\f\fmℓ\nj −m∗ℓ\nj\n\f\f \f\f 1 ≤j ≤n, mℓ\nj ∈mℓ, m∗ℓ\nj ∈m∗ℓ\t\n(5)\nNext, we will sort Sℓin descending order and select the value vectors corresponding to the indices of\nthe top k elements, which will be used as the subset Sℓfor the masking operation. This allows us to\nobserve and analyze the impact of masking these vectors on the model’s knowledge output for certain\nconcepts.\n3.3\nThe Definition of Parameter Specialization\nAfter obtaining the subset of value vectors Sℓthat exhibit specificity to a given concept at each layer\nof the model, as described in §3.2, we apply the masking operation to these value vectors, as shown\nin Eq. (4). We then analyze its impact on the model’s final outputs for the t concept-related questions\nand t∗irrelevant questions. By comparing the model’s responses after masking with the ground truth\nanswers, we compute the accuracy on concept-related questions, referred to as the Concept Specific\nScore after surgery, and the accuracy on irrelevant questions, referred to as the General Score after\nsurgery. To quantify the degrees of specialization of the model’s value vectors with respect to the\nconcept-related knowledge, we define the Parameter Specialization Score (PSS):\nPSS\n△= |General Score after surgery −Concept Specific Score after surgery|\nGeneral Score before surgery\n,\n(6)\nwhich is obtained by taking the absolute difference between the General Score and the Concept\nSpecific Score after surgery, and then dividing by the model’s accuracy on the entire dataset before\nsurgery. A higher PSS indicates that the parameter vectors in the model’s MLP layers exhibit a higher\ndegree of specialization towards specific knowledge. Conversely, a lower PSS suggests more severe\nknowledge superposition phenomena within the parameter vectors, resulting in a lower degree of\nspecialization.\n3.4\nDataset Construction\nTo thoroughly investigate the parameter specialization of knowledge with different frequencies in the\nparameter vectors of LLMs’ MLP, we introduce a dataset named SpecWiki. It includes 525 concepts\nselected from Wikipedia §, a widely recognized high-quality corpus for LLM training. These concepts\nare categorized based on their frequency levels to ensure a diverse distribution. We then design\ntwo distinct question formats—multiple-choice questions and open-ended generation prompts—to\nfacilitate a thorough examination of the models’ knowledge storage.\nConcept Selection\nWe treat each Wikipedia item as a defining concept, typically represented by\nan article focused on a specific subject, indicated by its title. We focus on specific entity concepts,\nsuch as historical figures, events and locations. We began by randomly sampling 2,400 pages (a\n0.01% rate) from the 2019 version of Wikipedia. Subsequently, we performed manual filtering to\nremove overly commonsensical or abstract concepts (such as the letter ’S’ and the word ’Freedom’),\nambiguous concepts (like ’Apple’), and those associated with pages under 1,000 words. Ultimately,\nthis resulted in 525 high-quality concepts spanning specific topics like people, arts, and events.\n‡The term \"general ability\" refers to the model’s fundamental skills, such as processing text inputs correctly\nand generating coherent outputs, rather than encoding knowledge specific to a particular concept.\n§https://en.wikipedia.org/\n4\n"
    },
    {
      "page_number": 5,
      "text": "Given that the frequency of knowledge in training datasets significantly influences a model’s ability\nto retain and comprehend it (Allen-Zhu & Li, 2023; Meng et al., 2022; Mallen et al., 2023), we utilize\nWikipedia page views as a proxy for knowledge frequency in the models’ pre-training datasets¶. To\nthis end, we calculated the page views for each concept on Wikipedia between January 1, 2010, and\nDecember 31, 2019||. Based on these statistics, concepts are categorized by page view frequency into\nthree equal tiers: low-frequency (bottom 33% of the distribution), medium-frequency (middle 33%),\nand high-frequency (top 33%). A more detailed distribution of the categories and the corresponding\nexample data of SpecWiki dataset are provided in Table 4 and Table 5, respectively, in the Appendix.\nThis approximation helps estimate the likelihood of a concept’s presence in the models’ pre-training\ndatasets and allows us to explore how knowledge at different frequency levels is stored in models and\nprovides a more comprehensive evaluation.\nQuestion Generation\nTo more precisely assess the retention of knowledge within the model, we\ndesign two sets of question formats.\n• Multi-Choice Questions. Drawing inspiration from the widely used Massive Multitask Language\nUnderstanding (MMLU) dataset (Hendrycks et al., 2021b), which evaluates general knowledge\nacross models, we similarly designed ten multiple-choice questions for each concept, ensuring the\nknowledge and answers could be directly found in the relevant Wikipedia articles. Specifically, we\nprovided GPT-4o (OpenAI et al., 2024) with the appropriate Wikipedia article for each concept\nand instructed it to extract ten questions without overlap, along with the correct answers derived\nfrom the article’s text. Next, it was instructed to generate three additional incorrect answers, aside\nfrom the golden answer, ensuring that none of them overlapped with the correct answer to avoid\nconfusion. The detailed prompt is available in §A.1. We also include sample multiple-choice\nquestions and results of manual verification of the generated data in Appendix §A.2.\n• Open-ended Generation. To more effectively assess the model’s ability to generate knowledge text\nfreely, and to overcome the randomness and lack of depth inherent in the Multi-Choice Question\nevaluation method, we also set up a series of Open-ended Generation questions. For each question\nrelated to a concept, we prompted the model to generate an answer of up to 150 tokens directly\nand used GPT-4o as an evaluator to evaluate whether the generated response correctly matched the\ngolden answer.\n4\nExperiment\n4.1\nExperimental Setup\nEvaluated Models\nTo provide a more comprehensive evaluation of how the degree of parameter\nspecialization evolves across large language models, we assessed 20 open-source models from\nvarious families and sizes in the community. Specifically, we evaluated LLaMA series (Touvron\net al., 2023a,b; Grattafiori et al., 2024), Qwen series (Bai et al., 2023; Yang et al., 2024; Team, 2025),\nGemma series (Team et al., 2024a,b), OLMo series (Groeneveld et al., 2024; OLMo et al., 2025), Yi\nseries (AI et al., 2025), Mistral series (Jiang et al., 2023), GPT-j-6b (Wang & Komatsuzaki, 2021),\nPythia-6.9b (Biderman et al., 2023), Falcon-7b (Almazrouei et al., 2023) and Mpt-7b (Databricks,\n2023). Refer to Appendix §B.1 for the implementation details of these models.\nKnowledge Vectors Masking Setup\nBased on the descriptions in §3.2, in order to obtain mℓand\nm∗ℓfor each concept in SpecWiki at each layer of the model, we set the number of concept-related\nquestions t to 10. Additionally, we randomly select 5 irrelevant concepts with no knowledge overlap\nfrom the benchmark, and gather the corresponding questions associated with these irrelevant concepts,\nresulting in t∗= 50 irrelevant questions. These collected questions will also be directly utilized in\nthe computation of both the Concept-Specific Score and the General Score.\n¶To better support this point, we include experiments in §A.4 of Appendix that validate the strong correlation\nbetween concept popularity and their frequency in the pretraining data.\n||The earliest release date of the evaluated models, such as GPT-J, is 2019. Therefore, their pretraining\ndatasets could not include knowledge or concepts that emerged after this period. To ensure a fair evaluation\nacross all models, any knowledge introduced post-2019, including the COVID-19 pandemic, was excluded from\nthe benchmark.\n5\n"
    },
    {
      "page_number": 6,
      "text": "0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nSpecWiki Performance (Multi-Choice Questions)\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\n0.16\nParameter Specialization Score(PSS)\nQwen1.5-7B\nQwen2-7B\nQwen2.5-7B\nLLaMA-7B\nLLaMA2-7B\nLLaMA3-8B\nOLMo-7B\nOLMo-2-7B\nGemma-7B\nGemma2-9B\nMistral-7B-v0.1\nMistral-7B-v0.2\nMistral-7B-v0.3\nYi-6B\nYi-1.5-6B\nFalcon-7B\nGPT-J-6B\nPythia-6.9B\nMpt-7B\nQwen3-8B\nPearson R: 0.92 (p=1.41e-08)\nSpearman : 0.93 (p=4.87e-09)\nSpecWiki Performance vs Parameter Specialization Score\nTrendline\n2021-06-09\n2022-05-30\n2023-05-20\n2024-05-09\n2025-04-29\nRelease Date\nFigure 2: Correlation between the performance on SpecWiki and parameter specialization score\n(PSS) in 20 language models. We use a color gradient to distinguish the release times of the models,\nwith cooler colors indicating earlier release dates and warmer colors representing later releases.\nAdditionally, the size of each circle reflects the model’s performance on MMLU, with larger circles\nindicating better performance. The blue trendline, obtained through linear regression fitting of the\ndata points, suggests a strong correlation between a model’s performance on SpecWiki and its degree\nof Parameter Specialization.\nRegarding the selection of model layers for masking, since the initial layers of a model typically\nhandle fundamental capabilities like basic text processing (Meng et al., 2022; Geva et al., 2023),\nmasking these layers could severely impair the model’s basic text generation abilities. Therefore, for\nall models in our study, we preserve the first 5 layers without masking and only apply vector masking\noperations to all subsequent layers.\nFor the PSS computation of each model, we selected five different fixed k values—10%, 20%, 30%,\n40%, and 50%—which represent the proportion of value vectors in the model’s MLP layers that were\nmasked. For each k, we calculated the corresponding PSS following 6, and then averaged the results\nto obtain the final PSS score for each model. This criterion was applied consistently across both the\nMultiple-Choice Questions (MCQ) and Open-ended Generation (OEG) tasks.\n4.2\nMain Results\nThe main results for the Multiple-Choice Questions setting can be seen in Figure 2. We observe a\nstrong correlation between the degree of Parameter Specialization (measured by PSS) and model\nperformance on SpecWiki across 20 models, with Pearson and Spearman coefficients of 0.92 and\n0.93, respectively. Models achieving better performance on SpecWiki exhibit higher Parameter\nSpecialization Scores. Furthermore, models with higher PSS are often those released more recently\n(warmer color) and exhibit stronger general abilities, as measured by their MMLU performance\n(larger circle). The corresponding results for the Open-ended Generation setting can be found in\nFigure 6 in §B.2, which exhibit similar patterns and trends.\nTo better analyze the variations in Parameter Specialization across models within the same family,\nwe selected eight models from four model families: LLaMA, Qwen, Mistral, and Gemma. We\nexamined how the difference between the General Score, which represents the model’s ability to\nhandle irrelevant knowledge, and the Concept Specific Score, which reflects the model’s ability to\nhandle task-specific knowledge, changes under different masking ratios of parameter vectors. The\nresults are shown in Figure 3.\nFrom the figure, we can observe a very similar pattern across models from the four families:\n1. Among models within the same family, more advanced models tend to achieve higher peaks in the\nGeneral Score - Concept Specific Score difference. This indicates that more advanced models\ngenerally exhibit higher levels of Parameter Specialization.\n6\n"
    },
    {
      "page_number": 7,
      "text": "0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nLLaMA Series Models\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nQwen Series Models\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nMistral Series Models\n0.0\n0.2\n0.4\n0.6\nVector Masking Rate\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nScore Difference (General - Concept Specific)\nGemma Series Models\nLLaMA-7B\nLLaMA3-8B\nQwen1.5-7B\nQwen2.5-7B\nMistral-7B-v1\nMistral-7B-v3\nGemma-7B\nGemma2-9B\nFigure 3: Analysis of Parameter Specialization variations across models within the same family. We\nselected eight models from four model families: LLaMA, Qwen, Mistral, and Gemma. The figure\nshows how the difference between the General Score (representing the model’s ability to handle\nirrelevant knowledge) and the Concept Specific Score (representing the model’s ability to handle\ntask-specific knowledge) changes under different masking ratios of parameter vectors.\n2. As the masking ratio of parameter vectors increases, from approximately 5% to 20%, the difference\nbetween the General Score and the Concept Specific Score gradually increases to a peak. This\nindicates that we are removing parameter vectors that are highly specific to the target knowledge.\nAfter reaching the peak, as the masking ratio continues to increase, the difference gradually\ndecreases to zero. This suggests that parameter vectors with lower activation are often those that\nhave a higher degree of knowledge superposition and are less specialized in the target knowledge.\nAdditionally, we unexpectedly found that when a small proportion of concept-related vectors (ranging\nfrom 5% to 10%) were masked, the performance of the masked models on unrelated questions\neven surpassed that of the original models. This observation is consistent across various models\nand indicates the positive impact of reducing irrelevant information interference in the model’s\nrepresentation, leading to improved performance.\nIn §5, we will further validate the causal relationship between the degree of model parameter\nspecialization and its ability to better utilize target knowledge through the finetuning experiments on\nadditional data.\n4.3\nImpact of Model Scale on Parameter Specialization\nModel\nAccuracyMCQ ↑\nPSS ↑\nQwen1.5-0.5B\n0.61 (±0.2)\n0.019 (±0.01)\nQwen1.5-1.8B\n0.61 (±0.3)\n0.044 (±0.02)\nQwen1.5-4B\n0.73 (±0.2)\n0.075 (±0.02)\nQwen1.5-7B\n0.75 (±0.2)\n0.121 (±0.04)\nQwen1.5-14B\n0.82 (±0.2)\n0.184 (±0.03)\nGemma2-2B\n0.72 (±0.3)\n0.057 (±0.02)\nGemma2-9B\n0.86 (±0.1)\n0.138 (±0.03)\nTable 1: Performance comparison of language models\nwith varying sizes on Multiple-Choice Question and\nParameter Specialization Score. Both the Qwen1.5 and\nGemma2 series models show improved Parameter Spe-\ncialization as the model scale increases, accompanied\nby better performance on the MCQ testing in SpceWiki.\nIn this section, to better explore the dif-\nferences in the degree of parameter spe-\ncialization across models of different sizes,\nwe conducted Knowledge Vectors Mask-\ning experiments on five Qwen1.5 models\nof varying sizes (0.5B, 1.8B, 4B, 7B, and\n14B) and on 2 Gemma2 models (2B and\n9B). The results are shown in Table 1. We\nobserve that in both the Qwen and Gemma\nmodel families, as the model size increases,\nthe corresponding Parameter Specializa-\ntion Score also increases. This trend is\naccompanied by improved performance on\nSpecWiki.\nThis suggests that in larger-\nscale models, the degree of superposition\nfor specific knowledge decreases and it\ntends to be distinctly represented across\ndesignated parameter vectors.\n4.4\nEvolution of Parameter Specialization During Pretraining\nTo better investigate the development of Parameter Specialization in the model from the perspective\nof model training dynamics, we analyzed 10 checkpoints from the OLMo-2-1124-7B (OLMo et al.,\n2025) pretraining process by using our SpecWiki. The results are shown in Figure 4 below.\n7\n"
    },
    {
      "page_number": 8,
      "text": "step10000\nstep100000\nstep210000\nstep310000\nstep410000\nstep510000\nstep610000\nstep810000\nstep910000\nOLMo-2-1124-7B Training Checkpoints\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\nParameter Specialization Score(PSS)\nParameter Specialization Score(PSS)\nSpecWiki Accuracy\n0.0\n0.2\n0.4\n0.6\n0.8\nSpecWiki Accuracy\nParameter Specialization Score(PSS) in OLMo2's Training Checkpoints\nFigure 4: Development of Parameter Specializa-\ntion in OLMo-2-1124-7B over the pretraining\nprocess.\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09\n0.10\nParameter Specialization Score (PSS)\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nSpecWiki Performance (MCQ)\nLow frequency\nMid frequency\nHigh frequency\nLLaMA2-7B-base\n0.09\n0.10\n0.11\n0.12\n0.13\n0.14\n0.15\n0.16\nParameter Specialization Score (PSS)\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nLow frequency\nMid frequency\nHigh frequency\nQwen2-7B-base\nFigure 5: Relationship between concept popu-\nlarity, model accuracy on MCQ, and Parameter\nSpecialization Score in LLaMA2-7B and Qwen2-\n7B models.\nModel\nAccuracyMCQ ↑\nAccuracyOEG ↑\nPSS ↑\nSemantic Entropy ↓\nLocal Intrinsic Dimension ↓\nLLaMA2-7B\n0.60 (±0.2)\n0.51 (±0.1)\n0.67 (±0.1)\n0.67 (±0.1)\n11.23 (±2.1)\nLLaMA2-7BF T −F V\n0.63 (±0.3)\n0.54 (±0.2)\n0.65 (±0.2)\n0.62 (±0.1)\n11.12 (±1.4)\nLLaMA2-7BF T −P V\n0.67 (±0.3)\n0.59 (±0.2)\n0.72 (±0.1)\n0.50 (±0.2)\n7.89 (±2.1)\nLLaMA2-7BF T −CV\n0.62 (±0.1)\n0.51 (±0.1)\n0.63 (±0.2)\n0.62 (±0.1)\n11.12 (±1.4)\nLLaMA2-7BF T −RV\n0.58 (±0.2)\n0.49 (±0.2)\n0.65 (±0.2)\n0.65 (±0.2)\n11.07(±2.7)\nQwen2-7B\n0.72 (±0.3)\n0.63 (±0.1)\n0.124 (±0.03)\n0.56 (±0.1)\n9.78 (±1.9)\nQwen2-7BF T −F V\n0.73 (±0.2)\n0.67 (±0.2)\n0.110 (±0.02)\n0.59 (±0.2)\n8.53 (±1.1)\nQwen2-7BF T −P V\n0.77 (±0.1)\n0.70 (±0.1)\n0.133 (±0.03)\n0.39 (±0.1)\n6.92 (±1.3)\nQwen2-7BF T −CV\n0.73 (±0.2)\n0.65 (±0.2)\n0.114 (±0.03)\n0.55 (±0.2)\n8.78 (±1.6)\nQwen2-7BF T −RV\n0.71 (±0.2)\n0.63 (±0.1)\n0.122 (±0.02)\n0.59 (±0.2)\n9.65 (±1.4)\nTable 2: The performance of both the original LLaMA2-7B-base and Qwen2-7B-base models,\nalong with their FT-FV, FT-PV, FT-CV and FT-RV variants, was assessed on a selection of 10 high-\nfrequency concepts from SpecWiki. Five metrics were used to evaluate their performance, including\ntheir general effectiveness, Parameter Specialization, and the degree of hallucination present in their\noutput.\nFrom the results, we observe that during the early training steps (step 10,000 to step 210,000), both\nthe PSS and the accuracy on SpeciWiki remain nearly unchanged and close to zero. In the subsequent\nphase (step 310,000 to step 510,000), although the model begins to show noticeable gains in accuracy\non SpeciWiki, the PSS are still under 0.1. However, it is during the later training steps (step 610,000\nto step 910,000) that parameter specialization begins to emerge, accompanied by a more substantial\nimprovement in accuracy. These findings suggest that parameter specialization does not occur in the\nearly stages of training, but rather emerges after a certain amount of data exposure. Furthermore, as\ntraining continues and the model sees more data, the degree of parameter specialization increases\naccordingly.\n4.5\nParameter Specialization in Relation to Concept Popularity\nIn this section, we analyze how the popularity of concepts themselves, which is roughly equivalent\nto their frequency in the pretraining data, will affect the level of parameter specialization for the\ncorresponding knowledge. We follow the classification method for concepts as outlined in §3.4,\ndividing them into high-frequency, mid-frequency, and low-frequency categories. The impact on their\nPSS scores is measured on two example models, LLaMA2-7B, and Qwen2.5-7B, which are shown in\nFigure 5.\nFrom the figure, it is clear that in both the LLaMA2-7B and Qwen2-7B models, as the popularity of\na concept decreases, the model’s accuracy on that specific knowledge declines, accompanied by a\nlower Parameter Specialization Score. This suggests that the degree of Parameter Specialization for a\nparticular knowledge in the model’s parameters is likely directly correlated with the frequency of that\nknowledge in the model’s pretraining dataset. The higher the frequency, the greater the Parameter\nSpecialization for that knowledge in the model.\n5\nValidation of Parameter Specialization Benefits for Knowledge Tasks\nIn this section, we conducted four sets of controlled training experiments, each involving continued\nfine-tuning on the Llama2-7B-base (Touvron et al., 2023a) and Qwen2-7B-base (Yang et al., 2024)\n8\n"
    },
    {
      "page_number": 9,
      "text": "models with additional knowledge data. These experiments aim to validate the causal relationship\nbetween improved parameter specialization and enhanced model performance on knowledge tasks.\n5.1\nFinetuning Setup\nWe randomly selected 10 high-frequency concepts from the SpecWiki benchmark. For each concept,\nwe gathered relevant textual material from the top 10 most popular Google search results, including\nthe corresponding Wikipedia article, and compiled this into an additional finetuning training dataset.\nNext, we will validate whether the improvement in Parameter Specialization and the enhanced\nefficiency in the model’s use of knowledge truly exhibit a causal relationship through four distinct\nfinetuning experiments. The experimental setups are detailed below:\nFT-FV(Full Vectors) Perform full finetuning (FT) on all parameter vectors of the MLPs across all\nlayers in the model, while keeping the other parameters frozen.\nFT-PV(Partial Vectors) Perform partial finetuning on a subset of the parameter vectors in the MLPs\nwhile keeping the other parameters frozen. Specifically, for each model, we apply finetuning\n(FT) to the top k\n8 most highly activated parameter vectors**. For the selection of k, please\nrefer to the description in §4.1.\nFT-CV(Complementary Vectors) Perform finetuning only on the complementary set of parameter\nvectors, excluding the target vectors.\nFT-RV(Random Vectors) Perform finetuning on a subset of parameter vectors randomly selected\nfrom the MLP, ensuring the same quantity as in the FT-PV setting.\n5.2\nFinetuning Results\nIn addition to evaluating the model’s performance on SpecWiki’s Multi-choice Question and Open-\nended Generation tests, as well as the Parameter Specialization scores, we also report two other\nmetrics, Semantic Entropy (Kuhn et al., 2022) and Local Intrinsic Dimension (LID) (Yin et al.,\n2024), for measuring the extent of hallucination in the model’s output. These metrics help evaluate\nwhether training strategies that enhance Parameter Specialization—by aligning better with the\nmodel’s knowledge retrieval mechanisms through a data-encoded strategy—can effectively reduce\nthe unintended side effect of hallucination. For a detailed introduction to these two hallucination\nmeasurements, please refer to §B.3.\nThe final results are presented in Table 2. From the results, we can see that the FT-PV method, which\nfinetunes only a small subset of the highly activated knowledge parameters, not only further enhances\nthe model’s Parameter Specialization compared to the three other finetuning setups, but also greatly\nimproves the model’s utilization of specific knowledge. As a result, it achieves the best performance\non the benchmark Multi-Choice questions and Open-ended generation tasks. Additionally, by\nreducing the influence of irrelevant information in the model’s key parameter vectors, FT-PV helps to\nsignificantly reduce the level of hallucination in the generated text.\nAlthough FT-FV and FT-CV does improve the model’s performance on both the Multi-Choice\nquestions and Open-ended generation tasks to some extent, compared to FT-PV, it does not lead\nto a better increase in Parameter Specialization. Additionally, the degree of hallucination in the\ngenerated text is not effectively reduced. FT-RV, serving as a counterpart to FT-PV, demonstrates\nthat fine-tuning the same number of arbitrary value vectors in the model’s MLP can not result in a\ndesirable knowledge enhancement.\n6\nConclusion\nThis study reveals that enhanced parameter specialization—where related knowledge is encoded in\nfocused parameter vectors—correlates with superior performance in large language models. Analyz-\ning 20 open-source models, we observed stronger models increasingly consolidate similar knowledge\ninto fewer parameters, while weaker models distribute it diffusely. Controlled experiments confirmed\n**We experimented with k\n2 , k\n4 , k\n8 , and\nk\n16, and found that finetuning only k\n8 of the parameter vectors was\nsufficient to achieve excellent performance.\n9\n"
    },
    {
      "page_number": 10,
      "text": "that optimizing this specialization improves task performance and reduces hallucination. These\nfindings highlight the importance of aligning knowledge storage with models’ retrieval mechanisms\nfor efficiency and accuracy. Future work should explore dynamic knowledge updates and scalability,\nadvancing both interpretability and performance in LLM design.\n7\nLimitations and Future Work\nIn our work, we have only examined and validated knowledge parameter specialization within the\nMLP, and this was done by treating vectors in the MLP as units of analysis. However, at least this\nremains one of the knowledge storage methods that has been extensively validated so far (Geva et al.,\n2021a; Meng et al., 2022; Geva et al., 2023). In fact, knowledge may also reside within the attention\nmodule of transformer models (Geva et al., 2023).\nAdditionally, due to GPU limitations, all the models we tested are smaller than or equal to 14B\nparameters, so we were unable to validate our conclusions on larger models, such as those with 35B\nparameters or more.\nIn future work, we will progressively narrow the focus of our research to individual neurons in\nlanguage models, aiming to measure and validate more precise Parameter Specialization and Pa-\nrameter Superposition. In addition, we will extend this concept to the study of other related model\narchitectures, including Mixture of Experts (Fedus et al., 2022), which similarly enhances model\nperformance by specializing expert parameters, as well as Sparse Auto-Encoders (Huben et al., 2024),\nwhich help clarify the model’s representations by leveraging a larger parameter space and mitigating\nthe superposition of these features.\nAcknowledgment\nThis research is supported by the Ministry of Education, Singapore, under its Academic Research\nFund (AcRF) Tier 1 grant, and funded through the SUTD Assistant Professorship Scheme (SAP\n2025_001).\nReferences\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt,\nJ., Altman, S., Anadkat, S., et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\nAI, ., :, Young, A., Chen, B., Li, C., Huang, C., Zhang, G., Zhang, G., Wang, G., Li, H., Zhu, J.,\nChen, J., Chang, J., Yu, K., Liu, P., Liu, Q., Yue, S., Yang, S., Yang, S., Xie, W., Huang, W., Hu,\nX., Ren, X., Niu, X., Nie, P., Li, Y., Xu, Y., Liu, Y., Wang, Y., Cai, Y., Gu, Z., Liu, Z., and Dai, Z.\nYi: Open foundation models by 01.ai, 2025. URL https://arxiv.org/abs/2403.04652.\nAllen-Zhu, Z. and Li, Y. Physics of language models: Part 3.1, knowledge storage and extraction,\n2023.\nAlmazrouei, E., Alobeidli, H., Alshamsi, A., Cappelli, A., Cojocaru, R., Debbah, M., Étienne Goffinet,\nHesslow, D., Launay, J., Malartic, Q., Mazzotta, D., Noune, B., Pannier, B., and Penedo, G. The\nfalcon series of open language models, 2023. URL https://arxiv.org/abs/2311.16867.\nBai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B.,\nJi, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren,\nX., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A.,\nYang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang,\nY., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T. Qwen technical report, 2023. URL\nhttps://arxiv.org/abs/2309.16609.\nBiderman, S., Schoelkopf, H., Anthony, Q., Bradley, H., O’Brien, K., Hallahan, E., Khan, M. A.,\nPurohit, S., Prashanth, U. S., Raff, E., Skowron, A., Sutawika, L., and van der Wal, O. Pythia:\nA suite for analyzing large language models across training and scaling, 2023. URL https:\n//arxiv.org/abs/2304.01373.\n10\n"
    },
    {
      "page_number": 11,
      "text": "Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda,\nY., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G.,\nMishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter,\nC., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss,\nA., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S.,\nSaunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford,\nA., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D.,\nMcCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code,\n2021a. URL https://arxiv.org/abs/2107.03374.\nChen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y.,\nJoseph, N., Brockman, G., et al. Evaluating large language models trained on code. arXiv preprint\narXiv:2107.03374, 2021b.\nCobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton,\nJ., Nakano, R., Hesse, C., and Schulman, J. Training verifiers to solve math word problems, 2021.\nURL https://arxiv.org/abs/2110.14168.\nDar, G., Geva, M., Gupta, A., and Berant, J. Analyzing transformers in embedding space. In\nRogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers), pp. 16124–16170, Toronto,\nCanada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.\n893. URL https://aclanthology.org/2023.acl-long.893.\nDatabricks. Introducing mpt-7b: A new standard for open-source, commercially usable llms, May\n2023. URL https://www.databricks.com/blog/mpt-7b. Accessed: Jan 29, 2025.\nElazar, Y., Bhagia, A., Magnusson, I. H., Ravichander, A., Schwenk, D., Suhr, A., Walsh, E. P.,\nGroeneveld, D., Soldaini, L., Singh, S., Hajishirzi, H., Smith, N. A., and Dodge, J. What’s in\nmy big data? In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=RvfPnOkPV4.\nElhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., Hatfield-Dodds, Z., Lasenby,\nR., Drain, D., Chen, C., et al. Toy models of superposition. arXiv preprint arXiv:2209.10652,\n2022.\nFedus, W., Zoph, B., and Shazeer, N. Switch transformers: Scaling to trillion parameter models with\nsimple and efficient sparsity, 2022. URL https://arxiv.org/abs/2101.03961.\nGao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A.,\nNabeshima, N., Presser, S., and Leahy, C. The pile: An 800gb dataset of diverse text for language\nmodeling, 2020. URL https://arxiv.org/abs/2101.00027.\nGeva, M., Schuster, R., Berant, J., and Levy, O. Transformer feed-forward layers are key-value\nmemories. In Moens, M.-F., Huang, X., Specia, L., and Yih, S. W.-t. (eds.), Proceedings of\nthe 2021 Conference on Empirical Methods in Natural Language Processing, pp. 5484–5495,\nOnline and Punta Cana, Dominican Republic, November 2021a. Association for Computational\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.446. URL https://aclanthology.org/2021.\nemnlp-main.446.\nGeva, M., Schuster, R., Berant, J., and Levy, O. Transformer feed-forward layers are key-value\nmemories. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, pp. 5484–5495, 2021b.\nGeva, M., Caciularu, A., Dar, G., Roit, P., Sadde, S., Shlain, M., Tamir, B., and Goldberg, Y. LM-\ndebugger: An interactive tool for inspection and intervention in transformer-based language models.\nIn Che, W. and Shutova, E. (eds.), Proceedings of the 2022 Conference on Empirical Methods in\nNatural Language Processing: System Demonstrations, pp. 12–21, Abu Dhabi, UAE, December\n2022a. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-demos.2. URL\nhttps://aclanthology.org/2022.emnlp-demos.2.\n11\n"
    },
    {
      "page_number": 12,
      "text": "Geva, M., Caciularu, A., Wang, K., and Goldberg, Y. Transformer feed-forward layers build\npredictions by promoting concepts in the vocabulary space. In Goldberg, Y., Kozareva, Z.,\nand Zhang, Y. (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural\nLanguage Processing, pp. 30–45, Abu Dhabi, United Arab Emirates, December 2022b. Asso-\nciation for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.3. URL https:\n//aclanthology.org/2022.emnlp-main.3.\nGeva, M., Bastings, J., Filippova, K., and Globerson, A. Dissecting recall of factual associations in\nauto-regressive language models. In Proceedings of the 2023 Conference on Empirical Methods in\nNatural Language Processing, pp. 12216–12235, 2023.\nGrattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur,\nA., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra,\nA., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson,\nA., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C.,\nMarra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C.,\nAllonsius, D., Song, D., Pintz, D., Livshits, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan,\nD., Garcia-Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan,\nE., Smith, E. M., Radenovic, F., Guzmán, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G. L.,\nThattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H.,\nTouvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee,\nJ., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J., Hong, J.,\nLee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca, J.,\nJohnstun, J., Saxe, J., Jia, J., Alwala, K. V., Prasad, K., Upasani, K., Plawiak, K., Li, K., Heafield,\nK., Stone, K., El-Arini, K., Iyer, K., Malik, K., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary,\nL., van der Maaten, L., Chen, L., Tan, L., Jenkins, L., Martin, L., Madaan, L., Malo, L., Blecher,\nL., Landzaat, L., de Oliveira, L., Muzzi, M., Pasupuleti, M., Singh, M., Paluri, M., Kardas, M.,\nTsimpoukelli, M., Oldham, M., Rita, M., Pavlova, M., Kambadur, M., Lewis, M., Si, M., Singh,\nM. K., Hassan, M., Goyal, N., Torabi, N., Bashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N.,\nDuchenne, O., Çelebi, O., Alrassy, P., Zhang, P., Li, P., Vasic, P., Weng, P., Bhargava, P., Dubal,\nP., Krishnan, P., Koura, P. S., Xu, P., He, Q., Dong, Q., Srinivasan, R., Ganapathy, R., Calderer,\nR., Cabral, R. S., Stojnic, R., Raileanu, R., Maheswari, R., Girdhar, R., Patel, R., Sauvestre, R.,\nPolidoro, R., Sumbaly, R., Taylor, R., Silva, R., Hou, R., Wang, R., Hosseini, S., Chennabasappa,\nS., Singh, S., Bell, S., Kim, S. S., Edunov, S., Nie, S., Narang, S., Raparthy, S., Shen, S., Wan, S.,\nBhosale, S., Zhang, S., Vandenhende, S., Batra, S., Whitman, S., Sootla, S., Collot, S., Gururangan,\nS., Borodinsky, S., Herman, T., Fowler, T., Sheasha, T., Georgiou, T., Scialom, T., Speckbacher, T.,\nMihaylov, T., Xiao, T., Karn, U., Goswami, V., Gupta, V., Ramanathan, V., Kerkez, V., Gonguet,\nV., Do, V., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong, W., Fu, W., Meers, W., Martinet,\nX., Wang, X., Wang, X., Tan, X. E., Xia, X., Xie, X., Jia, X., Wang, X., Goldschlag, Y., Gaur,\nY., Babaei, Y., Wen, Y., Song, Y., Zhang, Y., Li, Y., Mao, Y., Coudert, Z. D., Yan, Z., Chen, Z.,\nPapakipos, Z., Singh, A., Srivastava, A., Jain, A., Kelsey, A., Shajnfeld, A., Gangidi, A., Victoria,\nA., Goldstand, A., Menon, A., Sharma, A., Boesenberg, A., Baevski, A., Feinstein, A., Kallet, A.,\nSangani, A., Teo, A., Yunus, A., Lupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poulton, A.,\nRyan, A., Ramchandani, A., Dong, A., Franco, A., Goyal, A., Saraf, A., Chowdhury, A., Gabriel,\nA., Bharambe, A., Eisenman, A., Yazdan, A., James, B., Maurer, B., Leonhardi, B., Huang, B.,\nLoyd, B., Paola, B. D., Paranjape, B., Liu, B., Wu, B., Ni, B., Hancock, B., Wasti, B., Spence, B.,\nStojkovic, B., Gamido, B., Montalvo, B., Parker, C., Burton, C., Mejia, C., Liu, C., Wang, C., Kim,\nC., Zhou, C., Hu, C., Chu, C.-H., Cai, C., Tindal, C., Feichtenhofer, C., Gao, C., Civin, D., Beaty,\nD., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine, D., David, D., Parikh, D., Liskovich, D.,\nFoss, D., Wang, D., Le, D., Holland, D., Dowling, E., Jamil, E., Montgomery, E., Presani, E., Hahn,\nE., Wood, E., Le, E.-T., Brinkman, E., Arcaute, E., Dunbar, E., Smothers, E., Sun, F., Kreuk, F.,\nTian, F., Kokkinos, F., Ozgenel, F., Caggioni, F., Kanayet, F., Seide, F., Florez, G. M., Schwarz, G.,\nBadeer, G., Swee, G., Halpern, G., Herman, G., Sizov, G., Guangyi, Zhang, Lakshminarayanan, G.,\nInan, H., Shojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H., Rudolph, H., Suk, H., Aspegren,\nH., Goldman, H., Zhan, H., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I., Veliche, I.-E., Gat,\nI., Weissman, J., Geboski, J., Kohli, J., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J., Chan, J.,\nZhen, J., Reizenstein, J., Teboul, J., Zhong, J., Jin, J., Yang, J., Cummings, J., Carvill, J., Shepard,\nJ., McPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U, K. H., Saxena, K., Khandelwal, K.,\nZand, K., Matosich, K., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh, K., Huang, K.,\nChawla, K., Huang, K., Chen, L., Garg, L., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L.,\n12\n"
    },
    {
      "page_number": 13,
      "text": "Moshkovich, L., Wehrstedt, L., Khabsa, M., Avalani, M., Bhatt, M., Mankus, M., Hasson, M.,\nLennie, M., Reso, M., Groshev, M., Naumov, M., Lathi, M., Keneally, M., Liu, M., Seltzer, M. L.,\nValko, M., Restrepo, M., Patel, M., Vyatskov, M., Samvelyan, M., Clark, M., Macey, M., Wang,\nM., Hermoso, M. J., Metanat, M., Rastegari, M., Bansal, M., Santhanam, N., Parks, N., White,\nN., Bawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta, N., Laptev, N. P., Dong, N., Cheng, N.,\nChernoguz, O., Hart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P., Saab, P., Balaji, P., Rittner,\nP., Bontrager, P., Roux, P., Dollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P., Liang, Q., Alao,\nR., Rodriguez, R., Ayub, R., Murthy, R., Nayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan,\nR., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta, S., Siby, S., Bondu, S. J., Datta, S., Chugh,\nS., Hunt, S., Dhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma, S., Yamamoto, S., Ramaswamy,\nS., Lindsay, S., Lindsay, S., Feng, S., Lin, S., Zha, S. C., Patil, S., Shankar, S., Zhang, S., Zhang,\nS., Wang, S., Agarwal, S., Sajuyigbe, S., Chintala, S., Max, S., Chen, S., Kehoe, S., Satterfield,\nS., Govindaprasad, S., Gupta, S., Deng, S., Cho, S., Virk, S., Subramanian, S., Choudhury, S.,\nGoldman, S., Remez, T., Glaser, T., Best, T., Koehler, T., Robinson, T., Li, T., Zhang, T., Matthews,\nT., Chou, T., Shaked, T., Vontimitta, V., Ajayi, V., Montanez, V., Mohan, V., Kumar, V. S., Mangla,\nV., Ionescu, V., Poenaru, V., Mihailescu, V. T., Ivanov, V., Li, W., Wang, W., Jiang, W., Bouaziz,\nW., Constable, W., Tang, X., Wu, X., Wang, X., Wu, X., Gao, X., Kleinman, Y., Chen, Y., Hu, Y.,\nJia, Y., Qi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu, Wang, Zhao, Y., Hao, Y., Qian,\nY., Li, Y., He, Y., Rait, Z., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao, Z., and Ma, Z. The\nllama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783.\nGroeneveld, D., Beltagy, I., Walsh, P., Bhagia, A., Kinney, R., Tafjord, O., Jha, A. H., Ivison, H.,\nMagnusson, I., Wang, Y., Arora, S., Atkinson, D., Authur, R., Chandu, K. R., Cohan, A., Dumas, J.,\nElazar, Y., Gu, Y., Hessel, J., Khot, T., Merrill, W., Morrison, J., Muennighoff, N., Naik, A., Nam,\nC., Peters, M. E., Pyatkin, V., Ravichander, A., Schwenk, D., Shah, S., Smith, W., Strubell, E.,\nSubramani, N., Wortsman, M., Dasigi, P., Lambert, N., Richardson, K., Zettlemoyer, L., Dodge, J.,\nLo, K., Soldaini, L., Smith, N. A., and Hajishirzi, H. Olmo: Accelerating the science of language\nmodels. arXiv preprint arXiv:2402.00838, 2024.\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring\nmassive multitask language understanding. In International Conference on Learning Representa-\ntions, 2021a. URL https://openreview.net/forum?id=d7KBjmI3GmQ.\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring\nmassive multitask language understanding. Proceedings of the International Conference on\nLearning Representations (ICLR), 2021b.\nHong, Y., Yu, L., Yang, H., Ravfogel, S., and Geva, M. Intrinsic evaluation of unlearning using\nparametric knowledge traces. arXiv preprint arXiv:2406.11614, 2024a.\nHong, Y., Zou, Y., Hu, L., Zeng, Z., Wang, D., and Yang, H. Dissecting fine-tuning unlearning in\nlarge language models. In Al-Onaizan, Y., Bansal, M., and Chen, Y.-N. (eds.), Proceedings of the\n2024 Conference on Empirical Methods in Natural Language Processing, pp. 3933–3941, Miami,\nFlorida, USA, November 2024b. Association for Computational Linguistics. doi: 10.18653/v1/\n2024.emnlp-main.228. URL https://aclanthology.org/2024.emnlp-main.228/.\nHuben, R., Cunningham, H., Smith, L. R., Ewart, A., and Sharkey, L. Sparse autoencoders find highly\ninterpretable features in language models. In The Twelfth International Conference on Learning\nRepresentations, 2024. URL https://openreview.net/forum?id=F76bwRSLeK.\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de las Casas, D., Bressand,\nF., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L. R., Lachaux, M.-A., Stock, P., Scao,\nT. L., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. Mistral 7b, 2023. URL https:\n//arxiv.org/abs/2310.06825.\nKuhn, L., Gal, Y., and Farquhar, S. Semantic uncertainty: Linguistic invariances for uncertainty\nestimation in natural language generation. In The Eleventh International Conference on Learning\nRepresentations, 2022.\nMallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., and Hajishirzi, H. When not to trust language\nmodels: Investigating effectiveness of parametric and non-parametric memories. In Rogers, A.,\nBoyd-Graber, J., and Okazaki, N. (eds.), Proceedings of the 61st Annual Meeting of the Association\n13\n"
    },
    {
      "page_number": 14,
      "text": "for Computational Linguistics (Volume 1: Long Papers), pp. 9802–9822, Toronto, Canada, July\n2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.546. URL\nhttps://aclanthology.org/2023.acl-long.546/.\nMeng, K., Bau, D., Andonian, A. J., and Belinkov, Y. Locating and editing factual associations in\nGPT. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information\nProcessing Systems, 2022. URL https://openreview.net/forum?id=-h6WAS6eE4.\nOlah,\nC.\nDistributed\nrepresentations:\nComposition\n&\nsuperposition.\nhttps:\n//transformer-circuits.pub/2023/superposition-composition/index.html,\n2023. Published May 4th, 2023.\nOLMo, T., Walsh, P., Soldaini, L., Groeneveld, D., Lo, K., Arora, S., Bhagia, A., Gu, Y., Huang,\nS., Jordan, M., Lambert, N., Schwenk, D., Tafjord, O., Anderson, T., Atkinson, D., Brahman, F.,\nClark, C., Dasigi, P., Dziri, N., Guerquin, M., Ivison, H., Koh, P. W., Liu, J., Malik, S., Merrill,\nW., Miranda, L. J. V., Morrison, J., Murray, T., Nam, C., Pyatkin, V., Rangapur, A., Schmitz, M.,\nSkjonsberg, S., Wadden, D., Wilhelm, C., Wilson, M., Zettlemoyer, L., Farhadi, A., Smith, N. A.,\nand Hajishirzi, H. 2 olmo 2 furious, 2025. URL https://arxiv.org/abs/2501.00656.\nOpenAI, :, Hurst, A., Lerer, A., Goucher, A. P., Perelman, A., Ramesh, A., Clark, A., Ostrow, A.,\nWelihinda, A., Hayes, A., Radford, A., M ˛adry, A., Baker-Whitcomb, A., Beutel, A., Borzunov, A.,\nCarney, A., Chow, A., Kirillov, A., Nichol, A., Paino, A., Renzin, A., Passos, A. T., Kirillov, A.,\nChristakis, A., Conneau, A., Kamali, A., Jabri, A., Moyer, A., Tam, A., Crookes, A., Tootoochian,\nA., Tootoonchian, A., Kumar, A., Vallone, A., Karpathy, A., Braunstein, A., Cann, A., Codispoti,\nA., Galu, A., Kondrich, A., Tulloch, A., Mishchenko, A., Baek, A., Jiang, A., Pelisse, A., Woodford,\nA., Gosalia, A., Dhar, A., Pantuliano, A., Nayak, A., Oliver, A., Zoph, B., Ghorbani, B., Leimberger,\nB., Rossen, B., Sokolowsky, B., Wang, B., Zweig, B., Hoover, B., Samic, B., McGrew, B., Spero,\nB., Giertler, B., Cheng, B., Lightcap, B., Walkin, B., Quinn, B., Guarraci, B., Hsu, B., Kellogg, B.,\nEastman, B., Lugaresi, C., Wainwright, C., Bassin, C., Hudson, C., Chu, C., Nelson, C., Li, C.,\nShern, C. J., Conger, C., Barette, C., Voss, C., Ding, C., Lu, C., Zhang, C., Beaumont, C., Hallacy,\nC., Koch, C., Gibson, C., Kim, C., Choi, C., McLeavey, C., Hesse, C., Fischer, C., Winter, C.,\nCzarnecki, C., Jarvis, C., Wei, C., Koumouzelis, C., Sherburn, D., Kappler, D., Levin, D., Levy,\nD., Carr, D., Farhi, D., Mely, D., Robinson, D., Sasaki, D., Jin, D., Valladares, D., Tsipras, D., Li,\nD., Nguyen, D. P., Findlay, D., Oiwoh, E., Wong, E., Asdar, E., Proehl, E., Yang, E., Antonow,\nE., Kramer, E., Peterson, E., Sigler, E., Wallace, E., Brevdo, E., Mays, E., Khorasani, F., Such,\nF. P., Raso, F., Zhang, F., von Lohmann, F., Sulit, F., Goh, G., Oden, G., Salmon, G., Starace,\nG., Brockman, G., Salman, H., Bao, H., Hu, H., Wong, H., Wang, H., Schmidt, H., Whitney, H.,\nJun, H., Kirchner, H., de Oliveira Pinto, H. P., Ren, H., Chang, H., Chung, H. W., Kivlichan, I.,\nO’Connell, I., O’Connell, I., Osband, I., Silber, I., Sohl, I., Okuyucu, I., Lan, I., Kostrikov, I.,\nSutskever, I., Kanitscheider, I., Gulrajani, I., Coxon, J., Menick, J., Pachocki, J., Aung, J., Betker,\nJ., Crooks, J., Lennon, J., Kiros, J., Leike, J., Park, J., Kwon, J., Phang, J., Teplitz, J., Wei, J.,\nWolfe, J., Chen, J., Harris, J., Varavva, J., Lee, J. G., Shieh, J., Lin, J., Yu, J., Weng, J., Tang, J., Yu,\nJ., Jang, J., Candela, J. Q., Beutler, J., Landers, J., Parish, J., Heidecke, J., Schulman, J., Lachman,\nJ., McKay, J., Uesato, J., Ward, J., Kim, J. W., Huizinga, J., Sitkin, J., Kraaijeveld, J., Gross, J.,\nKaplan, J., Snyder, J., Achiam, J., Jiao, J., Lee, J., Zhuang, J., Harriman, J., Fricke, K., Hayashi,\nK., Singhal, K., Shi, K., Karthik, K., Wood, K., Rimbach, K., Hsu, K., Nguyen, K., Gu-Lemberg,\nK., Button, K., Liu, K., Howe, K., Muthukumar, K., Luther, K., Ahmad, L., Kai, L., Itow, L.,\nWorkman, L., Pathak, L., Chen, L., Jing, L., Guy, L., Fedus, L., Zhou, L., Mamitsuka, L., Weng, L.,\nMcCallum, L., Held, L., Ouyang, L., Feuvrier, L., Zhang, L., Kondraciuk, L., Kaiser, L., Hewitt, L.,\nMetz, L., Doshi, L., Aflak, M., Simens, M., Boyd, M., Thompson, M., Dukhan, M., Chen, M., Gray,\nM., Hudnall, M., Zhang, M., Aljubeh, M., Litwin, M., Zeng, M., Johnson, M., Shetty, M., Gupta,\nM., Shah, M., Yatbaz, M., Yang, M. J., Zhong, M., Glaese, M., Chen, M., Janner, M., Lampe, M.,\nPetrov, M., Wu, M., Wang, M., Fradin, M., Pokrass, M., Castro, M., de Castro, M. O. T., Pavlov,\nM., Brundage, M., Wang, M., Khan, M., Murati, M., Bavarian, M., Lin, M., Yesildal, M., Soto, N.,\nGimelshein, N., Cone, N., Staudacher, N., Summers, N., LaFontaine, N., Chowdhury, N., Ryder,\nN., Stathas, N., Turley, N., Tezak, N., Felix, N., Kudige, N., Keskar, N., Deutsch, N., Bundick,\nN., Puckett, N., Nachum, O., Okelola, O., Boiko, O., Murk, O., Jaffe, O., Watkins, O., Godement,\nO., Campbell-Moore, O., Chao, P., McMillan, P., Belov, P., Su, P., Bak, P., Bakkum, P., Deng, P.,\nDolan, P., Hoeschele, P., Welinder, P., Tillet, P., Pronin, P., Tillet, P., Dhariwal, P., Yuan, Q., Dias,\nR., Lim, R., Arora, R., Troll, R., Lin, R., Lopes, R. G., Puri, R., Miyara, R., Leike, R., Gaubert, R.,\n14\n"
    },
    {
      "page_number": 15,
      "text": "Zamani, R., Wang, R., Donnelly, R., Honsby, R., Smith, R., Sahai, R., Ramchandani, R., Huet,\nR., Carmichael, R., Zellers, R., Chen, R., Chen, R., Nigmatullin, R., Cheu, R., Jain, S., Altman,\nS., Schoenholz, S., Toizer, S., Miserendino, S., Agarwal, S., Culver, S., Ethersmith, S., Gray, S.,\nGrove, S., Metzger, S., Hermani, S., Jain, S., Zhao, S., Wu, S., Jomoto, S., Wu, S., Shuaiqi, Xia,\nPhene, S., Papay, S., Narayanan, S., Coffey, S., Lee, S., Hall, S., Balaji, S., Broda, T., Stramer, T.,\nXu, T., Gogineni, T., Christianson, T., Sanders, T., Patwardhan, T., Cunninghman, T., Degry, T.,\nDimson, T., Raoux, T., Shadwell, T., Zheng, T., Underwood, T., Markov, T., Sherbakov, T., Rubin,\nT., Stasi, T., Kaftan, T., Heywood, T., Peterson, T., Walters, T., Eloundou, T., Qi, V., Moeller, V.,\nMonaco, V., Kuo, V., Fomenko, V., Chang, W., Zheng, W., Zhou, W., Manassra, W., Sheu, W.,\nZaremba, W., Patil, Y., Qian, Y., Kim, Y., Cheng, Y., Zhang, Y., He, Y., Zhang, Y., Jin, Y., Dai, Y.,\nand Malkov, Y. Gpt-4o system card, 2024. URL https://arxiv.org/abs/2410.21276.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. Language models are\nunsupervised multitask learners. OpenAI blog, 2019.\nSukhbaatar, S., Weston, J., Fergus, R., et al. End-to-end memory networks. Advances in neural\ninformation processing systems, 28, 2015.\nTeam, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivière, M.,\nKale, M. S., Love, J., Tafti, P., Hussenot, L., Sessa, P. G., Chowdhery, A., Roberts, A., Barua,\nA., Botev, A., Castro-Ros, A., Slone, A., Héliou, A., Tacchetti, A., Bulanova, A., Paterson, A.,\nTsai, B., Shahriari, B., Lan, C. L., Choquette-Choo, C. A., Crepy, C., Cer, D., Ippolito, D., Reid,\nD., Buchatskaya, E., Ni, E., Noland, E., Yan, G., Tucker, G., Muraru, G.-C., Rozhdestvenskiy,\nG., Michalewski, H., Tenney, I., Grishchenko, I., Austin, J., Keeling, J., Labanowski, J., Lespiau,\nJ.-B., Stanway, J., Brennan, J., Chen, J., Ferret, J., Chiu, J., Mao-Jones, J., Lee, K., Yu, K.,\nMillican, K., Sjoesund, L. L., Lee, L., Dixon, L., Reid, M., Mikuła, M., Wirth, M., Sharman, M.,\nChinaev, N., Thain, N., Bachem, O., Chang, O., Wahltinez, O., Bailey, P., Michel, P., Yotov, P.,\nChaabouni, R., Comanescu, R., Jana, R., Anil, R., McIlroy, R., Liu, R., Mullins, R., Smith, S. L.,\nBorgeaud, S., Girgin, S., Douglas, S., Pandya, S., Shakeri, S., De, S., Klimenko, T., Hennigan,\nT., Feinberg, V., Stokowiec, W., hui Chen, Y., Ahmed, Z., Gong, Z., Warkentin, T., Peran, L.,\nGiang, M., Farabet, C., Vinyals, O., Dean, J., Kavukcuoglu, K., Hassabis, D., Ghahramani, Z.,\nEck, D., Barral, J., Pereira, F., Collins, E., Joulin, A., Fiedel, N., Senter, E., Andreev, A., and\nKenealy, K. Gemma: Open models based on gemini research and technology, 2024a. URL\nhttps://arxiv.org/abs/2403.08295.\nTeam, G., Riviere, M., Pathak, S., Sessa, P. G., Hardin, C., Bhupatiraju, S., Hussenot, L., Mesnard, T.,\nShahriari, B., Ramé, A., Ferret, J., Liu, P., Tafti, P., Friesen, A., Casbon, M., Ramos, S., Kumar, R.,\nLan, C. L., Jerome, S., Tsitsulin, A., Vieillard, N., Stanczyk, P., Girgin, S., Momchev, N., Hoffman,\nM., Thakoor, S., Grill, J.-B., Neyshabur, B., Bachem, O., Walton, A., Severyn, A., Parrish, A.,\nAhmad, A., Hutchison, A., Abdagic, A., Carl, A., Shen, A., Brock, A., Coenen, A., Laforge, A.,\nPaterson, A., Bastian, B., Piot, B., Wu, B., Royal, B., Chen, C., Kumar, C., Perry, C., Welty,\nC., Choquette-Choo, C. A., Sinopalnikov, D., Weinberger, D., Vijaykumar, D., Rogozi´nska, D.,\nHerbison, D., Bandy, E., Wang, E., Noland, E., Moreira, E., Senter, E., Eltyshev, E., Visin, F.,\nRasskin, G., Wei, G., Cameron, G., Martins, G., Hashemi, H., Klimczak-Pluci´nska, H., Batra,\nH., Dhand, H., Nardini, I., Mein, J., Zhou, J., Svensson, J., Stanway, J., Chan, J., Zhou, J. P.,\nCarrasqueira, J., Iljazi, J., Becker, J., Fernandez, J., van Amersfoort, J., Gordon, J., Lipschultz,\nJ., Newlan, J., yeong Ji, J., Mohamed, K., Badola, K., Black, K., Millican, K., McDonell, K.,\nNguyen, K., Sodhia, K., Greene, K., Sjoesund, L. L., Usui, L., Sifre, L., Heuermann, L., Lago, L.,\nMcNealus, L., Soares, L. B., Kilpatrick, L., Dixon, L., Martins, L., Reid, M., Singh, M., Iverson,\nM., Görner, M., Velloso, M., Wirth, M., Davidow, M., Miller, M., Rahtz, M., Watson, M., Risdal,\nM., Kazemi, M., Moynihan, M., Zhang, M., Kahng, M., Park, M., Rahman, M., Khatwani, M.,\nDao, N., Bardoliwalla, N., Devanathan, N., Dumai, N., Chauhan, N., Wahltinez, O., Botarda, P.,\nBarnes, P., Barham, P., Michel, P., Jin, P., Georgiev, P., Culliton, P., Kuppala, P., Comanescu, R.,\nMerhej, R., Jana, R., Rokni, R. A., Agarwal, R., Mullins, R., Saadat, S., Carthy, S. M., Cogan,\nS., Perrin, S., Arnold, S. M. R., Krause, S., Dai, S., Garg, S., Sheth, S., Ronstrom, S., Chan, S.,\nJordan, T., Yu, T., Eccles, T., Hennigan, T., Kocisky, T., Doshi, T., Jain, V., Yadav, V., Meshram, V.,\nDharmadhikari, V., Barkley, W., Wei, W., Ye, W., Han, W., Kwon, W., Xu, X., Shen, Z., Gong,\nZ., Wei, Z., Cotruta, V., Kirk, P., Rao, A., Giang, M., Peran, L., Warkentin, T., Collins, E., Barral,\nJ., Ghahramani, Z., Hadsell, R., Sculley, D., Banks, J., Dragan, A., Petrov, S., Vinyals, O., Dean,\nJ., Hassabis, D., Kavukcuoglu, K., Farabet, C., Buchatskaya, E., Borgeaud, S., Fiedel, N., Joulin,\n15\n"
    },
    {
      "page_number": 16,
      "text": "A., Kenealy, K., Dadashi, R., and Andreev, A. Gemma 2: Improving open language models at a\npractical size, 2024b. URL https://arxiv.org/abs/2408.00118.\nTeam, Q. Qwen3: Think deeper, act faster. https://qwenlm.github.io/blog/qwen3/, 2025.\nAccessed: 2025-04-29.\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal,\nN., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G. Llama: Open and\nefficient foundation language models, 2023a. URL https://arxiv.org/abs/2302.13971.\nTouvron, H., Martin, L., Stone, K. R., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S.,\nBhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D.,\nFernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini,\nS., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I. M., Korenev, A., Koura,\nP. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov,\nT., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten,\nA., Silva, R., Smith, E. M., Subramanian, R., Tan, X., Tang, B., Taylor, R., Williams, A., Kuan,\nJ. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A.,\nStojnic, R., Edunov, S., and Scialom, T. Llama 2: Open foundation and fine-tuned chat models.\narXiv preprint arXiv:2307.09288, 2023b.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and\nPolosukhin, I. Attention is all you need. Advances in neural information processing systems, 30,\n2017.\nWang, B. and Komatsuzaki, A. Gpt-j-6b: A 6 billion parameter autoregressive language model, May\n2021. URL https://github.com/kingoflolz/mesh-transformer-jax. Accessed: Jan 29,\n2025.\nYang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li, C., Li, C., Liu, D., Huang, F., Dong,\nG., Wei, H., Lin, H., Tang, J., Wang, J., Yang, J., Tu, J., Zhang, J., Ma, J., Yang, J., Xu, J., Zhou,\nJ., Bai, J., He, J., Lin, J., Dang, K., Lu, K., Chen, K., Yang, K., Li, M., Xue, M., Ni, N., Zhang,\nP., Wang, P., Peng, R., Men, R., Gao, R., Lin, R., Wang, S., Bai, S., Tan, S., Zhu, T., Li, T., Liu,\nT., Ge, W., Deng, X., Zhou, X., Ren, X., Zhang, X., Wei, X., Ren, X., Liu, X., Fan, Y., Yao, Y.,\nZhang, Y., Wan, Y., Chu, Y., Liu, Y., Cui, Z., Zhang, Z., Guo, Z., and Fan, Z. Qwen2 technical\nreport, 2024. URL https://arxiv.org/abs/2407.10671.\nYin, F., Srinivasa, J., and Chang, K.-W.\nCharacterizing truthfulness in large language model\ngenerations with local intrinsic dimension. In ICML, 2024. URL https://openreview.net/\nforum?id=7DbIyQlfaO.\nYu, L., Cao, M., Cheung, J. C. K., and Dong, Y. Mechanisms of non-factual hallucinations in\nlanguage models. arXiv preprint arXiv:2403.18167, 2024.\nZhang, W., Aljunied, M., Gao, C., Chia, Y. K., and Bing, L. M3exam: A multilingual, multimodal,\nmultilevel benchmark for examining large language models. Advances in Neural Information\nProcessing Systems, 36:5484–5505, 2023.\n16\n"
    },
    {
      "page_number": 17,
      "text": "A\nDetails of Dataset\nA.1\nDataset Construction Prompts\nBelow is our prompt for querying GPT-4o to generate the options for Multi-Choice questions of each\nconcept:\nPlease provide four answer options (A, B, C, D) for the following\nquestion, and indicate the correct answer.\nExample:\nQuestion:\n’When\nwas Costa Coffee founded?’\nOptions:\nA) 1971 B) 1985 C) 1992 D) 2000\nCorrect Answer:\nA) 1971\nNow, please answer the following question:\nQuestion:\nQuestion\nOptions:\nBelow is our prompt for querying the model to generate the answers for Multi-choice questions in\nthree-shot setting:\n**Question:** What is the capital city of France?\n**Options:** A.\nBerlin B. Madrid C. Paris D. Rome **Answer:** C\n**Question:** What is the largest planet in our solar system?\n**Options:** A. Earth B. Jupiter C. Mars D. Venus **Answer:** B\n**Question:** Which element has the chemical symbol \"O\"?\n**Options:**\nA. Oxygen B. Gold C. Silver D. Iron **Answer:** A\n**Question:** question **Options:** A. option a B. option b C. option\nc D. option d\nBelow is our prompt for collecting the coefficients in model when querying about concept-reated\nknowledge:\nQuestion:\nquestion Answer:\nanswer:\nA.2\nManual Verification\nHere, we describe the manual verification process used in constructing SpecWiki, including the\nvalidation of model-generated data:\nSpecifically, we analyze a subset of 524 (10%) questions from SpecWiki, by sampling 50% of the\nconcepts and randomly selecting 2 questions per concept. Then, we manually verify that the questions\nare about the given concept and that they are simple and reasonable. In addition, we review all the\ngenerated questions for 200 sampled concepts and verify they are not repetitive. We find that all\nanalyzed questions were about the given concept and that 522 (99%) of them are reasonable simple\nquestions. Moreover, we observe that questions are generally diverse, with only 1 out of 20 concepts\nhaving 2 (out of 10) similar questions. This shows that our data generation process produces valid\nand diverse instances for evaluation.\nA.3\nDataset Categories and Examples\nHere, we provided a more detailed distribution of the categories and the corresponding example data\nof SpecWiki dataset in Table 4 and Table 5, respectively.\nA.4\nValidation of Popularity-Frequency Correlation\nWe included a simple experiment to validate the strong correlation between the popularity of concepts\nand their frequency in the pretraining data. To be specific, we used The Pile(Gao et al., 2020),\nwhich currently serves as a significant portion of the pretraining dataset for most large language\nmodels(Touvron et al., 2023a; Groeneveld et al., 2024; Team et al., 2024a), as an example of a\npretraining corpus. We then counted the frequency with which each of the 525 concepts from\nSpecWiki appeared in all text segments of The Pile dataset via the Elasticsearch API(Elazar et al.,\n2024). Subsequently, we compared these frequencies with the popularity metrics for each concept and\n17\n"
    },
    {
      "page_number": 18,
      "text": "0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nSpecWiki Performance (Open-ended Generations)\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\n0.16\nParameter Specialization Score(PSS)\nQwen1.5-7B\nQwen2-7B\nQwen2.5-7B\nLLaMA-7B\nLLaMA2-7B\nLLaMA3-8B\nOLMo-7B\nOLMo-2-7B\nGemma-7B\nGemma2-9B\nMistral-7B-v0.1\nMistral-7B-v0.2\nMistral-7B-v0.3\nYi-6B\nYi-1.5-6B\nFalcon-7B\nGPT-J-6B\nPythia-6.9B\nMpt-7B\nQwen3-8B\nPearson R: 0.88 (p=3.75e-07)\nSpearman : 0.84 (p=3.29e-06)\nSpecWiki Performance vs Parameter Specialization Score\nTrendline\n2021-06-09\n2022-05-30\n2023-05-20\n2024-05-09\n2025-04-29\nRelease Date\nFigure 6: Performance across 20 models on Parameter Specialization Scores on Open-ended Genera-\ntion Setting.\ncomputed the corresponding Spearman’s rank correlation coefficient. The result is 0.814, indicating a\nstrong correlation.\nAdditionally, Table 3 presents the top 3 most popular and the bottom 3 least popular concept examples\nin SpecWiki, along with their occurrence counts in The Pile dataset and their corresponding popularity\nscores.\nTop 3 High Popularity Example Concept\nFrequency\nPopularity\nWikipedia\n911708\n1414686\nBarack Obama\n984586\n1128538\nIndia\n3839241\n1024513\nBottom 3 Low Popularity Example Concept\nFrequency\nPopularity\nDark Souls (video game)\n49\n27\nCulture of Latin America\n251\n90\nArray (data structure)\n1164\n94\nTable 3: Top and bottom 3 concepts ranked by popularity and their corresponding frequencies.\nB\nDetails of Experiments\nB.1\nThe implementation of the models\nFor all models, the inference is performed in a text completion/generation mode, without the addition\nof any instruction tokens, to better assess the knowledge present in the model. For the Multi-Choice\nQuestions task, we use a three-shot setup for each model and search for the answer within the next\n30 tokens generated by the model. For the open-ended generation task, we prompt the model in a\nzero-shot setting to produce an answer no longer than 150 tokens.\nAll the experiments in this work were conducted on four 80GB NVIDIA A800 GPUs.\nB.2\nParameter Specialization Scores on OEG Setting\nIn Figure 6 we provided the performance across 20 models on Parameter Specialization Scores on\nOpen-ended Generation Setting.\n18\n"
    },
    {
      "page_number": 19,
      "text": "High Frequency\nMedium Frequency\nLow Frequency\n(Number of Concepts: 181)\n(Number of Concepts: 191)\n(Number of Concepts: 153)\nCountry\n13.3%\nTechnology\n7.6%\nTechnology\n19.9%\nMathematics\n4.4%\nPerson\n21.9%\nBrand/Product\n6.3%\nCulture\n9.5%\nBrand/Product\n7.6%\nArt and Entertainment\n11.1%\nPolitics\n4.4%\nHistory\n10.6%\nMedical\n5.5%\nLocation\n8.6%\nPerson\n6.7%\nNatural Sciences\n10.5%\nLocation\n4.4%\nEntertainment\n8.6%\nCulture\n2.9%\nHistory\n8.6%\nMedical\n6.7%\nMedical/Biology\n7.7%\nCountry\n3.9%\nCompany/Organization\n7.3%\nOthers\n2.3%\nSports\n7.6%\nEntertainment\n6.7%\nCulture\n7.2%\nCompany/Organization\n3.3%\nOthers\n6.3%\nNatural Sciences\n2.1%\nTable 4: Ten most frequent concept categories of SpecWiki in high frequency, medium frequency,\nand low frequency levels.\nExample Concept\nFrequency Level\nCategory\nExample Multi-Choice QA\nExample Open-ended Generation\nThe Lord of the Rings\nHigh\nMonthly Views: 177540\nArt and Enter-\ntainment\nQuestion: \"Who is the main protagonist of ’The Lord of the Rings’?\",\nOptions: A: \"Frodo Baggins\", B: \"Gandalf the Grey\", C: \"Aragorn\", D:\n\"Legolas\".\nAnswer: A\nQuestion: \"Who is the author of ’The Lord of\nthe Rings’ trilogy?\"\nAnswer: \"J.R.R. Tolkien.\"\nDetritivore\nMedium\nMonthly Views: 11810\nBiology\nQuestion: \"What do detritivores consume to obtain nutrients?\",\nOptions: A: \"Fresh, living plants and animals\", B: \"Detritus, including\ndecomposing plant and animal parts and feces\", C: \"Sunlight and water\",\nD: \"Inorganic minerals and metals\".\nAnswer: B\nQuestion: \"What term is used for the consump-\ntion of dead wood by detritivores?\"\nAnswer: \"Sapro-xylophagy.\"\nMaluma\nLow\nMonthly Views: 2252\nPerson\nQuestion: \"In which city was Maluma born and raised?\"\nOptions: A: \"Bogotá\", B: \"Cali\", C: \"Medellín\", D: \"Cartagena\".\nAnswer: C\nQuestion: \"What is the name of Maluma’s 2023\nalbum?\"\nAnswer: \"Don Juan\"\nTable 5: Example data from the SpecWiki dataset.\nB.3\nHallucination Metric Descriptions\nIn this experiment, we additionally incorporate two metrics, Semantic Entropy (Kuhn et al., 2022)\nand Local Intrinsic Dimension (LID) (Yin et al., 2024), to assess hallucination. This helps evaluate\nwhether the finetuning methods that enhance Parameter Specialization also effectively mitigate the\nunintended side effect of hallucination in the model’s output.\nSemantic Entropy\nSemantic entropy is defined as a measure of uncertainty based on the distri-\nbution of semantically equivalent outputs. In this method, the outputs are grouped into clusters of\nsemantically similar responses, and the entropy is calculated among these groups. Formally, it is\nexpressed as:\nSemantic Entropy =\n1\n|C|\n|C|\nX\ni=1\nlog p(Ci|x)\nwhere Ci represents the summed likelihood of outputs in the i-th group, and |C| is the total number\nof such groups. The measure captures the uncertainty not in individual responses but within clusters\nof semantically similar outputs. This approach accounts for semantic equivalence among different\nresponses, providing a more robust evaluation of entropy in generative tasks.\nLocal Intrinsic Dimension\nThe Local Intrinsic Dimension (LID) method detects hallucinations\nin Large Language Models by measuring the discrepancy in the local intrinsic dimension of model\nactivations. This approach is grounded in the principle that LID represents the minimal number of\nactivations required to characterize a data point, with truthful outputs exhibiting lower LID values\ndue to their closer alignment with natural language structure, while hallucinated outputs tend to\nshow higher LID values due to mixing human prompt and model distributions. Technically, the\nmethod employs Maximum Likelihood Estimation (MLE) using a Poisson process to approximate\nthe count of neighbors surrounding sample points, computed through the formula m(Xi) = (1/(T −\n1) ∗P(log(QT /Qj)))−1, where T represents the number of nearest neighbors and Qj denotes the\nEuclidean distance to the j-th nearest neighbor. For more details about the Local Intrinsic Dimension\nmetric, please refer to the work (Yin et al., 2024).\n19\n"
    },
    {
      "page_number": 20,
      "text": "NeurIPS Paper Checklist\n1. Claims\nQuestion: Do the main claims made in the abstract and introduction accurately reflect the\npaper’s contributions and scope?\nAnswer: [Yes]\nJustification: The abstract and the introduction in the paper clearly state the claims, contri-\nbutions and scope of our work.\nGuidelines:\n• The answer NA means that the abstract and introduction do not include the claims\nmade in the paper.\n• The abstract and/or introduction should clearly state the claims made, including the\ncontributions made in the paper and important assumptions and limitations. A No or\nNA answer to this question will not be perceived well by the reviewers.\n• The claims made should match theoretical and experimental results, and reflect how\nmuch the results can be expected to generalize to other settings.\n• It is fine to include aspirational goals as motivation as long as it is clear that these goals\nare not attained by the paper.\n2. Limitations\nQuestion: Does the paper discuss the limitations of the work performed by the authors?\nAnswer: [Yes]\nJustification: We discuss the limitations of the work in §7.\nGuidelines:\n• The answer NA means that the paper has no limitation while the answer No means that\nthe paper has limitations, but those are not discussed in the paper.\n• The authors are encouraged to create a separate \"Limitations\" section in their paper.\n• The paper should point out any strong assumptions and how robust the results are to\nviolations of these assumptions (e.g., independence assumptions, noiseless settings,\nmodel well-specification, asymptotic approximations only holding locally). The authors\nshould reflect on how these assumptions might be violated in practice and what the\nimplications would be.\n• The authors should reflect on the scope of the claims made, e.g., if the approach was\nonly tested on a few datasets or with a few runs. In general, empirical results often\ndepend on implicit assumptions, which should be articulated.\n• The authors should reflect on the factors that influence the performance of the approach.\nFor example, a facial recognition algorithm may perform poorly when image resolution\nis low or images are taken in low lighting. Or a speech-to-text system might not be\nused reliably to provide closed captions for online lectures because it fails to handle\ntechnical jargon.\n• The authors should discuss the computational efficiency of the proposed algorithms\nand how they scale with dataset size.\n• If applicable, the authors should discuss possible limitations of their approach to\naddress problems of privacy and fairness.\n• While the authors might fear that complete honesty about limitations might be used by\nreviewers as grounds for rejection, a worse outcome might be that reviewers discover\nlimitations that aren’t acknowledged in the paper. The authors should use their best\njudgment and recognize that individual actions in favor of transparency play an impor-\ntant role in developing norms that preserve the integrity of the community. Reviewers\nwill be specifically instructed to not penalize honesty concerning limitations.\n3. Theory assumptions and proofs\nQuestion: For each theoretical result, does the paper provide the full set of assumptions and\na complete (and correct) proof?\nAnswer: [NA]\n20\n"
    },
    {
      "page_number": 21,
      "text": "Justification: Our work does not include any theoretical analysis or formal results.\nGuidelines:\n• The answer NA means that the paper does not include theoretical results.\n• All the theorems, formulas, and proofs in the paper should be numbered and cross-\nreferenced.\n• All assumptions should be clearly stated or referenced in the statement of any theorems.\n• The proofs can either appear in the main paper or the supplemental material, but if\nthey appear in the supplemental material, the authors are encouraged to provide a short\nproof sketch to provide intuition.\n• Inversely, any informal proof provided in the core of the paper should be complemented\nby formal proofs provided in appendix or supplemental material.\n• Theorems and Lemmas that the proof relies upon should be properly referenced.\n4. Experimental result reproducibility\nQuestion: Does the paper fully disclose all the information needed to reproduce the main ex-\nperimental results of the paper to the extent that it affects the main claims and/or conclusions\nof the paper (regardless of whether the code and data are provided or not)?\nAnswer: [Yes]\nJustification: We provide sufficient details in §3.4 and §4 to ensure that our datasets and\nexperiments are fully reproducible.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• If the paper includes experiments, a No answer to this question will not be perceived\nwell by the reviewers: Making the paper reproducible is important, regardless of\nwhether the code and data are provided or not.\n• If the contribution is a dataset and/or model, the authors should describe the steps taken\nto make their results reproducible or verifiable.\n• Depending on the contribution, reproducibility can be accomplished in various ways.\nFor example, if the contribution is a novel architecture, describing the architecture fully\nmight suffice, or if the contribution is a specific model and empirical evaluation, it may\nbe necessary to either make it possible for others to replicate the model with the same\ndataset, or provide access to the model. In general. releasing code and data is often\none good way to accomplish this, but reproducibility can also be provided via detailed\ninstructions for how to replicate the results, access to a hosted model (e.g., in the case\nof a large language model), releasing of a model checkpoint, or other means that are\nappropriate to the research performed.\n• While NeurIPS does not require releasing code, the conference does require all submis-\nsions to provide some reasonable avenue for reproducibility, which may depend on the\nnature of the contribution. For example\n(a) If the contribution is primarily a new algorithm, the paper should make it clear how\nto reproduce that algorithm.\n(b) If the contribution is primarily a new model architecture, the paper should describe\nthe architecture clearly and fully.\n(c) If the contribution is a new model (e.g., a large language model), then there should\neither be a way to access this model for reproducing the results or a way to reproduce\nthe model (e.g., with an open-source dataset or instructions for how to construct\nthe dataset).\n(d) We recognize that reproducibility may be tricky in some cases, in which case\nauthors are welcome to describe the particular way they provide for reproducibility.\nIn the case of closed-source models, it may be that access to the model is limited in\nsome way (e.g., to registered users), but it should be possible for other researchers\nto have some path to reproducing or verifying the results.\n5. Open access to data and code\nQuestion: Does the paper provide open access to the data and code, with sufficient instruc-\ntions to faithfully reproduce the main experimental results, as described in supplemental\nmaterial?\n21\n"
    },
    {
      "page_number": 22,
      "text": "Answer: [Yes]\nJustification: We release the code and datasets in the supplementary materials submitted\nalongside the main paper.\nGuidelines:\n• The answer NA means that paper does not include experiments requiring code.\n• Please see the NeurIPS code and data submission guidelines (https://nips.cc/\npublic/guides/CodeSubmissionPolicy) for more details.\n• While we encourage the release of code and data, we understand that this might not be\npossible, so “No” is an acceptable answer. Papers cannot be rejected simply for not\nincluding code, unless this is central to the contribution (e.g., for a new open-source\nbenchmark).\n• The instructions should contain the exact command and environment needed to run to\nreproduce the results. See the NeurIPS code and data submission guidelines (https:\n//nips.cc/public/guides/CodeSubmissionPolicy) for more details.\n• The authors should provide instructions on data access and preparation, including how\nto access the raw data, preprocessed data, intermediate data, and generated data, etc.\n• The authors should provide scripts to reproduce all experimental results for the new\nproposed method and baselines. If only a subset of experiments are reproducible, they\nshould state which ones are omitted from the script and why.\n• At submission time, to preserve anonymity, the authors should release anonymized\nversions (if applicable).\n• Providing as much information as possible in supplemental material (appended to the\npaper) is recommended, but including URLs to data and code is permitted.\n6. Experimental setting/details\nQuestion: Does the paper specify all the training and test details (e.g., data splits, hyper-\nparameters, how they were chosen, type of optimizer, etc.) necessary to understand the\nresults?\nAnswer: [Yes]\nJustification: We provide detailed specifications of all training and evaluation settings in\n§4.1 and §B.1.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The experimental setting should be presented in the core of the paper to a level of detail\nthat is necessary to appreciate the results and make sense of them.\n• The full details can be provided either with the code, in appendix, or as supplemental\nmaterial.\n7. Experiment statistical significance\nQuestion: Does the paper report error bars suitably and correctly defined or other appropriate\ninformation about the statistical significance of the experiments?\nAnswer: [Yes]\nJustification: We include error analysis to support the main experiments in our paper,\nspecifically in §4.3 and §5.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The authors should answer \"Yes\" if the results are accompanied by error bars, confi-\ndence intervals, or statistical significance tests, at least for the experiments that support\nthe main claims of the paper.\n• The factors of variability that the error bars are capturing should be clearly stated (for\nexample, train/test split, initialization, random drawing of some parameter, or overall\nrun with given experimental conditions).\n• The method for calculating the error bars should be explained (closed form formula,\ncall to a library function, bootstrap, etc.)\n22\n"
    },
    {
      "page_number": 23,
      "text": "• The assumptions made should be given (e.g., Normally distributed errors).\n• It should be clear whether the error bar is the standard deviation or the standard error\nof the mean.\n• It is OK to report 1-sigma error bars, but one should state it. The authors should\npreferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis\nof Normality of errors is not verified.\n• For asymmetric distributions, the authors should be careful not to show in tables or\nfigures symmetric error bars that would yield results that are out of range (e.g. negative\nerror rates).\n• If error bars are reported in tables or plots, The authors should explain in the text how\nthey were calculated and reference the corresponding figures or tables in the text.\n8. Experiments compute resources\nQuestion: For each experiment, does the paper provide sufficient information on the com-\nputer resources (type of compute workers, memory, time of execution) needed to reproduce\nthe experiments?\nAnswer: [Yes]\nJustification: We provide sufficient details on the replication of the experiments in §B.1 in\nAppendix.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n• The paper should indicate the type of compute workers CPU or GPU, internal cluster,\nor cloud provider, including relevant memory and storage.\n• The paper should provide the amount of compute required for each of the individual\nexperimental runs as well as estimate the total compute.\n• The paper should disclose whether the full research project required more compute\nthan the experiments reported in the paper (e.g., preliminary or failed experiments that\ndidn’t make it into the paper).\n9. Code of ethics\nQuestion: Does the research conducted in the paper conform, in every respect, with the\nNeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?\nAnswer: [Yes]\nJustification: We affirm that our research fully complies with the NeurIPS Code of Ethics.\nGuidelines:\n• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.\n• If the authors answer No, they should explain the special circumstances that require a\ndeviation from the Code of Ethics.\n• The authors should make sure to preserve anonymity (e.g., if there is a special consid-\neration due to laws or regulations in their jurisdiction).\n10. Broader impacts\nQuestion: Does the paper discuss both potential positive societal impacts and negative\nsocietal impacts of the work performed?\nAnswer: [NA]\nJustification: Our research focuses on the interpretability of internal model parameters and\ndoes not have direct societal impact.\nGuidelines:\n• The answer NA means that there is no societal impact of the work performed.\n• If the authors answer NA or No, they should explain why their work has no societal\nimpact or why the paper does not address societal impact.\n• Examples of negative societal impacts include potential malicious or unintended uses\n(e.g., disinformation, generating fake profiles, surveillance), fairness considerations\n(e.g., deployment of technologies that could make decisions that unfairly impact specific\ngroups), privacy considerations, and security considerations.\n23\n"
    },
    {
      "page_number": 24,
      "text": "• The conference expects that many papers will be foundational research and not tied\nto particular applications, let alone deployments. However, if there is a direct path to\nany negative applications, the authors should point it out. For example, it is legitimate\nto point out that an improvement in the quality of generative models could be used to\ngenerate deepfakes for disinformation. On the other hand, it is not needed to point out\nthat a generic algorithm for optimizing neural networks could enable people to train\nmodels that generate Deepfakes faster.\n• The authors should consider possible harms that could arise when the technology is\nbeing used as intended and functioning correctly, harms that could arise when the\ntechnology is being used as intended but gives incorrect results, and harms following\nfrom (intentional or unintentional) misuse of the technology.\n• If there are negative societal impacts, the authors could also discuss possible mitigation\nstrategies (e.g., gated release of models, providing defenses in addition to attacks,\nmechanisms for monitoring misuse, mechanisms to monitor how a system learns from\nfeedback over time, improving the efficiency and accessibility of ML).\n11. Safeguards\nQuestion: Does the paper describe safeguards that have been put in place for responsible\nrelease of data or models that have a high risk for misuse (e.g., pretrained language models,\nimage generators, or scraped datasets)?\nAnswer: [NA]\nJustification: The paper poses no such risks.\nGuidelines:\n• The answer NA means that the paper poses no such risks.\n• Released models that have a high risk for misuse or dual-use should be released with\nnecessary safeguards to allow for controlled use of the model, for example by requiring\nthat users adhere to usage guidelines or restrictions to access the model or implementing\nsafety filters.\n• Datasets that have been scraped from the Internet could pose safety risks. The authors\nshould describe how they avoided releasing unsafe images.\n• We recognize that providing effective safeguards is challenging, and many papers do\nnot require this, but we encourage authors to take this into account and make a best\nfaith effort.\n12. Licenses for existing assets\nQuestion: Are the creators or original owners of assets (e.g., code, data, models), used in\nthe paper, properly credited and are the license and terms of use explicitly mentioned and\nproperly respected?\nAnswer: [Yes]\nJustification: For the usage of other assets, we clearly cite their original sources and indicate\nthe corresponding versions and licenses.\nGuidelines:\n• The answer NA means that the paper does not use existing assets.\n• The authors should cite the original paper that produced the code package or dataset.\n• The authors should state which version of the asset is used and, if possible, include a\nURL.\n• The name of the license (e.g., CC-BY 4.0) should be included for each asset.\n• For scraped data from a particular source (e.g., website), the copyright and terms of\nservice of that source should be provided.\n• If assets are released, the license, copyright information, and terms of use in the\npackage should be provided. For popular datasets, paperswithcode.com/datasets\nhas curated licenses for some datasets. Their licensing guide can help determine the\nlicense of a dataset.\n• For existing datasets that are re-packaged, both the original license and the license of\nthe derived asset (if it has changed) should be provided.\n24\n"
    },
    {
      "page_number": 25,
      "text": "• If this information is not available online, the authors are encouraged to reach out to\nthe asset’s creators.\n13. New assets\nQuestion: Are new assets introduced in the paper well documented and is the documentation\nprovided alongside the assets?\nAnswer: [Yes]\nJustification: We include the complete dataset in the supplementary materials, and provide\ndetailed information about its construction in §3.4.\nGuidelines:\n• The answer NA means that the paper does not release new assets.\n• Researchers should communicate the details of the dataset/code/model as part of their\nsubmissions via structured templates. This includes details about training, license,\nlimitations, etc.\n• The paper should discuss whether and how consent was obtained from people whose\nasset is used.\n• At submission time, remember to anonymize your assets (if applicable). You can either\ncreate an anonymized URL or include an anonymized zip file.\n14. Crowdsourcing and research with human subjects\nQuestion: For crowdsourcing experiments and research with human subjects, does the paper\ninclude the full text of instructions given to participants and screenshots, if applicable, as\nwell as details about compensation (if any)?\nAnswer: [NA]\nJustification: The paper does not involve crowdsourcing nor research with human subjects.\nGuidelines:\n• The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n• Including this information in the supplemental material is fine, but if the main contribu-\ntion of the paper involves human subjects, then as much detail as possible should be\nincluded in the main paper.\n• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,\nor other labor should be paid at least the minimum wage in the country of the data\ncollector.\n15. Institutional review board (IRB) approvals or equivalent for research with human\nsubjects\nQuestion: Does the paper describe potential risks incurred by study participants, whether\nsuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)\napprovals (or an equivalent approval/review based on the requirements of your country or\ninstitution) were obtained?\nAnswer: [NA]\nJustification: The paper does not involve crowdsourcing nor research with human subjects.\nGuidelines:\n• The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n• Depending on the country in which research is conducted, IRB approval (or equivalent)\nmay be required for any human subjects research. If you obtained IRB approval, you\nshould clearly state this in the paper.\n• We recognize that the procedures for this may vary significantly between institutions\nand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the\nguidelines for their institution.\n• For initial submissions, do not include any information that would break anonymity (if\napplicable), such as the institution conducting the review.\n25\n"
    },
    {
      "page_number": 26,
      "text": "16. Declaration of LLM usage\nQuestion: Does the paper describe the usage of LLMs if it is an important, original, or\nnon-standard component of the core methods in this research? Note that if the LLM is used\nonly for writing, editing, or formatting purposes and does not impact the core methodology,\nscientific rigorousness, or originality of the research, declaration is not required.\nAnswer: [Yes]\nJustification: We only used GPT-4o to assist in generating evaluation questions for the\ndataset, and included manually verified results in §A.2 of Appendix.\nGuidelines:\n• The answer NA means that the core method development in this research does not\ninvolve LLMs as any important, original, or non-standard components.\n• Please refer to our LLM policy (https://neurips.cc/Conferences/2025/LLM)\nfor what should or should not be described.\n26\n"
    }
  ]
}