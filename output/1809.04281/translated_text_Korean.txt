=== Page 1 ===  
MUSIC TRANSFORMER:  
GENERATING MUSIC WITH LONG-TERM STRUCTURE  
Cheng-Zhi Anna Huang∗Ashish Vaswani  
Jakob Uszkoreit  
Noam Shazeer  
Ian Simon  
Curtis Hawthorne  
Andrew M. Dai  
Matthew D. Hoffman  
Monica Dinculescu  
Douglas Eck  
Google Brain  
ABSTRACT  
음악은 구조와 의미를 구축하기 위해 반복에 크게 의존한다. 자기 참조는 모티프에서 구절, 그리고 ABA 구조가 있는 곡과 같은 음악의 전체 섹션을 재사용하는 것까지 여러 시간 척도에서 발생한다. 자기 주의에 기반한 순서 모델인 트랜스포머(Vaswani et al., 2017)는 장기 일관성을 유지해야 하는 많은 생성 작업에서 매력적인 결과를 달성했다. 이는 자기 주의가 음악 모델링에 잘 맞을 수 있음을 시사한다. 그러나 음악 작곡 및 연주에서 상대적 타이밍은 매우 중요하다. 트랜스포머에서 상대 위치 정보를 표현하기 위한 기존 접근 방식은 쌍별 거리를 기반으로 주의를 조절한다(Shaw et al., 2018). 이는 음악 작곡과 같은 긴 시퀀스에는 비현실적이다. 왜냐하면 중간 상대 정보에 대한 메모리 복잡도가 시퀀스 길이에 대해 제곱이기 때문이다. 우리는 중간 메모리 요구 사항을 시퀀스 길이에 대해 선형으로 줄이는 알고리즘을 제안한다. 이는 수정된 상대적 주의 메커니즘을 가진 트랜스포머가 매력적인 구조로 1분 길이의 작곡(수천 단계, Oore et al. (2018)에서 모델링된 길이의 네 배)을 생성하고, 주어진 모티프를 일관되게 발전시키는 연속을 생성하며, seq2seq 설정에서 멜로디에 조건화된 반주를 생성할 수 있음을 보여준다. 우리는 JSB 코랄과 피아노-e-경쟁의 두 데이터 세트에서 우리의 상대적 주의 메커니즘을 가진 트랜스포머를 평가하고 후자의 데이터 세트에서 최첨단 결과를 얻었다.  
1  
INTRODUCTION  
음악 작품은 종종 모티프에서 구절, 그리고 구절-후렴과 같은 섹션에 이르기까지 다양한 수준에서 반복되는 요소로 구성된다. 일관된 작품을 생성하기 위해 모델은 이전에 등장했던 요소를 참조해야 하며, 때로는 먼 과거에서 반복하고 변형하며 추가로 발전시켜 대비와 놀라움을 만들어야 한다. 직관적으로, 자기 주의(Parikh et al., 2016)는 이 작업에 잘 맞는 것으로 보인다. 자신의 이전 출력에 대한 자기 주의는 자가 회귀 모델이 생성의 모든 단계에서 이전에 생성된 출력의 어떤 부분에도 접근할 수 있게 한다. 반대로, 순환 신경망은 고정 크기 상태 또는 메모리에서 참조할 요소를 능동적으로 저장하는 방법을 학습해야 하므로 훈련이 훨씬 더 어려워질 수 있다. 우리는 트랜스포머 디코더(Vaswani et al., 2017)의 여러 연속적인 층에서 반복되는 자기 주의가 음악에서 자기 참조 현상이 존재하는 여러 수준을 포착하는 데 도움이 된다고 믿는다.  
트랜스포머의 원래 공식에서는 절대 위치 표현에 의존하며, 위치 사인 함수 또는 학습된 위치 임베딩을 사용하여 각 위치의 입력 표현에 추가한다. 반면, 순환 신경망과 합성곱 신경망은 상대적 관점에서 위치를 모델링한다: RNN은 입력의 위치에 대해 반복을 통해, CNN은 커널을 적용하여 커버된 입력 표현의 상대적 위치에 따라 적용할 매개변수를 효과적으로 선택한다.  
∗Google AI Resident. Correspondence to: Cheng-Zhi Anna Huang <annahuang@google.com>  
1샘플은 다음 링크에서 청취할 수 있다:  
https://storage.googleapis.com/music-transformer/index.html  
1  
arXiv:1809.04281v3  [cs.LG]  12 Dec 2018

=== Page 2 ===  
음악은 상대적 차이가 절대값보다 더 중요할 수 있는 여러 차원을 가지고 있으며, 가장 두드러진 두 가지는 타이밍과 피치이다. 이러한 표현 간의 쌍별 관계를 포착하기 위해 Shaw et al. (2018)는 두 위치 간의 거리로 자기 주의를 조절하는 관계 인식 버전을 도입하였다. 우리는 이 접근 방식을 확장하여 상대적 타이밍과 선택적으로 피치를 포착하며, 이는 JSB 코랄에서 샘플 품질과 당황도를 모두 개선하는 결과를 가져온다. 원래의 트랜스포머와 달리, 우리의 상대적 주의 메커니즘을 가진 트랜스포머에서 생성된 샘플은 이 데이터 세트에 존재하는 규칙적인 타이밍 그리드를 유지한다. 모델은 또한 전반적인 타이밍을 포착하여 규칙적인 구절을 생성한다.  
상대적 주의의 원래 공식 (Shaw et al., 2018)은 O(L2D) 메모리를 요구하며, 여기서 L은 시퀀스 길이이고 D는 모델의 숨겨진 상태의 차원이다. 이는 인간이 연주한 기교적인 클래식 피아노 음악의 Piano-e-Competition 데이터 세트와 같은 긴 시퀀스에는 금지적이다. 3.4절에서는 메모리 요구 사항을 O(LD)로 줄이는 방법을 보여주어, 긴 시퀀스에 상대적 주의를 적용하는 것이 실용적임을 입증한다.  
Piano-e-Competition 데이터 세트는 대회 참가자의 공연에서 기록된 MIDI로 구성되어 있으며, < 10 밀리초의 세분화에서 표현력 있는 다이내믹과 타이밍을 가지고 있다. 모든 사건이 동일한 시간 척도에서 변하지 않기 때문에 불필요하게 긴 시퀀스를 생성할 수 있는 고정 그리드에서 시간을 이산화하는 것은 바람직하지 않다. 따라서 우리는 (Oore et al., 2018)에서 제안한 희소한 MIDI 유사 이벤트 기반 표현을 채택하여, 10 밀리초 해상도의 1분 음악을 약 2K 길이로 표현할 수 있게 하며, 고정 그리드 표현에서의 여러 성능 속성으로 6K에서 18K에 이르는 것과 비교된다. 시퀀스 내의 위치가 더 이상 시간에 해당하지 않기 때문에, 상대적 주의가 이러한 표현에서도 잘 작동할 것이라는 것은 명백하지 않다. 그러나 4.2절에서 우리는 그것이 강력한 기준선에 비해 당황도와 샘플 품질을 개선한다는 것을 보여줄 것이다.  
우리는 스케일, 아르페지오 및 기타 모티프와 같은 관용적인 피아노 제스처가 특정 문법을 나타내고 주기적으로 반복된다고 추측한다. 따라서 이들의 상대적 위치 거리를 아는 것은 이러한 규칙성을 모델링하는 데 더 쉽게 만든다. 절대 위치에 기반한 패턴이 아닌 관계 정보를 학습하려는 이러한 귀납적 편향은 상대적 주의가 있는 트랜스포머가 훈련된 길이를 넘어 일반화할 수 있음을 시사하며, 이는 4.2.1절에서 우리의 실험이 확인한다.  
1.1  
기여  
도메인 기여  
우리는 장기 구조를 나타내는 음악을 생성하는 데 있어 트랜스포머의 첫 번째 성공적인 사용을 보여준다. 우리의 작업 이전에는 LSTM이 Piano-e-Competition 데이터 세트에서 15초(~500 토큰)의 시간 척도로 사용되었다 (Oore et al., 2018). 우리의 작업은 트랜스포머가 이러한 복잡한 표현력 있는 피아노 공연을 모델링하는 데 있어 최첨단 당황도를 달성할 뿐만 아니라, 60초(~2000 토큰)의 규모로 생성할 수 있으며, 놀라운 내부 일관성을 유지함을 보여준다. 우리의 상대적 주의 메커니즘은 모델의 품질에 필수적이다. 청취 테스트(4.2.3절 참조)에서 상대적 자기 주의가 있는 모델의 샘플은 Vaswani et al. (2017)의 기준 트랜스포머 모델보다 더 일관성 있게 인식되었다. 상대적 주의는 트랜스포머가 주어진 모티프를 발전시키는 연속을 생성할 수 있게 할 뿐만 아니라, 훈련된 길이를 넘어 일관된 방식으로 일반화하고 생성할 수 있게 한다(4.2.1절 참조). seq2seq 설정에서 트랜스포머는 멜로디에 조건화된 반주를 생성할 수 있어 사용자가 모델과 상호작용할 수 있게 한다.  
알고리즘 기여  
상대적 자기 주의 메커니즘의 원래 공식 (Shaw et al., 2018)에서의 공간 복잡성은 긴 음악 작품에서 장기 구조를 포착하기에 충분한 길이의 시퀀스에서 훈련하는 것을 불가능하게 만들었다. 이를 해결하기 위해 우리는 상대적 자기 주의 메커니즘에 중요한 알고리즘 개선을 제시하여, 메모리 요구 사항을 O(L2D)에서 O(LD)로 극적으로 줄인다. 예를 들어, 우리는 시퀀스 길이 L = 2048 및 숨겨진 상태 크기 D = 512(헤드당 Dh = D
H = 64, 헤드 수 H = 8)에서 레이어당 메모리 소비를 8.5 GB에서 4.2 MB(헤드당 1.1 GB에서 0.52 MB)로 줄인다(표 1 참조), 이를 통해 우리는 GPU를 사용하여 긴 시퀀스에서 상대적 자기 주의 트랜스포머를 훈련할 수 있게 된다.  
2  
관련 연구  
시퀀스 모델은 음악 모델링을 위한 전형적인 선택이었으며, 숨겨진 마르코프 모델에서 RNN 및 장단기 기억 네트워크(예: Eck & Schmidhuber, 2002; Liang, 2016; Oore et al., 2018), 양방향 LSTM(예: Hadjeres et al., 2017)까지 다양하다. 다성 음악에 대한 순차 모델의 성공적인 적용은 종종 음악 악보나 공연을 직렬화하는 것을 요구한다.

=== Page 3 ===  
하나의 시퀀스로 통합되며, 예를 들어 서로 다른 악기나 목소리를 교차 배치하는 방식으로 이루어진다. 또는 2D 피아노 롤과 같은 표현(자세한 내용은 A.1 참조)은 다중 핫 피치 벡터의 시퀀스로 분해될 수 있으며, 이들의 결합 확률 분포는 제한된 볼츠만 기계(Restricted Boltzmann Machines) (Smolensky, 1986; Hinton et al., 2006) 또는 신경 자가 회귀 분포 추정기(Neural Autoregressive Distribution Estimators, NADE; Larochelle & Murray, 2011)를 사용하여 포착할 수 있다. 피아노 롤은 이미지와 유사하며, 생성적 적대 신경망(Generative Adversarial Networks) (예: Dong et al., 2018) 또는 순서 없는 NADE (Uria et al., 2014; 2016)로 훈련된 CNN에 의해 모델링될 수 있다(예: Huang et al., 2017).  
Lattner et al. (2018)은 스타일 전이 방식에서 자기 유사성을 사용하며, 곡의 자기 유사성 구조가 입력 악보에 유사한 반복 구조를 부과하기 위한 경량 하강법의 템플릿 목표로 작용한다. 자기 주의는 자기 유사성의 일반화로 볼 수 있다; 전자는 입력을 다양한 프로젝션을 통해 쿼리와 키로 매핑하고, 후자는 두 가지 모두에 대해 동일한 프로젝션을 사용한다.  
점곱 자기 주의(Dot-product self-attention)는 트랜스포머의 핵심 메커니즘이며, 최근 몇몇 연구는 이미지 생성, 음성 및 요약을 위해 이를 적용하고 개선하는 데 집중하고 있다 (Parmar et al., 2018; Povey et al., 2018; Liu et al., 2018). 이러한 노력에서 직면한 주요 도전 과제는 긴 시퀀스에 대한 주의를 계산적으로 확장하는 것이다. 이는 자기 주의의 시간 및 공간 복잡도가 시퀀스 길이에 대해 제곱으로 증가하기 때문이다. 상대적 자기 주의(Shaw et al., 2018)의 경우, 이는 특히 문제가 되며, 공간 복잡도 또한 각 위치 표현의 차원 또는 깊이에 대해 선형으로 증가하기 때문이다.  
3  
모델  
3.1  
데이터 표현  
우리는 기호 음악을 위한 생성 모델 훈련에 언어 모델링 접근 방식을 취한다. 따라서 우리는 음악을 데이터 세트에 의해 결정된 어휘로 구성된 이산 토큰의 시퀀스로 표현한다. 서로 다른 장르의 데이터 세트는 다성 음악을 단일 스트림으로 직렬화하고 시간을 이산화하는 다양한 방법을 요구한다.  
JSB 코랄 데이터 세트는 네 부분으로 구성된 합창 음악으로, 이는 행이 목소리에 해당하고 열이 16분 음표로 이산화된 시간에 해당하는 행렬로 표현될 수 있다. 이 행렬의 항목은 어떤 피치가 연주되고 있는지를 나타내는 정수이다. 이 행렬은 먼저 행을 따라 내려간 다음 열을 통해 오른쪽으로 이동하여 래스터 스캔 방식으로 직렬화될 수 있다(자세한 내용은 A.1 참조). JSB 코랄과 비교할 때, 피아노-e-경쟁 데이터 세트의 피아노 공연 데이터는 훨씬 더 세밀한 표현력 있는 타이밍 정보와 더 많은 목소리를 포함한다. 따라서 우리는 Oore et al. (2018)에서 제안한 공연 인코딩을 사용하며, 이는 128개의 NOTE_ON 이벤트, 128개의 NOTE_OFF, 100개의 TIME_SHIFT를 포함하여 10ms에서 표현력 있는 타이밍을 가능하게 하고, 32개의 VELOCITY 빈을 통해 표현력 있는 다이내믹을 제공한다(자세한 내용은 A.2 참조).  
3.2  
배경: 트랜스포머의 자기 주의  
트랜스포머 디코더는 주로 자기 주의 메커니즘과 학습된 또는 사인 곱 위치 정보를 사용하는 자가 회귀 생성 모델이다. 각 층은 자기 주의 서브 레이어와 피드포워드 서브 레이어로 구성된다.  
주의 층은 먼저 L 차원의 D 차원 벡터 시퀀스 X = (x1, x2, . . . , xL)를 쿼리 Q = XW Q, 키 K = XW K, 값 V = XW V로 변환하며, 여기서 W Q, W K, W V는 각각 D × D 정사각형 행렬이다. 각 L × D 쿼리, 키 및 값 행렬은 H L × Dh 부분 또는 주의 헤드로 분할되며, h로 인덱스되고 차원 Dh = D/H를 가진다. 이를 통해 모델은 역사적 데이터의 서로 다른 부분에 집중할 수 있다. 스케일된 점곱 주의는 각 헤드에 대해 벡터 출력 시퀀스를 계산한다:  
Zh = Attention(Qh, Kh, V h) = Softmax  
QhKh⊤  
√Dh  
  
(1)  
각 헤드의 주의 출력은 연결되어 선형 변환을 거쳐 Z라는 L × D 차원 행렬을 생성한다. 상삼각 마스크는 쿼리가 시퀀스의 이후 키에 주의를 기울일 수 없도록 보장한다. 트랜스포머 모델의 잔여 연결 및 학습률과 같은 기타 세부 사항에 대해서는 Vaswani et al. (2017)을 참조할 수 있다. 피드포워드(FF) 서브 레이어는 그 다음 출력 Z를 취한다.

=== Page 4 ===  
이전 자기 주의 서브 레이어에서 출력된 Z를 취하고, 깊이 D 차원에서 두 개의 포인트별 밀집 레이어를 수행한다. 이는 식 (2)에서 보여준다. W1, W2, b1, b2는 이 두 레이어의 가중치와 편향이다.  
FF(Z) = ReLU(ZW1 + b1)W2 + b2  
(2)  
3.3  
상대 위치 자기 주의  
트랜스포머 모델이 타이밍 정보를 표현하기 위해 위치 사인 곱에만 의존하기 때문에, Shaw et al. (2018)은 두 위치 간의 거리에 의해 주의가 영향을 받을 수 있도록 상대 위치 표현을 도입하였다. 이는 쿼리 iq와 키 jk 간의 가능한 쌍별 거리 r = jk − iq에 대한 임베딩을 포함하는 별도의 상대 위치 임베딩 Er의 형태 (H, L, Dh)를 학습하는 것을 포함한다. 임베딩은 거리 −L + 1에서 0까지 정렬되며, 각 헤드에 대해 별도로 학습된다. Shaw et al. (2018)에서는 상대 임베딩이 쿼리와 상호작용하여 각 헤드의 주의 확률을 조절하는 L × L 차원의 로짓 행렬 Srel을 생성한다:  
RelativeAttention = Softmax  
QK⊤+ Srel  
√Dh  
  
V.  
(3)  
명확성을 위해 헤드 인덱스는 생략하였다. 우리의 작업은 주의 계산에 상대 거리 정보를 주입하기 위해 동일한 접근 방식을 사용하면서 Srel을 계산하는 메모리 사용량을 크게 개선한다. 각 헤드에 대해 Shaw et al. (2018)은 모든 키와 쿼리 간의 상대 거리와 관련된 임베딩을 포함하는 형태 (L, L, Dh)의 중간 텐서 R을 인스턴스화한다. 그런 다음 Q는 (L, 1, Dh) 텐서로 재구성되고, Srel = QR⊤가 된다. 이는 총 공간 복잡도 O(L2D)를 초래하여 긴 시퀀스에 대한 적용을 제한한다.  
3.4  
상대 위치 기반 주의의 메모리 효율적 구현  
우리는 상대 주의의 중간 메모리 요구 사항을 O(L2D)에서 O(LD)로 줄여 상대 주의의 구현을 개선한다. 예시 길이는 표 1에 나타나 있다. 우리는 QR⊤에서 필요한 모든 항이 상대 위치 임베딩 Er과 Q를 직접 곱하면 이미 사용 가능하다는 것을 관찰한다. QEr⊤를 계산한 후, 그 (iq, r) 항목은 위치 iq의 쿼리와 상대 거리 r의 임베딩 간의 내적을 포함한다. 그러나 식 (3)의 행렬 Srel에서 각 상대 로짓 (iq, jk)은 쿼리 iq의 위치와 상대 거리 jk − iq의 임베딩 간의 내적이어야 하며, 이는 QK⊤의 인덱싱과 일치해야 한다. 따라서 우리는 상대 로짓을 올바른 위치로 이동시키기 위해 QEr⊤를 "왜곡"해야 하며, 이는 그림 1에서 설명되고 다음 섹션에서 자세히 설명된다. 두 방법의 시간 복잡도는 O(L2D)이며, 실제로 우리의 방법은 길이 650에서 6배 더 빠르다.  
그림 1: 상대 전역 주의: 하단 행은 R을 인스턴스화할 필요가 없는 메모리 효율적인 "왜곡" 알고리즘을 설명하며, 이는 O(L2D)이다. 회색은 마스킹되거나 패딩된 위치를 나타낸다. 각 색상은 서로 다른 상대 거리에 해당한다.  
2여기서 배치 크기가 1이라고 가정한다. 배치 크기가 B일 경우, Q는 (L, B, Dh)로 재구성되고 Srel은 배치 행렬-행렬 곱으로 계산된다.  
4

=== Page 5 ===  
표 1: 전체 상대 메모리 복잡도(중간 상대 임베딩(R 또는 Er) + 상대 로짓 Srel), Dh = 64를 가정할 때 16GB 메모리에 맞는 최대 훈련 길이, 그리고 레이어당 헤드당 메모리 사용량(단위: MB)을 비교한 것이다.  
구현  
상대 메모리  
최대 L  
L = 650  
L = 2048  
L = 3500  
Shaw et al. (2018)  
O(L2D + L2)  
650  
108 + 1.7  
1100 + 16  
3100 + 49  
우리의 방법  
O(LD + L2)  
3500  
0.17 + 1.7  
0.52 + 16  
0.90 + 49  
3.4.1  
“왜곡” 절차  
따라서 우리는 절대-상대 (iq, r) 인덱스 행렬을 절대-절대 (iq, jk) 인덱스 행렬로 변환하기 위한 “왜곡” 절차를 제안한다. 행 인덱스 iq는 동일하게 유지되며, 열 인덱스는 다음 식에 따라 이동된다: jk = r −(L −1) + iq. 예를 들어, 그림 1에서 왜곡 후 QEr⊤의 (0, 2) 위치에 있는 상단 오른쪽 초록 점은 열 인덱스가 2 −(3 −1) + 0 = 0이 되어 Srel에서 (0, 0) 위치가 된다.  
아래에 그림 1에 설명된 단계를 요약한다.  
1. 가장 왼쪽 열 앞에 길이 L의 더미 열 벡터를 패딩한다.  
2. 행렬의 형태를 (L+1, L)로 변경한다. (이 단계는 NumPy 스타일의 행 우선 순서 정렬을 가정한다.)  
3. 해당 행렬을 슬라이스하여 마지막 l 행과 모든 열만 유지하여 다시 (L, L) 행렬을 생성하되, 이제는 절대-절대 인덱스가 되는 Srel을 얻는다.  
3.5  
상대적 지역 주의  
매우 긴 시퀀스의 경우, 기본 트랜스포머의 제곱 메모리 요구 사항은 비현실적이다. 지역 주의는 예를 들어 위키피디아와 이미지 생성(Liu et al., 2018; Parmar et al., 2018)에서 입력 시퀀스를 겹치지 않는 블록으로 나누어 사용되었다. 각 블록은 자기 자신과 이전 블록에 주의를 기울인다. 이는 그림 2의 오른쪽 상단 모서리에 있는 작은 썸네일에서 보여준다.  
상대 주의를 지역 사례로 확장하기 위해, 우리는 먼저 오른쪽 블록이 전역 사례(그림 1 참조)와 동일한 구성임을 주목하지만 훨씬 작다는 것을 알 수 있다: ( L  
M )² (여기서 M은 블록의 수이고, N은 결과 블록 길이)로 L²와는 다르다. 왼쪽 블록은 -1(오른쪽 상단)에서 -2N + 1(왼쪽 하단)까지의 상대 인덱스가 마스킹되지 않는다. 따라서 지역 사례에 대한 학습된 Er의 형태는 (2N −1, N)이다.  
전역 사례와 유사하게, 우리는 먼저 QEr⊤를 계산한 다음 그림 2에 설명된 절차를 사용하여 QK⊤와 동일한 인덱싱을 갖도록 왜곡한다.  
1. 가장 오른쪽 열 뒤에 길이 N의 더미 열 벡터를 패딩한다.  
2. 행렬을 평탄화한 다음 길이 N −1의 더미 행으로 패딩한다.  
3. 행렬의 형태를 (N + 1, 2N −1)로 변경한다.  
4. 해당 행렬을 슬라이스하여 처음 N 행과 마지막 N 열만 유지하여 (N, N) 행렬을 생성한다.  
그림 2: 상대 지역 주의: 오른쪽 썸네일은 Srel에 대한 원하는 구성을 보여준다. “왜곡” 절차는 왼쪽에서 오른쪽으로 표시된다.  
5

=== Page 6 ===  
4  
실험  
4.1  
J.S. 바흐 코랄  
J.S. 바흐 코랄은 음악 생성 모델을 평가하기 위해 사용되는 전통적인 데이터셋이다 3 (예: Allan & Williams, 2005; Boulanger-Lewandowski et al., 2012; Liang, 2016; Hadjeres et al., 2016; Huang et al., 2017). 이 데이터셋은 악보 기반의 4부 코랄로 구성된다. 우리는 먼저 악보를 16분 음표 그리드로 이산화한 다음, 모든 음성을 시간 단계 내에서 반복하며 직렬화한 후 시간을 진행시킨다 (자세한 내용은 A.1 참조). 시퀀스 내 위치와 작품의 타이밍/악기 그리드 내 위치 간에는 직접적인 대응 관계가 있으므로, 상대 위치 표현을 추가하면 이 문법을 배우는 것이 더 쉬워질 수 있다. 우리는 실제로 상대 주의가 기준 트랜스포머에 비해 음의 로그 우도(NLL)를 크게 개선하는 것을 확인하였다 (표 2). 이 개선은 샘플 품질에도 반영된다. 샘플은 이제 필요한 타이밍/악기 그리드를 유지하며, 항상 시간을 진행하기 전에 네 단계를 진행한다. 지역 타이밍이 유지되므로, 모델은 더 글로벌한 수준에서 타이밍을 포착할 수 있어 정규 구절을 생성하게 된다, 이는 그림 3에서 보여준다.  
그림 3: 상대 자기 주의가 없는 트랜스포머의 무조건 샘플(왼쪽)과 상대 자기 주의가 있는 샘플(오른쪽). 녹색 수직 상자는 카덴스가 유지되는 (서브)구절의 끝을 나타낸다.  
상대 주의 외에도, 우리는 입력 임베딩에 사인 곱을 추가하는 대신 연결하여 절대 타이밍을 향상시키는 방법도 탐구하였다. 이는 모델이 절대 위치 매핑을 더 직접적으로 학습할 수 있도록 한다. 이는 기준 및 상대 트랜스포머 모두의 성능을 더욱 개선한다 (표 2). 우리는 COCONET과 비교하는데, 이는 전통적인 데이터셋 분할을 사용하여 16음표 그리드에서 평가된 가장 성능이 좋은 모델 중 하나이기 때문이다. 직접 비교를 위해, 우리는 검증 세트에서 음 단위 손실을 얻기 위해 COCONET을 재평가하였다 4. 트랜스포머 모델(약칭 TF)에 대해, 우리는 Tensor2Tensor 프레임워크(Vaswani et al., 2018)에서 우리의 주의 메커니즘을 구현하였다. 우리는 8개의 헤드를 사용하고, 쿼리, 키(att) 및 값 숨겨진 크기(hs)를 구성 내에서 고정하였다. 우리는 레이어 수(L in {4,5,6}), 주의 숨겨진 크기(att in {256, 512}) 및 포인트별 피드포워드 숨겨진 크기(ff in {512, 1024})를 조정하였다.  
4.1.1  
관계 정보를 포착하기 위한 상대 주의의 일반화  
음악적 사건은 타이밍, 음높이, 악기 등 여러 속성을 지닌다. 더 많은 관계 정보를 포착하기 위해, 우리는 상대 주의를 확장하여 추가 속성의 쌍별 거리를 포착한다. 우리는 타이밍에 대한 별도의 상대 임베딩 Et와 음높이에 대한 상대 임베딩 Ep를 학습한다. Et는 두 위치가 얼마나 16분 음표로 떨어져 있는지를 나타내는 항목을 가지며, Ep는 쌍별 음높이 간격을 임베딩한다. 그러나 이 접근 방식은 J.S. 바흐 코랄을 넘어서는 확장이 직접적으로 불가능하다. 왜냐하면 Rt와 Rp에 대한 상대 임베딩을 명시적으로 수집해야 하며, 이는 Shaw et al. (2018)에서와 같이 메모리 복잡도 O(L2D)를 초래하기 때문이다. 이는 상대 정보가 시퀀스 내 위치와 같은 내용 불변 정보가 아닌 내용에 기반하여 계산되기 때문이다. 첫 번째 레이어에 추가 타이밍 신호를 추가하는 것으로 충분했으며, 아마도 이는 원시 입력 내용과 가장 가까웠기 때문이다. 여기서 상대 로짓은 세 항목에서 계산된다, Srel = Skew(QEr) + Q(Rt + Rp), 다른 레이어는 오직 하나의 항목인 Skew(QEr)만 가진다.  
4.2  
피아노-e-경쟁  
우리는 피아노-e-경쟁의 첫 6년을 사용한다. 이 해들은 MIDI 데이터가 공개되어 약 1100개의 작품으로 나뉘며, 80/10/10으로 분할된다. 각 작품은 표현력 있는 다이내믹과 타이밍을 가진 클래식 피아노 공연을 캡처한 MIDI 데이터로, MIDI와 유사한 표현으로 인코딩된다.  
3J.S. 바흐 코랄 데이터셋: https://github.com/czhuang/JSB-Chorales-dataset  
4일부 초기 논문에서는 "코드"를 모델링하는 RNN-RBM과 같은 모델과 비교하기 위해 프레임 단위 손실을 보고한다. Coconet은 음 단위 또는 프레임 단위 손실로 평가될 수 있다.  
5피아노-e-경쟁 데이터셋(경쟁 역사): http://www.piano-e-competition.com/  
6

=== Page 7 ===  
섹션 A.2에서 설명한 바와 같이, 우리는 2000 토큰 시퀀스의 무작위 크롭에 대해 훈련하였고, 두 가지 종류의 데이터 증강을 사용하였다: {−3, −2, . . . , 2, 3} 반음에서 균일하게 샘플링된 피치 전이와 {0.95, 0.975, 1.0, 1.025, 1.05} 집합에서 균일하게 샘플링된 시간 스트레치. 우리는 Magenta의 PerformanceRNN (LSTM, 이 데이터셋을 처음 사용한 모델) (Oore et al., 2018) 및 LookBack RNN (주의가 있는 LSTM) (Waite, 2016)과 비교한다. LookBack RNN은 바선이 있는 단음악을 요구하는 입력 표현을 사용하며, 이는 연주된 다성 음악 데이터에는 존재하지 않는 정보이므로, 우리는 단순히 그들의 아키텍처를 채택한다. 표 3은 트랜스포머 기반 아키텍처가 LSTM 기반 모델보다 이 데이터셋에 더 잘 맞음을 보여준다.  
표 2: 16분 음표에서 J.S. 바흐 코랄에 대한 음 단위 검증 NLL. 상대 주의, 더 많은 타이밍 및 관계 정보가 성능을 향상시킨다.  
모델 변형  
검증 NLL  
COCONET (CNN, 연대기, 64L, 128 3x3f)  
0.436  
COCONET (CNN, 순서 없는, 64L, 128 3x3f)  
≤0.238 6  
트랜스포머 (TF) 기준 (Vaswani et al., 2017) (5L, 256hs, 256att, 1024ff, 8h)  
0.417  
TF 기준 + 연결 위치 사인 함수 (cps)  
0.398  
TF 기준 + 연결 위치 사인 함수, 악기 레이블 (cpsi)  
0.370  
상대 트랜스포머 (Shaw et al., 2018) (5L, 512hs, 512att, 512ff, 256r, 8h)  
0.357  
상대 트랜스포머 + 연결 위치 사인 함수, 악기 레이블 (cpsi)  
0.347  
상대 트랜스포머 + cpsi + 상대 피치 및 시간  
0.335  
표 3: 이벤트 기반 표현을 가진 피아노-e-경쟁 데이터셋에 대한 검증 NLL, 길이 L = 2048. 상대 주의가 있는 트랜스포머 (우리의 효율적인 공식화)가 최첨단 성능을 달성한다.  
모델 변형  
검증 NLL  
PERFORMANCE RNN (LSTM) (3L, 1024hs)  
1.969  
주의가 있는 LSTM (3L, 1024hs, 1024att)  
1.959  
트랜스포머 (TF) 기준 (6L, 256hs, 512att, 2048fs, 1024r, 8h)  
1.861  
지역 주의가 있는 TF (Liu et al., 2018) (8L, 1024fs, 512bs)  
1.863  
상대 전역 주의가 있는 TF (우리의 효율적인 공식화) (6L, 2048fs, 1024r)  
1.835  
상대 지역 주의가 있는 TF (우리의) (6L, 1024fs, 2048r, 512bs)  
1.840  
우리는 Tensor2Tensor 프레임워크 (Vaswani et al., 2018)에서 우리의 주의 메커니즘을 구현하였고, 훈련을 위해 기본 하이퍼파라미터를 사용하였다. 학습률 0.1, 드롭아웃 0.1, 조기 중단을 적용하였다. 우리는 네 가지 아키텍처를 비교하였으며, 두 축에서 변형하였다: 전역 대 지역, 그리고 일반 대 상대 주의. 우리는 쿼리 및 키 숨겨진 크기 (att)를 숨겨진 크기 (hs)의 절반으로 줄이는 것이 잘 작동함을 발견하였고, 이 관계를 모든 모델에 사용하였으며, 레이어 수 (L) 및 필터 크기 (fs)를 조정하였다. 우리는 지역 주의에 대해 블록 크기 (bs) 512를 사용하였다. 상대 전역 주의의 경우 최대 상대 거리를 훈련 시퀀스 길이의 절반으로 설정하였고, 상대 지역 주의의 경우 전체 메모리 길이 (두 블록)로 설정하였다. 표 3은 상대 주의 (전역 또는 지역)가 일반 자기 주의 (전역 또는 지역)보다 우수함을 보여준다. 모든 것이 동일하다면, 지역 및 전역 주의는 유사한 성능을 보인다. 비록 지역 주의가 모든 이력을 한 번에 보지 않지만, 레이어를 통해 더 큰 수용 영역을 구축할 수 있다. 이는 지역 주의가 훨씬 적은 메모리를 요구하므로, 훨씬 긴 시퀀스에 대한 훈련에서 미래에 이점이 될 수 있다.  
6COCONET은 순서에 대한 앙상블인 OrderlessNADE의 인스턴스이다. 연대기 손실은 모델을 자기 회귀적으로 평가하며, 왼쪽에서 오른쪽으로 진행된다. 우리는 또한 여러 무작위 순서에 대한 손실을 평균하여 혼합으로 모델을 평가할 수 있다. 이는 로그 우도의 하한이다. 정확히 샘플링하는 것은 다루기 어렵지만, 깁스 샘플링을 통해 근사할 수 있다.  
7

=== Page 8 ===  
그림 4: 모델이 프라임을 계속하는 방식을 비교한 것 (왼쪽 상단). 상대 주의가 있는 트랜스포머 샘플에서는 반복되는 모티프와 구조가 보이지만 (상단 행), 기준 트랜스포머 (중간 행)와 PerformanceRNN (LSTM) (하단 행)에서는 덜 나타난다.  
4.2.1  
정성적 프라이밍 실험  
그림 4의 왼쪽 상단 모서리에 표시된 초기 모티프(쇼팽의 에튀드 Op. 10, No. 5)로 프라임을 주었을 때, 모델들이 정성적으로 다르게 작동하는 것을 볼 수 있다. 상대 주의가 있는 트랜스포머는 모티프를 발전시켜 명확한 윤곽을 가진 구절을 생성하며, 이는 반복되고 다양해진다. 기준 트랜스포머는 모티프를 보다 균일하게 사용하며, LSTM은 처음에는 모티프를 사용하지만 곧 다른 자료로 흘러간다. 생성된 샘플은 훈련 시퀀스의 두 배 길이라는 점에 유의하라. 상대 주의는 훈련된 것보다 긴 길이로 일반화할 수 있었지만 기준 트랜스포머는 훈련 길이를 초과하면 성능이 저하된다. 우리의 상대 트랜스포머가 과거 모티프에 어떻게 주의를 기울이는지에 대한 시각화는 부록 C를 참조하라.  
4.2.2  
화성화: 멜로디에 대한 조건화  
트랜스포머의 시퀀스-투-시퀀스 설정을 탐구하기 위해, 우리는 인코더가 주어진 멜로디를 입력받고 디코더가 전체 공연, 즉 멜로디와 반주를 실현해야 하는 조건부 생성 작업을 실험하였다. 멜로디는 Waite (2016)에서처럼 토큰 시퀀스로 인코딩되며, 100ms 그리드로 양자화된다. 디코더는 섹션 3.1에서 설명된 공연 인코딩을 사용하며 (A.2에서 추가 설명됨), 디코더 측에서 상대 주의를 사용하고, 표 4에서 성능이 개선됨을 보여준다.  
표 4:  
Piano-e-Competition에서 제공된 실제 멜로디에 대한 검증 조건부 NLL.  
모델 변형  
NLL  
기준 트랜스포머  
2.066  
상대 트랜스포머 (우리의)  
1.786  
4.2.3  
인간 평가  
Piano-e-Competition 데이터셋에서 훈련된 모델의 인식된 샘플 품질과 프라이밍 시퀀스의 연속성을 생성하는 능력을 비교하기 위해, 우리는 기준 트랜스포머, 상대 주의가 있는 우리의 트랜스포머, PerformanceRNN (LSTM), 그리고 검증 세트를 비교하는 청취 테스트 연구를 수행하였다. 참가자들은 두 개의 음악 발췌(같은 프라이밍 시퀀스를 받은 두 개의 다른 모델에서)를 제시받고, 더 음악적인 것을 리커트 척도로 평가하도록 요청받았다. 각 모델에 대해 우리는 각각 다른 프라임을 가진 10개의 샘플을 생성하고, 이를 세 개의 다른 모델과 비교하여 총 60개의 쌍 비교를 하였다. 각 쌍은 3명의 서로 다른 참가자에 의해 평가되어 총 180개의 비교가 이루어졌다.  
그림 5는 각 모델의 발췌가 더 음악적으로 선택된 비교의 수를 보여준다. 상대 주의를 사용하여 기준 트랜스포머 모델에 비해 샘플 품질이 개선된 것은 통계적으로 유의미하였다 (분석은 부록 B를 참조하라), 집합적으로나 쌍 간에 모두 마찬가지이다. 집합적으로 LSTM이 연구에서 트랜스포머보다 더 나은 성능을 보였지만, 더 높은 당황도를 가졌음에도 불구하고, 서로 정면으로 비교했을 때 결과는 통계적으로 유의미하지 않았다 (부록 B의 표 5를 참조하라).  
8

=== Page 9 ===  
(우리의)  
그림 5: 각 모델의 승리 수. 오차 막대는 평균의 표준 편차를 나타낸다.  
5  
결론  
이 연구에서 우리는 상대 주의가 장착된 트랜스포머가 기호 음악의 생성 모델링에 매우 적합하다는 것을 입증하였다. 우리 모델의 샘플에서 나타나는 매력적인 장기 구조는 이 연구 방향에 대한 우리의 열정을 불러일으킨다. 더욱이, 프라임을 확장할 수 있는 능력은 특히 창의적인 도구로서의 잠재적 응용을 시사한다.  
상대 주의로 인한 유의미한 개선은 원래 트랜스포머의 단점을 강조하며, 이는 다른 분야에서의 성능을 제한할 수 있다. 예를 들어, 다양한 시간 척도에서 주기성을 포착하는 트랜스포머의 능력을 개선하거나 피치와 유사한 스칼라 특성 간의 관계를 개선하면 시계열 모델을 향상시킬 수 있다. 우리의 메모리 효율적인 구현은 상대 주의를 긴 텍스트나 심지어 오디오 파형과 같은 훨씬 긴 시퀀스에 적용할 수 있게 하여, 적용할 수 있는 문제의 범위를 크게 확장한다.  
6  
감사의 말  
우리는 Transformer (Vaswani et al., 2017) 및 Tensor2Tensor (Vaswani et al., 2018) 논문에서 많은 동료들에게 감사드리며, 그들이 우리의 여정에 도움을 주었다: Lukasz Kaiser, Ryan Sepassi, Niki Parmar 및 Llion Jones. Magenta와 친구들에게도 그들의 지원과 많은 통찰력 있는 논의에 대해 감사드린다: Jesse Engel, Adam Roberts, Fred Bertsch, Erich Elsen, Sander Dieleman, Sageev Oore, Carey Radebaugh, Natasha Jaques, Daphne Ippolito, Sherol Chan, Vida Vakilotojar, Dustin Tran, Ben Poole 및 Tim Cooijmans.  
참고문헌  
Moray Allan 및 Christopher KI Williams. 확률적 추론에 의한 코랄 화성화. 신경 정보 처리 시스템의 발전, 17:25–32, 2005.  
Nicolas Boulanger-Lewandowski, Yoshua Bengio, 및 Pascal Vincent. 고차원 시퀀스에서의 시간 의존성 모델링: 다성 음악 생성 및 전사에의 응용. 국제 기계 학습 회의, 2012.  
Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, 및 Yi-Hsuan Yang. Musegan: 기호 음악 생성 및 반주를 위한 다중 트랙 순차 생성 적대 신경망. 인공지능에 관한 AAAI 회의 논문집, 2018.  
Douglas Eck 및 Juergen Schmidhuber. 음악에서 시간 구조 찾기: LSTM 순환 신경망을 이용한 블루스 즉흥 연주. 신호 처리용 신경망에 관한 제12회 IEEE 워크숍 논문집, 2002.  
Gaëtan Hadjeres, Jason Sakellariou, 및 François Pachet. 지수 가족을 이용한 다성 음악에서의 스타일 모방 및 코드 발명. arXiv 사전 인쇄 arXiv:1609.05152, 2016.  
Gaëtan Hadjeres, François Pachet, 및 Frank Nielsen. Deepbach: 바흐 코랄 생성을 위한 조정 가능한 모델. 국제 기계 학습 회의, pp. 1362–1371, 2017.  
Geoffrey E Hinton, Simon Osindero, 및 Yee-Whye Teh. 깊은 신뢰 네트워크를 위한 빠른 학습 알고리즘. 신경 계산, 18(7):1527–1554, 2006.  
9

=== Page 10 ===  
Cheng-Zhi Anna Huang, Tim Cooijmans, Adam Roberts, Aaron Courville, and Doug Eck. 카운터포인트 by convolution. In Proceedings of the International Conference on Music Information Retrieval, 2017.  
Hugo Larochelle and Iain Murray. 신경 자기 회귀 분포 추정기. In AISTATS, volume 1, pp. 2, 2011.  
Stefan Lattner, Maarten Grachten, and Gerhard Widmer. 합성곱 제한 볼츠만 기계와 제약을 사용하여 다성 음악 생성에서 고차원 구조 부여. Journal of Creative Music Systems, 2(2), 2018.  
Feynman Liang. Bachbot: 바흐 코랄 스타일의 자동 작곡. 석사 논문, University of Cambridge, 2016.  
Peter J Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 긴 시퀀스를 요약하여 위키피디아 생성. In Proceedings of the International Conference on Learning Representations, 2018.  
Sageev Oore, Ian Simon, Sander Dieleman, Douglas Eck, and Karen Simonyan. 이번에는 감정을 담아: 표현력 있는 음악 공연 학습. arXiv preprint arXiv:1808.03715, 2018.  
Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. 자연어 추론을 위한 분해 가능한 주의 모델. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2016.  
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Łukasz Kaiser, Noam Shazeer, and Alexander Ku. 이미지 트랜스포머. In Proceedings of the International Conference on Machine Learning, 2018.  
Daniel Povey, Hossein Hadian, Pegah Ghahremani, Ke Li, and Sanjeev Khudanpur. ASR를 위한 시간 제한 자기 주의 레이어. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018.  
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. 상대 위치 표현을 가진 자기 주의. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, volume 2, 2018.  
Paul Smolensky. 동적 시스템에서의 정보 처리: 화음 이론의 기초. 기술 보고서, DTIC Document, 1986.  
Benigno Uria, Iain Murray, and Hugo Larochelle. 깊고 다루기 쉬운 밀도 추정기. In International Conference on Machine Learning, pp. 467–475, 2014.  
Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. 신경 자기 회귀 분포 추정. The Journal of Machine Learning Research, 17(1):7184–7220, 2016.  
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 주의는 당신이 필요한 전부입니다. In Advances in Neural Information Processing Systems, 2017.  
Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan N. Gomez, Stephan Gouws, Llion Jones, Łukasz Kaiser, Nal Kalchbrenner, Niki Parmar, Ryan Sepassi, Noam Shazeer, and Jakob Uszkoreit. 신경 기계 번역을 위한 Tensor2tensor. CoRR, abs/1803.07416, 2018.  
Elliot Waite. 노래와 이야기에서 장기 구조 생성. https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn, 2016.  
10

=== Page 11 ===  
A  
도메인 특화 표현  
음악을 위한 시퀀스 모델을 조정하려면 다성 텍스처를 직렬화하는 방법에 대한 결정을 내려야 한다. 데이터 유형, 즉 악보 또는 연주 여부에 따라 모든 정보를 인코딩하는 데 더 자연스러운 표현이 있으며, 여전히 합리적인 시퀀스 길이를 유지할 수 있다.  
A.1  
직렬화된 악기/시간 그리드 (J.S. 바흐 코랄)  
첫 번째 데이터셋인 J.S. 바흐 코랄은 4부 악보 기반의 합창 음악으로 구성되어 있다. 시간 해상도는 16분 음표로, 직렬화된 그리드와 같은 표현을 사용할 수 있다. 그림 6은 피아노 롤(왼쪽)이 그리드(오른쪽)로 표현되는 방법을 보여준다(Huang et al., 2017). 행은 네 개의 목소리 각각의 MIDI 피치 번호를 나타내며, 위에서 아래로 소프라노(S), 알토(A), 테너(T), 베이스(B) 순이다. 열은 16분 음표로 진행되는 이산화된 시간이다. 여기서 4분 음표와 같은 긴 음표는 여러 번 반복하여 나누어진다. 그리드를 시퀀스로 직렬화하기 위해, 우리는 먼저 시간 단계 1에서 모든 목소리를 반복한 후 다음 열로 이동하고, 다시 위에서 아래로 반복하는 방식으로 부분을 교차한다. 결과 시퀀스는 S1A1T1B1S2A2T2B2...이며, 여기서 첨자는 시간 단계를 나타낸다. 직렬화 후 가장 일반적인 시퀀스 길이는 1024이다. 각 토큰은 피치에서 원-핫으로 표현된다.  
S: 67, 67, 67, 67  
A: 62, 62, 62, 62  
T: 59, 59, 57, 57  
B: 43, 43, 45, 45  
그림 6: BWV 428의 첫 마디가 피아노 롤(왼쪽, x축은 이산화된 시간, y축은 MIDI 피치 번호)로 시각화되고, 16분 음표 해상도로 그리드 표현으로 인코딩된다(오른쪽). 소프라노와 알토 목소리는 피치 G4 (67)와 D4 (62)에서 4분 음표를 가지며, 테너는 피치 B3 (59)와 A3 (57)에서 8분 음표를 가지며, 베이스는 피치 A2 (45)와 G2 (43)에서 8분 음표를 가진다.  
A.2  
MIDI 유사 이벤트 기반 (피아노-e-경쟁)  
두 번째 데이터셋인 피아노-e-경쟁은 표현적인 타이밍과 다이내믹스를 가진 다성 피아노 연주로 구성되어 있다. 여기서 시간 해상도는 밀리초 수준이므로, 그리드 표현은 너무 긴 시퀀스를 초래할 것이다. 대신, 다성 연주는 (Oore et al., 2018)에서 제안된 대로 원-핫 인코딩된 이벤트의 시퀀스로 직렬화된다.  
먼저, 입력 MIDI 파일은 지속 페달 제어 이벤트에 따라 음표 지속 시간을 연장하도록 전처리된다. 지속 페달은 지속 제어 변경 값이 >= 64일 때 눌려 있다고 간주된다; 이후 제어 변경 값이 < 64일 때 지속 페달이 올라간 것으로 간주된다. 지속 페달이 눌린 기간 내에서 각 음표의 지속 시간은 동일한 피치의 다음 음표 시작 또는 지속 기간의 끝 중 먼저 발생하는 시점으로 연장된다. 원래 지속 시간이 지속 페달이 눌린 시간 이후로 연장되면, 원래 지속 시간이 사용된다.  
다음으로, MIDI 음표 이벤트는 다음 어휘 집합에서 시퀀스로 변환된다: 128개의 NOTE_ON 이벤트는 128개의 MIDI 피치 중 하나로 음표를 시작하는 데 사용되며, 128개의 NOTE_OFF 이벤트는 128개의 MIDI 피치 중 하나로 음표를 종료하는 데 사용된다. 100개의 TIME_SHIFT 이벤트는 10ms에서 1s까지 10ms 단위로 시간 이동을 나타내며, 32개의 SET_VELOCITY 이벤트는 128개의 가능한 MIDI 속도를 32개의 빈으로 양자화하여 미래의 NOTE_ON 이벤트에 대한 속도를 나타낸다. 예시 연주 인코딩은 그림 7에 나타나 있다.  
11

=== Page 12 ===  
SET_VELOCITY<80>, NOTE_ON<60>  
TIME_SHIFT<500>, NOTE_ON<64>  
TIME_SHIFT<500>, NOTE_ON<67>  
TIME_SHIFT<1000>, NOTE_OFF<60>, NOTE_OFF<64>,  
NOTE_OFF<67>  
TIME_SHIFT<500>, SET_VELOCITY<100>, NOTE_ON<65>  
TIME_SHIFT<500>, NOTE_OFF<65>  
그림 7: 피아노 롤(왼쪽)로 시각화된 피아노 연주의 스니펫과 성능 이벤트로 인코딩된 모습(오른쪽, 왼쪽에서 오른쪽으로, 그리고 아래로 직렬화됨). C 장조 화음이 지속 페달이 활성화된 상태에서 아르페지오로 연주된다. 2초 지점에서 페달이 해제되어 모든 음이 종료된다. 3초 지점에서 F가 0.5초 동안 연주된다. C 화음은 속도 80으로 연주되고, F는 속도 100으로 연주된다.  
B  
청취 테스트 보충 자료  
B.1  
연구 절차  
참가자들은 공통의 프라이밍 시퀀스를 공유하는 두 개의 음악 발췌를 제시받았다. 각 발췌에 대해 프라이밍 시퀀스가 재생된 후 2.5초의 침묵이 이어지고, 다시 프라이밍 시퀀스가 재생된 후 그 시퀀스의 연속이 이어졌다. 연속 부분은 모델 중 하나에서 샘플링되거나 우리의 검증 세트에서 추출되었다. 우리는 동일한 모델을 제외한 데이터와 모델 샘플의 모든 가능한 쌍을 평가했다. 각 연속 부분은 섹션 A.2에서 설명된 인코딩을 사용하여 512 이벤트 길이를 가졌다. 이는 모델이 훈련된 길이와 일치하며, 훈련된 길이를 초과하여 생성할 때 발생하는 저하 효과를 제거하기 위해 설정되었다. 참가자들은 1에서 5까지의 리커트 척도로 어떤 발췌가 더 음악적이라고 생각하는지 질문받았다. 쌍은 왼쪽과 오른쪽으로 배치되며, 1은 왼쪽이 훨씬 더 음악적임을, 2는 왼쪽이 약간 더 음악적임을, 3은 동점임을, 4는 오른쪽이 약간 더 음악적임을, 5는 오른쪽이 훨씬 더 음악적임을 나타낸다. 각 모델에 대해 우리는 서로 다른 프라임을 가진 10개의 샘플을 생성하고, 이를 세 개의 다른 모델과 비교하여 총 60개의 쌍별 비교를 수행했다. 각 쌍은 3명의 다른 참가자에 의해 평가되어 총 180개의 비교가 이루어졌다.  
B.2  
분석  
평가의 Kruskal-Wallis H 테스트 결과, 모델 간에 통계적으로 유의미한 차이가 있음을 보여주었다: χ2(2) = 63.84, p = 8.86e-14< 0.01. 표 5는 일치하는 샘플에 대해 Wilcoxon signed-rank 테스트를 사용하여 각 쌍 내 비교에 대한 사후 분석을 보여준다. 표 6은 모든 쌍과 비교할 때 각 모델의 성능이 얼마나 잘 나타나는지를 보여주며, 독립 샘플에 대해 Mann–Whitney U 테스트를 사용하여 각 모델의 집합을 서로 비교한다. 우리는 다중 비교를 수정하기 위해 두 가지 모두에 대해 Bonferroni 수정을 사용한다. 승리 및 패배 카운트는 각각 점수 4, 5와 점수 1, 2를 부여하며, 동점 점수는 3이다.  
쌍 내 및 집합 간 모두에서 참가자들은 우리의 상대 트랜스포머 샘플을 기본 트랜스포머보다 더 음악적이라고 평가했다(p < 0.01/6).  
쌍 내에서는 다른 모델 쌍, 즉 기본 트랜스포머 대 LSTM 및 LSTM 대 상대 트랜스포머 간에 일관된 통계적으로 유의미한 차이를 관찰하지 못했다.  
집합 간 비교에서 LSTM은 전반적으로 기본 트랜스포머보다 더 음악적으로 인식되었다. 상대 트랜스포머는 LSTM을 초과하는 데 약간 가까워졌으며, p = 0.018이었다. 두 샘플을 들었을 때, 질적으로 다른 소리가 나는 것이 확실하다. 상대 트랜스포머는 종종 훨씬 더 많은 구조를 나타내지만(그림 4에 나타남), 기본 트랜스포머가 저하되는 것을 방지하기 위해 10초에서 15초의 샘플을 사용했기 때문에 청취 테스트에서 효과가 덜 두드러졌을 가능성이 있다. 이는 장기 구조에 대한 비교를 약화시킨다.  
검증 세트의 실제 음악과 비교할 때, 집합 간에서는 실제 음악이 LSTM 및 기본 트랜스포머보다 더 나은 것으로 나타났다. 실제 음악과 상대 트랜스포머 간에는 통계적으로 유의미한 차이가 없었다. 이는 아마도 샘플이 너무 짧았기 때문일 것이며, 실제 음악은 확실히 여전히 더 나은 것으로 평가되었다.  
12

=== Page 13 ===  
표 5: 일치하는 샘플에 대한 Wilcoxon signed-rank 테스트를 사용하여 각 쌍의 쌍별 비교에 대한 사후 분석. p 값이 0.01/6=0.0016보다 작으면 통계적으로 유의미한 차이를 나타내며 별표로 표시된다.  
쌍  
승리  
동점  
패배  
p 값  
우리의 상대 트랜스포머  
실제 음악  
11  
4  
15  
0.243  
우리의 상대 트랜스포머  
기본 트랜스포머  
23  
1  
6  
0.0006*  
우리의 상대 트랜스포머  
LSTM  
18  
1  
11  
0.204  
기본 트랜스포머  
LSTM  
5  
3  
22  
0.006  
기본 트랜스포머  
실제 음악  
6  
0  
24  
0.0004*  
LSTM  
실제 음악  
6  
2  
22  
0.0014  
표 6: (승리, 동점, 패배)에서 각 쌍의 집합을 비교하며, 독립 샘플에 대해 Mann–Whitney U 테스트를 사용한다.  
모델  
모델  
p 값  
우리의 상대 트랜스포머  
(52, 6, 32)  
실제 음악  
(61, 6, 23)  
0.020  
우리의 상대 트랜스포머  
(52, 6, 32)  
기본 트랜스포머  
(17, 4, 69)  
1.26e-9*  
우리의 상대 트랜스포머  
(52, 6, 32)  
LSTM  
(39, 6, 45)  
0.018  
기본 트랜스포머  
(17, 4, 69)  
LSTM  
(39, 6, 45)  
3.70e-5*  
기본 트랜스포머  
(17, 4, 69)  
실제 음악  
(61, 6, 23)  
6.73e-14*  
LSTM  
(39, 6, 45)  
실제 음악  
(61, 6, 23)  
4.06e-5*  
C  
소프트맥스 주의 시각화  
주의 기반 모델의 한 가지 장점은 주의 분포를 시각화할 수 있다는 것이다. 이는 모델이 반복 구조를 어떻게 형성하고 있는지, 얼마나 멀리 과거를 참조하고 있는지를 엿볼 수 있게 해준다. 아래 시각화의 피아노 롤은 상대 주의가 있는 트랜스포머에서 생성된 샘플이다. 각 그림은 쿼리(모든 주의 선의 출처)와 이전 메모리가 주의 받고 있는 모습을 보여준다(더 많은 소프트맥스 확률을 받는 음표가 강조 표시됨). 주의 선의 색상은 서로 다른 헤드를 나타내고 너비는 소프트맥스 확률의 가중치를 나타낸다.  
그림 8: 이 곡은 반복적인 삼각형 윤곽을 가지고 있다. 쿼리는 후반의 피크 중 하나에 위치하고 있으며, 피크의 모든 이전 높은 음에 주의를 기울인다, 곡의 시작 부분까지.  
그림 9: 쿼리는 왼손의 음표이며, 즉각적인 과거 이웃과 주로 이전 왼손 화음에 주의를 기울이며, 대부분의 주의 선이 피아노 롤의 하반부에 분포되어 있다.  
13  

=== Page 14 ===  
D  
“왜곡” 절차에 대한 이전 그림  
0  
0  
.  
.  
.  
0  
0  
0  
.  
.  
.  
0  
0  
0  
0  
.  
.  
.  
단계 1  
단계 2,3:  
그림 10: 상대적 전역 주의: 절대-상대 (iq, r) 색인 매트릭스를 절대-절대 (iq, jk)로 “왜곡”하기 위한 단계(왼쪽에서 오른쪽으로). 회색은 자기 주의 마스크 또는 왜곡 절차에 의해 도입된 항목을 나타낸다. 상대 거리 0인 위치가 표시된다. 보라색으로 윤곽이 그려진 항목은 단계 3에서 제거된다.  
(N+1, 2N-1)  
-1  
-N  
-2N+1  
-N  
(N, N)  
0  
0  
0  
.  
.  
.  
-1  
-N  
-2N+1  
-N  
-1  
-2N+1  
(N, 2N-1)  
평탄화 후 N-1 패드  
단계 1, 2  
단계 3  
단계 4  
그림 11: 상대적 지역 주의: (iq, r) 색인 매트릭스를 2N −1 범위의 상대 색인 r로 “왜곡”하기 위한 단계(왼쪽에서 오른쪽으로). 모양은 상자 위에 표시되며, 상자 안의 색인은 상대 거리를 제공한다.  
14