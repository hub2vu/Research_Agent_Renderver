{
  "success": true,
  "error": null,
  "summary": {
    "input_count": 99,
    "filtered_count": 0,
    "scored_count": 99,
    "output_count": 10,
    "purpose": "general",
    "ranking_mode": "balanced",
    "profile_used": "users/profile.json",
    "llm_verification_used": false,
    "llm_calls_made": 0
  },
  "ranked_papers": [
    {
      "rank": 1,
      "paper_id": "117147",
      "title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion",
      "authors": [
        "Lin Wu",
        "Zhixiang Chen",
        "Jianglin Lan"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.7887838055491911,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 1,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "MUST_KEYWORD_MATCH",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "117147",
        "title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion",
        "abstract": "Generating realistic 3D human-object interactions (HOIs) remains a challenging task due to the difficulty of modeling detailed interaction dynamics. Existing methods treat human and object motions independently, resulting in physically implausible and causally inconsistent behaviors. In this work, we present HOI-Dyn, a novel framework that formulates HOI generation as a driver-responder system, where human actions drive object responses. At the core of our method is a lightweight transformer-based interaction dynamics model that explicitly predicts how objects should react to human motion. To further enforce consistency, we introduce a residual-based dynamics loss that mitigates the impact of dynamics prediction errors and prevents misleading optimization signals. The dynamics model is used only during training, preserving inference efficiency. Through extensive qualitative and quantitative experiments, we demonstrate that our approach not only enhances the quality of HOI generation but also establishes a feasible metric for evaluating the quality of generated interactions. Project website: https://wulin97.github.io/hoi-dyn",
        "authors": [
          "Lin Wu",
          "Zhixiang Chen",
          "Jianglin Lan"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.026898067444562912,
        "keyword_score": 0,
        "combined_score": 0.008069420233368874
      }
    },
    {
      "rank": 2,
      "paper_id": "115272",
      "title": "Act Only When It Pays: Efficient Reinforcement Learning for LLM Reasoning via Selective Rollouts",
      "authors": [
        "Haizhong Zheng",
        "Yang Zhou",
        "Brian Bartoldson",
        "Bhavya Kailkhura",
        "Fan Lai",
        "Jiawei Zhao",
        "Beidi Chen"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "115272",
        "title": "Act Only When It Pays: Efficient Reinforcement Learning for LLM Reasoning via Selective Rollouts",
        "abstract": "Reinforcement learning, such as PPO and GRPO, has powered recent breakthroughs in LLM reasoning. Scaling rollout to sample more prompts enables models to selectively use higher-quality data for training, which can stabilize RL training and improve model performance, but at the cost of significant computational overhead. In this paper, we first show that a substantial portion of this overhead can be avoided by skipping uninformative prompts before rollout. Our analysis of reward dynamics reveals a strong temporal consistency in prompt value: prompts that are uninformative in one epoch of training are likely to remain uninformative in near future epochs. Based on these insights, we propose GRESO (GRPO with Efficient Selective Rollout), an online, lightweight pre-rollout filtering algorithm that predicts and skips uninformative prompts using reward training dynamics. By evaluating GRESO on a broad range of math reasoning benchmarks and models, like Qwen2.5-Math-1.5B, DeepSeek-R1-Distill-Qwen-1.5B, Qwen2.5-Math-7B, Qwen2.5-14B, and Qwen2.5-32B, we show that GRESO achieves up to 2.4x wall-clock time speedup in rollout and up to 2.0x speedup in total training time without accuracy degradation. We make our code publicly available at https://github.com/Infini-AI-Lab/GRESO/.",
        "authors": [
          "Haizhong Zheng",
          "Yang Zhou",
          "Brian Bartoldson",
          "Bhavya Kailkhura",
          "Fan Lai",
          "Jiawei Zhao",
          "Beidi Chen"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.032414522022008896,
        "keyword_score": 0,
        "combined_score": 0.009724356606602669
      }
    },
    {
      "rank": 3,
      "paper_id": "115893",
      "title": "Let a Neural Network be Your Invariant",
      "authors": [
        "Mirco Giacobbe",
        "Daniel Kroening",
        "Abhinandan Pal",
        "Michael Tautschnig"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "115893",
        "title": "Let a Neural Network be Your Invariant",
        "abstract": "Safety verification ensures that a system avoids undesired behaviour. Liveness complements safety, ensuring that the system also achieves its desired objectives. A complete specification of functional correctness must combine both safety and liveness. Proving with mathematical certainty that a system satisfies a safety property demands presenting an appropriate inductive invariant of the system, whereas proving liveness requires showing a measure of progress witnessed by a ranking function. Neural model checking has recently introduced a data-driven approach to the formal verification of reactive systems, albeit focusing on ranking functions and thus addressing liveness properties only. In this paper, we extend and generalise neural model checking to additionally encompass inductive invariants and thus safety properties as well. Given a system and a linear temporal logic specification of safety and liveness, our approach alternates a learning and a checking component towards the construction of a provably sound neural certificate. Our new method introduces a neural certificate architecture that jointly represents inductive invariants as proofs of safety, and ranking functions as proofs of liveness. Moreover, our new architecture is amenable to training using constraint solvers, accelerating prior neural model checking work otherwise based on gradient descent. We experimentally demonstrate that our method is orders of magnitude faster than the state-of-the-art model checkers on pure liveness and combined safety and liveness verification tasks written in SystemVerilog, while enabling the verification of richer properties than was previously possible for neural model checking.",
        "authors": [
          "Mirco Giacobbe",
          "Daniel Kroening",
          "Abhinandan Pal",
          "Michael Tautschnig"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.03195718675851822,
        "keyword_score": 0,
        "combined_score": 0.009587156027555466
      }
    },
    {
      "rank": 4,
      "paper_id": "116832",
      "title": "Repo2Run: Automated Building Executable Environment for Code Repository at Scale",
      "authors": [
        "Ruida Hu",
        "Chao Peng",
        "XinchenWang",
        "Junjielong Xu",
        "Cuiyun Gao"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "116832",
        "title": "Repo2Run: Automated Building Executable Environment for Code Repository at Scale",
        "abstract": "Scaling up executable code data is significant for improving language modelsâ€™ software engineering capability. The intricate nature of the process makes it labor-intensive, time-consuming and expert-knowledge-dependent to build a large number of executable code repositories, limiting the scalability of existing work based on running tests. The primary bottleneck lies in the automated building of test environments for different repositories, which is an essential yet underexplored task. To mitigate the gap, we introduce Repo2Run, the first LLM-based agent aiming at automating the building of executable test environments for any repositories at scale. Specifically, given a code repository, Repo2Run iteratively builds the Docker image, runs unit tests based on the feedback of the building, and synthesizes the Dockerfile until the entire pipeline is executed successfully. The resulting Dockerfile can then be used to create Docker container environments for running code and tests. We created a benchmark containing 420 Python repositories with unit tests for evaluation. The results illustrate that Repo2Run achieves an 86.0% success rate, outperforming SWE-agent by 77.0%. The resources of Repo2Run are available at https://github.com/bytedance/Repo2Run.",
        "authors": [
          "Ruida Hu",
          "Chao Peng",
          "XinchenWang",
          "Junjielong Xu",
          "Cuiyun Gao"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.031051645055413246,
        "keyword_score": 0,
        "combined_score": 0.009315493516623974
      }
    },
    {
      "rank": 5,
      "paper_id": "119194",
      "title": "Fair Matroid Selection",
      "authors": [
        "Kiarash Banihashem",
        "MohammadTaghi Hajiaghayi",
        "Danny Mittal"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "119194",
        "title": "Fair Matroid Selection",
        "abstract": "We investigate the problem of sequentially selecting elements of an unknown matroid in an online manner to form an independent set, with the goal of maximizing the minimum probability of acceptance across all elements, a property we define as $f$-fairness. Under adversarial arrival orders, we design an $\\alpha(\\ln(k)+1)$-fair algorithm, where $\\alpha$ is the arboricity of the matroid and $k$ is the rank, a result that is nearly optimal. For laminar matroids, we develop an $(2\\alpha-1)$-fair algorithm, which is optimal up to constant factors, achieved through a novel online coloring scheme. In the random arrival order setting, we achieve a $(4+o(1))\\alpha$-fair algorithm for graphic matroids, matching the optimal result up to constant factors, relying on a novel technique for learning a degeneracy ordering using a sampled subset of edges. We further generalize our result to $p$-matchoids, obtaining a $\\beta(p\\ln k+1)$-fair algorithm for the adversarial arrival model, where $\\beta$ is the optimal offline fairness. Notably, all our results can be extended to a setting with no prior knowledge of the matroid with only a logarithmic increase in the fairness factor.",
        "authors": [
          "Kiarash Banihashem",
          "MohammadTaghi Hajiaghayi",
          "Danny Mittal"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.03104609251022339,
        "keyword_score": 0,
        "combined_score": 0.009313827753067017
      }
    },
    {
      "rank": 6,
      "paper_id": "117510",
      "title": "SAFE: Multitask Failure Detection for Vision-Language-Action Models",
      "authors": [
        "Qiao Gu",
        "Yuanliang Ju",
        "Shengxiang Sun",
        "Igor Gilitschenski",
        "Haruki Nishimura",
        "Masha Itkina",
        "Florian Shkurti"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "117510",
        "title": "SAFE: Multitask Failure Detection for Vision-Language-Action Models",
        "abstract": "While vision-language-action models (VLAs) have shown promising robotic behaviors across a diverse set of manipulation tasks, they achieve limited success rates when deployed on novel tasks out of the box. To allow these policies to safely interact with their environments, we need a failure detector that gives a timely alert such that the robot can stop, backtrack, or ask for help. However, existing failure detectors are trained and tested only on one or a few specific tasks, while generalist VLAs require the detector to generalize and detect failures also in unseen tasks and novel environments. In this paper, we introduce the multitask failure detection problem and propose SAFE, a failure detector for generalist robot policies such as VLAs. We analyze the VLA feature space and find that VLAs have sufficient high-level knowledge about task success and failure, which is generic across different tasks. Based on this insight, we design SAFE to learn from VLA internal features and predict a single scalar indicating the likelihood of task failure. SAFE is trained on both successful and failed rollouts and is evaluated on unseen tasks. SAFE is compatible with different policy architectures. We test it on OpenVLA, $\\pi_0$, and $\\pi_0$-FAST in both simulated and real-world environments extensively. We compare SAFE with diverse baselines and show that SAFE achieves state-of-the-art failure detection performance and the best trade-off between accuracy and detection time using conformal prediction. More qualitative results and code can be found at the project webpage: https://vla-safe.github.io/",
        "authors": [
          "Qiao Gu",
          "Yuanliang Ju",
          "Shengxiang Sun",
          "Igor Gilitschenski",
          "Haruki Nishimura",
          "Masha Itkina",
          "Florian Shkurti"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.030467059463262558,
        "keyword_score": 0,
        "combined_score": 0.009140117838978766
      }
    },
    {
      "rank": 7,
      "paper_id": "115240",
      "title": "On Group Sufficiency Under Label Bias",
      "authors": [
        "Haoran Zhang",
        "Olawale Salaudeen",
        "Marzyeh Ghassemi"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "115240",
        "title": "On Group Sufficiency Under Label Bias",
        "abstract": "Real-world classification datasets often contain label bias, where observed labels differ systematically from the true labels at different rates for different demographic groups. Machine learning models trained on such datasets may then exhibit disparities in predictive performance across these groups. In this work, we characterize the problem of learning fair classification models with respect to the underlying ground truth labels when given only label biased data. We focus on the particular fairness definition of group sufficiency, i.e. equal calibration of risk scores across protected groups. We theoretically show that enforcing fairness with respect to label biased data necessarily results in group miscalibration with respect to the true labels. We then propose a regularizer which minimizes an upper bound on the sufficiency gap by penalizing a conditional mutual information term. Across experiments on eight tabular, image, and text datasets with both synthetic and real label noise, we find that our method reduces the sufficiency gap by up to 7.2% with no significant decrease in overall accuracy.",
        "authors": [
          "Haoran Zhang",
          "Olawale Salaudeen",
          "Marzyeh Ghassemi"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.030351117253303528,
        "keyword_score": 0,
        "combined_score": 0.009105335175991058
      }
    },
    {
      "rank": 8,
      "paper_id": "118935",
      "title": "Adaptive Data Analysis for Growing Data",
      "authors": [
        "Neil Marchant",
        "Benjamin Rubinstein"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "118935",
        "title": "Adaptive Data Analysis for Growing Data",
        "abstract": "Reuse of data in adaptive workflows poses challenges regarding overfitting and the statistical validity of results. Previous work has demonstrated that interacting with data via differentially private algorithms can mitigate overfitting, achieving worst-case generalization guarantees with asymptotically optimal data requirements. However, such past work assumes data is _static_ and cannot accommodate situations where data _grows_ over time. In this paper we address this gap, presenting the first generalization bounds for adaptive analysis on dynamic data. We allow the analyst to adaptively _schedule_ their queries conditioned on the current size of the data, in addition to previous queries and responses. We also incorporate time-varying empirical accuracy bounds and mechanisms, allowing for tighter guarantees as data accumulates. In a batched query setting, the asymptotic data requirements of our bound grows with the square-root of the number of adaptive queries, matching prior works' improvement over data splitting for the static setting. We instantiate our bound for statistical queries with the clipped Gaussian mechanism, where it empirically outperforms baselines composed from static bounds.",
        "authors": [
          "Neil Marchant",
          "Benjamin Rubinstein"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.029307153075933456,
        "keyword_score": 0,
        "combined_score": 0.008792145922780036
      }
    },
    {
      "rank": 9,
      "paper_id": "118949",
      "title": "Optimal Online Change Detection via Random Fourier Features",
      "authors": [
        "Florian Kalinke",
        "Shakeel Gavioli-Akilagun"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "118949",
        "title": "Optimal Online Change Detection via Random Fourier Features",
        "abstract": "This article studies the problem of online non-parametric change point detection in multivariate data streams. We approach the problem through the lens of kernel-based two-sample testing and introduce a sequential testing procedure based on random Fourier features, running with logarithmic time complexity per observation and with overall logarithmic space complexity. The algorithm has two advantages compared to the state of the art. First, our approach is genuinely online, and no access to training data known to be from the pre-change distribution is necessary. Second, the algorithm does not require the user to specify a window parameter over which local tests are to be calculated. We prove strong theoretical guarantees on the algorithm's performance, including information-theoretic bounds demonstrating that the detection delay is optimal in the minimax sense. Numerical studies on real and synthetic data show that our algorithm is competitive with respect to the state of the art.",
        "authors": [
          "Florian Kalinke",
          "Shakeel Gavioli-Akilagun"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.028720593079924583,
        "keyword_score": 0,
        "combined_score": 0.008616177923977375
      }
    },
    {
      "rank": 10,
      "paper_id": "117655",
      "title": "Second-Order Convergence in Private Stochastic Non-Convex Optimization",
      "authors": [
        "Youming Tao",
        "Zuyuan Zhang",
        "Dongxiao Yu",
        "Xiuzhen Cheng",
        "Falko Dressler",
        "Di Wang"
      ],
      "published": "2025-12-01",
      "score": {
        "final": 0.688783805549191,
        "breakdown": {
          "semantic_relevance": 0,
          "must_keywords": 0,
          "author_trust": 1,
          "institution_trust": 1,
          "recency": 0.6939190277459557,
          "practicality": 0,
          "keyword_score": 0.0
        },
        "soft_penalty": 0.3,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "NO_CODE"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "117655",
        "title": "Second-Order Convergence in Private Stochastic Non-Convex Optimization",
        "abstract": "We investigate the problem of finding second-order stationary points (SOSP) in differentially private (DP) stochastic non-convex optimization. Existing methods suffer from two key limitations: \\textbf{(i)} inaccurate convergence error rate due to overlooking gradient variance in the saddle point escape analysis, and \\textbf{(ii)} dependence on auxiliary private model selection procedures for identifying DP-SOSP, which can significantly impair utility, particularly in distributed settings. To address these issues, we propose a generic perturbed stochastic gradient descent (PSGD) framework built upon Gaussian noise injection and general gradient oracles. A core innovation of our framework is using model drift distance to determine whether PSGD escapes saddle points, ensuring convergence to approximate local minima without relying on second-order information or additional DP-SOSP identification. By leveraging the adaptive DP-SPIDER estimator as a specific gradient oracle, we develop a new DP algorithm that rectifies the convergence error rates reported in prior work. We further extend this algorithm to distributed learning with arbitrarily heterogeneous data, providing the first formal guarantees for finding DP-SOSP in such settings. Our analysis also highlights the detrimental impacts of private selection procedures in distributed learning under high-dimensional models, underscoring the practical benefits of our design. Numerical experiments on real-world datasets validate the efficacy of our approach.",
        "authors": [
          "Youming Tao",
          "Zuyuan Zhang",
          "Dongxiao Yu",
          "Xiuzhen Cheng",
          "Falko Dressler",
          "Di Wang"
        ],
        "published": "2025-12-01",
        "categories": [
          "NeurIPS 2025"
        ],
        "pdf_url": null,
        "github_url": null,
        "semantic_score": 0.028553485870361328,
        "keyword_score": 0,
        "combined_score": 0.008566045761108398
      }
    }
  ],
  "filtered_papers": [],
  "contrastive_paper": null,
  "comparison_notes": [],
  "output_path": "/data/output/rankings/2026-01-28_2026-01-28T10-20-50_ranked.json",
  "generated_at": "2026-01-28T10:20:50.798495"
}