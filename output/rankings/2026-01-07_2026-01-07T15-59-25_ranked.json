{
  "success": true,
  "error": null,
  "summary": {
    "input_count": 50,
    "filtered_count": 0,
    "scored_count": 50,
    "output_count": 3,
    "purpose": "general",
    "ranking_mode": "novelty",
    "profile_used": "users/profile.json",
    "llm_verification_used": false,
    "llm_calls_made": 0
  },
  "ranked_papers": [
    {
      "rank": 1,
      "paper_id": "2201.00978v1",
      "title": "PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture",
      "authors": [
        "Kai Han",
        "Jianyuan Guo",
        "Yehui Tang",
        "Yunhe Wang"
      ],
      "published": "2022-01-04T04:56:57+00:00",
      "score": {
        "final": 0.265,
        "breakdown": {
          "semantic_relevance": 0.0,
          "must_keywords": 1.0,
          "author_trust": 1.0,
          "institution_trust": 1.0,
          "recency": 0.05,
          "practicality": 0.0
        },
        "soft_penalty": -0.0,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "MUST_KEYWORD_MATCH",
        "NO_CODE",
        "OLDER_PAPER"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "2201.00978v1",
        "title": "PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture",
        "abstract": "Transformer networks have achieved great progress for computer vision tasks. Transformer-in-Transformer (TNT) architecture utilizes inner transformer and outer transformer to extract both local and global representations. In this work, we present new TNT baselines by introducing two advanced designs: 1) pyramid architecture, and 2) convolutional stem. The new \"PyramidTNT\" significantly improves the original TNT by establishing hierarchical representations. PyramidTNT achieves better performances than the previous state-of-the-art vision transformers such as Swin Transformer. We hope this new baseline will be helpful to the further research and application of vision transformer. Code will be available at https://github.com/huawei-noah/CV-Backbones/tree/master/tnt_pytorch.",
        "authors": [
          "Kai Han",
          "Jianyuan Guo",
          "Yehui Tang",
          "Yunhe Wang"
        ],
        "published": "2022-01-04T04:56:57+00:00",
        "categories": [
          "cs.CV"
        ],
        "pdf_url": "https://arxiv.org/pdf/2201.00978v1",
        "github_url": null
      }
    },
    {
      "rank": 2,
      "paper_id": "2104.11502v1",
      "title": "Learning to Cluster Faces via Transformer",
      "authors": [
        "Jinxing Ye",
        "Xioajiang Peng",
        "Baigui Sun",
        "Kai Wang",
        "Xiuyu Sun",
        "Hao Li",
        "Hanqing Wu"
      ],
      "published": "2021-04-23T09:43:36+00:00",
      "score": {
        "final": 0.265,
        "breakdown": {
          "semantic_relevance": 0.0,
          "must_keywords": 1.0,
          "author_trust": 1.0,
          "institution_trust": 1.0,
          "recency": 0.05,
          "practicality": 0.0
        },
        "soft_penalty": -0.0,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "MUST_KEYWORD_MATCH",
        "NO_CODE",
        "OLDER_PAPER"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "2104.11502v1",
        "title": "Learning to Cluster Faces via Transformer",
        "abstract": "Face clustering is a useful tool for applications like automatic face annotation and retrieval. The main challenge is that it is difficult to cluster images from the same identity with different face poses, occlusions, and image quality. Traditional clustering methods usually ignore the relationship between individual images and their neighbors which may contain useful context information. In this paper, we repurpose the well-known Transformer and introduce a Face Transformer for supervised face clustering. In Face Transformer, we decompose the face clustering into two steps: relation encoding and linkage predicting. Specifically, given a face image, a \\textbf{relation encoder} module aggregates local context information from its neighbors and a \\textbf{linkage predictor} module judges whether a pair of images belong to the same cluster or not. In the local linkage graph view, Face Transformer can generate more robust node and edge representations compared to existing methods. Experiments on both MS-Celeb-1M and DeepFashion show that our method achieves state-of-the-art performance, e.g., 91.12\\% in pairwise F-score on MS-Celeb-1M.",
        "authors": [
          "Jinxing Ye",
          "Xioajiang Peng",
          "Baigui Sun",
          "Kai Wang",
          "Xiuyu Sun",
          "Hao Li",
          "Hanqing Wu"
        ],
        "published": "2021-04-23T09:43:36+00:00",
        "categories": [
          "cs.CV"
        ],
        "pdf_url": "https://arxiv.org/pdf/2104.11502v1",
        "github_url": null
      }
    },
    {
      "rank": 3,
      "paper_id": "2305.14858v2",
      "title": "Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers",
      "authors": [
        "Zixuan Jiang",
        "Jiaqi Gu",
        "Hanqing Zhu",
        "David Z. Pan"
      ],
      "published": "2023-05-24T08:08:26+00:00",
      "score": {
        "final": 0.265,
        "breakdown": {
          "semantic_relevance": 0.0,
          "must_keywords": 1.0,
          "author_trust": 1.0,
          "institution_trust": 1.0,
          "recency": 0.05,
          "practicality": 0.0
        },
        "soft_penalty": -0.0,
        "penalty_keywords": [],
        "evaluation_method": "embedding_low"
      },
      "tags": [
        "PREFERRED_AUTHOR",
        "PREFERRED_INSTITUTION",
        "MUST_KEYWORD_MATCH",
        "NO_CODE",
        "OLDER_PAPER"
      ],
      "local_status": {
        "already_downloaded": false,
        "local_path": null
      },
      "original_data": {
        "paper_id": "2305.14858v2",
        "title": "Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers",
        "abstract": "Transformers have achieved great success in machine learning applications. Normalization techniques, such as Layer Normalization (LayerNorm, LN) and Root Mean Square Normalization (RMSNorm), play a critical role in accelerating and stabilizing the training of Transformers. While LayerNorm recenters and rescales input vectors, RMSNorm only rescales the vectors by their RMS value. Despite being more computationally efficient, RMSNorm may compromise the representation ability of Transformers. There is currently no consensus regarding the preferred normalization technique, as some models employ LayerNorm while others utilize RMSNorm, especially in recent large language models. It is challenging to convert Transformers with one normalization to the other type. While there is an ongoing disagreement between the two normalization types, we propose a solution to unify two mainstream Transformer architectures, Pre-LN and Pre-RMSNorm Transformers. By removing the inherent redundant mean information in the main branch of Pre-LN Transformers, we can reduce LayerNorm to RMSNorm, achieving higher efficiency. We further propose the Compressed RMSNorm (CRMSNorm) and Pre-CRMSNorm Transformer based on a lossless compression of the zero-mean vectors. We formally establish the equivalence of Pre-LN, Pre-RMSNorm, and Pre-CRMSNorm Transformer variants in both training and inference. It implies that Pre-LN Transformers can be substituted with Pre-(C)RMSNorm counterparts at almost no cost, offering the same arithmetic functionality along with free efficiency improvement. Experiments demonstrate that we can reduce the training and inference time of Pre-LN Transformers by 1% - 10%.",
        "authors": [
          "Zixuan Jiang",
          "Jiaqi Gu",
          "Hanqing Zhu",
          "David Z. Pan"
        ],
        "published": "2023-05-24T08:08:26+00:00",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.NE"
        ],
        "pdf_url": "https://arxiv.org/pdf/2305.14858v2",
        "github_url": null
      }
    }
  ],
  "filtered_papers": [],
  "contrastive_paper": null,
  "comparison_notes": [],
  "output_path": "/data/output/rankings/2026-01-07_2026-01-07T15-59-25_ranked.json",
  "generated_at": "2026-01-07T15:59:25.258669"
}