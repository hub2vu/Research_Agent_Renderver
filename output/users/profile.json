{
  "interests": {
    "primary": [
      "Latent Space Interpolation in Transformers",
      "Continuous Representation Learning",
      "Model Merging & Weight Interpolation"
    ],
    "secondary": [
      "Diffusion vs Autoregressive Hybrid",
      "Geometric Analysis of Weight Spaces",
      "Flow Matching"
    ],
    "exploratory": [
      "Mechanistic Interpretability of Interpolated Weights",
      "Efficient Model Scaling via Weight Interpolation"
    ]
  },
  "keywords": {
    "must_include": [
      "transformer",
      "latent",
      "interpolation",
      "representation"
    ],
    "exclude": {
      "hard": [
        "medical",
        "clinical",
        "healthcare",
        "biology"
      ],
      "soft": [
        "attention",
        "saliency map",
        "visualization",
        "GAN"
      ]
    }
  },
  "preferred_institutions": [
    "DeepMind",
    "OpenAI",
    "Stanford University",
    "MIT",
    "Carnegie Mellon University",
    "Google Research",
    "Anthropic"
  ],
  "constraints": {
    "min_year": 2000,
    "require_code": false,
    "exclude_local_papers": true
  },
  "purpose": "literature_review",
  "ranking_mode": "balanced",
  "top_k": 5,
  "include_contrastive": false,
  "contrastive_type": "method"
}