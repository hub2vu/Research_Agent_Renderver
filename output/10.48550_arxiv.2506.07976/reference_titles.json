{
  "filename": "10.48550_arxiv.2506.07976",
  "original_filename": "10.48550_arxiv.2506.07976",
  "references_detected": 116,
  "titles_extracted": 91,
  "titles": [
    "Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham Neubig",
    "Introducing computer use, a new claude 3.5 sonnet, and claude 3.5 haiku, 2024",
    "Browser use: Enable ai to control your browser, 2024",
    "Your code’s new collaborator, 2025",
    "Galliker, Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Allen Z",
    "Fine-tuning large vision-language models as decisionmaking agents via reinforcement learning",
    "Emergence of pragmatics from referential game between theory of mind agents, 2021",
    "Iterative teacher-aware learning",
    "Mixtureof-mamba: Enhancing multi-modal state-space models with modality-aware sparsity, 2025",
    "Hi robot: Open-ended instruction following with hierarchical vision-language-action models",
    "Scribeagent: Towards specialized web agents using production-scale workflow data",
    "Mind2web: Towards a generalist agent for the web",
    "Dery, Corey Staten, Mikhail Khodak, Graham Neubig, and Ameet Talwalkar",
    "Tag-llm: Repurposing general-purpose llms for specialized domains",
    "Agudelo, Peter Qian, and Tianlong Chen",
    "Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning",
    "Li, Sergey Levine, and Aviral Kumar",
    "Proceedings of the AAAI Conference on Artificial Intelligence, 35(11):9558– 9566, May",
    "Webrl: Training llm web agents via self-evolving online curriculum reinforcement learning, 2025",
    "Claude takes research to new places, 2025",
    "Gemini deep research, 2025",
    "Zettlemoyer, Percy Liang, Emmanuel J",
    "Inference scaling laws: An empirical analysis of compute-optimal inference for LLM problem-solving",
    "Inference-aware finetuning for best-of-n sampling in large language models",
    "Scaling LLM test-time compute optimally can be more effective than scaling parameters for reasoning",
    "Webglm: Towards an efficient web-enhanced question answering system with human preferences",
    "Agentoccam: A simple yet strong baseline for llm-based web agents, 2024",
    "Webpilot: A versatile and autonomous multi-agent system for web task execution with strategic exploration, 2024",
    "UPS: Efficiently building foundation models for PDE solving via cross-modal adaptation",
    "Cat: Content-adaptive image tokenization, 2025",
    "Agenttrek: Agent trajectory synthesis via guiding replay with web tutorials",
    "Beyond browsing: Api-based web agents, 2024",
    "Specialized foundation models struggle to beat supervised baselines, 2024",
    "Mathematical reconstruction of patient-specific vascular networks based on clinical images and global optimization",
    "Codepde: An inference framework for llm-driven pde solver generation, 2025",
    "Fatemi, Xiaolong Jin, Zora Zhiruo Wang, Apurva Gandhi, Yueqi Song, Yu Gu, Jayanth Srinivasa, Gaowen Liu, Graham Neubig, and Yu Su",
    "Autonomous evaluation and refinement of digital agents",
    "Efficient architecture search for diverse tasks",
    "NAS-bench-360: Benchmarking neural architecture search on diverse tasks",
    "Autoguide: Automated generation and selection of state-aware guidelines for large language model agents",
    "Gpt-4 technical report, 2024",
    "Introducing the next generation of claude, 2024",
    "In Conference on Language Modeling (COLM",
    "Agent-e: From autonomous web navigation to foundational design principles in agentic systems",
    "L2g: Repurposing language models for genomics tasks",
    "Plan-and-act: Improving planning of agents for long-horizon tasks",
    "Co-Reyes, Avi Singh, Kate Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, Lei M",
    "Tree search for language model agents",
    "Synapse: Trajectory-as-exemplar prompting with memory for computer control",
    "Agent workflow memory",
    "Infogent: An agent-based framework for web information aggregation",
    "Bagel: Bootstrapping agents by guiding exploration with language",
    "Nnetscape navigator: Complex demonstrations for web agents without a demonstrator",
    "Towards internet-scale training for agents",
    "Agent q: Advanced reasoning and learning for autonomous ai agents",
    "Archer: Training language model agents via hierarchical multi-turn rl",
    "Distrl: An asynchronous distributed reinforcement learning framework for on-device control agents",
    "Autowebglm: A large language model-based web navigating agent",
    "Scaling llm test-time compute optimally can be more effective than scaling model parameters",
    "Training verifiers to solve math word problems",
    "Rewarding progress: Scaling automated process verifiers for llm reasoning",
    "Scaling testtime compute without verification or rl is suboptimal",
    "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning",
    "Ragen: Understanding self-evolution in llm agents via multi-turn reinforcement learning, 2025",
    "React: Synergizing reasoning and acting in language models, 2023",
    "Exact: Teaching ai agents to explore with reflective-mcts and exploratory learning",
    "Generative verifiers: Reward modeling as next-token prediction",
    "Metaxas, and Tong Che",
    "Pan, Wen Zhang, Huajun Chen, Fan Yang, Zenan Zhou, and Weipeng Chen",
    "Think twice, act once: A co-evolution framework of llm and rl for large-scale decision making, 2025",
    "Inducing programmatic skills for agentic tasks",
    "Gemma 3 technical report",
    "Recursive introspection: Teaching language model agents how to self-improve",
    "Policy gradient methods for reinforcement learning with function approximation",
    "Star: Bootstrapping reasoning with reasoning",
    "Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, ICML",
    "Bayen, Sham M",
    "Analysis and improvement of policy gradient estimation",
    "Policy gradients with variance related risk criteria",
    "Curriculum learning",
    "Taylor, and Peter Stone",
    "A survey on curriculum learning",
    "Teacher–student curriculum learning",
    "Abbeel, and Wojciech Zaremba",
    "Gonzalez, Hao Zhang, and Ion Stoica",
    "Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters",
    "Ui-tars: Pioneering automated gui interaction with native agents",
    "Archer: Training language model agents via hierarchical multi-turn rl",
    "Towards enterprise-ready computer using generalist agent",
    "Dashboard",
    "STRICTLY follow the format"
  ],
  "diagnostics": {
    "has_references_header": true,
    "parsed_items_count": 116,
    "is_numbered": true,
    "id_normalized": false
  }
}