Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham Neubig
Browser use: Enable ai to control your browser, 2024
Your code’s new collaborator, 2025
Fine-tuning large vision-language models as decisionmaking agents via reinforcement learning
Dery, Corey Staten, Mikhail Khodak, Graham Neubig, and Ameet Talwalkar
Tag-llm: Repurposing general-purpose llms for specialized domains
Agudelo, Peter Qian, and Tianlong Chen
Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning
Li, Sergey Levine, and Aviral Kumar
Proceedings of the AAAI Conference on Artificial Intelligence, 35(11):9558– 9566, May
Webrl: Training llm web agents via self-evolving online curriculum reinforcement learning, 2025
Gemini deep research, 2025
Agentoccam: A simple yet strong baseline for llm-based web agents, 2024
UPS: Efficiently building foundation models for PDE solving via cross-modal adaptation
Beyond browsing: Api-based web agents, 2024
Efficient architecture search for diverse tasks
NAS-bench-360: Benchmarking neural architecture search on diverse tasks
Autoguide: Automated generation and selection of state-aware guidelines for large language model agents
Gpt-4 technical report, 2024
In Conference on Language Modeling (COLM
L2g: Repurposing language models for genomics tasks
Co-Reyes, Avi Singh, Kate Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, Lei M
Tree search for language model agents
Synapse: Trajectory-as-exemplar prompting with memory for computer control
Infogent: An agent-based framework for web information aggregation
Bagel: Bootstrapping agents by guiding exploration with language
Nnetscape navigator: Complex demonstrations for web agents without a demonstrator
Archer: Training language model agents via hierarchical multi-turn rl
Distrl: An asynchronous distributed reinforcement learning framework for on-device control agents
Autowebglm: A large language model-based web navigating agent
Scaling llm test-time compute optimally can be more effective than scaling model parameters
Training verifiers to solve math word problems
Rewarding progress: Scaling automated process verifiers for llm reasoning
Scaling testtime compute without verification or rl is suboptimal
Generative verifiers: Reward modeling as next-token prediction
Metaxas, and Tong Che
Pan, Wen Zhang, Huajun Chen, Fan Yang, Zenan Zhou, and Weipeng Chen
Policy gradient methods for reinforcement learning with function approximation
Star: Bootstrapping reasoning with reasoning
Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data, ICML
Bayen, Sham M
Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters
Archer: Training language model agents via hierarchical multi-turn rl
Dashboard
STRICTLY follow the format