{
  "edges": [
    {
      "source": "PwxYoMvmvy",
      "target": "HqjRlT65WX",
      "similarity": 0.877
    },
    {
      "source": "PwxYoMvmvy",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8694
    },
    {
      "source": "PwxYoMvmvy",
      "target": "Furthermore",
      "similarity": 0.8646
    },
    {
      "source": "PwxYoMvmvy",
      "target": "S1Bv3068Xt",
      "similarity": 0.8601
    },
    {
      "source": "PwxYoMvmvy",
      "target": "eHehzSDUFp",
      "similarity": 0.8537
    },
    {
      "source": "ONfWFluZBI",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.852
    },
    {
      "source": "ONfWFluZBI",
      "target": "8TBGdH3t6a",
      "similarity": 0.8506
    },
    {
      "source": "ONfWFluZBI",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8325
    },
    {
      "source": "ONfWFluZBI",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.814
    },
    {
      "source": "ONfWFluZBI",
      "target": "h0ZfDIrj7T",
      "similarity": 0.8106
    },
    {
      "source": "odjMSBSWRt",
      "target": "To this end",
      "similarity": 0.8473
    },
    {
      "source": "odjMSBSWRt",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8425
    },
    {
      "source": "odjMSBSWRt",
      "target": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "similarity": 0.8404
    },
    {
      "source": "odjMSBSWRt",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8395
    },
    {
      "source": "odjMSBSWRt",
      "target": "First",
      "similarity": 0.8385
    },
    {
      "source": "imT03YXlG2",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8495
    },
    {
      "source": "imT03YXlG2",
      "target": "ssRdQimeUI",
      "similarity": 0.8436
    },
    {
      "source": "imT03YXlG2",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8421
    },
    {
      "source": "imT03YXlG2",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8388
    },
    {
      "source": "imT03YXlG2",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.8341
    },
    {
      "source": "w7P92BEsb2",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8739
    },
    {
      "source": "w7P92BEsb2",
      "target": "aXwukBD6M6",
      "similarity": 0.8379
    },
    {
      "source": "w7P92BEsb2",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8324
    },
    {
      "source": "w7P92BEsb2",
      "target": "Pnk7vMbznK",
      "similarity": 0.8314
    },
    {
      "source": "w7P92BEsb2",
      "target": "Nevertheless",
      "similarity": 0.8277
    },
    {
      "source": "Due to the high costs of setting up and running experiments",
      "target": "AcVpLS86RT",
      "similarity": 0.8988
    },
    {
      "source": "Due to the high costs of setting up and running experiments",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8727
    },
    {
      "source": "Due to the high costs of setting up and running experiments",
      "target": "In this task",
      "similarity": 0.8725
    },
    {
      "source": "Due to the high costs of setting up and running experiments",
      "target": "Mjn53GtMxi",
      "similarity": 0.8634
    },
    {
      "source": "Due to the high costs of setting up and running experiments",
      "target": "In this work",
      "similarity": 0.863
    },
    {
      "source": "However",
      "target": "To this end",
      "similarity": 0.9034
    },
    {
      "source": "However",
      "target": "HrdVqFSn1e",
      "similarity": 0.8808
    },
    {
      "source": "However",
      "target": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "similarity": 0.8557
    },
    {
      "source": "However",
      "target": "As such",
      "similarity": 0.8531
    },
    {
      "source": "However",
      "target": "yFGR36PLDJ",
      "similarity": 0.8474
    },
    {
      "source": "This work presents Physics-Informed Experimental Design (PIED)",
      "target": "We then propose a novel implicitly-defined GNN architecture",
      "similarity": 0.8585
    },
    {
      "source": "This work presents Physics-Informed Experimental Design (PIED)",
      "target": "hSZaCIznB2",
      "similarity": 0.8473
    },
    {
      "source": "This work presents Physics-Informed Experimental Design (PIED)",
      "target": "GeUK3zGreN",
      "similarity": 0.8446
    },
    {
      "source": "This work presents Physics-Informed Experimental Design (PIED)",
      "target": "03OkC0LKDD",
      "similarity": 0.829
    },
    {
      "source": "This work presents Physics-Informed Experimental Design (PIED)",
      "target": "U834XHJuqk",
      "similarity": 0.8284
    },
    {
      "source": "PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization",
      "target": "zpENPcQSj1",
      "similarity": 0.8838
    },
    {
      "source": "PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization",
      "target": "from computer vision to speech and natural language processing",
      "similarity": 0.8734
    },
    {
      "source": "PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization",
      "target": "rwqShzb9li",
      "similarity": 0.8711
    },
    {
      "source": "PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization",
      "target": "Specifically",
      "similarity": 0.871
    },
    {
      "source": "PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization",
      "target": "yp95goUAT1",
      "similarity": 0.8571
    },
    {
      "source": "Through experiments based on noisy simulated data and even real world experimental data",
      "target": "require manual interventions or focus only on appearance modifications without",
      "similarity": 0.8377
    },
    {
      "source": "Through experiments based on noisy simulated data and even real world experimental data",
      "target": "RQz7szbVDs",
      "similarity": 0.8128
    },
    {
      "source": "Through experiments based on noisy simulated data and even real world experimental data",
      "target": "magnitudes in solutions preferred by SAEs.\"",
      "similarity": 0.805
    },
    {
      "source": "Through experiments based on noisy simulated data and even real world experimental data",
      "target": "VxvnV6slP0",
      "similarity": 0.8039
    },
    {
      "source": "Through experiments based on noisy simulated data and even real world experimental data",
      "target": "ofuLWn8DFZ",
      "similarity": 0.795
    },
    {
      "source": "FDimWzmcWn",
      "target": "sound",
      "similarity": 0.8597
    },
    {
      "source": "FDimWzmcWn",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.8434
    },
    {
      "source": "FDimWzmcWn",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8361
    },
    {
      "source": "FDimWzmcWn",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8356
    },
    {
      "source": "FDimWzmcWn",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8339
    },
    {
      "source": "Sd4wYYOhmY",
      "target": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "similarity": 0.885
    },
    {
      "source": "Sd4wYYOhmY",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.837
    },
    {
      "source": "Sd4wYYOhmY",
      "target": "8enWnd6Gp3",
      "similarity": 0.8277
    },
    {
      "source": "Sd4wYYOhmY",
      "target": "ogXkmugNZw",
      "similarity": 0.8262
    },
    {
      "source": "Sd4wYYOhmY",
      "target": "deep learning model called HR-Heim which has superior performance on both",
      "similarity": 0.8216
    },
    {
      "source": "This study highlights a major",
      "target": "8egnwady4b",
      "similarity": 0.8821
    },
    {
      "source": "This study highlights a major",
      "target": "pXlmOmlHJZ",
      "similarity": 0.8642
    },
    {
      "source": "This study highlights a major",
      "target": "On the other hand",
      "similarity": 0.8395
    },
    {
      "source": "This study highlights a major",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8377
    },
    {
      "source": "This study highlights a major",
      "target": "zg3ec1TdAP",
      "similarity": 0.8305
    },
    {
      "source": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "target": "Yet",
      "similarity": 0.8635
    },
    {
      "source": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "target": "To overcome these limitations",
      "similarity": 0.842
    },
    {
      "source": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "target": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "similarity": 0.838
    },
    {
      "source": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "target": "p60Y6o85Cj",
      "similarity": 0.8225
    },
    {
      "source": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "target": "O6znYvxC1U",
      "similarity": 0.8163
    },
    {
      "source": "Then",
      "target": "irrtPRFksw",
      "similarity": 0.8218
    },
    {
      "source": "Then",
      "target": "goFpCuJalN",
      "similarity": 0.8193
    },
    {
      "source": "Then",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8188
    },
    {
      "source": "Then",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.8094
    },
    {
      "source": "Then",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8089
    },
    {
      "source": "In particular",
      "target": "To the best of our knowledge",
      "similarity": 0.826
    },
    {
      "source": "In particular",
      "target": "matched mask pairs between prediction and annotation respectively. Extensive",
      "similarity": 0.8123
    },
    {
      "source": "In particular",
      "target": "Vz0CWFMPUe",
      "similarity": 0.8088
    },
    {
      "source": "In particular",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8079
    },
    {
      "source": "In particular",
      "target": "gcouwCx7dG",
      "similarity": 0.8076
    },
    {
      "source": "Lastly",
      "target": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "similarity": 0.7977
    },
    {
      "source": "Lastly",
      "target": "cnKhHxN3xj",
      "similarity": 0.7875
    },
    {
      "source": "Lastly",
      "target": "eUEMjwh5wK",
      "similarity": 0.7834
    },
    {
      "source": "Lastly",
      "target": "9D2QvO1uWj",
      "similarity": 0.7821
    },
    {
      "source": "Lastly",
      "target": "S85PP4xjFD",
      "similarity": 0.7754
    },
    {
      "source": "For example",
      "target": "jTEKTdI3K9",
      "similarity": 0.9086
    },
    {
      "source": "For example",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8995
    },
    {
      "source": "For example",
      "target": "se4vjm7h4E",
      "similarity": 0.897
    },
    {
      "source": "For example",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8919
    },
    {
      "source": "For example",
      "target": "We  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods",
      "similarity": 0.8917
    },
    {
      "source": "Overall",
      "target": "ReItdfwMcg",
      "similarity": 0.8367
    },
    {
      "source": "Overall",
      "target": "Usklli4gMc",
      "similarity": 0.8362
    },
    {
      "source": "Overall",
      "target": "kGvXIlIVLM",
      "similarity": 0.8325
    },
    {
      "source": "Overall",
      "target": "In this paper",
      "similarity": 0.83
    },
    {
      "source": "Overall",
      "target": "For example",
      "similarity": 0.8258
    },
    {
      "source": "75PhjtbBdr",
      "target": "Za3M6OZuCU",
      "similarity": 0.8199
    },
    {
      "source": "75PhjtbBdr",
      "target": "However",
      "similarity": 0.8122
    },
    {
      "source": "75PhjtbBdr",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.8018
    },
    {
      "source": "75PhjtbBdr",
      "target": "number of parameters required for fine-tuning these models. These compression",
      "similarity": 0.7987
    },
    {
      "source": "75PhjtbBdr",
      "target": "j9VVzueEbG",
      "similarity": 0.7953
    },
    {
      "source": "XLMAMmowdY",
      "target": "IuU0wcO0mo",
      "similarity": 0.82
    },
    {
      "source": "XLMAMmowdY",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8181
    },
    {
      "source": "XLMAMmowdY",
      "target": "TrKRpaOk8y",
      "similarity": 0.8116
    },
    {
      "source": "XLMAMmowdY",
      "target": "dqyuCsBvn9",
      "similarity": 0.811
    },
    {
      "source": "XLMAMmowdY",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8106
    },
    {
      "source": "VNMJfBBUd5",
      "target": "KW8yzAOIZr",
      "similarity": 0.8221
    },
    {
      "source": "VNMJfBBUd5",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8147
    },
    {
      "source": "VNMJfBBUd5",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8081
    },
    {
      "source": "VNMJfBBUd5",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8037
    },
    {
      "source": "VNMJfBBUd5",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.7996
    },
    {
      "source": "yRKelogz5i",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8658
    },
    {
      "source": "yRKelogz5i",
      "target": "FFE.\"",
      "similarity": 0.8572
    },
    {
      "source": "yRKelogz5i",
      "target": "In experimental validation across a variety of active learning tasks",
      "similarity": 0.8491
    },
    {
      "source": "yRKelogz5i",
      "target": "Ke2BEL4csm",
      "similarity": 0.8449
    },
    {
      "source": "yRKelogz5i",
      "target": "prompts. As such",
      "similarity": 0.8413
    },
    {
      "source": "uClUUJk05H",
      "target": "sYNWqQYJhz",
      "similarity": 0.8791
    },
    {
      "source": "uClUUJk05H",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.8656
    },
    {
      "source": "uClUUJk05H",
      "target": "JV8zULNh24",
      "similarity": 0.8622
    },
    {
      "source": "uClUUJk05H",
      "target": "L238BAx0wP",
      "similarity": 0.8609
    },
    {
      "source": "uClUUJk05H",
      "target": "eLLBILFRsA",
      "similarity": 0.856
    },
    {
      "source": "O6znYvxC1U",
      "target": "However",
      "similarity": 0.8918
    },
    {
      "source": "O6znYvxC1U",
      "target": "p60Y6o85Cj",
      "similarity": 0.8563
    },
    {
      "source": "O6znYvxC1U",
      "target": "In this paper",
      "similarity": 0.8419
    },
    {
      "source": "O6znYvxC1U",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.8417
    },
    {
      "source": "O6znYvxC1U",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8312
    },
    {
      "source": "Our theoretical contributions first consist in novel integral formulas that accurately describe the predictors of BNNs in the asymptotic linear-width and sublinear-width regimes. Moreover",
      "target": "UyU8ETswPg",
      "similarity": 0.8047
    },
    {
      "source": "Our theoretical contributions first consist in novel integral formulas that accurately describe the predictors of BNNs in the asymptotic linear-width and sublinear-width regimes. Moreover",
      "target": "PgXpOOqtyd",
      "similarity": 0.7976
    },
    {
      "source": "Our theoretical contributions first consist in novel integral formulas that accurately describe the predictors of BNNs in the asymptotic linear-width and sublinear-width regimes. Moreover",
      "target": "However",
      "similarity": 0.7937
    },
    {
      "source": "Our theoretical contributions first consist in novel integral formulas that accurately describe the predictors of BNNs in the asymptotic linear-width and sublinear-width regimes. Moreover",
      "target": "poorly on compositional tasks",
      "similarity": 0.7826
    },
    {
      "source": "Our theoretical contributions first consist in novel integral formulas that accurately describe the predictors of BNNs in the asymptotic linear-width and sublinear-width regimes. Moreover",
      "target": "zXCnIyX9MG",
      "similarity": 0.7795
    },
    {
      "source": "From a practical standpoint",
      "target": "To overcome these challenges",
      "similarity": 0.8344
    },
    {
      "source": "From a practical standpoint",
      "target": "Q0s6kgrUMr",
      "similarity": 0.8272
    },
    {
      "source": "From a practical standpoint",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.8226
    },
    {
      "source": "From a practical standpoint",
      "target": "OQqNieeivq",
      "similarity": 0.8216
    },
    {
      "source": "From a practical standpoint",
      "target": "In this paper",
      "similarity": 0.8151
    },
    {
      "source": "wVTJRnZ11Z",
      "target": "However",
      "similarity": 0.8253
    },
    {
      "source": "wVTJRnZ11Z",
      "target": "This process naturally incorporates recency bias",
      "similarity": 0.7984
    },
    {
      "source": "wVTJRnZ11Z",
      "target": "Q6PAnqYVpo",
      "similarity": 0.7979
    },
    {
      "source": "wVTJRnZ11Z",
      "target": "These datasets are typically massive",
      "similarity": 0.7879
    },
    {
      "source": "wVTJRnZ11Z",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.7831
    },
    {
      "source": "However",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8827
    },
    {
      "source": "However",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8756
    },
    {
      "source": "However",
      "target": "SOTA LLMs",
      "similarity": 0.8667
    },
    {
      "source": "However",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8616
    },
    {
      "source": "However",
      "target": "xvhV3LvYTc",
      "similarity": 0.8601
    },
    {
      "source": "To address this challenge",
      "target": "NUD03NBDOE",
      "similarity": 0.8413
    },
    {
      "source": "To address this challenge",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8397
    },
    {
      "source": "To address this challenge",
      "target": "5pd78GmXC6",
      "similarity": 0.8363
    },
    {
      "source": "To address this challenge",
      "target": "y9A2TpaGsE",
      "similarity": 0.8305
    },
    {
      "source": "To address this challenge",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8297
    },
    {
      "source": "xPTzjpIQNp",
      "target": "previous results.\"",
      "similarity": 0.9047
    },
    {
      "source": "xPTzjpIQNp",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8801
    },
    {
      "source": "xPTzjpIQNp",
      "target": "TUvg5uwdeG",
      "similarity": 0.8781
    },
    {
      "source": "xPTzjpIQNp",
      "target": "per subject over the entire disease development phases. The dataset consists of",
      "similarity": 0.8674
    },
    {
      "source": "xPTzjpIQNp",
      "target": "To this end",
      "similarity": 0.8672
    },
    {
      "source": "3bcN6xlO6f",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.9253
    },
    {
      "source": "3bcN6xlO6f",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.9243
    },
    {
      "source": "3bcN6xlO6f",
      "target": "Furthermore",
      "similarity": 0.91
    },
    {
      "source": "3bcN6xlO6f",
      "target": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "similarity": 0.904
    },
    {
      "source": "3bcN6xlO6f",
      "target": "NDLmZZWATc",
      "similarity": 0.902
    },
    {
      "source": "WwmtcGr4lP",
      "target": "a3g2l4yEys",
      "similarity": 0.7962
    },
    {
      "source": "WwmtcGr4lP",
      "target": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "similarity": 0.785
    },
    {
      "source": "WwmtcGr4lP",
      "target": "To do this successfully",
      "similarity": 0.7807
    },
    {
      "source": "WwmtcGr4lP",
      "target": "oYSsbY3G4o",
      "similarity": 0.7804
    },
    {
      "source": "WwmtcGr4lP",
      "target": "calibration data is also crucial to post-training pruning",
      "similarity": 0.7751
    },
    {
      "source": "GdXI5zCoAt",
      "target": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "similarity": 0.8817
    },
    {
      "source": "GdXI5zCoAt",
      "target": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "similarity": 0.847
    },
    {
      "source": "GdXI5zCoAt",
      "target": "However",
      "similarity": 0.8431
    },
    {
      "source": "GdXI5zCoAt",
      "target": "a challenge",
      "similarity": 0.8408
    },
    {
      "source": "GdXI5zCoAt",
      "target": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "similarity": 0.8377
    },
    {
      "source": "3tukjsVyrE",
      "target": "For that purpose",
      "similarity": 0.8422
    },
    {
      "source": "3tukjsVyrE",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8399
    },
    {
      "source": "3tukjsVyrE",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.8368
    },
    {
      "source": "3tukjsVyrE",
      "target": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "similarity": 0.8356
    },
    {
      "source": "3tukjsVyrE",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8323
    },
    {
      "source": "Traditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data",
      "target": "Tz8Li6G2xU",
      "similarity": 0.7869
    },
    {
      "source": "Traditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data",
      "target": "sahQq2sH5x",
      "similarity": 0.7681
    },
    {
      "source": "Traditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data",
      "target": "IcYDRzcccP",
      "similarity": 0.7654
    },
    {
      "source": "Traditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data",
      "target": "ig2wk7kK9J",
      "similarity": 0.765
    },
    {
      "source": "Traditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data",
      "target": "However",
      "similarity": 0.7581
    },
    {
      "source": "We propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8447
    },
    {
      "source": "We propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora",
      "target": "a task efficiently",
      "similarity": 0.8425
    },
    {
      "source": "We propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora",
      "target": "h0vC0fm1q7",
      "similarity": 0.8364
    },
    {
      "source": "We propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora",
      "target": "0fJfVOSUra",
      "similarity": 0.8349
    },
    {
      "source": "We propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora",
      "target": "Furthermore",
      "similarity": 0.8276
    },
    {
      "source": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "target": "resource",
      "similarity": 0.9288
    },
    {
      "source": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "target": "In the MetaICL in-context learning evaluation",
      "similarity": 0.896
    },
    {
      "source": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "target": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "similarity": 0.8816
    },
    {
      "source": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "target": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "similarity": 0.8737
    },
    {
      "source": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "target": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "similarity": 0.8562
    },
    {
      "source": "We also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz)",
      "target": "In this paper",
      "similarity": 0.8443
    },
    {
      "source": "We also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz)",
      "target": "mUMvr33FTu",
      "similarity": 0.843
    },
    {
      "source": "We also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz)",
      "target": "As a case study",
      "similarity": 0.8295
    },
    {
      "source": "We also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz)",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8244
    },
    {
      "source": "We also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz)",
      "target": "Our code and additional resources are available at https://structuredllm.com.\"",
      "similarity": 0.8233
    },
    {
      "source": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "target": "In the MetaICL in-context learning evaluation",
      "similarity": 0.8591
    },
    {
      "source": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "target": "cbttLtO94Q",
      "similarity": 0.8402
    },
    {
      "source": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "target": "lOfuvmi2HT",
      "similarity": 0.8323
    },
    {
      "source": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "target": "resource",
      "similarity": 0.8286
    },
    {
      "source": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "target": "UxzKcIZedp",
      "similarity": 0.8274
    },
    {
      "source": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8758
    },
    {
      "source": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8665
    },
    {
      "source": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "target": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "similarity": 0.8662
    },
    {
      "source": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8646
    },
    {
      "source": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "target": "u2QdCiOgwA",
      "similarity": 0.8617
    },
    {
      "source": "sb1HgVDLjN",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8261
    },
    {
      "source": "sb1HgVDLjN",
      "target": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "similarity": 0.8172
    },
    {
      "source": "sb1HgVDLjN",
      "target": "b57IG6N20B",
      "similarity": 0.817
    },
    {
      "source": "sb1HgVDLjN",
      "target": "Sf4ep9Udjf",
      "similarity": 0.8043
    },
    {
      "source": "sb1HgVDLjN",
      "target": "context window",
      "similarity": 0.8025
    },
    {
      "source": "NtwFghsJne",
      "target": "We continue pre-training with high-rated",
      "similarity": 0.8445
    },
    {
      "source": "NtwFghsJne",
      "target": "SQnitDuow6",
      "similarity": 0.8221
    },
    {
      "source": "NtwFghsJne",
      "target": "SEARCH (SFS)**",
      "similarity": 0.8169
    },
    {
      "source": "NtwFghsJne",
      "target": "KSLkFYHlYg",
      "similarity": 0.8155
    },
    {
      "source": "NtwFghsJne",
      "target": "of natural language. However",
      "similarity": 0.8122
    },
    {
      "source": "kbeX97jExm",
      "target": "In response",
      "similarity": 0.8741
    },
    {
      "source": "kbeX97jExm",
      "target": "Jszf4et48m",
      "similarity": 0.874
    },
    {
      "source": "kbeX97jExm",
      "target": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "similarity": 0.8668
    },
    {
      "source": "kbeX97jExm",
      "target": "254NJe9JEw",
      "similarity": 0.8657
    },
    {
      "source": "kbeX97jExm",
      "target": "JAMxRSXLFz",
      "similarity": 0.864
    },
    {
      "source": "5o9JJJPPm6",
      "target": "WfxPVtYRlL",
      "similarity": 0.8837
    },
    {
      "source": "5o9JJJPPm6",
      "target": "In this task",
      "similarity": 0.8713
    },
    {
      "source": "5o9JJJPPm6",
      "target": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "similarity": 0.8661
    },
    {
      "source": "5o9JJJPPm6",
      "target": "2o58Mbqkd2",
      "similarity": 0.8501
    },
    {
      "source": "5o9JJJPPm6",
      "target": "2pNLknCTvG",
      "similarity": 0.8497
    },
    {
      "source": "Nfd7z9d6Bb",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8675
    },
    {
      "source": "Nfd7z9d6Bb",
      "target": "Finally",
      "similarity": 0.8593
    },
    {
      "source": "Nfd7z9d6Bb",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.852
    },
    {
      "source": "Nfd7z9d6Bb",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8519
    },
    {
      "source": "Nfd7z9d6Bb",
      "target": "In addition",
      "similarity": 0.8469
    },
    {
      "source": "GM7cmQfk2F",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8386
    },
    {
      "source": "GM7cmQfk2F",
      "target": "6LtdZCyuZR",
      "similarity": 0.8334
    },
    {
      "source": "GM7cmQfk2F",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8327
    },
    {
      "source": "GM7cmQfk2F",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8175
    },
    {
      "source": "GM7cmQfk2F",
      "target": "In this work",
      "similarity": 0.8112
    },
    {
      "source": "l11DZY5Nxu",
      "target": "Real-world causal structures",
      "similarity": 0.8133
    },
    {
      "source": "l11DZY5Nxu",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8125
    },
    {
      "source": "l11DZY5Nxu",
      "target": "All prior work in TDS learning focuses on classification",
      "similarity": 0.8085
    },
    {
      "source": "l11DZY5Nxu",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8076
    },
    {
      "source": "l11DZY5Nxu",
      "target": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "similarity": 0.8075
    },
    {
      "source": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "target": "dTkqaCKLPp",
      "similarity": 0.895
    },
    {
      "source": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "target": "In this paper",
      "similarity": 0.8704
    },
    {
      "source": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "target": "Yet",
      "similarity": 0.8696
    },
    {
      "source": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "target": "Given these challenges",
      "similarity": 0.8581
    },
    {
      "source": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8564
    },
    {
      "source": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "target": "JUr0YOMvZA",
      "similarity": 0.8744
    },
    {
      "source": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "target": "sion",
      "similarity": 0.8738
    },
    {
      "source": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "target": "90DC0IvlSs",
      "similarity": 0.8641
    },
    {
      "source": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8611
    },
    {
      "source": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "target": "For that purpose",
      "similarity": 0.8586
    },
    {
      "source": "anomalous values; 2) Fix: had the root cause nodes assumed usual values",
      "target": "While existing T2S distillation models address this limitation through $1$-step generation",
      "similarity": 0.8865
    },
    {
      "source": "anomalous values; 2) Fix: had the root cause nodes assumed usual values",
      "target": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "similarity": 0.8301
    },
    {
      "source": "anomalous values; 2) Fix: had the root cause nodes assumed usual values",
      "target": "In particular",
      "similarity": 0.8208
    },
    {
      "source": "anomalous values; 2) Fix: had the root cause nodes assumed usual values",
      "target": "However",
      "similarity": 0.8071
    },
    {
      "source": "anomalous values; 2) Fix: had the root cause nodes assumed usual values",
      "target": "1F8xTfv6ah",
      "similarity": 0.8048
    },
    {
      "source": "target node would not have been anomalous. Prior methods of assessing the fix",
      "target": "71XtUhazG0",
      "similarity": 0.8835
    },
    {
      "source": "target node would not have been anomalous. Prior methods of assessing the fix",
      "target": "ScVnYBaSEw",
      "similarity": 0.866
    },
    {
      "source": "target node would not have been anomalous. Prior methods of assessing the fix",
      "target": "27SSnLl85x",
      "similarity": 0.8503
    },
    {
      "source": "target node would not have been anomalous. Prior methods of assessing the fix",
      "target": "By playing against itself",
      "similarity": 0.8478
    },
    {
      "source": "target node would not have been anomalous. Prior methods of assessing the fix",
      "target": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "similarity": 0.8436
    },
    {
      "source": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "target": "vcX0k4rGTt",
      "similarity": 0.8887
    },
    {
      "source": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "target": "analysis)",
      "similarity": 0.8806
    },
    {
      "source": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "target": "SOTA LLMs",
      "similarity": 0.8796
    },
    {
      "source": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8724
    },
    {
      "source": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "target": "We have prepared an efficient implementation",
      "similarity": 0.8724
    },
    {
      "source": "trained on historical data. But since anomalies are rare and fall outside the training distribution",
      "target": "ZkFMe3OPfw",
      "similarity": 0.882
    },
    {
      "source": "trained on historical data. But since anomalies are rare and fall outside the training distribution",
      "target": "precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.\"",
      "similarity": 0.8491
    },
    {
      "source": "trained on historical data. But since anomalies are rare and fall outside the training distribution",
      "target": "However",
      "similarity": 0.806
    },
    {
      "source": "trained on historical data. But since anomalies are rare and fall outside the training distribution",
      "target": "qssVptHTPN",
      "similarity": 0.7975
    },
    {
      "source": "trained on historical data. But since anomalies are rare and fall outside the training distribution",
      "target": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "similarity": 0.7975
    },
    {
      "source": "overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis",
      "target": "wHebuIb6IH",
      "similarity": 0.8718
    },
    {
      "source": "overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.869
    },
    {
      "source": "overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8531
    },
    {
      "source": "overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis",
      "target": "Furthermore",
      "similarity": 0.8485
    },
    {
      "source": "overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis",
      "target": "J9VogDTa1W",
      "similarity": 0.8465
    },
    {
      "source": "comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM\u2019s complexity to demonstrate the cases where IDI\u2019s interventional approach outperforms the counterfactual approach and vice versa.",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8556
    },
    {
      "source": "comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM\u2019s complexity to demonstrate the cases where IDI\u2019s interventional approach outperforms the counterfactual approach and vice versa.",
      "target": "The best-performing model",
      "similarity": 0.8434
    },
    {
      "source": "comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM\u2019s complexity to demonstrate the cases where IDI\u2019s interventional approach outperforms the counterfactual approach and vice versa.",
      "target": "QogcGNXJVw",
      "similarity": 0.8423
    },
    {
      "source": "comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM\u2019s complexity to demonstrate the cases where IDI\u2019s interventional approach outperforms the counterfactual approach and vice versa.",
      "target": "jTEKTdI3K9",
      "similarity": 0.8294
    },
    {
      "source": "comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM\u2019s complexity to demonstrate the cases where IDI\u2019s interventional approach outperforms the counterfactual approach and vice versa.",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8233
    },
    {
      "source": "Experiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released",
      "target": "per subject over the entire disease development phases. The dataset consists of",
      "similarity": 0.8629
    },
    {
      "source": "Experiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released",
      "target": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "similarity": 0.8521
    },
    {
      "source": "Experiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released",
      "target": "TDy5Ih78b4",
      "similarity": 0.8436
    },
    {
      "source": "Experiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8414
    },
    {
      "source": "Experiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released",
      "target": "a challenge",
      "similarity": 0.8393
    },
    {
      "source": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "target": "fvkElsJOsN",
      "similarity": 0.8682
    },
    {
      "source": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "target": "ajSmXqgS24",
      "similarity": 0.8485
    },
    {
      "source": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "target": "dmCGjPFVhF",
      "similarity": 0.834
    },
    {
      "source": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "target": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "similarity": 0.8271
    },
    {
      "source": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "target": "In this work",
      "similarity": 0.8242
    },
    {
      "source": "TbTJJNjumY",
      "target": "Second",
      "similarity": 0.8791
    },
    {
      "source": "TbTJJNjumY",
      "target": "stacking methods. Specifically",
      "similarity": 0.8682
    },
    {
      "source": "TbTJJNjumY",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8674
    },
    {
      "source": "TbTJJNjumY",
      "target": "2mqb8bPHeb",
      "similarity": 0.8596
    },
    {
      "source": "TbTJJNjumY",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.859
    },
    {
      "source": "h0vC0fm1q7",
      "target": "a task efficiently",
      "similarity": 0.8936
    },
    {
      "source": "h0vC0fm1q7",
      "target": "Furthermore",
      "similarity": 0.8693
    },
    {
      "source": "h0vC0fm1q7",
      "target": "0fJfVOSUra",
      "similarity": 0.8668
    },
    {
      "source": "h0vC0fm1q7",
      "target": "(BoneMet) dataset",
      "similarity": 0.8392
    },
    {
      "source": "h0vC0fm1q7",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.8368
    },
    {
      "source": "In this paper",
      "target": "TrVYEZtSQH",
      "similarity": 0.8674
    },
    {
      "source": "In this paper",
      "target": "zg3ec1TdAP",
      "similarity": 0.862
    },
    {
      "source": "In this paper",
      "target": "yR47RmND1m",
      "similarity": 0.8487
    },
    {
      "source": "In this paper",
      "target": "Zk9guOl9NS",
      "similarity": 0.8313
    },
    {
      "source": "In this paper",
      "target": "This study highlights a major",
      "similarity": 0.83
    },
    {
      "source": "r1KcapkzCt",
      "target": "relying on backward propagation",
      "similarity": 0.8484
    },
    {
      "source": "r1KcapkzCt",
      "target": "SRpq5OBpED",
      "similarity": 0.8409
    },
    {
      "source": "r1KcapkzCt",
      "target": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "similarity": 0.8398
    },
    {
      "source": "r1KcapkzCt",
      "target": "This construction process is fundamental to applying graph-based models",
      "similarity": 0.8342
    },
    {
      "source": "r1KcapkzCt",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.834
    },
    {
      "source": "In this paper",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8444
    },
    {
      "source": "In this paper",
      "target": "Bpn8q40n1n",
      "similarity": 0.8404
    },
    {
      "source": "In this paper",
      "target": "L238BAx0wP",
      "similarity": 0.8372
    },
    {
      "source": "In this paper",
      "target": "jY5oml9fe9",
      "similarity": 0.8323
    },
    {
      "source": "In this paper",
      "target": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "similarity": 0.8293
    },
    {
      "source": "Za3M6OZuCU",
      "target": "However",
      "similarity": 0.7824
    },
    {
      "source": "Za3M6OZuCU",
      "target": "NfCEVihkdC",
      "similarity": 0.7772
    },
    {
      "source": "Za3M6OZuCU",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.7769
    },
    {
      "source": "Za3M6OZuCU",
      "target": "kN25ggeq1J",
      "similarity": 0.7645
    },
    {
      "source": "Za3M6OZuCU",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.7623
    },
    {
      "source": "rAoEub6Nw2",
      "target": "GBfYgjOfSe",
      "similarity": 0.8771
    },
    {
      "source": "rAoEub6Nw2",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8729
    },
    {
      "source": "rAoEub6Nw2",
      "target": "pZiyCaVuti",
      "similarity": 0.8628
    },
    {
      "source": "rAoEub6Nw2",
      "target": "4xWQS2z77v",
      "similarity": 0.8421
    },
    {
      "source": "rAoEub6Nw2",
      "target": "74vnDs1R97",
      "similarity": 0.8361
    },
    {
      "source": "QEHrmQPBdd",
      "target": "J9FgrqOOni",
      "similarity": 0.8435
    },
    {
      "source": "QEHrmQPBdd",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8423
    },
    {
      "source": "QEHrmQPBdd",
      "target": "ikkvC1UnnE",
      "similarity": 0.8354
    },
    {
      "source": "QEHrmQPBdd",
      "target": "4A9IdSa1ul",
      "similarity": 0.8305
    },
    {
      "source": "QEHrmQPBdd",
      "target": "In this paper",
      "similarity": 0.8285
    },
    {
      "source": "Despite their importance",
      "target": "NKotdPUc3L",
      "similarity": 0.8458
    },
    {
      "source": "Despite their importance",
      "target": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "similarity": 0.8457
    },
    {
      "source": "Despite their importance",
      "target": "In this task",
      "similarity": 0.8439
    },
    {
      "source": "Despite their importance",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8415
    },
    {
      "source": "Despite their importance",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8414
    },
    {
      "source": "However",
      "target": "CvGqMD5OtX",
      "similarity": 0.8196
    },
    {
      "source": "However",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8173
    },
    {
      "source": "However",
      "target": "(1) When the representation dimension is regarded as the time axis",
      "similarity": 0.8165
    },
    {
      "source": "However",
      "target": "Finally",
      "similarity": 0.8139
    },
    {
      "source": "However",
      "target": "Most importantly",
      "similarity": 0.81
    },
    {
      "source": "To this end",
      "target": "HrdVqFSn1e",
      "similarity": 0.861
    },
    {
      "source": "To this end",
      "target": "yFGR36PLDJ",
      "similarity": 0.8561
    },
    {
      "source": "To this end",
      "target": "As such",
      "similarity": 0.8518
    },
    {
      "source": "To this end",
      "target": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "similarity": 0.8356
    },
    {
      "source": "To this end",
      "target": "Together",
      "similarity": 0.8339
    },
    {
      "source": "Extensive experiments demonstrate that RM-Bench strongly correlates with policy model performance",
      "target": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "similarity": 0.8971
    },
    {
      "source": "Extensive experiments demonstrate that RM-Bench strongly correlates with policy model performance",
      "target": "E36NHwe7Zc",
      "similarity": 0.8819
    },
    {
      "source": "Extensive experiments demonstrate that RM-Bench strongly correlates with policy model performance",
      "target": "G4wARwjF8M",
      "similarity": 0.8235
    },
    {
      "source": "Extensive experiments demonstrate that RM-Bench strongly correlates with policy model performance",
      "target": "tePFpDgyqg",
      "similarity": 0.8213
    },
    {
      "source": "Extensive experiments demonstrate that RM-Bench strongly correlates with policy model performance",
      "target": "faceswaps",
      "similarity": 0.8108
    },
    {
      "source": "We evaluate nearly 40 reward models on RM-Bench.",
      "target": "In light of this",
      "similarity": 0.8354
    },
    {
      "source": "We evaluate nearly 40 reward models on RM-Bench.",
      "target": "CLIP",
      "similarity": 0.8338
    },
    {
      "source": "We evaluate nearly 40 reward models on RM-Bench.",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8308
    },
    {
      "source": "We evaluate nearly 40 reward models on RM-Bench.",
      "target": "gFvRRCnQvX",
      "similarity": 0.8169
    },
    {
      "source": "We evaluate nearly 40 reward models on RM-Bench.",
      "target": "Furthermore",
      "similarity": 0.8168
    },
    {
      "source": "Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%",
      "target": "din0lGfZFd",
      "similarity": 0.8777
    },
    {
      "source": "Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%",
      "target": "To this end",
      "similarity": 0.8724
    },
    {
      "source": "Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8707
    },
    {
      "source": "Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%",
      "target": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "similarity": 0.8685
    },
    {
      "source": "Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%",
      "target": "However",
      "similarity": 0.8643
    },
    {
      "source": "These findings highlight the significant room for improvement in current reward models.\"",
      "target": "Exploration can also be directed using intrinsic rewards",
      "similarity": 0.8627
    },
    {
      "source": "These findings highlight the significant room for improvement in current reward models.\"",
      "target": "JAMxRSXLFz",
      "similarity": 0.861
    },
    {
      "source": "These findings highlight the significant room for improvement in current reward models.\"",
      "target": "across new LLMs and different tasks because of their limited ability to leverage",
      "similarity": 0.8601
    },
    {
      "source": "These findings highlight the significant room for improvement in current reward models.\"",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8574
    },
    {
      "source": "These findings highlight the significant room for improvement in current reward models.\"",
      "target": "254NJe9JEw",
      "similarity": 0.8564
    },
    {
      "source": "nNiWRRj6r9",
      "target": "9KxnxWOBA5",
      "similarity": 0.8821
    },
    {
      "source": "nNiWRRj6r9",
      "target": "Yet",
      "similarity": 0.8649
    },
    {
      "source": "nNiWRRj6r9",
      "target": "QhxjQOMdDF",
      "similarity": 0.853
    },
    {
      "source": "nNiWRRj6r9",
      "target": "First",
      "similarity": 0.8507
    },
    {
      "source": "nNiWRRj6r9",
      "target": "OhauMUNW8T",
      "similarity": 0.85
    },
    {
      "source": "In online learning scenarios where data arrives sequentially",
      "target": "otW0TJOUYF",
      "similarity": 0.9102
    },
    {
      "source": "In online learning scenarios where data arrives sequentially",
      "target": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "similarity": 0.9002
    },
    {
      "source": "In online learning scenarios where data arrives sequentially",
      "target": "4ktJJBvvUd",
      "similarity": 0.8978
    },
    {
      "source": "In online learning scenarios where data arrives sequentially",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8797
    },
    {
      "source": "In online learning scenarios where data arrives sequentially",
      "target": "FrFQpAgnGE",
      "similarity": 0.8753
    },
    {
      "source": "Next",
      "target": "kxnoqaisCT",
      "similarity": 0.8522
    },
    {
      "source": "Next",
      "target": "8TBGdH3t6a",
      "similarity": 0.8419
    },
    {
      "source": "Next",
      "target": "8DBTq09LgN",
      "similarity": 0.8413
    },
    {
      "source": "Next",
      "target": "4vzGQcVUG8",
      "similarity": 0.8328
    },
    {
      "source": "Next",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.8309
    },
    {
      "source": "XBF63bHDZw",
      "target": "X6y5CC44HM",
      "similarity": 0.8516
    },
    {
      "source": "XBF63bHDZw",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8076
    },
    {
      "source": "XBF63bHDZw",
      "target": "z0hUsPhwUN",
      "similarity": 0.8055
    },
    {
      "source": "XBF63bHDZw",
      "target": "For instance",
      "similarity": 0.8048
    },
    {
      "source": "XBF63bHDZw",
      "target": "RQz7szbVDs",
      "similarity": 0.8048
    },
    {
      "source": "R2834dhBlo",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.869
    },
    {
      "source": "R2834dhBlo",
      "target": "6bKEWevgSd",
      "similarity": 0.8686
    },
    {
      "source": "R2834dhBlo",
      "target": "jQP5o1VAVc",
      "similarity": 0.859
    },
    {
      "source": "R2834dhBlo",
      "target": "In response",
      "similarity": 0.855
    },
    {
      "source": "R2834dhBlo",
      "target": "fGIqGfmgkW",
      "similarity": 0.8533
    },
    {
      "source": "ZS7UEI3vG5",
      "target": "9EqQC2ct4H",
      "similarity": 0.8663
    },
    {
      "source": "ZS7UEI3vG5",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8636
    },
    {
      "source": "ZS7UEI3vG5",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8611
    },
    {
      "source": "ZS7UEI3vG5",
      "target": "for the development of effective diagnosis and prognosis solutions. While deep",
      "similarity": 0.8544
    },
    {
      "source": "ZS7UEI3vG5",
      "target": "eHehzSDUFp",
      "similarity": 0.8542
    },
    {
      "source": "samples from some underlying population $p^\\ast$",
      "target": "connection component",
      "similarity": 0.8577
    },
    {
      "source": "samples from some underlying population $p^\\ast$",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8548
    },
    {
      "source": "samples from some underlying population $p^\\ast$",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.849
    },
    {
      "source": "samples from some underlying population $p^\\ast$",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8458
    },
    {
      "source": "samples from some underlying population $p^\\ast$",
      "target": "yR47RmND1m",
      "similarity": 0.8376
    },
    {
      "source": "dependency on the (inverse) survival mass $1/\\alpha$",
      "target": "1qGkuxI9UX",
      "similarity": 0.8314
    },
    {
      "source": "dependency on the (inverse) survival mass $1/\\alpha$",
      "target": "https://github.com/OceannTwT/Tool-Planner.\"",
      "similarity": 0.8287
    },
    {
      "source": "dependency on the (inverse) survival mass $1/\\alpha$",
      "target": "In doing so",
      "similarity": 0.8258
    },
    {
      "source": "dependency on the (inverse) survival mass $1/\\alpha$",
      "target": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "similarity": 0.8221
    },
    {
      "source": "dependency on the (inverse) survival mass $1/\\alpha$",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8209
    },
    {
      "source": "both in terms of runtime and in number of oracle calls to the set $S$.  In this work we design a new learning method with runtime and query complexity polynomial in $1/\\alpha$.",
      "target": "Furthermore",
      "similarity": 0.8735
    },
    {
      "source": "both in terms of runtime and in number of oracle calls to the set $S$.  In this work we design a new learning method with runtime and query complexity polynomial in $1/\\alpha$.",
      "target": "Second",
      "similarity": 0.8438
    },
    {
      "source": "both in terms of runtime and in number of oracle calls to the set $S$.  In this work we design a new learning method with runtime and query complexity polynomial in $1/\\alpha$.",
      "target": "4vzGQcVUG8",
      "similarity": 0.8403
    },
    {
      "source": "both in terms of runtime and in number of oracle calls to the set $S$.  In this work we design a new learning method with runtime and query complexity polynomial in $1/\\alpha$.",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8171
    },
    {
      "source": "both in terms of runtime and in number of oracle calls to the set $S$.  In this work we design a new learning method with runtime and query complexity polynomial in $1/\\alpha$.",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8139
    },
    {
      "source": "Our result significantly improves over the prior works",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8488
    },
    {
      "source": "Our result significantly improves over the prior works",
      "target": "SqoL14HDm0",
      "similarity": 0.8392
    },
    {
      "source": "Our result significantly improves over the prior works",
      "target": "FCMpUOZkxi",
      "similarity": 0.838
    },
    {
      "source": "Our result significantly improves over the prior works",
      "target": "Bpn8q40n1n",
      "similarity": 0.834
    },
    {
      "source": "Our result significantly improves over the prior works",
      "target": "mkuB677eMM",
      "similarity": 0.8334
    },
    {
      "source": "by focusing on efficiently solving the underlying optimization problem using a general",
      "target": "The latter formulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan",
      "similarity": 0.8391
    },
    {
      "source": "by focusing on efficiently solving the underlying optimization problem using a general",
      "target": "Further",
      "similarity": 0.8368
    },
    {
      "source": "by focusing on efficiently solving the underlying optimization problem using a general",
      "target": "Finally",
      "similarity": 0.8105
    },
    {
      "source": "by focusing on efficiently solving the underlying optimization problem using a general",
      "target": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "similarity": 0.8089
    },
    {
      "source": "by focusing on efficiently solving the underlying optimization problem using a general",
      "target": "Based on this",
      "similarity": 0.7918
    },
    {
      "source": "purpose optimization algorithm with minimal assumptions.\"",
      "target": "tnB94WQGrn",
      "similarity": 0.8731
    },
    {
      "source": "purpose optimization algorithm with minimal assumptions.\"",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8656
    },
    {
      "source": "purpose optimization algorithm with minimal assumptions.\"",
      "target": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "similarity": 0.8611
    },
    {
      "source": "purpose optimization algorithm with minimal assumptions.\"",
      "target": "ZSdubdbOoi",
      "similarity": 0.8545
    },
    {
      "source": "purpose optimization algorithm with minimal assumptions.\"",
      "target": "CvGqMD5OtX",
      "similarity": 0.8484
    },
    {
      "source": "gx1wHnf5Vp",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8435
    },
    {
      "source": "gx1wHnf5Vp",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8377
    },
    {
      "source": "gx1wHnf5Vp",
      "target": "FrFQpAgnGE",
      "similarity": 0.8367
    },
    {
      "source": "gx1wHnf5Vp",
      "target": "2mqb8bPHeb",
      "similarity": 0.8329
    },
    {
      "source": "gx1wHnf5Vp",
      "target": "bMC1t7eLRc",
      "similarity": 0.832
    },
    {
      "source": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "target": "introduce a novel inductive graph framework",
      "similarity": 0.9009
    },
    {
      "source": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "target": "Thus",
      "similarity": 0.8711
    },
    {
      "source": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.8635
    },
    {
      "source": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "target": "eU39PDsZtT",
      "similarity": 0.8626
    },
    {
      "source": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "target": "rTCJ29pkuA",
      "similarity": 0.8616
    },
    {
      "source": "As a result",
      "target": "fL4qWkSmtM",
      "similarity": 0.88
    },
    {
      "source": "As a result",
      "target": "To explore this",
      "similarity": 0.8652
    },
    {
      "source": "As a result",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8596
    },
    {
      "source": "As a result",
      "target": "Inspired by these findings",
      "similarity": 0.8589
    },
    {
      "source": "As a result",
      "target": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "similarity": 0.832
    },
    {
      "source": "All experimental resources",
      "target": "xiQNfYl33p",
      "similarity": 0.8968
    },
    {
      "source": "All experimental resources",
      "target": "In preregistered experiments",
      "similarity": 0.8929
    },
    {
      "source": "All experimental resources",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8834
    },
    {
      "source": "All experimental resources",
      "target": "8DBTq09LgN",
      "similarity": 0.8805
    },
    {
      "source": "All experimental resources",
      "target": "QowsEic1sc",
      "similarity": 0.8799
    },
    {
      "source": "E4LAVLXAHW",
      "target": "L9eBxTCpQG",
      "similarity": 0.8851
    },
    {
      "source": "E4LAVLXAHW",
      "target": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "similarity": 0.8817
    },
    {
      "source": "E4LAVLXAHW",
      "target": "1qq1QJKM5q",
      "similarity": 0.8797
    },
    {
      "source": "E4LAVLXAHW",
      "target": "ff2V3UR9sC",
      "similarity": 0.8795
    },
    {
      "source": "E4LAVLXAHW",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8752
    },
    {
      "source": "tpHqsyZ3YX",
      "target": "Finally",
      "similarity": 0.8739
    },
    {
      "source": "tpHqsyZ3YX",
      "target": "Glm7Kj47nN",
      "similarity": 0.8539
    },
    {
      "source": "tpHqsyZ3YX",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8369
    },
    {
      "source": "tpHqsyZ3YX",
      "target": "HN8V0flwJF",
      "similarity": 0.8366
    },
    {
      "source": "tpHqsyZ3YX",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8328
    },
    {
      "source": "Previous studies have developed LLM assistants",
      "target": "To this end",
      "similarity": 0.8927
    },
    {
      "source": "Previous studies have developed LLM assistants",
      "target": "oP7arLOWix",
      "similarity": 0.8914
    },
    {
      "source": "Previous studies have developed LLM assistants",
      "target": "Qja5s0K3VX",
      "similarity": 0.8851
    },
    {
      "source": "Previous studies have developed LLM assistants",
      "target": "previous results.\"",
      "similarity": 0.8838
    },
    {
      "source": "Previous studies have developed LLM assistants",
      "target": "However",
      "similarity": 0.8813
    },
    {
      "source": "However",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8388
    },
    {
      "source": "However",
      "target": "At the inference stage",
      "similarity": 0.8387
    },
    {
      "source": "However",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8238
    },
    {
      "source": "However",
      "target": "In experiments with GPT-4",
      "similarity": 0.8224
    },
    {
      "source": "However",
      "target": "distributions of counterfactual prompts created by applying prefixes sampled from",
      "similarity": 0.8189
    },
    {
      "source": "In this paper",
      "target": "of 24 OOD scenarios. Further",
      "similarity": 0.8616
    },
    {
      "source": "In this paper",
      "target": "D2hhkU5O48",
      "similarity": 0.8319
    },
    {
      "source": "In this paper",
      "target": "In this paper",
      "similarity": 0.8317
    },
    {
      "source": "In this paper",
      "target": "kVrwHLAb20",
      "similarity": 0.8232
    },
    {
      "source": "In this paper",
      "target": "1tBvzOYTLF",
      "similarity": 0.8195
    },
    {
      "source": "In $\\texttt{ProAdvPrompter}$",
      "target": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "similarity": 0.857
    },
    {
      "source": "In $\\texttt{ProAdvPrompter}$",
      "target": "Finally",
      "similarity": 0.8397
    },
    {
      "source": "In $\\texttt{ProAdvPrompter}$",
      "target": "First",
      "similarity": 0.8327
    },
    {
      "source": "In $\\texttt{ProAdvPrompter}$",
      "target": "Bpn8q40n1n",
      "similarity": 0.8318
    },
    {
      "source": "In $\\texttt{ProAdvPrompter}$",
      "target": "By defining a topology-aware method to manipulate graph orbits",
      "similarity": 0.8286
    },
    {
      "source": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "target": "4O0v4s3IzY",
      "similarity": 0.8816
    },
    {
      "source": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "target": "is often a non-linear function",
      "similarity": 0.8689
    },
    {
      "source": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "target": "As a case study",
      "similarity": 0.8671
    },
    {
      "source": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "target": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "similarity": 0.8654
    },
    {
      "source": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "target": "PIpGN5Ko3v",
      "similarity": 0.8615
    },
    {
      "source": "Additionally",
      "target": "KAIqwkB3dT",
      "similarity": 0.8662
    },
    {
      "source": "Additionally",
      "target": "NTHMw8S1Ow",
      "similarity": 0.858
    },
    {
      "source": "Additionally",
      "target": "INqLJwqUmc",
      "similarity": 0.8574
    },
    {
      "source": "Additionally",
      "target": "n2NidsYDop",
      "similarity": 0.8543
    },
    {
      "source": "Additionally",
      "target": "mTCbq2QssD",
      "similarity": 0.849
    },
    {
      "source": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "target": "7bAjVh3CG3",
      "similarity": 0.8683
    },
    {
      "source": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "target": "h1XoHOd19I",
      "similarity": 0.8546
    },
    {
      "source": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "target": "In this paper",
      "similarity": 0.8521
    },
    {
      "source": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "target": "objects",
      "similarity": 0.8435
    },
    {
      "source": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "target": "relying on backward propagation",
      "similarity": 0.8431
    },
    {
      "source": "Moreover",
      "target": "3bcN6xlO6f",
      "similarity": 0.8992
    },
    {
      "source": "Moreover",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8917
    },
    {
      "source": "Moreover",
      "target": "Furthermore",
      "similarity": 0.8911
    },
    {
      "source": "Moreover",
      "target": "JytL2MrlLT",
      "similarity": 0.8841
    },
    {
      "source": "Moreover",
      "target": "given the unique characteristics of the expanded expert space",
      "similarity": 0.8823
    },
    {
      "source": "An ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).\"",
      "target": "To overcome such limitations",
      "similarity": 0.8691
    },
    {
      "source": "An ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).\"",
      "target": "MF7ljU8xcf",
      "similarity": 0.8387
    },
    {
      "source": "An ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).\"",
      "target": "OjAU0LLDbe",
      "similarity": 0.8245
    },
    {
      "source": "An ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).\"",
      "target": "pPQPQ7Yd58",
      "similarity": 0.824
    },
    {
      "source": "An ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).\"",
      "target": "In this paper",
      "similarity": 0.8226
    },
    {
      "source": "kVrwHLAb20",
      "target": "During training with 128K-long contexts",
      "similarity": 0.8402
    },
    {
      "source": "kVrwHLAb20",
      "target": "D2hhkU5O48",
      "similarity": 0.8062
    },
    {
      "source": "kVrwHLAb20",
      "target": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "similarity": 0.7956
    },
    {
      "source": "kVrwHLAb20",
      "target": "md9qolJwLl",
      "similarity": 0.7937
    },
    {
      "source": "kVrwHLAb20",
      "target": "To address these challenges",
      "similarity": 0.7936
    },
    {
      "source": "dTkqaCKLPp",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8866
    },
    {
      "source": "dTkqaCKLPp",
      "target": "Given these challenges",
      "similarity": 0.8777
    },
    {
      "source": "dTkqaCKLPp",
      "target": "https://github.com/OceannTwT/Tool-Planner.\"",
      "similarity": 0.8777
    },
    {
      "source": "dTkqaCKLPp",
      "target": "Yet",
      "similarity": 0.8627
    },
    {
      "source": "dTkqaCKLPp",
      "target": "T2d0geb6y0",
      "similarity": 0.8604
    },
    {
      "source": "DFSb67ksVr",
      "target": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "similarity": 0.8313
    },
    {
      "source": "DFSb67ksVr",
      "target": "However",
      "similarity": 0.8185
    },
    {
      "source": "DFSb67ksVr",
      "target": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "similarity": 0.8176
    },
    {
      "source": "DFSb67ksVr",
      "target": "CxXGvKRDnL",
      "similarity": 0.8159
    },
    {
      "source": "DFSb67ksVr",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8045
    },
    {
      "source": "Existing estimators often rely on non-differentiable combinatorial components. Here",
      "target": "30oIfmrcFO",
      "similarity": 0.8528
    },
    {
      "source": "Existing estimators often rely on non-differentiable combinatorial components. Here",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8341
    },
    {
      "source": "Existing estimators often rely on non-differentiable combinatorial components. Here",
      "target": "This paper proposes",
      "similarity": 0.834
    },
    {
      "source": "Existing estimators often rely on non-differentiable combinatorial components. Here",
      "target": "2ET561DyPe",
      "similarity": 0.834
    },
    {
      "source": "Existing estimators often rely on non-differentiable combinatorial components. Here",
      "target": "Building on this",
      "similarity": 0.8337
    },
    {
      "source": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8793
    },
    {
      "source": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "target": "254NJe9JEw",
      "similarity": 0.8663
    },
    {
      "source": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "target": "JAMxRSXLFz",
      "similarity": 0.8597
    },
    {
      "source": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "target": "X1U74IwuxG",
      "similarity": 0.8537
    },
    {
      "source": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "target": "In response",
      "similarity": 0.8507
    },
    {
      "source": "We design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.",
      "target": "R4h5PXzUuU",
      "similarity": 0.8506
    },
    {
      "source": "We design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8393
    },
    {
      "source": "We design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.",
      "target": "MeGDmZjUXy",
      "similarity": 0.8379
    },
    {
      "source": "We design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8356
    },
    {
      "source": "We design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8254
    },
    {
      "source": "However",
      "target": "jJXZvPe5z0",
      "similarity": 0.8411
    },
    {
      "source": "However",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8277
    },
    {
      "source": "However",
      "target": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "similarity": 0.826
    },
    {
      "source": "However",
      "target": "p60Y6o85Cj",
      "similarity": 0.8246
    },
    {
      "source": "However",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8222
    },
    {
      "source": "These steps result in MxNet",
      "target": "QWunLKbBGF",
      "similarity": 0.8738
    },
    {
      "source": "These steps result in MxNet",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8734
    },
    {
      "source": "These steps result in MxNet",
      "target": "odU59TxdiB",
      "similarity": 0.8704
    },
    {
      "source": "These steps result in MxNet",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8612
    },
    {
      "source": "These steps result in MxNet",
      "target": "A1HhtITVEi",
      "similarity": 0.8599
    },
    {
      "source": "TXfzH933qV",
      "target": "sIE2rI3ZPs",
      "similarity": 0.8413
    },
    {
      "source": "TXfzH933qV",
      "target": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "similarity": 0.841
    },
    {
      "source": "TXfzH933qV",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8409
    },
    {
      "source": "TXfzH933qV",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.84
    },
    {
      "source": "TXfzH933qV",
      "target": "As models are becoming larger to capture more complex capabilities",
      "similarity": 0.8399
    },
    {
      "source": "NGKQoaqLpo",
      "target": "stacking methods. Specifically",
      "similarity": 0.8768
    },
    {
      "source": "NGKQoaqLpo",
      "target": "To demonstrate the effectiveness of our framework",
      "similarity": 0.8744
    },
    {
      "source": "NGKQoaqLpo",
      "target": "Second",
      "similarity": 0.8728
    },
    {
      "source": "NGKQoaqLpo",
      "target": "generative process is partially-ordered following the CGM structure. This",
      "similarity": 0.8686
    },
    {
      "source": "NGKQoaqLpo",
      "target": "Antib6Uovh",
      "similarity": 0.8661
    },
    {
      "source": "To systematically study this phenomenon",
      "target": "To remedy this problem",
      "similarity": 0.8495
    },
    {
      "source": "To systematically study this phenomenon",
      "target": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "similarity": 0.8442
    },
    {
      "source": "To systematically study this phenomenon",
      "target": "84WmbzikPP",
      "similarity": 0.8383
    },
    {
      "source": "To systematically study this phenomenon",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8283
    },
    {
      "source": "To systematically study this phenomenon",
      "target": "UvPdpa4LuV",
      "similarity": 0.8206
    },
    {
      "source": "Finally",
      "target": "xnF2U0ro7b",
      "similarity": 0.8749
    },
    {
      "source": "Finally",
      "target": "VVixJ9QavY",
      "similarity": 0.8586
    },
    {
      "source": "Finally",
      "target": "1F8xTfv6ah",
      "similarity": 0.8578
    },
    {
      "source": "Finally",
      "target": "To address the lack of annotations on levels of severity",
      "similarity": 0.8423
    },
    {
      "source": "Finally",
      "target": "qIbbBSzH6n",
      "similarity": 0.8423
    },
    {
      "source": "G7sIFXugTX",
      "target": "2kGKsyhtvh",
      "similarity": 0.8468
    },
    {
      "source": "G7sIFXugTX",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.8417
    },
    {
      "source": "G7sIFXugTX",
      "target": "To this end",
      "similarity": 0.837
    },
    {
      "source": "G7sIFXugTX",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8231
    },
    {
      "source": "G7sIFXugTX",
      "target": "HN8V0flwJF",
      "similarity": 0.8212
    },
    {
      "source": "82p8VHRsaK",
      "target": "ue1Tt3h1VC",
      "similarity": 0.844
    },
    {
      "source": "82p8VHRsaK",
      "target": "9kJperA2a4",
      "similarity": 0.835
    },
    {
      "source": "82p8VHRsaK",
      "target": "jTEKTdI3K9",
      "similarity": 0.8336
    },
    {
      "source": "82p8VHRsaK",
      "target": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "similarity": 0.8307
    },
    {
      "source": "82p8VHRsaK",
      "target": "v1rFkElnIn",
      "similarity": 0.8261
    },
    {
      "source": "Ouu3HnIVBc",
      "target": "KAIqwkB3dT",
      "similarity": 0.8388
    },
    {
      "source": "Ouu3HnIVBc",
      "target": "mTCbq2QssD",
      "similarity": 0.8314
    },
    {
      "source": "Ouu3HnIVBc",
      "target": "n2NidsYDop",
      "similarity": 0.8313
    },
    {
      "source": "Ouu3HnIVBc",
      "target": "layer-progressive neuron locating",
      "similarity": 0.8308
    },
    {
      "source": "Ouu3HnIVBc",
      "target": "Moreover",
      "similarity": 0.8277
    },
    {
      "source": "wFg0shwoRe",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8445
    },
    {
      "source": "wFg0shwoRe",
      "target": "kX8h23UG6v",
      "similarity": 0.8425
    },
    {
      "source": "wFg0shwoRe",
      "target": "MeGDmZjUXy",
      "similarity": 0.8394
    },
    {
      "source": "wFg0shwoRe",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8377
    },
    {
      "source": "wFg0shwoRe",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8294
    },
    {
      "source": "x83w6yGIWb",
      "target": "sVNfWhtaJC",
      "similarity": 0.8806
    },
    {
      "source": "x83w6yGIWb",
      "target": "1xzqz73hvL",
      "similarity": 0.8579
    },
    {
      "source": "x83w6yGIWb",
      "target": "several graph- and simplicial complex-based models on three topological classification",
      "similarity": 0.8415
    },
    {
      "source": "x83w6yGIWb",
      "target": "Inspired by these findings",
      "similarity": 0.8252
    },
    {
      "source": "x83w6yGIWb",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8206
    },
    {
      "source": "compression has become increasingly crucial for reducing costs and improving",
      "target": "kRBQwlkFSP",
      "similarity": 0.8432
    },
    {
      "source": "compression has become increasingly crucial for reducing costs and improving",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8428
    },
    {
      "source": "compression has become increasingly crucial for reducing costs and improving",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.841
    },
    {
      "source": "compression has become increasingly crucial for reducing costs and improving",
      "target": "Existing approaches",
      "similarity": 0.8409
    },
    {
      "source": "compression has become increasingly crucial for reducing costs and improving",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.8399
    },
    {
      "source": "inference efficiency. Post-training pruning is a promising method that does not",
      "target": "stacking methods. Specifically",
      "similarity": 0.8944
    },
    {
      "source": "inference efficiency. Post-training pruning is a promising method that does not",
      "target": "hyfe5q5TD0",
      "similarity": 0.8937
    },
    {
      "source": "inference efficiency. Post-training pruning is a promising method that does not",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8921
    },
    {
      "source": "inference efficiency. Post-training pruning is a promising method that does not",
      "target": "2mqb8bPHeb",
      "similarity": 0.8783
    },
    {
      "source": "inference efficiency. Post-training pruning is a promising method that does not",
      "target": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "similarity": 0.8717
    },
    {
      "source": "require resource-intensive iterative training and only needs a small amount of",
      "target": "U42TkrEDzb",
      "similarity": 0.8657
    },
    {
      "source": "require resource-intensive iterative training and only needs a small amount of",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.8639
    },
    {
      "source": "require resource-intensive iterative training and only needs a small amount of",
      "target": "especially in topological deep learning (TDL)",
      "similarity": 0.8476
    },
    {
      "source": "require resource-intensive iterative training and only needs a small amount of",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8424
    },
    {
      "source": "require resource-intensive iterative training and only needs a small amount of",
      "target": "GhexuBLxbO",
      "similarity": 0.841
    },
    {
      "source": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8744
    },
    {
      "source": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "target": "1R5BcYS8EC",
      "similarity": 0.873
    },
    {
      "source": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "target": "Y7slJZPGCy",
      "similarity": 0.8705
    },
    {
      "source": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "target": "dgR6i4TSng",
      "similarity": 0.8585
    },
    {
      "source": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "target": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "similarity": 0.8579
    },
    {
      "source": "explore the effects of calibration data",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.9104
    },
    {
      "source": "explore the effects of calibration data",
      "target": "SOTA LLMs",
      "similarity": 0.8752
    },
    {
      "source": "explore the effects of calibration data",
      "target": "Building on the SpiderBoost algorithm framework",
      "similarity": 0.8687
    },
    {
      "source": "explore the effects of calibration data",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8655
    },
    {
      "source": "explore the effects of calibration data",
      "target": "U3PBITXNG6",
      "similarity": 0.8565
    },
    {
      "source": "calibration data is also crucial to post-training pruning",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8666
    },
    {
      "source": "calibration data is also crucial to post-training pruning",
      "target": "of extreme weather events",
      "similarity": 0.8486
    },
    {
      "source": "calibration data is also crucial to post-training pruning",
      "target": "component of real-world software development.\"",
      "similarity": 0.8437
    },
    {
      "source": "calibration data is also crucial to post-training pruning",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8397
    },
    {
      "source": "calibration data is also crucial to post-training pruning",
      "target": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "similarity": 0.8343
    },
    {
      "source": "data",
      "target": "67X93aZHII",
      "similarity": 0.8391
    },
    {
      "source": "data",
      "target": "l0fn10vSyM",
      "similarity": 0.8374
    },
    {
      "source": "data",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8295
    },
    {
      "source": "data",
      "target": "5pd78GmXC6",
      "similarity": 0.826
    },
    {
      "source": "data",
      "target": "OJsMGsO6yn",
      "similarity": 0.8131
    },
    {
      "source": "pre-training data",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8994
    },
    {
      "source": "pre-training data",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8962
    },
    {
      "source": "pre-training data",
      "target": "JytL2MrlLT",
      "similarity": 0.8894
    },
    {
      "source": "pre-training data",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8835
    },
    {
      "source": "pre-training data",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8831
    },
    {
      "source": "is usually inaccessible for advanced LLMs",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8727
    },
    {
      "source": "is usually inaccessible for advanced LLMs",
      "target": "590yfqz1LE",
      "similarity": 0.8645
    },
    {
      "source": "is usually inaccessible for advanced LLMs",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.854
    },
    {
      "source": "is usually inaccessible for advanced LLMs",
      "target": "9cQB1Hwrtw",
      "similarity": 0.851
    },
    {
      "source": "is usually inaccessible for advanced LLMs",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8489
    },
    {
      "source": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "target": "sZJNkorXMk",
      "similarity": 0.8587
    },
    {
      "source": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8571
    },
    {
      "source": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "target": "8EfxjTCg2k",
      "similarity": 0.8556
    },
    {
      "source": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "target": "Moreover",
      "similarity": 0.8547
    },
    {
      "source": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "target": "JYwVijuNA7",
      "similarity": 0.8447
    },
    {
      "source": "show that the proposed strategy can enhance the performance of strong pruning",
      "target": "6HcnC3pPkp",
      "similarity": 0.8879
    },
    {
      "source": "show that the proposed strategy can enhance the performance of strong pruning",
      "target": "kX8h23UG6v",
      "similarity": 0.8744
    },
    {
      "source": "show that the proposed strategy can enhance the performance of strong pruning",
      "target": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "similarity": 0.8697
    },
    {
      "source": "show that the proposed strategy can enhance the performance of strong pruning",
      "target": "We conduct a detailed analysis of early stopping in our algorithm",
      "similarity": 0.8686
    },
    {
      "source": "show that the proposed strategy can enhance the performance of strong pruning",
      "target": "In this paper",
      "similarity": 0.8644
    },
    {
      "source": "methods (e.g.",
      "target": "We have prepared an efficient implementation",
      "similarity": 0.8408
    },
    {
      "source": "methods (e.g.",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8373
    },
    {
      "source": "methods (e.g.",
      "target": "8g4XgC8HPF",
      "similarity": 0.8351
    },
    {
      "source": "methods (e.g.",
      "target": "This paper introduces *data taggants*",
      "similarity": 0.8346
    },
    {
      "source": "methods (e.g.",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.833
    },
    {
      "source": "Se6MgCtRhz",
      "target": "IuU0wcO0mo",
      "similarity": 0.8832
    },
    {
      "source": "Se6MgCtRhz",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8761
    },
    {
      "source": "Se6MgCtRhz",
      "target": "Tn5B6Udq3E",
      "similarity": 0.869
    },
    {
      "source": "Se6MgCtRhz",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8671
    },
    {
      "source": "Se6MgCtRhz",
      "target": "https://github.com/mint-vu/MCNC.\"",
      "similarity": 0.8613
    },
    {
      "source": "BUj9VSCoET",
      "target": "In this task",
      "similarity": 0.8352
    },
    {
      "source": "BUj9VSCoET",
      "target": "YFxfcQMLWX",
      "similarity": 0.8316
    },
    {
      "source": "BUj9VSCoET",
      "target": "WfxPVtYRlL",
      "similarity": 0.8305
    },
    {
      "source": "BUj9VSCoET",
      "target": "FZv3kPHTtB",
      "similarity": 0.8258
    },
    {
      "source": "BUj9VSCoET",
      "target": "In response",
      "similarity": 0.82
    },
    {
      "source": "To overcome these challenges",
      "target": "Q0s6kgrUMr",
      "similarity": 0.8342
    },
    {
      "source": "To overcome these challenges",
      "target": "traditional energy-based models",
      "similarity": 0.8337
    },
    {
      "source": "To overcome these challenges",
      "target": "DKgAFfCs5F",
      "similarity": 0.8144
    },
    {
      "source": "To overcome these challenges",
      "target": "kSISSDUYFh",
      "similarity": 0.8074
    },
    {
      "source": "To overcome these challenges",
      "target": "3n6DYH3cIP",
      "similarity": 0.8049
    },
    {
      "source": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "target": "44cMlQSreK",
      "similarity": 0.861
    },
    {
      "source": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "target": "7HEMpBTb3R",
      "similarity": 0.8505
    },
    {
      "source": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "target": "Finally",
      "similarity": 0.8392
    },
    {
      "source": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "target": "In the MetaICL in-context learning evaluation",
      "similarity": 0.8322
    },
    {
      "source": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "target": "In this paper",
      "similarity": 0.8194
    },
    {
      "source": "5z9GjHgerY",
      "target": "g6syfIrVuS",
      "similarity": 0.8935
    },
    {
      "source": "5z9GjHgerY",
      "target": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "similarity": 0.845
    },
    {
      "source": "5z9GjHgerY",
      "target": "b24n2LS2BJ",
      "similarity": 0.8378
    },
    {
      "source": "5z9GjHgerY",
      "target": "4es2oO9tw1",
      "similarity": 0.8338
    },
    {
      "source": "5z9GjHgerY",
      "target": "MBBRHDuiwM",
      "similarity": 0.8337
    },
    {
      "source": "In this paper",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8053
    },
    {
      "source": "In this paper",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.8045
    },
    {
      "source": "In this paper",
      "target": "To address these challenges",
      "similarity": 0.8037
    },
    {
      "source": "In this paper",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.801
    },
    {
      "source": "In this paper",
      "target": "p60Y6o85Cj",
      "similarity": 0.8003
    },
    {
      "source": "To enable structural learning with the language model",
      "target": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "similarity": 0.9247
    },
    {
      "source": "To enable structural learning with the language model",
      "target": "also study the necessity of this condition via ablation studies and analytical exam-",
      "similarity": 0.9144
    },
    {
      "source": "To enable structural learning with the language model",
      "target": "0e2pcSxQJS",
      "similarity": 0.8733
    },
    {
      "source": "To enable structural learning with the language model",
      "target": "qFZnAC4GHR",
      "similarity": 0.8675
    },
    {
      "source": "To enable structural learning with the language model",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8652
    },
    {
      "source": "By training on both experimental and high-quality synthetic structures",
      "target": "of our proposed method through a new understanding of the contrastive loss of",
      "similarity": 0.8457
    },
    {
      "source": "By training on both experimental and high-quality synthetic structures",
      "target": "zDC3iCBxJb",
      "similarity": 0.8239
    },
    {
      "source": "By training on both experimental and high-quality synthetic structures",
      "target": "nzjSvVZBIp",
      "similarity": 0.8069
    },
    {
      "source": "By training on both experimental and high-quality synthetic structures",
      "target": "At the inference stage",
      "similarity": 0.7959
    },
    {
      "source": "By training on both experimental and high-quality synthetic structures",
      "target": "entities of a sentence (subject",
      "similarity": 0.7948
    },
    {
      "source": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "target": "Our novel resource",
      "similarity": 0.8334
    },
    {
      "source": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "target": "0GzqVqCKns",
      "similarity": 0.8282
    },
    {
      "source": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "target": "dence on a transductive learning framework. To address these shortcomings",
      "similarity": 0.8155
    },
    {
      "source": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8145
    },
    {
      "source": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "target": "u3TL0qxLWf",
      "similarity": 0.8143
    },
    {
      "source": "Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.",
      "target": "6GATHdOi1x",
      "similarity": 0.8521
    },
    {
      "source": "Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.",
      "target": "Such models faced convergence issues due to vanishing gradient",
      "similarity": 0.8258
    },
    {
      "source": "Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.",
      "target": "To this end",
      "similarity": 0.8199
    },
    {
      "source": "Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.",
      "target": "(e.g.",
      "similarity": 0.8145
    },
    {
      "source": "Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.",
      "target": "models. However",
      "similarity": 0.8112
    },
    {
      "source": "Moreover",
      "target": "4YzVF9isgD",
      "similarity": 0.8483
    },
    {
      "source": "Moreover",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8398
    },
    {
      "source": "Moreover",
      "target": "E48QvQppIN",
      "similarity": 0.8371
    },
    {
      "source": "Moreover",
      "target": "First",
      "similarity": 0.8361
    },
    {
      "source": "Moreover",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.828
    },
    {
      "source": "moWiYJuSGF",
      "target": "Taking advantage of residual-like architectural designs",
      "similarity": 0.8703
    },
    {
      "source": "moWiYJuSGF",
      "target": "hovDbX4Gh6",
      "similarity": 0.8386
    },
    {
      "source": "moWiYJuSGF",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8108
    },
    {
      "source": "moWiYJuSGF",
      "target": "potential algorithms to solve one task",
      "similarity": 0.8106
    },
    {
      "source": "moWiYJuSGF",
      "target": "MMwaQEVsAg",
      "similarity": 0.8097
    },
    {
      "source": "4YzVF9isgD",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.9048
    },
    {
      "source": "4YzVF9isgD",
      "target": "E48QvQppIN",
      "similarity": 0.8944
    },
    {
      "source": "4YzVF9isgD",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.88
    },
    {
      "source": "4YzVF9isgD",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.875
    },
    {
      "source": "4YzVF9isgD",
      "target": "2pNLknCTvG",
      "similarity": 0.8742
    },
    {
      "source": "Kak2ZH5Itp",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8523
    },
    {
      "source": "Kak2ZH5Itp",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8473
    },
    {
      "source": "Kak2ZH5Itp",
      "target": "(2) use them to evaluate and contextualize the degree of disentanglement and",
      "similarity": 0.8415
    },
    {
      "source": "Kak2ZH5Itp",
      "target": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "similarity": 0.8407
    },
    {
      "source": "Kak2ZH5Itp",
      "target": "2pNLknCTvG",
      "similarity": 0.8401
    },
    {
      "source": "dgR6i4TSng",
      "target": "However",
      "similarity": 0.8769
    },
    {
      "source": "dgR6i4TSng",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8751
    },
    {
      "source": "dgR6i4TSng",
      "target": "a challenge",
      "similarity": 0.8717
    },
    {
      "source": "dgR6i4TSng",
      "target": "TDy5Ih78b4",
      "similarity": 0.8704
    },
    {
      "source": "dgR6i4TSng",
      "target": "yUC8pU508S",
      "similarity": 0.8645
    },
    {
      "source": "rpwGUtTeA5",
      "target": "BLWaTeucYX",
      "similarity": 0.9007
    },
    {
      "source": "rpwGUtTeA5",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8913
    },
    {
      "source": "rpwGUtTeA5",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.8749
    },
    {
      "source": "rpwGUtTeA5",
      "target": "bAFVlpFQvT",
      "similarity": 0.8742
    },
    {
      "source": "rpwGUtTeA5",
      "target": "(3) Lightweight training on 5B long-context data is sufficient to extend the hybrid model's context length from 4K to 128K.",
      "similarity": 0.8728
    },
    {
      "source": "Following the derived guidelines",
      "target": "other baselines across all metrics",
      "similarity": 0.8791
    },
    {
      "source": "Following the derived guidelines",
      "target": "However",
      "similarity": 0.8778
    },
    {
      "source": "Following the derived guidelines",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8745
    },
    {
      "source": "Following the derived guidelines",
      "target": "bSq0XGS3kW",
      "similarity": 0.8676
    },
    {
      "source": "Following the derived guidelines",
      "target": "NvDRvtrGLo",
      "similarity": 0.8631
    },
    {
      "source": "On the AlpacaEval benchmark",
      "target": "On the other hand",
      "similarity": 0.8662
    },
    {
      "source": "On the AlpacaEval benchmark",
      "target": "To address this gap",
      "similarity": 0.8233
    },
    {
      "source": "On the AlpacaEval benchmark",
      "target": "Moreover",
      "similarity": 0.8193
    },
    {
      "source": "On the AlpacaEval benchmark",
      "target": "To benchmark current systems on visually rich document retrieval",
      "similarity": 0.8179
    },
    {
      "source": "On the AlpacaEval benchmark",
      "target": "ogXkmugNZw",
      "similarity": 0.8174
    },
    {
      "source": "UxzKcIZedp",
      "target": "u2QdCiOgwA",
      "similarity": 0.8843
    },
    {
      "source": "UxzKcIZedp",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8824
    },
    {
      "source": "UxzKcIZedp",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8732
    },
    {
      "source": "UxzKcIZedp",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8677
    },
    {
      "source": "UxzKcIZedp",
      "target": "BL4WBIfyrz",
      "similarity": 0.8625
    },
    {
      "source": "Despite recent advancements in single-person motion generation",
      "target": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "similarity": 0.8554
    },
    {
      "source": "Despite recent advancements in single-person motion generation",
      "target": "8bjspmAMBk",
      "similarity": 0.8539
    },
    {
      "source": "Despite recent advancements in single-person motion generation",
      "target": "higher-order models.\"",
      "similarity": 0.8356
    },
    {
      "source": "Despite recent advancements in single-person motion generation",
      "target": "eNbA8Fqir4",
      "similarity": 0.8276
    },
    {
      "source": "Despite recent advancements in single-person motion generation",
      "target": "AZR4R3lw7y",
      "similarity": 0.8214
    },
    {
      "source": "To address these challenges",
      "target": "However",
      "similarity": 0.8074
    },
    {
      "source": "To address these challenges",
      "target": "Moreover",
      "similarity": 0.8047
    },
    {
      "source": "To address these challenges",
      "target": "In this paper",
      "similarity": 0.8036
    },
    {
      "source": "To address these challenges",
      "target": "oCUYc7BzXQ",
      "similarity": 0.8029
    },
    {
      "source": "To address these challenges",
      "target": "Existing safety constraints are then integrated into the COP",
      "similarity": 0.8018
    },
    {
      "source": "First",
      "target": "t6QHYUOQL7",
      "similarity": 0.8842
    },
    {
      "source": "First",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8767
    },
    {
      "source": "First",
      "target": "Yet",
      "similarity": 0.8756
    },
    {
      "source": "First",
      "target": "OhauMUNW8T",
      "similarity": 0.8701
    },
    {
      "source": "First",
      "target": "pDDODPtpx9",
      "similarity": 0.8688
    },
    {
      "source": "Second",
      "target": "uqe5HkjbT9",
      "similarity": 0.8437
    },
    {
      "source": "Second",
      "target": "6bKEWevgSd",
      "similarity": 0.833
    },
    {
      "source": "Second",
      "target": "Metrics for probability measures",
      "similarity": 0.83
    },
    {
      "source": "Second",
      "target": "To overcome these challenges",
      "similarity": 0.8235
    },
    {
      "source": "Second",
      "target": "Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.",
      "similarity": 0.8166
    },
    {
      "source": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "target": "Kwo20MWWCb",
      "similarity": 0.8694
    },
    {
      "source": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "target": "kbm6tsICar",
      "similarity": 0.8682
    },
    {
      "source": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "target": "nx9Z5Kva96",
      "similarity": 0.8633
    },
    {
      "source": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8573
    },
    {
      "source": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "target": "4dAgG8ma3B",
      "similarity": 0.8529
    },
    {
      "source": "1Iu2Yte5N6",
      "target": "oDbiL9CLoS",
      "similarity": 0.8231
    },
    {
      "source": "1Iu2Yte5N6",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8084
    },
    {
      "source": "1Iu2Yte5N6",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.8041
    },
    {
      "source": "1Iu2Yte5N6",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8019
    },
    {
      "source": "1Iu2Yte5N6",
      "target": "ISqx8giekS",
      "similarity": 0.7904
    },
    {
      "source": "1qP3lsatCR",
      "target": "hwSmPOAmhk",
      "similarity": 0.8557
    },
    {
      "source": "1qP3lsatCR",
      "target": "JAMxRSXLFz",
      "similarity": 0.8473
    },
    {
      "source": "1qP3lsatCR",
      "target": "Our key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix",
      "similarity": 0.84
    },
    {
      "source": "1qP3lsatCR",
      "target": "AWg2tkbydO",
      "similarity": 0.8387
    },
    {
      "source": "1qP3lsatCR",
      "target": "254NJe9JEw",
      "similarity": 0.8356
    },
    {
      "source": "In this paper",
      "target": "h6ktwCPYxE",
      "similarity": 0.8319
    },
    {
      "source": "In this paper",
      "target": "aKJr5NnN8U",
      "similarity": 0.8279
    },
    {
      "source": "In this paper",
      "target": "78tc3EiUrN",
      "similarity": 0.8177
    },
    {
      "source": "In this paper",
      "target": "dsP91M4hDL",
      "similarity": 0.8136
    },
    {
      "source": "In this paper",
      "target": "In addition",
      "similarity": 0.8101
    },
    {
      "source": "tNn6Hskmti",
      "target": "content recommendation",
      "similarity": 0.8127
    },
    {
      "source": "tNn6Hskmti",
      "target": "5yDS32hKJc",
      "similarity": 0.8061
    },
    {
      "source": "tNn6Hskmti",
      "target": "We find that naively applying LLMs to proof optimization falls short",
      "similarity": 0.7887
    },
    {
      "source": "tNn6Hskmti",
      "target": "3RSLW9YSgk",
      "similarity": 0.786
    },
    {
      "source": "tNn6Hskmti",
      "target": "amDkNPVWcn",
      "similarity": 0.7852
    },
    {
      "source": "rlgplAuN2p",
      "target": "5x88lQ2MsH",
      "similarity": 0.8378
    },
    {
      "source": "rlgplAuN2p",
      "target": "Because of this",
      "similarity": 0.8286
    },
    {
      "source": "rlgplAuN2p",
      "target": "NIkfix2eDQ",
      "similarity": 0.8235
    },
    {
      "source": "rlgplAuN2p",
      "target": "HN8V0flwJF",
      "similarity": 0.8225
    },
    {
      "source": "rlgplAuN2p",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8198
    },
    {
      "source": "pDDODPtpx9",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8963
    },
    {
      "source": "pDDODPtpx9",
      "target": "In this paper",
      "similarity": 0.8916
    },
    {
      "source": "pDDODPtpx9",
      "target": "To this end",
      "similarity": 0.885
    },
    {
      "source": "pDDODPtpx9",
      "target": "R4q3cY3kQf",
      "similarity": 0.8839
    },
    {
      "source": "pDDODPtpx9",
      "target": "Usklli4gMc",
      "similarity": 0.8808
    },
    {
      "source": "bqf0aCF3Dd",
      "target": "In this work",
      "similarity": 0.8375
    },
    {
      "source": "bqf0aCF3Dd",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8304
    },
    {
      "source": "bqf0aCF3Dd",
      "target": "P6IVIoGRRg",
      "similarity": 0.8287
    },
    {
      "source": "bqf0aCF3Dd",
      "target": "In addition",
      "similarity": 0.827
    },
    {
      "source": "bqf0aCF3Dd",
      "target": "Extensive experiments validate BiGR's superior performance in generation quality",
      "similarity": 0.8255
    },
    {
      "source": "yR47RmND1m",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.886
    },
    {
      "source": "yR47RmND1m",
      "target": "MJNywBdSDy",
      "similarity": 0.8453
    },
    {
      "source": "yR47RmND1m",
      "target": "At the inference stage",
      "similarity": 0.8403
    },
    {
      "source": "yR47RmND1m",
      "target": "entities of a sentence (subject",
      "similarity": 0.8391
    },
    {
      "source": "yR47RmND1m",
      "target": "zg3ec1TdAP",
      "similarity": 0.8374
    },
    {
      "source": "1eQT9OzfNQ",
      "target": "However",
      "similarity": 0.8899
    },
    {
      "source": "1eQT9OzfNQ",
      "target": "fv9XU7CyN2",
      "similarity": 0.8867
    },
    {
      "source": "1eQT9OzfNQ",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8804
    },
    {
      "source": "1eQT9OzfNQ",
      "target": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "similarity": 0.8779
    },
    {
      "source": "1eQT9OzfNQ",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8759
    },
    {
      "source": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "target": "yUC8pU508S",
      "similarity": 0.8942
    },
    {
      "source": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "target": "However",
      "similarity": 0.8772
    },
    {
      "source": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "target": "TDy5Ih78b4",
      "similarity": 0.8705
    },
    {
      "source": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "target": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "similarity": 0.8664
    },
    {
      "source": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "target": "prefix distributions",
      "similarity": 0.8564
    },
    {
      "source": "2) We tailor the compression workflow",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8537
    },
    {
      "source": "2) We tailor the compression workflow",
      "target": "F57HPKZ6KD",
      "similarity": 0.8451
    },
    {
      "source": "2) We tailor the compression workflow",
      "target": "VQwI055flA",
      "similarity": 0.8426
    },
    {
      "source": "2) We tailor the compression workflow",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8389
    },
    {
      "source": "2) We tailor the compression workflow",
      "target": "WCRQFlji2q",
      "similarity": 0.8371
    },
    {
      "source": "3) We train the model through compression-based auto-regression",
      "target": "90DC0IvlSs",
      "similarity": 0.8746
    },
    {
      "source": "3) We train the model through compression-based auto-regression",
      "target": "However",
      "similarity": 0.87
    },
    {
      "source": "3) We train the model through compression-based auto-regression",
      "target": "to address these failure modes",
      "similarity": 0.868
    },
    {
      "source": "3) We train the model through compression-based auto-regression",
      "target": "Fty0wTcemV",
      "similarity": 0.868
    },
    {
      "source": "3) We train the model through compression-based auto-regression",
      "target": "For TP",
      "similarity": 0.8669
    },
    {
      "source": "4) During training",
      "target": "SUc1UOWndp",
      "similarity": 0.7917
    },
    {
      "source": "4) During training",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.79
    },
    {
      "source": "4) During training",
      "target": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "similarity": 0.7867
    },
    {
      "source": "4) During training",
      "target": "FJv8VMPxWi",
      "similarity": 0.7852
    },
    {
      "source": "4) During training",
      "target": "PxlfzEePC0",
      "similarity": 0.7833
    },
    {
      "source": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8812
    },
    {
      "source": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "target": "For example",
      "similarity": 0.871
    },
    {
      "source": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "target": "v1rFkElnIn",
      "similarity": 0.8676
    },
    {
      "source": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "target": "pq1WUegkza",
      "similarity": 0.8662
    },
    {
      "source": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "target": "jTEKTdI3K9",
      "similarity": 0.8591
    },
    {
      "source": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "target": "is often a non-linear function",
      "similarity": 0.9048
    },
    {
      "source": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "target": "4O0v4s3IzY",
      "similarity": 0.8985
    },
    {
      "source": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "target": "As a case study",
      "similarity": 0.8781
    },
    {
      "source": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "target": "Additionally",
      "similarity": 0.8745
    },
    {
      "source": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "target": "phAlw3JPms",
      "similarity": 0.8666
    },
    {
      "source": "7mlvOHL6qJ",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.9022
    },
    {
      "source": "7mlvOHL6qJ",
      "target": "However",
      "similarity": 0.8991
    },
    {
      "source": "7mlvOHL6qJ",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8856
    },
    {
      "source": "7mlvOHL6qJ",
      "target": "In this paper",
      "similarity": 0.8851
    },
    {
      "source": "7mlvOHL6qJ",
      "target": "MyVC4X5B2X",
      "similarity": 0.8838
    },
    {
      "source": "2Chkk5Ye2s",
      "target": "7WaRh4gCXp",
      "similarity": 0.8814
    },
    {
      "source": "2Chkk5Ye2s",
      "target": "To guide this search",
      "similarity": 0.862
    },
    {
      "source": "2Chkk5Ye2s",
      "target": "Discoveries of such relations",
      "similarity": 0.8213
    },
    {
      "source": "2Chkk5Ye2s",
      "target": "xI71dsS3o4",
      "similarity": 0.8203
    },
    {
      "source": "2Chkk5Ye2s",
      "target": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "similarity": 0.8137
    },
    {
      "source": "L14sqcrUC3",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8661
    },
    {
      "source": "L14sqcrUC3",
      "target": "Here",
      "similarity": 0.8226
    },
    {
      "source": "L14sqcrUC3",
      "target": "kxnoqaisCT",
      "similarity": 0.8225
    },
    {
      "source": "L14sqcrUC3",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8211
    },
    {
      "source": "L14sqcrUC3",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8172
    },
    {
      "source": "To ensure this progress",
      "target": "FhTAG591Ve",
      "similarity": 0.8447
    },
    {
      "source": "To ensure this progress",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.8364
    },
    {
      "source": "To ensure this progress",
      "target": "CNL-P introduces precise grammar structures and strict semantic norms",
      "similarity": 0.8173
    },
    {
      "source": "To ensure this progress",
      "target": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "similarity": 0.8155
    },
    {
      "source": "To ensure this progress",
      "target": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "similarity": 0.8153
    },
    {
      "source": "First",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.9033
    },
    {
      "source": "First",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8948
    },
    {
      "source": "First",
      "target": "To this end",
      "similarity": 0.8928
    },
    {
      "source": "First",
      "target": "AJpUZd8Clb",
      "similarity": 0.8758
    },
    {
      "source": "First",
      "target": "We propose RAMEN",
      "similarity": 0.8738
    },
    {
      "source": "Second",
      "target": "C06kww3Qky",
      "similarity": 0.8792
    },
    {
      "source": "Second",
      "target": "xiQNfYl33p",
      "similarity": 0.879
    },
    {
      "source": "Second",
      "target": "wide dissemination",
      "similarity": 0.8773
    },
    {
      "source": "Second",
      "target": "To demonstrate the effectiveness of our framework",
      "similarity": 0.8773
    },
    {
      "source": "Second",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8739
    },
    {
      "source": "In this work",
      "target": "However",
      "similarity": 0.9276
    },
    {
      "source": "In this work",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8655
    },
    {
      "source": "In this work",
      "target": "From this perspective",
      "similarity": 0.8499
    },
    {
      "source": "In this work",
      "target": "In parallel",
      "similarity": 0.8393
    },
    {
      "source": "In this work",
      "target": "world perspective. To address this",
      "similarity": 0.8342
    },
    {
      "source": "To this end",
      "target": "models. However",
      "similarity": 0.9106
    },
    {
      "source": "To this end",
      "target": "Yet",
      "similarity": 0.8947
    },
    {
      "source": "To this end",
      "target": "OhauMUNW8T",
      "similarity": 0.8929
    },
    {
      "source": "To this end",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8893
    },
    {
      "source": "To this end",
      "target": "Existing methods occupy only a few isolated patches in this space",
      "similarity": 0.8763
    },
    {
      "source": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "target": "6HcnC3pPkp",
      "similarity": 0.8771
    },
    {
      "source": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "target": "kX8h23UG6v",
      "similarity": 0.864
    },
    {
      "source": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "target": "E2PFv7ad3p",
      "similarity": 0.8475
    },
    {
      "source": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "target": "We conduct a detailed analysis of early stopping in our algorithm",
      "similarity": 0.8467
    },
    {
      "source": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8426
    },
    {
      "source": "eIgGesYKLG",
      "target": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "similarity": 0.8508
    },
    {
      "source": "eIgGesYKLG",
      "target": "agHddsQhsL",
      "similarity": 0.837
    },
    {
      "source": "eIgGesYKLG",
      "target": "fL4qWkSmtM",
      "similarity": 0.8138
    },
    {
      "source": "eIgGesYKLG",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8089
    },
    {
      "source": "eIgGesYKLG",
      "target": "uREg3OHjLL",
      "similarity": 0.8077
    },
    {
      "source": "p0DjhjPXl3",
      "target": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "similarity": 0.8612
    },
    {
      "source": "p0DjhjPXl3",
      "target": "Aye5wL6TCn",
      "similarity": 0.8317
    },
    {
      "source": "p0DjhjPXl3",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.8311
    },
    {
      "source": "p0DjhjPXl3",
      "target": "To address these challenges",
      "similarity": 0.8293
    },
    {
      "source": "p0DjhjPXl3",
      "target": "the costliness of the labels",
      "similarity": 0.8279
    },
    {
      "source": "uMEsKEiB7J",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8521
    },
    {
      "source": "uMEsKEiB7J",
      "target": "For the diversity",
      "similarity": 0.8512
    },
    {
      "source": "uMEsKEiB7J",
      "target": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "similarity": 0.8441
    },
    {
      "source": "uMEsKEiB7J",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8396
    },
    {
      "source": "uMEsKEiB7J",
      "target": "Second",
      "similarity": 0.8361
    },
    {
      "source": "eIB1UZFcFg",
      "target": "However",
      "similarity": 0.8562
    },
    {
      "source": "eIB1UZFcFg",
      "target": "Our findings emphasize the importance of quality ranking",
      "similarity": 0.8508
    },
    {
      "source": "eIB1UZFcFg",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.8468
    },
    {
      "source": "eIB1UZFcFg",
      "target": "U42TkrEDzb",
      "similarity": 0.8468
    },
    {
      "source": "eIB1UZFcFg",
      "target": "This method constrains the parameter space to low-dimensional pre-defined and",
      "similarity": 0.8466
    },
    {
      "source": "KnoS9XxIlK",
      "target": "NvDRvtrGLo",
      "similarity": 0.8836
    },
    {
      "source": "KnoS9XxIlK",
      "target": "bSq0XGS3kW",
      "similarity": 0.8806
    },
    {
      "source": "KnoS9XxIlK",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8762
    },
    {
      "source": "KnoS9XxIlK",
      "target": "other baselines across all metrics",
      "similarity": 0.864
    },
    {
      "source": "KnoS9XxIlK",
      "target": "il5yUQsrjC",
      "similarity": 0.8594
    },
    {
      "source": "UQJ7CDW8nb",
      "target": "TJo6aQb7mK",
      "similarity": 0.8019
    },
    {
      "source": "UQJ7CDW8nb",
      "target": "PrefEval comprises 3",
      "similarity": 0.7964
    },
    {
      "source": "UQJ7CDW8nb",
      "target": "0LSAmFCc4p",
      "similarity": 0.785
    },
    {
      "source": "UQJ7CDW8nb",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.7722
    },
    {
      "source": "UQJ7CDW8nb",
      "target": "YLIsIzC74j",
      "similarity": 0.7717
    },
    {
      "source": "MBBRHDuiwM",
      "target": "4es2oO9tw1",
      "similarity": 0.8949
    },
    {
      "source": "MBBRHDuiwM",
      "target": "We validate our approach on benchmarks from image and medical domains",
      "similarity": 0.8829
    },
    {
      "source": "MBBRHDuiwM",
      "target": "b24n2LS2BJ",
      "similarity": 0.8697
    },
    {
      "source": "MBBRHDuiwM",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.8676
    },
    {
      "source": "MBBRHDuiwM",
      "target": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "similarity": 0.8615
    },
    {
      "source": "Zzs3JwknAY",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8516
    },
    {
      "source": "Zzs3JwknAY",
      "target": "THqWPzL00e",
      "similarity": 0.82
    },
    {
      "source": "Zzs3JwknAY",
      "target": "IIsTO4P3Ag",
      "similarity": 0.8197
    },
    {
      "source": "Zzs3JwknAY",
      "target": "aTYexOYlLb",
      "similarity": 0.8134
    },
    {
      "source": "Zzs3JwknAY",
      "target": "9chRqsPOGL",
      "similarity": 0.813
    },
    {
      "source": "VnLhUogHYE",
      "target": "Moreover",
      "similarity": 0.8802
    },
    {
      "source": "VnLhUogHYE",
      "target": "given the unique characteristics of the expanded expert space",
      "similarity": 0.8661
    },
    {
      "source": "VnLhUogHYE",
      "target": "pre-training data",
      "similarity": 0.857
    },
    {
      "source": "VnLhUogHYE",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8515
    },
    {
      "source": "VnLhUogHYE",
      "target": "we propose the Ternary Choice MoE (TC-MoE)",
      "similarity": 0.8508
    },
    {
      "source": "5pd78GmXC6",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8713
    },
    {
      "source": "5pd78GmXC6",
      "target": "jointly reconstructs and optimizes explicit geometry",
      "similarity": 0.8696
    },
    {
      "source": "5pd78GmXC6",
      "target": "Second",
      "similarity": 0.8666
    },
    {
      "source": "5pd78GmXC6",
      "target": "Among these",
      "similarity": 0.8602
    },
    {
      "source": "5pd78GmXC6",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8514
    },
    {
      "source": "Neural methods have shown promising results for subgraph matching.",
      "target": "Existing methods occupy only a few isolated patches in this space",
      "similarity": 0.8728
    },
    {
      "source": "Neural methods have shown promising results for subgraph matching.",
      "target": "nCrJD7qPJN",
      "similarity": 0.872
    },
    {
      "source": "Neural methods have shown promising results for subgraph matching.",
      "target": "kbeX97jExm",
      "similarity": 0.8566
    },
    {
      "source": "Neural methods have shown promising results for subgraph matching.",
      "target": "ngmEcEer8a",
      "similarity": 0.856
    },
    {
      "source": "Neural methods have shown promising results for subgraph matching.",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8528
    },
    {
      "source": "Our study of recent systems suggests refactoring them into a unified design space for graph matching networks.",
      "target": "U42TkrEDzb",
      "similarity": 0.8166
    },
    {
      "source": "Our study of recent systems suggests refactoring them into a unified design space for graph matching networks.",
      "target": "1qgZXeMTTU",
      "similarity": 0.8158
    },
    {
      "source": "Our study of recent systems suggests refactoring them into a unified design space for graph matching networks.",
      "target": "SRpq5OBpED",
      "similarity": 0.8133
    },
    {
      "source": "Our study of recent systems suggests refactoring them into a unified design space for graph matching networks.",
      "target": "1R5BcYS8EC",
      "similarity": 0.8094
    },
    {
      "source": "Our study of recent systems suggests refactoring them into a unified design space for graph matching networks.",
      "target": "wUtXB43Chi",
      "similarity": 0.8091
    },
    {
      "source": "Existing methods occupy only a few isolated patches in this space",
      "target": "models. However",
      "similarity": 0.8791
    },
    {
      "source": "Existing methods occupy only a few isolated patches in this space",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8652
    },
    {
      "source": "Existing methods occupy only a few isolated patches in this space",
      "target": "OhauMUNW8T",
      "similarity": 0.862
    },
    {
      "source": "Existing methods occupy only a few isolated patches in this space",
      "target": "Building on these insights",
      "similarity": 0.8449
    },
    {
      "source": "Existing methods occupy only a few isolated patches in this space",
      "target": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "similarity": 0.8406
    },
    {
      "source": "We undertake the first comprehensive exploration of this space",
      "target": "o1Et3MogPw",
      "similarity": 0.8855
    },
    {
      "source": "We undertake the first comprehensive exploration of this space",
      "target": "Finally",
      "similarity": 0.8818
    },
    {
      "source": "We undertake the first comprehensive exploration of this space",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8702
    },
    {
      "source": "We undertake the first comprehensive exploration of this space",
      "target": "is often a non-linear function",
      "similarity": 0.8637
    },
    {
      "source": "We undertake the first comprehensive exploration of this space",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8601
    },
    {
      "source": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "target": "To enrich long documents",
      "similarity": 0.9098
    },
    {
      "source": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "target": "K3KrOsR6y9",
      "similarity": 0.9016
    },
    {
      "source": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "target": "20qZK2T7fa",
      "similarity": 0.8686
    },
    {
      "source": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "target": "To bridge this gap in understanding",
      "similarity": 0.8661
    },
    {
      "source": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8517
    },
    {
      "source": "Beyond better performance",
      "target": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "similarity": 0.8489
    },
    {
      "source": "Beyond better performance",
      "target": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "similarity": 0.8243
    },
    {
      "source": "Beyond better performance",
      "target": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "similarity": 0.8083
    },
    {
      "source": "Beyond better performance",
      "target": "X0epAjg0hd",
      "similarity": 0.8054
    },
    {
      "source": "Beyond better performance",
      "target": "7bAjVh3CG3",
      "similarity": 0.803
    },
    {
      "source": "DTqx3iqjkz",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8545
    },
    {
      "source": "DTqx3iqjkz",
      "target": "sound",
      "similarity": 0.8498
    },
    {
      "source": "DTqx3iqjkz",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8477
    },
    {
      "source": "DTqx3iqjkz",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8349
    },
    {
      "source": "DTqx3iqjkz",
      "target": "UyU8ETswPg",
      "similarity": 0.8334
    },
    {
      "source": "ngmEcEer8a",
      "target": "nCrJD7qPJN",
      "similarity": 0.9159
    },
    {
      "source": "ngmEcEer8a",
      "target": "EQgEMAD4kv",
      "similarity": 0.9004
    },
    {
      "source": "ngmEcEer8a",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8821
    },
    {
      "source": "ngmEcEer8a",
      "target": "254NJe9JEw",
      "similarity": 0.8788
    },
    {
      "source": "ngmEcEer8a",
      "target": "faceswaps",
      "similarity": 0.8784
    },
    {
      "source": "aWXnKanInf",
      "target": "9EqQC2ct4H",
      "similarity": 0.8731
    },
    {
      "source": "aWXnKanInf",
      "target": "6F6qwdycgJ",
      "similarity": 0.8627
    },
    {
      "source": "aWXnKanInf",
      "target": "Our findings demonstrate that data taggants can reliably detect  models trained on the protected dataset with high confidence",
      "similarity": 0.8565
    },
    {
      "source": "aWXnKanInf",
      "target": "pCj2sLNoJq",
      "similarity": 0.8539
    },
    {
      "source": "aWXnKanInf",
      "target": "Antib6Uovh",
      "similarity": 0.8539
    },
    {
      "source": "nCrJD7qPJN",
      "target": "For TP",
      "similarity": 0.9038
    },
    {
      "source": "nCrJD7qPJN",
      "target": "faceswaps",
      "similarity": 0.9032
    },
    {
      "source": "nCrJD7qPJN",
      "target": "to address these failure modes",
      "similarity": 0.8936
    },
    {
      "source": "nCrJD7qPJN",
      "target": "To address both challenges we augment the recently proposed",
      "similarity": 0.8927
    },
    {
      "source": "nCrJD7qPJN",
      "target": "EQgEMAD4kv",
      "similarity": 0.8855
    },
    {
      "source": "n8h1z588eu",
      "target": "0uRc3CfJIQ",
      "similarity": 0.8306
    },
    {
      "source": "n8h1z588eu",
      "target": "JsVIGVntnQ",
      "similarity": 0.8296
    },
    {
      "source": "n8h1z588eu",
      "target": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "similarity": 0.8292
    },
    {
      "source": "n8h1z588eu",
      "target": "2o58Mbqkd2",
      "similarity": 0.8273
    },
    {
      "source": "n8h1z588eu",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.8262
    },
    {
      "source": "Given a dataset comprising several groups",
      "target": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "similarity": 0.8311
    },
    {
      "source": "Given a dataset comprising several groups",
      "target": "VELhv9BBfn",
      "similarity": 0.8211
    },
    {
      "source": "Given a dataset comprising several groups",
      "target": "In this paper",
      "similarity": 0.8159
    },
    {
      "source": "Given a dataset comprising several groups",
      "target": "HN8V0flwJF",
      "similarity": 0.813
    },
    {
      "source": "Given a dataset comprising several groups",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.808
    },
    {
      "source": "Due to these fairness constraints",
      "target": "On various mathematical benchmarks",
      "similarity": 0.8426
    },
    {
      "source": "Due to these fairness constraints",
      "target": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "similarity": 0.8421
    },
    {
      "source": "Due to these fairness constraints",
      "target": "cfKZ5VrhXt",
      "similarity": 0.8413
    },
    {
      "source": "Due to these fairness constraints",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8354
    },
    {
      "source": "Due to these fairness constraints",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8242
    },
    {
      "source": "We propose a novel ``Relax and Merge'' framework that returns a $(1+4\\rho + O(\\epsilon))$-approximate solution",
      "target": "pDDODPtpx9",
      "similarity": 0.8655
    },
    {
      "source": "We propose a novel ``Relax and Merge'' framework that returns a $(1+4\\rho + O(\\epsilon))$-approximate solution",
      "target": "To tackle this challenge",
      "similarity": 0.85
    },
    {
      "source": "We propose a novel ``Relax and Merge'' framework that returns a $(1+4\\rho + O(\\epsilon))$-approximate solution",
      "target": "To this end",
      "similarity": 0.8458
    },
    {
      "source": "We propose a novel ``Relax and Merge'' framework that returns a $(1+4\\rho + O(\\epsilon))$-approximate solution",
      "target": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "similarity": 0.8453
    },
    {
      "source": "We propose a novel ``Relax and Merge'' framework that returns a $(1+4\\rho + O(\\epsilon))$-approximate solution",
      "target": "To overcome those challenges",
      "similarity": 0.8429
    },
    {
      "source": "VELhv9BBfn",
      "target": "To address these limitations",
      "similarity": 0.8348
    },
    {
      "source": "VELhv9BBfn",
      "target": "gQoBw7sGAu",
      "similarity": 0.8325
    },
    {
      "source": "VELhv9BBfn",
      "target": "Finally",
      "similarity": 0.8211
    },
    {
      "source": "VELhv9BBfn",
      "target": "1H90Gb9rJ9",
      "similarity": 0.8008
    },
    {
      "source": "VELhv9BBfn",
      "target": "KSLkFYHlYg",
      "similarity": 0.7969
    },
    {
      "source": "x1yOHtFfDh",
      "target": "However",
      "similarity": 0.843
    },
    {
      "source": "x1yOHtFfDh",
      "target": "5o9JJJPPm6",
      "similarity": 0.8334
    },
    {
      "source": "x1yOHtFfDh",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.831
    },
    {
      "source": "x1yOHtFfDh",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8241
    },
    {
      "source": "x1yOHtFfDh",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8239
    },
    {
      "source": "gcouwCx7dG",
      "target": "This enables the network to adaptively reuse parameters across tasks",
      "similarity": 0.8806
    },
    {
      "source": "gcouwCx7dG",
      "target": "We release models",
      "similarity": 0.8708
    },
    {
      "source": "gcouwCx7dG",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8692
    },
    {
      "source": "gcouwCx7dG",
      "target": "FrFQpAgnGE",
      "similarity": 0.8524
    },
    {
      "source": "gcouwCx7dG",
      "target": "nx9Z5Kva96",
      "similarity": 0.8489
    },
    {
      "source": "In this paper",
      "target": "Jszf4et48m",
      "similarity": 0.8583
    },
    {
      "source": "In this paper",
      "target": "riieAeQBJm",
      "similarity": 0.8576
    },
    {
      "source": "In this paper",
      "target": "dAeET8gxqg",
      "similarity": 0.8542
    },
    {
      "source": "In this paper",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8473
    },
    {
      "source": "In this paper",
      "target": "78tc3EiUrN",
      "similarity": 0.8446
    },
    {
      "source": "The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index",
      "target": "L9eBxTCpQG",
      "similarity": 0.8616
    },
    {
      "source": "The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index",
      "target": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "similarity": 0.8473
    },
    {
      "source": "The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index",
      "target": "In addition",
      "similarity": 0.8406
    },
    {
      "source": "The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index",
      "target": "E4LAVLXAHW",
      "similarity": 0.8391
    },
    {
      "source": "The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index",
      "target": "Vanilla SFT (i.e.",
      "similarity": 0.8374
    },
    {
      "source": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.837
    },
    {
      "source": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "target": "pq1WUegkza",
      "similarity": 0.835
    },
    {
      "source": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "target": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "similarity": 0.8272
    },
    {
      "source": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8257
    },
    {
      "source": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8249
    },
    {
      "source": "OJsMGsO6yn",
      "target": "5pd78GmXC6",
      "similarity": 0.8379
    },
    {
      "source": "OJsMGsO6yn",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8368
    },
    {
      "source": "OJsMGsO6yn",
      "target": "WOt1owGfuN",
      "similarity": 0.8344
    },
    {
      "source": "OJsMGsO6yn",
      "target": "explore the effects of calibration data",
      "similarity": 0.8307
    },
    {
      "source": "OJsMGsO6yn",
      "target": "MxbEiFRf39",
      "similarity": 0.827
    },
    {
      "source": "iLUcsecZJp",
      "target": "Further",
      "similarity": 0.9053
    },
    {
      "source": "iLUcsecZJp",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8665
    },
    {
      "source": "iLUcsecZJp",
      "target": "aVfDrl7xDV",
      "similarity": 0.8609
    },
    {
      "source": "iLUcsecZJp",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8578
    },
    {
      "source": "iLUcsecZJp",
      "target": "5xSRg3eYZz",
      "similarity": 0.8536
    },
    {
      "source": "Our findings show that ICL with transformers",
      "target": "To address these limitations",
      "similarity": 0.8214
    },
    {
      "source": "Our findings show that ICL with transformers",
      "target": "8TBGdH3t6a",
      "similarity": 0.8073
    },
    {
      "source": "Our findings show that ICL with transformers",
      "target": "FEZOLWexPb",
      "similarity": 0.8064
    },
    {
      "source": "Our findings show that ICL with transformers",
      "target": "In this paper",
      "similarity": 0.8061
    },
    {
      "source": "Our findings show that ICL with transformers",
      "target": "4es2oO9tw1",
      "similarity": 0.8056
    },
    {
      "source": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8532
    },
    {
      "source": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "target": "Extending our study to production RAG models",
      "similarity": 0.8399
    },
    {
      "source": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "target": "JAMxRSXLFz",
      "similarity": 0.8378
    },
    {
      "source": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "target": "In particular",
      "similarity": 0.8377
    },
    {
      "source": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "target": "kbeX97jExm",
      "similarity": 0.8332
    },
    {
      "source": "(including gradient-based",
      "target": "Fk3eod9aaD",
      "similarity": 0.8979
    },
    {
      "source": "(including gradient-based",
      "target": "Validated using our collected college-level circuit analysis problems",
      "similarity": 0.8848
    },
    {
      "source": "(including gradient-based",
      "target": "FxNNiUgtfa",
      "similarity": 0.8686
    },
    {
      "source": "(including gradient-based",
      "target": "FtjLUHyZAO",
      "similarity": 0.8604
    },
    {
      "source": "(including gradient-based",
      "target": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "similarity": 0.8579
    },
    {
      "source": "The construction of such learning algorithm is determined by the pre-training process",
      "target": "zGzs5SIwT8",
      "similarity": 0.8794
    },
    {
      "source": "The construction of such learning algorithm is determined by the pre-training process",
      "target": "G4wARwjF8M",
      "similarity": 0.8437
    },
    {
      "source": "The construction of such learning algorithm is determined by the pre-training process",
      "target": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "similarity": 0.8421
    },
    {
      "source": "The construction of such learning algorithm is determined by the pre-training process",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8367
    },
    {
      "source": "The construction of such learning algorithm is determined by the pre-training process",
      "target": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "similarity": 0.7912
    },
    {
      "source": "With above understanding",
      "target": "txZVQRc2ab",
      "similarity": 0.8753
    },
    {
      "source": "With above understanding",
      "target": "dropping",
      "similarity": 0.8387
    },
    {
      "source": "With above understanding",
      "target": "cVyELMpMRS",
      "similarity": 0.8339
    },
    {
      "source": "With above understanding",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8334
    },
    {
      "source": "With above understanding",
      "target": "Dem5LyVk8R",
      "similarity": 0.8269
    },
    {
      "source": "E36NHwe7Zc",
      "target": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "similarity": 0.8972
    },
    {
      "source": "E36NHwe7Zc",
      "target": "also study the necessity of this condition via ablation studies and analytical exam-",
      "similarity": 0.855
    },
    {
      "source": "E36NHwe7Zc",
      "target": "few-shot reconstruction and forecasting of synthetic dynamical systems",
      "similarity": 0.8484
    },
    {
      "source": "E36NHwe7Zc",
      "target": "FiyS0ecSm0",
      "similarity": 0.8484
    },
    {
      "source": "E36NHwe7Zc",
      "target": "named Pacmann",
      "similarity": 0.8471
    },
    {
      "source": "XmProj9cPs",
      "target": "To this end",
      "similarity": 0.8893
    },
    {
      "source": "XmProj9cPs",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.886
    },
    {
      "source": "XmProj9cPs",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8733
    },
    {
      "source": "XmProj9cPs",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8707
    },
    {
      "source": "XmProj9cPs",
      "target": "In this paper",
      "similarity": 0.8622
    },
    {
      "source": "We introduce Spider 2.0",
      "target": "wxPnuFp8fZ",
      "similarity": 0.8468
    },
    {
      "source": "We introduce Spider 2.0",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8266
    },
    {
      "source": "We introduce Spider 2.0",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.822
    },
    {
      "source": "We introduce Spider 2.0",
      "target": "hNjCVVm0EQ",
      "similarity": 0.8192
    },
    {
      "source": "We introduce Spider 2.0",
      "target": "component of real-world software development.\"",
      "similarity": 0.815
    },
    {
      "source": "The databases in Spider 2.0 are sourced from real data applications",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8759
    },
    {
      "source": "The databases in Spider 2.0 are sourced from real data applications",
      "target": "instructions",
      "similarity": 0.8734
    },
    {
      "source": "The databases in Spider 2.0 are sourced from real data applications",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8717
    },
    {
      "source": "The databases in Spider 2.0 are sourced from real data applications",
      "target": "In this paper",
      "similarity": 0.8683
    },
    {
      "source": "The databases in Spider 2.0 are sourced from real data applications",
      "target": "3E8YNv1HjU",
      "similarity": 0.8632
    },
    {
      "source": "We show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata",
      "target": "At the inference stage",
      "similarity": 0.8286
    },
    {
      "source": "We show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata",
      "target": "FEpAUnS7f7",
      "similarity": 0.8274
    },
    {
      "source": "We show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata",
      "target": "Bpn8q40n1n",
      "similarity": 0.8233
    },
    {
      "source": "We show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata",
      "target": "OwpLQrpdwE",
      "similarity": 0.8167
    },
    {
      "source": "We show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata",
      "target": "In this paper",
      "similarity": 0.8162
    },
    {
      "source": "This challenge calls for models to interact with complex SQL workflow environments",
      "target": "This paper proposes",
      "similarity": 0.8748
    },
    {
      "source": "This challenge calls for models to interact with complex SQL workflow environments",
      "target": "dEg5SdGaiq",
      "similarity": 0.866
    },
    {
      "source": "This challenge calls for models to interact with complex SQL workflow environments",
      "target": "tePFpDgyqg",
      "similarity": 0.8646
    },
    {
      "source": "This challenge calls for models to interact with complex SQL workflow environments",
      "target": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "similarity": 0.8625
    },
    {
      "source": "This challenge calls for models to interact with complex SQL workflow environments",
      "target": "However",
      "similarity": 0.8595
    },
    {
      "source": "Our evaluations indicate that based on o1-preview",
      "target": "l0fn10vSyM",
      "similarity": 0.8591
    },
    {
      "source": "Our evaluations indicate that based on o1-preview",
      "target": "y9A2TpaGsE",
      "similarity": 0.8454
    },
    {
      "source": "Our evaluations indicate that based on o1-preview",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8449
    },
    {
      "source": "Our evaluations indicate that based on o1-preview",
      "target": "WwwJfkGq0G",
      "similarity": 0.8426
    },
    {
      "source": "Our evaluations indicate that based on o1-preview",
      "target": "To address these challenges",
      "similarity": 0.8388
    },
    {
      "source": "Our results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation --- especially in prior text-to-SQL benchmarks --- they require significant improvement in order to achieve adequate performance for real-world enterprise usage.",
      "target": "world perspective. To address this",
      "similarity": 0.8845
    },
    {
      "source": "Our results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation --- especially in prior text-to-SQL benchmarks --- they require significant improvement in order to achieve adequate performance for real-world enterprise usage.",
      "target": "NfCEVihkdC",
      "similarity": 0.8779
    },
    {
      "source": "Our results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation --- especially in prior text-to-SQL benchmarks --- they require significant improvement in order to achieve adequate performance for real-world enterprise usage.",
      "target": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "similarity": 0.8686
    },
    {
      "source": "Our results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation --- especially in prior text-to-SQL benchmarks --- they require significant improvement in order to achieve adequate performance for real-world enterprise usage.",
      "target": "2vHIHrJAcI",
      "similarity": 0.8548
    },
    {
      "source": "Our results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation --- especially in prior text-to-SQL benchmarks --- they require significant improvement in order to achieve adequate performance for real-world enterprise usage.",
      "target": "During training with 128K-long contexts",
      "similarity": 0.8399
    },
    {
      "source": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "target": "xiQNfYl33p",
      "similarity": 0.9037
    },
    {
      "source": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "target": "In preregistered experiments",
      "similarity": 0.8854
    },
    {
      "source": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "target": "To demonstrate the effectiveness of our framework",
      "similarity": 0.8819
    },
    {
      "source": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "target": "All experimental resources",
      "similarity": 0.8799
    },
    {
      "source": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "target": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "similarity": 0.8783
    },
    {
      "source": "Our code",
      "target": "At the inference stage",
      "similarity": 0.8442
    },
    {
      "source": "Our code",
      "target": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "similarity": 0.8347
    },
    {
      "source": "Our code",
      "target": "In this paper",
      "similarity": 0.8172
    },
    {
      "source": "Our code",
      "target": "rvvSSmGIFS",
      "similarity": 0.8169
    },
    {
      "source": "Our code",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8166
    },
    {
      "source": "xsELpEPn4A",
      "target": "gVkX9QMBO3",
      "similarity": 0.9177
    },
    {
      "source": "xsELpEPn4A",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8901
    },
    {
      "source": "xsELpEPn4A",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.8769
    },
    {
      "source": "xsELpEPn4A",
      "target": "oYemKnlIrO",
      "similarity": 0.8749
    },
    {
      "source": "xsELpEPn4A",
      "target": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "similarity": 0.8743
    },
    {
      "source": "g6syfIrVuS",
      "target": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "similarity": 0.8537
    },
    {
      "source": "g6syfIrVuS",
      "target": "mXHTifc1Fn",
      "similarity": 0.8076
    },
    {
      "source": "g6syfIrVuS",
      "target": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "similarity": 0.8041
    },
    {
      "source": "g6syfIrVuS",
      "target": "7XIkRgYjK3",
      "similarity": 0.8015
    },
    {
      "source": "g6syfIrVuS",
      "target": "b24n2LS2BJ",
      "similarity": 0.7986
    },
    {
      "source": "To provide theoretical and quantitative insights",
      "target": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "similarity": 0.9005
    },
    {
      "source": "To provide theoretical and quantitative insights",
      "target": "However",
      "similarity": 0.8734
    },
    {
      "source": "To provide theoretical and quantitative insights",
      "target": "To address this",
      "similarity": 0.8551
    },
    {
      "source": "To provide theoretical and quantitative insights",
      "target": "To this end",
      "similarity": 0.8545
    },
    {
      "source": "To provide theoretical and quantitative insights",
      "target": "Qja5s0K3VX",
      "similarity": 0.8497
    },
    {
      "source": "Furthermore",
      "target": "0fJfVOSUra",
      "similarity": 0.8952
    },
    {
      "source": "Furthermore",
      "target": "(BoneMet) dataset",
      "similarity": 0.8838
    },
    {
      "source": "Furthermore",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.876
    },
    {
      "source": "Furthermore",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8668
    },
    {
      "source": "Furthermore",
      "target": "a task efficiently",
      "similarity": 0.8575
    },
    {
      "source": "We demonstrate that",
      "target": "7bAjVh3CG3",
      "similarity": 0.8562
    },
    {
      "source": "We demonstrate that",
      "target": "lvw3UgeVxS",
      "similarity": 0.8437
    },
    {
      "source": "We demonstrate that",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8397
    },
    {
      "source": "We demonstrate that",
      "target": "Although existing LLM-based moderators can detect harmful content",
      "similarity": 0.8349
    },
    {
      "source": "We demonstrate that",
      "target": "h1XoHOd19I",
      "similarity": 0.8336
    },
    {
      "source": "For TP",
      "target": "training data. Equipped with these findings",
      "similarity": 0.9139
    },
    {
      "source": "For TP",
      "target": "to address these failure modes",
      "similarity": 0.9079
    },
    {
      "source": "For TP",
      "target": "90DC0IvlSs",
      "similarity": 0.9057
    },
    {
      "source": "For TP",
      "target": "254NJe9JEw",
      "similarity": 0.8875
    },
    {
      "source": "For TP",
      "target": "BI2int5SAC",
      "similarity": 0.8858
    },
    {
      "source": "CMMpcs9prj",
      "target": "Our primary contribution is a \\emph{controlled",
      "similarity": 0.837
    },
    {
      "source": "CMMpcs9prj",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.811
    },
    {
      "source": "CMMpcs9prj",
      "target": "yRKelogz5i",
      "similarity": 0.8053
    },
    {
      "source": "CMMpcs9prj",
      "target": "MxbEiFRf39",
      "similarity": 0.8044
    },
    {
      "source": "CMMpcs9prj",
      "target": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "similarity": 0.8028
    },
    {
      "source": "aQj9Ifxrl6",
      "target": "kam84eEmub",
      "similarity": 0.8092
    },
    {
      "source": "aQj9Ifxrl6",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.7896
    },
    {
      "source": "aQj9Ifxrl6",
      "target": "zXCnIyX9MG",
      "similarity": 0.7868
    },
    {
      "source": "aQj9Ifxrl6",
      "target": "TrVYEZtSQH",
      "similarity": 0.7857
    },
    {
      "source": "aQj9Ifxrl6",
      "target": "a two-player game and propose a novel online algorithm",
      "similarity": 0.7694
    },
    {
      "source": "(a.k.a.",
      "target": "vue9P1Ypk6",
      "similarity": 0.8503
    },
    {
      "source": "(a.k.a.",
      "target": "a dependency parser",
      "similarity": 0.8459
    },
    {
      "source": "(a.k.a.",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8353
    },
    {
      "source": "(a.k.a.",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.8084
    },
    {
      "source": "(a.k.a.",
      "target": "To fill this gap",
      "similarity": 0.8069
    },
    {
      "source": "models to generalize when the proportions of the groups shift during deployment.",
      "target": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "similarity": 0.8557
    },
    {
      "source": "models to generalize when the proportions of the groups shift during deployment.",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.8483
    },
    {
      "source": "models to generalize when the proportions of the groups shift during deployment.",
      "target": "$$",
      "similarity": 0.8366
    },
    {
      "source": "models to generalize when the proportions of the groups shift during deployment.",
      "target": "(including gradient-based",
      "similarity": 0.8028
    },
    {
      "source": "models to generalize when the proportions of the groups shift during deployment.",
      "target": "Fk3eod9aaD",
      "similarity": 0.7992
    },
    {
      "source": "To improve robustness to such shifts",
      "target": "rWjZWHYPcz",
      "similarity": 0.8418
    },
    {
      "source": "To improve robustness to such shifts",
      "target": "space are required in general even for outputting a constant factor",
      "similarity": 0.8046
    },
    {
      "source": "To improve robustness to such shifts",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.8029
    },
    {
      "source": "To improve robustness to such shifts",
      "target": "tQyh0gnfqW",
      "similarity": 0.798
    },
    {
      "source": "To improve robustness to such shifts",
      "target": "uncertainty estimation and improved interpretability.\"",
      "similarity": 0.7969
    },
    {
      "source": "that train models or perform hyperparameter tuning using the group-labeled data",
      "target": "This helps LLMs better interpret and execute the prompts",
      "similarity": 0.8639
    },
    {
      "source": "that train models or perform hyperparameter tuning using the group-labeled data",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8566
    },
    {
      "source": "that train models or perform hyperparameter tuning using the group-labeled data",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8505
    },
    {
      "source": "that train models or perform hyperparameter tuning using the group-labeled data",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8354
    },
    {
      "source": "that train models or perform hyperparameter tuning using the group-labeled data",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.8323
    },
    {
      "source": "to minimize the worst-case loss over groups. However",
      "target": "DpLFmc09pC",
      "similarity": 0.8666
    },
    {
      "source": "to minimize the worst-case loss over groups. However",
      "target": "AAXBfJNHDt",
      "similarity": 0.8474
    },
    {
      "source": "to minimize the worst-case loss over groups. However",
      "target": "In this paper",
      "similarity": 0.8434
    },
    {
      "source": "to minimize the worst-case loss over groups. However",
      "target": "In this work",
      "similarity": 0.8411
    },
    {
      "source": "to minimize the worst-case loss over groups. However",
      "target": "ScVnYBaSEw",
      "similarity": 0.8366
    },
    {
      "source": "high-quality labels is often required to obtain noticeable improvements. Given",
      "target": "rK0YJwL69S",
      "similarity": 0.8907
    },
    {
      "source": "high-quality labels is often required to obtain noticeable improvements. Given",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8536
    },
    {
      "source": "high-quality labels is often required to obtain noticeable improvements. Given",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8513
    },
    {
      "source": "high-quality labels is often required to obtain noticeable improvements. Given",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.8232
    },
    {
      "source": "high-quality labels is often required to obtain noticeable improvements. Given",
      "target": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "similarity": 0.8218
    },
    {
      "source": "the costliness of the labels",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8756
    },
    {
      "source": "the costliness of the labels",
      "target": "JytL2MrlLT",
      "similarity": 0.8743
    },
    {
      "source": "the costliness of the labels",
      "target": "1CIUkpoata",
      "similarity": 0.8716
    },
    {
      "source": "the costliness of the labels",
      "target": "p01BR4njlY",
      "similarity": 0.8658
    },
    {
      "source": "the costliness of the labels",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.865
    },
    {
      "source": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "target": "To overcome this limitation",
      "similarity": 0.9081
    },
    {
      "source": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "target": "IQxBDLmVpT",
      "similarity": 0.8987
    },
    {
      "source": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "target": "powerful expressiveness",
      "similarity": 0.8747
    },
    {
      "source": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8644
    },
    {
      "source": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8643
    },
    {
      "source": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8827
    },
    {
      "source": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "target": "Building on the SpiderBoost algorithm framework",
      "similarity": 0.8677
    },
    {
      "source": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.8671
    },
    {
      "source": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8639
    },
    {
      "source": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "target": "SOTA LLMs",
      "similarity": 0.862
    },
    {
      "source": "Reweighting (GSR)",
      "target": "YzxMu1asQi",
      "similarity": 0.8954
    },
    {
      "source": "Reweighting (GSR)",
      "target": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "similarity": 0.873
    },
    {
      "source": "Reweighting (GSR)",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8728
    },
    {
      "source": "Reweighting (GSR)",
      "target": "aMBSY2ebPw",
      "similarity": 0.8726
    },
    {
      "source": "Reweighting (GSR)",
      "target": "Usklli4gMc",
      "similarity": 0.8722
    },
    {
      "source": "group-unlabeled data",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8639
    },
    {
      "source": "group-unlabeled data",
      "target": "reaching 90\\% quality of a state-of-the-art",
      "similarity": 0.8594
    },
    {
      "source": "group-unlabeled data",
      "target": "To make this efficient",
      "similarity": 0.8551
    },
    {
      "source": "group-unlabeled data",
      "target": "cKlzKs3Nnb",
      "similarity": 0.8429
    },
    {
      "source": "group-unlabeled data",
      "target": "wSkvf2WyYz",
      "similarity": 0.8348
    },
    {
      "source": "layer on the reweighted data using influence functions. Our GSR is theoretically",
      "target": "9OMvtboTJg",
      "similarity": 0.8281
    },
    {
      "source": "layer on the reweighted data using influence functions. Our GSR is theoretically",
      "target": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "similarity": 0.8207
    },
    {
      "source": "layer on the reweighted data using influence functions. Our GSR is theoretically",
      "target": "5btFIv2PNb",
      "similarity": 0.8125
    },
    {
      "source": "layer on the reweighted data using influence functions. Our GSR is theoretically",
      "target": "dmCGjPFVhF",
      "similarity": 0.8018
    },
    {
      "source": "layer on the reweighted data using influence functions. Our GSR is theoretically",
      "target": "Jjr2Odj8DJ",
      "similarity": 0.7976
    },
    {
      "source": "sound",
      "target": "6GATHdOi1x",
      "similarity": 0.8728
    },
    {
      "source": "sound",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8721
    },
    {
      "source": "sound",
      "target": "hlvLM3GX8R",
      "similarity": 0.8689
    },
    {
      "source": "sound",
      "target": "iXCeQ2m6vT",
      "similarity": 0.8681
    },
    {
      "source": "sound",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8643
    },
    {
      "source": "population shifts. In particular",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8751
    },
    {
      "source": "population shifts. In particular",
      "target": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "similarity": 0.8621
    },
    {
      "source": "population shifts. In particular",
      "target": "To address this limitation",
      "similarity": 0.861
    },
    {
      "source": "population shifts. In particular",
      "target": "across new LLMs and different tasks because of their limited ability to leverage",
      "similarity": 0.8587
    },
    {
      "source": "population shifts. In particular",
      "target": "With extensive ablation studies",
      "similarity": 0.8572
    },
    {
      "source": "approaches that require the same amount or even more group labels. Our code is",
      "target": "GFgn2LprFR",
      "similarity": 0.8002
    },
    {
      "source": "approaches that require the same amount or even more group labels. Our code is",
      "target": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "similarity": 0.7984
    },
    {
      "source": "approaches that require the same amount or even more group labels. Our code is",
      "target": "In this work",
      "similarity": 0.7959
    },
    {
      "source": "approaches that require the same amount or even more group labels. Our code is",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.795
    },
    {
      "source": "approaches that require the same amount or even more group labels. Our code is",
      "target": "zXCnIyX9MG",
      "similarity": 0.7937
    },
    {
      "source": "available at https://github.com/qiaoruiyt/GSR.\"",
      "target": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "similarity": 0.8832
    },
    {
      "source": "available at https://github.com/qiaoruiyt/GSR.\"",
      "target": "EEgYUccwsV",
      "similarity": 0.8725
    },
    {
      "source": "available at https://github.com/qiaoruiyt/GSR.\"",
      "target": "suz4utPr9Y",
      "similarity": 0.8655
    },
    {
      "source": "available at https://github.com/qiaoruiyt/GSR.\"",
      "target": "wPMRwmytZe",
      "similarity": 0.8512
    },
    {
      "source": "available at https://github.com/qiaoruiyt/GSR.\"",
      "target": "eeJz7eDWKO",
      "similarity": 0.8457
    },
    {
      "source": "xP1radUi32",
      "target": "9chRqsPOGL",
      "similarity": 0.8705
    },
    {
      "source": "xP1radUi32",
      "target": "wmV4cIbgl6",
      "similarity": 0.8608
    },
    {
      "source": "xP1radUi32",
      "target": "GySIAKEwtZ",
      "similarity": 0.8605
    },
    {
      "source": "xP1radUi32",
      "target": "is usually inaccessible for advanced LLMs",
      "similarity": 0.8487
    },
    {
      "source": "xP1radUi32",
      "target": "590yfqz1LE",
      "similarity": 0.8468
    },
    {
      "source": "5wxCQDtbMo",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8911
    },
    {
      "source": "5wxCQDtbMo",
      "target": "a challenge",
      "similarity": 0.8893
    },
    {
      "source": "5wxCQDtbMo",
      "target": "1R5BcYS8EC",
      "similarity": 0.8884
    },
    {
      "source": "5wxCQDtbMo",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8699
    },
    {
      "source": "5wxCQDtbMo",
      "target": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "similarity": 0.8662
    },
    {
      "source": "41HlN8XYM5",
      "target": "(IOI) task using GPT-2 Small",
      "similarity": 0.8171
    },
    {
      "source": "41HlN8XYM5",
      "target": "GFgn2LprFR",
      "similarity": 0.808
    },
    {
      "source": "41HlN8XYM5",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8054
    },
    {
      "source": "41HlN8XYM5",
      "target": "8rbkePAapb",
      "similarity": 0.7991
    },
    {
      "source": "41HlN8XYM5",
      "target": "However",
      "similarity": 0.7989
    },
    {
      "source": "In this work",
      "target": "Qja5s0K3VX",
      "similarity": 0.8823
    },
    {
      "source": "In this work",
      "target": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "similarity": 0.8781
    },
    {
      "source": "In this work",
      "target": "p4cLtzk4oe",
      "similarity": 0.861
    },
    {
      "source": "In this work",
      "target": "je3GZissZc",
      "similarity": 0.8565
    },
    {
      "source": "In this work",
      "target": "7El7K1DoyX",
      "similarity": 0.8562
    },
    {
      "source": "CD-T is compatible to all transformer types",
      "target": "tyEyYT267x",
      "similarity": 0.8964
    },
    {
      "source": "CD-T is compatible to all transformer types",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8391
    },
    {
      "source": "CD-T is compatible to all transformer types",
      "target": "FBhKUXK7od",
      "similarity": 0.8299
    },
    {
      "source": "CD-T is compatible to all transformer types",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8273
    },
    {
      "source": "CD-T is compatible to all transformer types",
      "target": "In this work",
      "similarity": 0.8214
    },
    {
      "source": "CD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.882
    },
    {
      "source": "CD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning",
      "target": "K2jOacHUlO",
      "similarity": 0.8445
    },
    {
      "source": "CD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning",
      "target": "m73tETvFkX",
      "similarity": 0.8364
    },
    {
      "source": "CD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning",
      "target": "lfPkGWXLLf",
      "similarity": 0.8351
    },
    {
      "source": "CD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning",
      "target": "uREg3OHjLL",
      "similarity": 0.8246
    },
    {
      "source": "On three standard circuit evaluation datasets (indirect object identification",
      "target": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "similarity": 0.8193
    },
    {
      "source": "On three standard circuit evaluation datasets (indirect object identification",
      "target": "MscdsFVZrN",
      "similarity": 0.8186
    },
    {
      "source": "On three standard circuit evaluation datasets (indirect object identification",
      "target": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "similarity": 0.8145
    },
    {
      "source": "On three standard circuit evaluation datasets (indirect object identification",
      "target": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "similarity": 0.8085
    },
    {
      "source": "On three standard circuit evaluation datasets (indirect object identification",
      "target": "XdRIno98gG",
      "similarity": 0.8075
    },
    {
      "source": "we demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes.",
      "target": "As a result",
      "similarity": 0.8763
    },
    {
      "source": "we demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes.",
      "target": "EyaH1wzmao",
      "similarity": 0.8585
    },
    {
      "source": "we demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes.",
      "target": "dOAkHmsjRX",
      "similarity": 0.8544
    },
    {
      "source": "we demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes.",
      "target": "TljGdvzFq2",
      "similarity": 0.8475
    },
    {
      "source": "we demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes.",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8475
    },
    {
      "source": "In addition",
      "target": "In this paper",
      "similarity": 0.8487
    },
    {
      "source": "In addition",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8468
    },
    {
      "source": "In addition",
      "target": "aKkDY1Wca0",
      "similarity": 0.8396
    },
    {
      "source": "In addition",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8383
    },
    {
      "source": "In addition",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8311
    },
    {
      "source": "Finally",
      "target": "C06kww3Qky",
      "similarity": 0.8514
    },
    {
      "source": "Finally",
      "target": "NHhjczmJjo",
      "similarity": 0.8411
    },
    {
      "source": "Finally",
      "target": "Finally",
      "similarity": 0.8389
    },
    {
      "source": "Finally",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8358
    },
    {
      "source": "Finally",
      "target": "pDDODPtpx9",
      "similarity": 0.8344
    },
    {
      "source": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "target": "WfxPVtYRlL",
      "similarity": 0.8599
    },
    {
      "source": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "target": "T4LtGj7us1",
      "similarity": 0.8595
    },
    {
      "source": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "target": "2pNLknCTvG",
      "similarity": 0.8412
    },
    {
      "source": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8388
    },
    {
      "source": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "target": "E48QvQppIN",
      "similarity": 0.8347
    },
    {
      "source": "cbttLtO94Q",
      "target": "We found that long distance referrals",
      "similarity": 0.8722
    },
    {
      "source": "cbttLtO94Q",
      "target": "BL4WBIfyrz",
      "similarity": 0.8651
    },
    {
      "source": "cbttLtO94Q",
      "target": "riieAeQBJm",
      "similarity": 0.8637
    },
    {
      "source": "cbttLtO94Q",
      "target": "Further",
      "similarity": 0.8561
    },
    {
      "source": "cbttLtO94Q",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8557
    },
    {
      "source": "The gold-standard approach is to run a full RLHF training pipeline and directly probe downstream LLM performance.",
      "target": "Our findings emphasize the importance of quality ranking",
      "similarity": 0.8421
    },
    {
      "source": "The gold-standard approach is to run a full RLHF training pipeline and directly probe downstream LLM performance.",
      "target": "However",
      "similarity": 0.8287
    },
    {
      "source": "The gold-standard approach is to run a full RLHF training pipeline and directly probe downstream LLM performance.",
      "target": "sZJNkorXMk",
      "similarity": 0.8278
    },
    {
      "source": "The gold-standard approach is to run a full RLHF training pipeline and directly probe downstream LLM performance.",
      "target": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "similarity": 0.8258
    },
    {
      "source": "The gold-standard approach is to run a full RLHF training pipeline and directly probe downstream LLM performance.",
      "target": "eIB1UZFcFg",
      "similarity": 0.8201
    },
    {
      "source": "However",
      "target": "Mjn53GtMxi",
      "similarity": 0.8638
    },
    {
      "source": "However",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8605
    },
    {
      "source": "However",
      "target": "In response",
      "similarity": 0.8567
    },
    {
      "source": "However",
      "target": "AcVpLS86RT",
      "similarity": 0.8507
    },
    {
      "source": "However",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8469
    },
    {
      "source": "To address this",
      "target": "However",
      "similarity": 0.8301
    },
    {
      "source": "To address this",
      "target": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "similarity": 0.8243
    },
    {
      "source": "To address this",
      "target": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "similarity": 0.8213
    },
    {
      "source": "To address this",
      "target": "component of real-world software development.\"",
      "similarity": 0.8175
    },
    {
      "source": "To address this",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8173
    },
    {
      "source": "These proxy tasks consist of a large-scale human preference and a verifiable correctness preference dataset",
      "target": "In the field of multi-objective optimization",
      "similarity": 0.812
    },
    {
      "source": "These proxy tasks consist of a large-scale human preference and a verifiable correctness preference dataset",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.7947
    },
    {
      "source": "These proxy tasks consist of a large-scale human preference and a verifiable correctness preference dataset",
      "target": "7VkHffT5X2",
      "similarity": 0.7858
    },
    {
      "source": "These proxy tasks consist of a large-scale human preference and a verifiable correctness preference dataset",
      "target": "Consequently",
      "similarity": 0.7791
    },
    {
      "source": "These proxy tasks consist of a large-scale human preference and a verifiable correctness preference dataset",
      "target": "data affects predictions is often difficult due to model training costs. Current",
      "similarity": 0.7775
    },
    {
      "source": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "target": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "similarity": 0.9124
    },
    {
      "source": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "target": "Using this approach",
      "similarity": 0.8755
    },
    {
      "source": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "target": "2pNLknCTvG",
      "similarity": 0.8741
    },
    {
      "source": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "target": "In brief",
      "similarity": 0.8726
    },
    {
      "source": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "target": "We propose RAMEN",
      "similarity": 0.8707
    },
    {
      "source": "Ultimately",
      "target": "Our findings indicate that",
      "similarity": 0.9069
    },
    {
      "source": "Ultimately",
      "target": "Es4RPNDtmq",
      "similarity": 0.9051
    },
    {
      "source": "Ultimately",
      "target": "6ycX677p2l",
      "similarity": 0.89
    },
    {
      "source": "Ultimately",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8805
    },
    {
      "source": "Ultimately",
      "target": "LNL7zKvm7e",
      "similarity": 0.8799
    },
    {
      "source": "9EqQC2ct4H",
      "target": "pCj2sLNoJq",
      "similarity": 0.9134
    },
    {
      "source": "9EqQC2ct4H",
      "target": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "similarity": 0.8915
    },
    {
      "source": "9EqQC2ct4H",
      "target": "6F6qwdycgJ",
      "similarity": 0.8729
    },
    {
      "source": "9EqQC2ct4H",
      "target": "To enable TTA for regression",
      "similarity": 0.8713
    },
    {
      "source": "9EqQC2ct4H",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8671
    },
    {
      "source": "AJM52ygi6Y",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8713
    },
    {
      "source": "AJM52ygi6Y",
      "target": "Then",
      "similarity": 0.8586
    },
    {
      "source": "AJM52ygi6Y",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8411
    },
    {
      "source": "AJM52ygi6Y",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8272
    },
    {
      "source": "AJM52ygi6Y",
      "target": "CAssIgPN4I",
      "similarity": 0.8235
    },
    {
      "source": "We assume that the functions $f_i$",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8213
    },
    {
      "source": "We assume that the functions $f_i$",
      "target": "JbRM5QKRDd",
      "similarity": 0.8204
    },
    {
      "source": "We assume that the functions $f_i$",
      "target": "Instruct",
      "similarity": 0.8155
    },
    {
      "source": "We assume that the functions $f_i$",
      "target": "Second",
      "similarity": 0.807
    },
    {
      "source": "We assume that the functions $f_i$",
      "target": "4anfpHj0wf",
      "similarity": 0.8065
    },
    {
      "source": "This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning.",
      "target": "2pNLknCTvG",
      "similarity": 0.8556
    },
    {
      "source": "This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning.",
      "target": "jxMAPMqNr5",
      "similarity": 0.8468
    },
    {
      "source": "This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning.",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8456
    },
    {
      "source": "This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning.",
      "target": "T4LtGj7us1",
      "similarity": 0.8442
    },
    {
      "source": "This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning.",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8399
    },
    {
      "source": "We propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge",
      "target": "ThRMTCgpvo",
      "similarity": 0.8667
    },
    {
      "source": "We propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge",
      "target": "NJxCpMt0sf",
      "similarity": 0.8558
    },
    {
      "source": "We propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8525
    },
    {
      "source": "We propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge",
      "target": "data",
      "similarity": 0.8504
    },
    {
      "source": "We propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge",
      "target": "lvw3UgeVxS",
      "similarity": 0.826
    },
    {
      "source": "5RZoYIT3u6",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.822
    },
    {
      "source": "5RZoYIT3u6",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8165
    },
    {
      "source": "5RZoYIT3u6",
      "target": "aTYexOYlLb",
      "similarity": 0.8127
    },
    {
      "source": "5RZoYIT3u6",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8083
    },
    {
      "source": "5RZoYIT3u6",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8075
    },
    {
      "source": "4A9IdSa1ul",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.878
    },
    {
      "source": "4A9IdSa1ul",
      "target": "In this paper",
      "similarity": 0.8669
    },
    {
      "source": "4A9IdSa1ul",
      "target": "In this paper",
      "similarity": 0.8649
    },
    {
      "source": "4A9IdSa1ul",
      "target": "T2d0geb6y0",
      "similarity": 0.8632
    },
    {
      "source": "4A9IdSa1ul",
      "target": "For example",
      "similarity": 0.862
    },
    {
      "source": "OL44KtasKc",
      "target": "In this paper",
      "similarity": 0.8487
    },
    {
      "source": "OL44KtasKc",
      "target": "Rz0kozh3LE",
      "similarity": 0.8458
    },
    {
      "source": "OL44KtasKc",
      "target": "Finally",
      "similarity": 0.844
    },
    {
      "source": "OL44KtasKc",
      "target": "It was numerically observed that the linear interpolation",
      "similarity": 0.8412
    },
    {
      "source": "OL44KtasKc",
      "target": "f7KxfUrRSb",
      "similarity": 0.8386
    },
    {
      "source": "In response",
      "target": "Mjn53GtMxi",
      "similarity": 0.879
    },
    {
      "source": "In response",
      "target": "YFxfcQMLWX",
      "similarity": 0.8735
    },
    {
      "source": "In response",
      "target": "AcVpLS86RT",
      "similarity": 0.8704
    },
    {
      "source": "In response",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8654
    },
    {
      "source": "In response",
      "target": "In this task",
      "similarity": 0.8555
    },
    {
      "source": "eHehzSDUFp",
      "target": "HqjRlT65WX",
      "similarity": 0.8666
    },
    {
      "source": "eHehzSDUFp",
      "target": "zY37C8d6bS",
      "similarity": 0.8634
    },
    {
      "source": "eHehzSDUFp",
      "target": "OuLgaHEmzi",
      "similarity": 0.861
    },
    {
      "source": "eHehzSDUFp",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8508
    },
    {
      "source": "eHehzSDUFp",
      "target": "than existing search techniques",
      "similarity": 0.8497
    },
    {
      "source": "wM2sfVgMDH",
      "target": "NKotdPUc3L",
      "similarity": 0.8579
    },
    {
      "source": "wM2sfVgMDH",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.841
    },
    {
      "source": "wM2sfVgMDH",
      "target": "4D0f16Vwc3",
      "similarity": 0.8234
    },
    {
      "source": "wM2sfVgMDH",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8194
    },
    {
      "source": "wM2sfVgMDH",
      "target": "and performing sophisticated tasks",
      "similarity": 0.819
    },
    {
      "source": "4sJ2FYE65U",
      "target": "EyaH1wzmao",
      "similarity": 0.8717
    },
    {
      "source": "4sJ2FYE65U",
      "target": "FXw0okNcOb",
      "similarity": 0.8686
    },
    {
      "source": "4sJ2FYE65U",
      "target": "4D0f16Vwc3",
      "similarity": 0.8583
    },
    {
      "source": "4sJ2FYE65U",
      "target": "In this work",
      "similarity": 0.8546
    },
    {
      "source": "4sJ2FYE65U",
      "target": "eLLBILFRsA",
      "similarity": 0.8505
    },
    {
      "source": "E2PFv7ad3p",
      "target": "We conduct a detailed analysis of early stopping in our algorithm",
      "similarity": 0.8701
    },
    {
      "source": "E2PFv7ad3p",
      "target": "6HcnC3pPkp",
      "similarity": 0.8689
    },
    {
      "source": "E2PFv7ad3p",
      "target": "show that the proposed strategy can enhance the performance of strong pruning",
      "similarity": 0.861
    },
    {
      "source": "E2PFv7ad3p",
      "target": "kX8h23UG6v",
      "similarity": 0.8604
    },
    {
      "source": "E2PFv7ad3p",
      "target": "In this paper",
      "similarity": 0.8602
    },
    {
      "source": "bc3sUsS6ck",
      "target": "ANBuEJesgx",
      "similarity": 0.8257
    },
    {
      "source": "bc3sUsS6ck",
      "target": "bIlnpVM4bc",
      "similarity": 0.8147
    },
    {
      "source": "bc3sUsS6ck",
      "target": "GbgCRJedQ7",
      "similarity": 0.8076
    },
    {
      "source": "bc3sUsS6ck",
      "target": "UgPoHhYQ2U",
      "similarity": 0.7975
    },
    {
      "source": "bc3sUsS6ck",
      "target": "mNVR9jJYqK",
      "similarity": 0.793
    },
    {
      "source": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator",
      "target": "Notably",
      "similarity": 0.8175
    },
    {
      "source": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator",
      "target": "DpLFmc09pC",
      "similarity": 0.8022
    },
    {
      "source": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator",
      "target": "GkWA6NjePN",
      "similarity": 0.8009
    },
    {
      "source": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator",
      "target": "5X5Z7Ffrjb",
      "similarity": 0.7959
    },
    {
      "source": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator",
      "target": "This value discrepancy problem propagates errors throughout the optimization process",
      "similarity": 0.7954
    },
    {
      "source": "Notably",
      "target": "To overcome those challenges",
      "similarity": 0.8532
    },
    {
      "source": "Notably",
      "target": "This value discrepancy problem propagates errors throughout the optimization process",
      "similarity": 0.8246
    },
    {
      "source": "Notably",
      "target": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "similarity": 0.824
    },
    {
      "source": "Notably",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8224
    },
    {
      "source": "Notably",
      "target": "In offline evaluations",
      "similarity": 0.822
    },
    {
      "source": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "target": "Meanwhile",
      "similarity": 0.87
    },
    {
      "source": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "target": "dw9VUsSHGB",
      "similarity": 0.8651
    },
    {
      "source": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8601
    },
    {
      "source": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "target": "To address this",
      "similarity": 0.8581
    },
    {
      "source": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "target": "xiQNfYl33p",
      "similarity": 0.8505
    },
    {
      "source": "In StreamingQA",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8452
    },
    {
      "source": "In StreamingQA",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8447
    },
    {
      "source": "In StreamingQA",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8272
    },
    {
      "source": "In StreamingQA",
      "target": "nibeaHUEJx",
      "similarity": 0.8269
    },
    {
      "source": "In StreamingQA",
      "target": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "similarity": 0.8197
    },
    {
      "source": "In the MetaICL in-context learning evaluation",
      "target": "resource",
      "similarity": 0.8832
    },
    {
      "source": "In the MetaICL in-context learning evaluation",
      "target": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "similarity": 0.8386
    },
    {
      "source": "In the MetaICL in-context learning evaluation",
      "target": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "similarity": 0.8307
    },
    {
      "source": "In the MetaICL in-context learning evaluation",
      "target": "YslOW2SO6S",
      "similarity": 0.8196
    },
    {
      "source": "In the MetaICL in-context learning evaluation",
      "target": "Vanilla SFT (i.e.",
      "similarity": 0.8139
    },
    {
      "source": "On MSC",
      "target": "This process naturally incorporates recency bias",
      "similarity": 0.8285
    },
    {
      "source": "On MSC",
      "target": "a given query",
      "similarity": 0.8189
    },
    {
      "source": "On MSC",
      "target": "ZadnlOHsHv",
      "similarity": 0.8117
    },
    {
      "source": "On MSC",
      "target": "However",
      "similarity": 0.807
    },
    {
      "source": "On MSC",
      "target": "finetuned on 4K-length sequences",
      "similarity": 0.8031
    },
    {
      "source": "prompting with full conversation history.",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8222
    },
    {
      "source": "prompting with full conversation history.",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.8068
    },
    {
      "source": "prompting with full conversation history.",
      "target": "imT03YXlG2",
      "similarity": 0.8066
    },
    {
      "source": "prompting with full conversation history.",
      "target": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "similarity": 0.8065
    },
    {
      "source": "prompting with full conversation history.",
      "target": "while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs.",
      "similarity": 0.8055
    },
    {
      "source": "Overall",
      "target": "l0fn10vSyM",
      "similarity": 0.8556
    },
    {
      "source": "Overall",
      "target": "owP2mymrTD",
      "similarity": 0.8442
    },
    {
      "source": "Overall",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8385
    },
    {
      "source": "Overall",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8341
    },
    {
      "source": "Overall",
      "target": "ZSdubdbOoi",
      "similarity": 0.8248
    },
    {
      "source": "pXlmOmlHJZ",
      "target": "8egnwady4b",
      "similarity": 0.8315
    },
    {
      "source": "pXlmOmlHJZ",
      "target": "At the inference stage",
      "similarity": 0.8253
    },
    {
      "source": "pXlmOmlHJZ",
      "target": "On the other hand",
      "similarity": 0.8216
    },
    {
      "source": "pXlmOmlHJZ",
      "target": "standard training and",
      "similarity": 0.82
    },
    {
      "source": "pXlmOmlHJZ",
      "target": "First",
      "similarity": 0.8134
    },
    {
      "source": "e32cI4r8Eo",
      "target": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "similarity": 0.8352
    },
    {
      "source": "e32cI4r8Eo",
      "target": "ANBuEJesgx",
      "similarity": 0.8339
    },
    {
      "source": "e32cI4r8Eo",
      "target": "jTEKTdI3K9",
      "similarity": 0.8253
    },
    {
      "source": "e32cI4r8Eo",
      "target": "9kJperA2a4",
      "similarity": 0.8225
    },
    {
      "source": "e32cI4r8Eo",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8218
    },
    {
      "source": "p01BR4njlY",
      "target": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "similarity": 0.8677
    },
    {
      "source": "p01BR4njlY",
      "target": "1CIUkpoata",
      "similarity": 0.858
    },
    {
      "source": "p01BR4njlY",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.857
    },
    {
      "source": "p01BR4njlY",
      "target": "41uZB8bDFh",
      "similarity": 0.8556
    },
    {
      "source": "p01BR4njlY",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8473
    },
    {
      "source": "Q6PAnqYVpo",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8957
    },
    {
      "source": "Q6PAnqYVpo",
      "target": "In this work",
      "similarity": 0.8836
    },
    {
      "source": "Q6PAnqYVpo",
      "target": "For TP",
      "similarity": 0.8769
    },
    {
      "source": "Q6PAnqYVpo",
      "target": "BI2int5SAC",
      "similarity": 0.8742
    },
    {
      "source": "Q6PAnqYVpo",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8661
    },
    {
      "source": "For that purpose",
      "target": "JUr0YOMvZA",
      "similarity": 0.9058
    },
    {
      "source": "For that purpose",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.8824
    },
    {
      "source": "For that purpose",
      "target": "findings reveal that incorporating collective judgments from such a mixed pool",
      "similarity": 0.8704
    },
    {
      "source": "For that purpose",
      "target": "BI2int5SAC",
      "similarity": 0.8697
    },
    {
      "source": "For that purpose",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.868
    },
    {
      "source": "Nonetheless",
      "target": "Building on these insights",
      "similarity": 0.8003
    },
    {
      "source": "Nonetheless",
      "target": "OQqNieeivq",
      "similarity": 0.7926
    },
    {
      "source": "Nonetheless",
      "target": "owP2mymrTD",
      "similarity": 0.7915
    },
    {
      "source": "Nonetheless",
      "target": "bEqI61iBue",
      "similarity": 0.7903
    },
    {
      "source": "Nonetheless",
      "target": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "similarity": 0.7902
    },
    {
      "source": "In addition",
      "target": "Finally",
      "similarity": 0.8541
    },
    {
      "source": "In addition",
      "target": "YslOW2SO6S",
      "similarity": 0.8525
    },
    {
      "source": "In addition",
      "target": "VpWki1v2P8",
      "similarity": 0.85
    },
    {
      "source": "In addition",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8473
    },
    {
      "source": "In addition",
      "target": "NHhjczmJjo",
      "similarity": 0.8467
    },
    {
      "source": "Given these challenges",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8731
    },
    {
      "source": "Given these challenges",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8641
    },
    {
      "source": "Given these challenges",
      "target": "https://github.com/OceannTwT/Tool-Planner.\"",
      "similarity": 0.8564
    },
    {
      "source": "Given these challenges",
      "target": "Yet",
      "similarity": 0.8556
    },
    {
      "source": "Given these challenges",
      "target": "Es4RPNDtmq",
      "similarity": 0.8478
    },
    {
      "source": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "target": "41uZB8bDFh",
      "similarity": 0.8643
    },
    {
      "source": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.864
    },
    {
      "source": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "target": "SOTA LLMs",
      "similarity": 0.8554
    },
    {
      "source": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "target": "AcVpLS86RT",
      "similarity": 0.8484
    },
    {
      "source": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "target": "r0pLGGcuY6",
      "similarity": 0.8422
    },
    {
      "source": "We have prepared an efficient implementation",
      "target": "vcX0k4rGTt",
      "similarity": 0.8655
    },
    {
      "source": "We have prepared an efficient implementation",
      "target": "analysis)",
      "similarity": 0.8618
    },
    {
      "source": "We have prepared an efficient implementation",
      "target": "In this task",
      "similarity": 0.8565
    },
    {
      "source": "We have prepared an efficient implementation",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8436
    },
    {
      "source": "We have prepared an efficient implementation",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8428
    },
    {
      "source": "Our experiments demonstrate that the proposed method",
      "target": "JytL2MrlLT",
      "similarity": 0.9011
    },
    {
      "source": "Our experiments demonstrate that the proposed method",
      "target": "FAfxvdv1Dy",
      "similarity": 0.898
    },
    {
      "source": "Our experiments demonstrate that the proposed method",
      "target": "1CIUkpoata",
      "similarity": 0.8941
    },
    {
      "source": "Our experiments demonstrate that the proposed method",
      "target": "DPzQ5n3mNm",
      "similarity": 0.8888
    },
    {
      "source": "Our experiments demonstrate that the proposed method",
      "target": "1NprT9Kz0d",
      "similarity": 0.8854
    },
    {
      "source": "(i) can execute searches on billion-scale corpora in less than a second",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8816
    },
    {
      "source": "(i) can execute searches on billion-scale corpora in less than a second",
      "target": "l0fn10vSyM",
      "similarity": 0.859
    },
    {
      "source": "(i) can execute searches on billion-scale corpora in less than a second",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8569
    },
    {
      "source": "(i) can execute searches on billion-scale corpora in less than a second",
      "target": "KlN00vQEY2",
      "similarity": 0.8539
    },
    {
      "source": "(i) can execute searches on billion-scale corpora in less than a second",
      "target": "natural language commands",
      "similarity": 0.8503
    },
    {
      "source": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "target": "Usklli4gMc",
      "similarity": 0.8627
    },
    {
      "source": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "target": "pDDODPtpx9",
      "similarity": 0.86
    },
    {
      "source": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "target": "J9FgrqOOni",
      "similarity": 0.8555
    },
    {
      "source": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8554
    },
    {
      "source": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "target": "Mjn53GtMxi",
      "similarity": 0.8515
    },
    {
      "source": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "target": "Using tools from the Wasserstein geometry",
      "similarity": 0.8597
    },
    {
      "source": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "target": "This paper introduces WebRL",
      "similarity": 0.8562
    },
    {
      "source": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8486
    },
    {
      "source": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.8466
    },
    {
      "source": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.8459
    },
    {
      "source": "67X93aZHII",
      "target": "kX8h23UG6v",
      "similarity": 0.8708
    },
    {
      "source": "67X93aZHII",
      "target": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "similarity": 0.8645
    },
    {
      "source": "67X93aZHII",
      "target": "E2PFv7ad3p",
      "similarity": 0.8501
    },
    {
      "source": "67X93aZHII",
      "target": "6HcnC3pPkp",
      "similarity": 0.8399
    },
    {
      "source": "67X93aZHII",
      "target": "show that the proposed strategy can enhance the performance of strong pruning",
      "similarity": 0.8382
    },
    {
      "source": "BpyHIrpUOL",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8687
    },
    {
      "source": "BpyHIrpUOL",
      "target": "pDDODPtpx9",
      "similarity": 0.8658
    },
    {
      "source": "BpyHIrpUOL",
      "target": "bilities",
      "similarity": 0.8631
    },
    {
      "source": "BpyHIrpUOL",
      "target": "xsELpEPn4A",
      "similarity": 0.862
    },
    {
      "source": "BpyHIrpUOL",
      "target": "In this paper",
      "similarity": 0.8615
    },
    {
      "source": "This study proposes \\textbf{PolyhedronNet}",
      "target": "Overall",
      "similarity": 0.8618
    },
    {
      "source": "This study proposes \\textbf{PolyhedronNet}",
      "target": "Crucially",
      "similarity": 0.8617
    },
    {
      "source": "This study proposes \\textbf{PolyhedronNet}",
      "target": "TvGPP8i18S",
      "similarity": 0.8557
    },
    {
      "source": "This study proposes \\textbf{PolyhedronNet}",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8516
    },
    {
      "source": "This study proposes \\textbf{PolyhedronNet}",
      "target": "F57HPKZ6KD",
      "similarity": 0.8513
    },
    {
      "source": "To effectively learn the representation of the entire surface-attributed graph",
      "target": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "similarity": 0.8122
    },
    {
      "source": "To effectively learn the representation of the entire surface-attributed graph",
      "target": "I6UbnkUveF",
      "similarity": 0.8033
    },
    {
      "source": "To effectively learn the representation of the entire surface-attributed graph",
      "target": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "similarity": 0.7923
    },
    {
      "source": "To effectively learn the representation of the entire surface-attributed graph",
      "target": "TtKN1TpvUu",
      "similarity": 0.7861
    },
    {
      "source": "To effectively learn the representation of the entire surface-attributed graph",
      "target": "TrVYEZtSQH",
      "similarity": 0.7856
    },
    {
      "source": "Our experimental evaluations on four distinct datasets",
      "target": "mNVR9jJYqK",
      "similarity": 0.833
    },
    {
      "source": "Our experimental evaluations on four distinct datasets",
      "target": "LLMs. Interestingly",
      "similarity": 0.8257
    },
    {
      "source": "Our experimental evaluations on four distinct datasets",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.824
    },
    {
      "source": "Our experimental evaluations on four distinct datasets",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8232
    },
    {
      "source": "Our experimental evaluations on four distinct datasets",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.823
    },
    {
      "source": "ig2wk7kK9J",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8684
    },
    {
      "source": "ig2wk7kK9J",
      "target": "size in stages. We show that this approach not only generalizes prior works like",
      "similarity": 0.8495
    },
    {
      "source": "ig2wk7kK9J",
      "target": "JYwVijuNA7",
      "similarity": 0.8481
    },
    {
      "source": "ig2wk7kK9J",
      "target": "To this end",
      "similarity": 0.848
    },
    {
      "source": "ig2wk7kK9J",
      "target": "Our code and additional resources are available at https://structuredllm.com.\"",
      "similarity": 0.8447
    },
    {
      "source": "CGON8Btleu",
      "target": "FPfCUJTsCn",
      "similarity": 0.8777
    },
    {
      "source": "CGON8Btleu",
      "target": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "similarity": 0.8521
    },
    {
      "source": "CGON8Btleu",
      "target": "dTPz4rEDok",
      "similarity": 0.8166
    },
    {
      "source": "CGON8Btleu",
      "target": "framework and identified important coverage assumptions (called belief and outcome coverage) that enable accurate OPE of memoryless policies with polynomial sample complexities",
      "similarity": 0.809
    },
    {
      "source": "CGON8Btleu",
      "target": "We validate our approach on benchmarks from image and medical domains",
      "similarity": 0.8049
    },
    {
      "source": "HN0CYZbAPw",
      "target": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "similarity": 0.916
    },
    {
      "source": "HN0CYZbAPw",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8553
    },
    {
      "source": "HN0CYZbAPw",
      "target": "Neb17mimVH",
      "similarity": 0.8526
    },
    {
      "source": "HN0CYZbAPw",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.847
    },
    {
      "source": "HN0CYZbAPw",
      "target": "riieAeQBJm",
      "similarity": 0.8402
    },
    {
      "source": "wfLuiDjQ0u",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.9025
    },
    {
      "source": "wfLuiDjQ0u",
      "target": "large-scale settings",
      "similarity": 0.867
    },
    {
      "source": "wfLuiDjQ0u",
      "target": "position reveals interpretable low-rank structure across toy tasks",
      "similarity": 0.8543
    },
    {
      "source": "wfLuiDjQ0u",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8506
    },
    {
      "source": "wfLuiDjQ0u",
      "target": "JytL2MrlLT",
      "similarity": 0.8441
    },
    {
      "source": "In this paper",
      "target": "these successes",
      "similarity": 0.8691
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8505
    },
    {
      "source": "In this paper",
      "target": "1F8xTfv6ah",
      "similarity": 0.8366
    },
    {
      "source": "In this paper",
      "target": "p0DjhjPXl3",
      "similarity": 0.818
    },
    {
      "source": "In this paper",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.807
    },
    {
      "source": "8UFG9D8xeU",
      "target": "Extensive experiments validate BiGR's superior performance in generation quality",
      "similarity": 0.8379
    },
    {
      "source": "8UFG9D8xeU",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8371
    },
    {
      "source": "8UFG9D8xeU",
      "target": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "similarity": 0.826
    },
    {
      "source": "8UFG9D8xeU",
      "target": "However",
      "similarity": 0.8239
    },
    {
      "source": "8UFG9D8xeU",
      "target": "kRBQwlkFSP",
      "similarity": 0.8237
    },
    {
      "source": "pOq9vDIYev",
      "target": "We highlight the critical concept of *order consistency* in reward modeling and demonstrate that the BT model possesses this property.",
      "similarity": 0.824
    },
    {
      "source": "pOq9vDIYev",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.8202
    },
    {
      "source": "pOq9vDIYev",
      "target": "8bjspmAMBk",
      "similarity": 0.7839
    },
    {
      "source": "pOq9vDIYev",
      "target": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "similarity": 0.7824
    },
    {
      "source": "pOq9vDIYev",
      "target": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "similarity": 0.7754
    },
    {
      "source": "e2NRNQ0sZe",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.8292
    },
    {
      "source": "e2NRNQ0sZe",
      "target": "vcX0k4rGTt",
      "similarity": 0.828
    },
    {
      "source": "e2NRNQ0sZe",
      "target": "To address these challenges",
      "similarity": 0.8258
    },
    {
      "source": "e2NRNQ0sZe",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8108
    },
    {
      "source": "e2NRNQ0sZe",
      "target": "this simple method is computationally fast",
      "similarity": 0.8106
    },
    {
      "source": "Oeb0I3JcVc",
      "target": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "similarity": 0.8933
    },
    {
      "source": "Oeb0I3JcVc",
      "target": "sampling methods",
      "similarity": 0.8374
    },
    {
      "source": "Oeb0I3JcVc",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8297
    },
    {
      "source": "Oeb0I3JcVc",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8251
    },
    {
      "source": "Oeb0I3JcVc",
      "target": "C45YqeBDUM",
      "similarity": 0.8234
    },
    {
      "source": "FvQsk3la17",
      "target": "WCRQFlji2q",
      "similarity": 0.8754
    },
    {
      "source": "FvQsk3la17",
      "target": "qZEdmyqCHF",
      "similarity": 0.8687
    },
    {
      "source": "FvQsk3la17",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8666
    },
    {
      "source": "FvQsk3la17",
      "target": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "similarity": 0.8653
    },
    {
      "source": "FvQsk3la17",
      "target": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "similarity": 0.8651
    },
    {
      "source": "Notably",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8382
    },
    {
      "source": "Notably",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8368
    },
    {
      "source": "Notably",
      "target": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "similarity": 0.8293
    },
    {
      "source": "Notably",
      "target": "Our proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data",
      "similarity": 0.8288
    },
    {
      "source": "Notably",
      "target": "cmfyMV45XO",
      "similarity": 0.8276
    },
    {
      "source": "cfKZ5VrhXt",
      "target": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "similarity": 0.8501
    },
    {
      "source": "cfKZ5VrhXt",
      "target": "j8WHjM9aMm",
      "similarity": 0.8409
    },
    {
      "source": "cfKZ5VrhXt",
      "target": "g0rnZeBguq",
      "similarity": 0.8325
    },
    {
      "source": "cfKZ5VrhXt",
      "target": "of our proposed method through a new understanding of the contrastive loss of",
      "similarity": 0.8307
    },
    {
      "source": "cfKZ5VrhXt",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8275
    },
    {
      "source": "aVfDrl7xDV",
      "target": "Further",
      "similarity": 0.8668
    },
    {
      "source": "aVfDrl7xDV",
      "target": "5xSRg3eYZz",
      "similarity": 0.8667
    },
    {
      "source": "aVfDrl7xDV",
      "target": "bsFWJ0Kget",
      "similarity": 0.858
    },
    {
      "source": "aVfDrl7xDV",
      "target": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "similarity": 0.8398
    },
    {
      "source": "aVfDrl7xDV",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8383
    },
    {
      "source": "xQCXInDq0m",
      "target": "293V3bJbmE",
      "similarity": 0.869
    },
    {
      "source": "xQCXInDq0m",
      "target": "y9A2TpaGsE",
      "similarity": 0.8554
    },
    {
      "source": "xQCXInDq0m",
      "target": "Our key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM",
      "similarity": 0.8498
    },
    {
      "source": "xQCXInDq0m",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.847
    },
    {
      "source": "xQCXInDq0m",
      "target": "This includes evaluating capabilities",
      "similarity": 0.8463
    },
    {
      "source": "Dem5LyVk8R",
      "target": "unDQOUah0F",
      "similarity": 0.8562
    },
    {
      "source": "Dem5LyVk8R",
      "target": "iVMcYxTiVM",
      "similarity": 0.8531
    },
    {
      "source": "Dem5LyVk8R",
      "target": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "similarity": 0.8433
    },
    {
      "source": "Dem5LyVk8R",
      "target": "Crucially",
      "similarity": 0.8317
    },
    {
      "source": "Dem5LyVk8R",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8185
    },
    {
      "source": "lIVRgt4nLv",
      "target": "md9qolJwLl",
      "similarity": 0.8184
    },
    {
      "source": "lIVRgt4nLv",
      "target": "8sSqNntaMr",
      "similarity": 0.8084
    },
    {
      "source": "lIVRgt4nLv",
      "target": "1tBvzOYTLF",
      "similarity": 0.8067
    },
    {
      "source": "lIVRgt4nLv",
      "target": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "similarity": 0.805
    },
    {
      "source": "lIVRgt4nLv",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.8043
    },
    {
      "source": "In addition",
      "target": "JAMxRSXLFz",
      "similarity": 0.8711
    },
    {
      "source": "In addition",
      "target": "NGKQoaqLpo",
      "similarity": 0.8641
    },
    {
      "source": "In addition",
      "target": "254NJe9JEw",
      "similarity": 0.8593
    },
    {
      "source": "In addition",
      "target": "kbeX97jExm",
      "similarity": 0.8544
    },
    {
      "source": "In addition",
      "target": "In contrast",
      "similarity": 0.851
    },
    {
      "source": "kO0DgO07hW",
      "target": "E48QvQppIN",
      "similarity": 0.8283
    },
    {
      "source": "kO0DgO07hW",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8154
    },
    {
      "source": "kO0DgO07hW",
      "target": "To overcome those challenges",
      "similarity": 0.8133
    },
    {
      "source": "kO0DgO07hW",
      "target": "Additionally",
      "similarity": 0.8113
    },
    {
      "source": "kO0DgO07hW",
      "target": "T4LtGj7us1",
      "similarity": 0.8084
    },
    {
      "source": "o1Et3MogPw",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8701
    },
    {
      "source": "o1Et3MogPw",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8555
    },
    {
      "source": "o1Et3MogPw",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8467
    },
    {
      "source": "o1Et3MogPw",
      "target": "Moreover",
      "similarity": 0.8461
    },
    {
      "source": "o1Et3MogPw",
      "target": "Se6MgCtRhz",
      "similarity": 0.8421
    },
    {
      "source": "tBom4xOW1H",
      "target": "benchmarking higher-order models",
      "similarity": 0.8231
    },
    {
      "source": "tBom4xOW1H",
      "target": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "similarity": 0.8198
    },
    {
      "source": "tBom4xOW1H",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.8096
    },
    {
      "source": "tBom4xOW1H",
      "target": "irrtPRFksw",
      "similarity": 0.7961
    },
    {
      "source": "tBom4xOW1H",
      "target": "However",
      "similarity": 0.7929
    },
    {
      "source": "K7xpl3LZQp",
      "target": "VoayJihXra",
      "similarity": 0.8936
    },
    {
      "source": "K7xpl3LZQp",
      "target": "relying on backward propagation",
      "similarity": 0.888
    },
    {
      "source": "K7xpl3LZQp",
      "target": "9qS3HzSDNv",
      "similarity": 0.8798
    },
    {
      "source": "K7xpl3LZQp",
      "target": "d7pr2doXn3",
      "similarity": 0.8776
    },
    {
      "source": "K7xpl3LZQp",
      "target": "In this work",
      "similarity": 0.8653
    },
    {
      "source": "wxPnuFp8fZ",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8355
    },
    {
      "source": "wxPnuFp8fZ",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8323
    },
    {
      "source": "wxPnuFp8fZ",
      "target": "In this paper",
      "similarity": 0.8298
    },
    {
      "source": "wxPnuFp8fZ",
      "target": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "similarity": 0.8273
    },
    {
      "source": "wxPnuFp8fZ",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8271
    },
    {
      "source": "v593OaNePQ",
      "target": "JAMxRSXLFz",
      "similarity": 0.8853
    },
    {
      "source": "v593OaNePQ",
      "target": "To this end",
      "similarity": 0.8809
    },
    {
      "source": "v593OaNePQ",
      "target": "To this end",
      "similarity": 0.8743
    },
    {
      "source": "v593OaNePQ",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8665
    },
    {
      "source": "v593OaNePQ",
      "target": "254NJe9JEw",
      "similarity": 0.8646
    },
    {
      "source": "fMbLszVO1H",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8057
    },
    {
      "source": "fMbLszVO1H",
      "target": "On the other hand",
      "similarity": 0.7918
    },
    {
      "source": "fMbLszVO1H",
      "target": "In brief",
      "similarity": 0.7889
    },
    {
      "source": "fMbLszVO1H",
      "target": "8eNLKk5by4",
      "similarity": 0.7859
    },
    {
      "source": "fMbLszVO1H",
      "target": "AUCYptvAf3",
      "similarity": 0.7841
    },
    {
      "source": "Es4RPNDtmq",
      "target": "LNL7zKvm7e",
      "similarity": 0.8911
    },
    {
      "source": "Es4RPNDtmq",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8899
    },
    {
      "source": "Es4RPNDtmq",
      "target": "Our findings indicate that",
      "similarity": 0.8854
    },
    {
      "source": "Es4RPNDtmq",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8843
    },
    {
      "source": "Es4RPNDtmq",
      "target": "i1NNCrRxdM",
      "similarity": 0.8805
    },
    {
      "source": "84WmbzikPP",
      "target": "il5yUQsrjC",
      "similarity": 0.9045
    },
    {
      "source": "84WmbzikPP",
      "target": "8eNLKk5by4",
      "similarity": 0.9002
    },
    {
      "source": "84WmbzikPP",
      "target": "In particular",
      "similarity": 0.887
    },
    {
      "source": "84WmbzikPP",
      "target": "XdRIno98gG",
      "similarity": 0.8716
    },
    {
      "source": "84WmbzikPP",
      "target": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "similarity": 0.8701
    },
    {
      "source": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "target": "8rbkePAapb",
      "similarity": 0.8477
    },
    {
      "source": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "target": "spDUv05cEq",
      "similarity": 0.8189
    },
    {
      "source": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.8151
    },
    {
      "source": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "target": "To address this",
      "similarity": 0.8119
    },
    {
      "source": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "target": "eUEMjwh5wK",
      "similarity": 0.8093
    },
    {
      "source": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "target": "UIFAJZ22ZF",
      "similarity": 0.8903
    },
    {
      "source": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8536
    },
    {
      "source": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8447
    },
    {
      "source": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "target": "a hypergraph",
      "similarity": 0.8421
    },
    {
      "source": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "target": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "similarity": 0.841
    },
    {
      "source": "To address this",
      "target": "Lastly",
      "similarity": 0.8528
    },
    {
      "source": "To address this",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8478
    },
    {
      "source": "To address this",
      "target": "zpENPcQSj1",
      "similarity": 0.8332
    },
    {
      "source": "To address this",
      "target": "2pNLknCTvG",
      "similarity": 0.8291
    },
    {
      "source": "To address this",
      "target": "It was numerically observed that the linear interpolation",
      "similarity": 0.8245
    },
    {
      "source": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "target": "Mjn53GtMxi",
      "similarity": 0.8891
    },
    {
      "source": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "target": "In this task",
      "similarity": 0.8644
    },
    {
      "source": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "target": "xvhV3LvYTc",
      "similarity": 0.857
    },
    {
      "source": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "target": "In this work",
      "similarity": 0.8498
    },
    {
      "source": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "target": "YFxfcQMLWX",
      "similarity": 0.8464
    },
    {
      "source": "Additionally",
      "target": "NEu8wgPctU",
      "similarity": 0.8424
    },
    {
      "source": "Additionally",
      "target": "First",
      "similarity": 0.8405
    },
    {
      "source": "Additionally",
      "target": "4NTrco82W0",
      "similarity": 0.832
    },
    {
      "source": "Additionally",
      "target": "ScVnYBaSEw",
      "similarity": 0.8178
    },
    {
      "source": "Additionally",
      "target": "27SSnLl85x",
      "similarity": 0.8138
    },
    {
      "source": "Empirically",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8477
    },
    {
      "source": "Empirically",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8453
    },
    {
      "source": "Empirically",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8439
    },
    {
      "source": "Empirically",
      "target": "kwCHcaeHrf",
      "similarity": 0.8432
    },
    {
      "source": "Empirically",
      "target": "Building on this",
      "similarity": 0.8423
    },
    {
      "source": "7El7K1DoyX",
      "target": "je3GZissZc",
      "similarity": 0.8896
    },
    {
      "source": "7El7K1DoyX",
      "target": "jqmptcSNVG",
      "similarity": 0.8847
    },
    {
      "source": "7El7K1DoyX",
      "target": "In this work",
      "similarity": 0.8756
    },
    {
      "source": "7El7K1DoyX",
      "target": "In this paper",
      "similarity": 0.8711
    },
    {
      "source": "7El7K1DoyX",
      "target": "IuU0wcO0mo",
      "similarity": 0.8705
    },
    {
      "source": "M4qNIzQYpd",
      "target": "E4LAVLXAHW",
      "similarity": 0.827
    },
    {
      "source": "M4qNIzQYpd",
      "target": "JAMxRSXLFz",
      "similarity": 0.823
    },
    {
      "source": "M4qNIzQYpd",
      "target": "These findings highlight the significant room for improvement in current reward models.\"",
      "similarity": 0.8197
    },
    {
      "source": "M4qNIzQYpd",
      "target": "relying on backward propagation",
      "similarity": 0.8196
    },
    {
      "source": "M4qNIzQYpd",
      "target": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "similarity": 0.8194
    },
    {
      "source": "OhauMUNW8T",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.9063
    },
    {
      "source": "OhauMUNW8T",
      "target": "Yet",
      "similarity": 0.9025
    },
    {
      "source": "OhauMUNW8T",
      "target": "models. However",
      "similarity": 0.8936
    },
    {
      "source": "OhauMUNW8T",
      "target": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "similarity": 0.876
    },
    {
      "source": "OhauMUNW8T",
      "target": "For example",
      "similarity": 0.8644
    },
    {
      "source": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "target": "FhTAG591Ve",
      "similarity": 0.8641
    },
    {
      "source": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.8222
    },
    {
      "source": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "target": "To address this",
      "similarity": 0.8214
    },
    {
      "source": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8204
    },
    {
      "source": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "target": "To bridge this gap",
      "similarity": 0.819
    },
    {
      "source": "We analyzed conventional position encoding methods for long contexts and found the following characteristics.",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8831
    },
    {
      "source": "We analyzed conventional position encoding methods for long contexts and found the following characteristics.",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8416
    },
    {
      "source": "We analyzed conventional position encoding methods for long contexts and found the following characteristics.",
      "target": "is usually inaccessible for advanced LLMs",
      "similarity": 0.8402
    },
    {
      "source": "We analyzed conventional position encoding methods for long contexts and found the following characteristics.",
      "target": "FviefuxmeW",
      "similarity": 0.8359
    },
    {
      "source": "We analyzed conventional position encoding methods for long contexts and found the following characteristics.",
      "target": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "similarity": 0.8298
    },
    {
      "source": "(1) When the representation dimension is regarded as the time axis",
      "target": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "similarity": 0.9016
    },
    {
      "source": "(1) When the representation dimension is regarded as the time axis",
      "target": "aMBSY2ebPw",
      "similarity": 0.8744
    },
    {
      "source": "(1) When the representation dimension is regarded as the time axis",
      "target": "To overcome those challenges",
      "similarity": 0.8643
    },
    {
      "source": "(1) When the representation dimension is regarded as the time axis",
      "target": "Mjn53GtMxi",
      "similarity": 0.8591
    },
    {
      "source": "(1) When the representation dimension is regarded as the time axis",
      "target": "1qGkuxI9UX",
      "similarity": 0.8534
    },
    {
      "source": "However",
      "target": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "similarity": 0.8656
    },
    {
      "source": "However",
      "target": "We are the first to identify these challenges in online VFL",
      "similarity": 0.8482
    },
    {
      "source": "However",
      "target": "iyJOUELYir",
      "similarity": 0.845
    },
    {
      "source": "However",
      "target": "To explore this",
      "similarity": 0.8429
    },
    {
      "source": "However",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8387
    },
    {
      "source": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "target": "In this paper",
      "similarity": 0.8717
    },
    {
      "source": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "target": "l6QnSQizmN",
      "similarity": 0.8698
    },
    {
      "source": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "target": "zCZnEXF3bN",
      "similarity": 0.8694
    },
    {
      "source": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "target": "HaX48yksVL",
      "similarity": 0.8675
    },
    {
      "source": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "target": "affects effectiveness in two downstream proxy model applications: data",
      "similarity": 0.8634
    },
    {
      "source": "(2)",
      "target": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "similarity": 0.8076
    },
    {
      "source": "(2)",
      "target": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "similarity": 0.805
    },
    {
      "source": "(2)",
      "target": "ogXkmugNZw",
      "similarity": 0.79
    },
    {
      "source": "(2)",
      "target": "o2Igqm95SJ",
      "similarity": 0.7846
    },
    {
      "source": "(2)",
      "target": "However",
      "similarity": 0.7802
    },
    {
      "source": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "target": "Together",
      "similarity": 0.8822
    },
    {
      "source": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "target": "yFGR36PLDJ",
      "similarity": 0.8799
    },
    {
      "source": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "target": "In addition",
      "similarity": 0.8634
    },
    {
      "source": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8535
    },
    {
      "source": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "target": "HrdVqFSn1e",
      "similarity": 0.8529
    },
    {
      "source": "However",
      "target": "pretraining methods. Stagewise training approaches to improve efficiency",
      "similarity": 0.8259
    },
    {
      "source": "However",
      "target": "2vHIHrJAcI",
      "similarity": 0.8256
    },
    {
      "source": "However",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8193
    },
    {
      "source": "However",
      "target": "NfCEVihkdC",
      "similarity": 0.8153
    },
    {
      "source": "However",
      "target": "world perspective. To address this",
      "similarity": 0.814
    },
    {
      "source": "From these insights",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8637
    },
    {
      "source": "From these insights",
      "target": "In this paper",
      "similarity": 0.8506
    },
    {
      "source": "From these insights",
      "target": "pDDODPtpx9",
      "similarity": 0.8501
    },
    {
      "source": "From these insights",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8497
    },
    {
      "source": "From these insights",
      "target": "JSB171dSUU",
      "similarity": 0.8491
    },
    {
      "source": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "target": "Usklli4gMc",
      "similarity": 0.8606
    },
    {
      "source": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "target": "riieAeQBJm",
      "similarity": 0.854
    },
    {
      "source": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "target": "IuU0wcO0mo",
      "similarity": 0.8534
    },
    {
      "source": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "target": "7El7K1DoyX",
      "similarity": 0.8525
    },
    {
      "source": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "target": "In this work",
      "similarity": 0.8523
    },
    {
      "source": "In particular",
      "target": "over methods trained using much larger datasets.",
      "similarity": 0.8768
    },
    {
      "source": "In particular",
      "target": "xoXn62FzD0",
      "similarity": 0.8689
    },
    {
      "source": "In particular",
      "target": "Tv36j85SqR",
      "similarity": 0.8522
    },
    {
      "source": "In particular",
      "target": "I8af9JdQTy",
      "similarity": 0.8439
    },
    {
      "source": "In particular",
      "target": "nibeaHUEJx",
      "similarity": 0.8423
    },
    {
      "source": "chfJJYC3iL",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8361
    },
    {
      "source": "chfJJYC3iL",
      "target": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "similarity": 0.8321
    },
    {
      "source": "chfJJYC3iL",
      "target": "o1Et3MogPw",
      "similarity": 0.8305
    },
    {
      "source": "chfJJYC3iL",
      "target": "However",
      "similarity": 0.8303
    },
    {
      "source": "chfJJYC3iL",
      "target": "Finally",
      "similarity": 0.8294
    },
    {
      "source": "NUD03NBDOE",
      "target": "5pd78GmXC6",
      "similarity": 0.8299
    },
    {
      "source": "NUD03NBDOE",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8296
    },
    {
      "source": "NUD03NBDOE",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.827
    },
    {
      "source": "NUD03NBDOE",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.8244
    },
    {
      "source": "NUD03NBDOE",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8225
    },
    {
      "source": "bgpNJBD6Va",
      "target": "d16mJDyQN6",
      "similarity": 0.8977
    },
    {
      "source": "bgpNJBD6Va",
      "target": "1F8xTfv6ah",
      "similarity": 0.7975
    },
    {
      "source": "bgpNJBD6Va",
      "target": "In particular",
      "similarity": 0.7964
    },
    {
      "source": "bgpNJBD6Va",
      "target": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "similarity": 0.7888
    },
    {
      "source": "bgpNJBD6Va",
      "target": "Second",
      "similarity": 0.7839
    },
    {
      "source": "A6Y7AqlzLW",
      "target": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "similarity": 0.8117
    },
    {
      "source": "A6Y7AqlzLW",
      "target": "To this end",
      "similarity": 0.8113
    },
    {
      "source": "A6Y7AqlzLW",
      "target": "t6QHYUOQL7",
      "similarity": 0.7975
    },
    {
      "source": "A6Y7AqlzLW",
      "target": "JYwVijuNA7",
      "similarity": 0.7948
    },
    {
      "source": "A6Y7AqlzLW",
      "target": "First",
      "similarity": 0.7905
    },
    {
      "source": "*progress*: a change in the likelihood of producing a correct response in the future",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.842
    },
    {
      "source": "*progress*: a change in the likelihood of producing a correct response in the future",
      "target": "ofuLWn8DFZ",
      "similarity": 0.8415
    },
    {
      "source": "*progress*: a change in the likelihood of producing a correct response in the future",
      "target": "Furthermore",
      "similarity": 0.8403
    },
    {
      "source": "*progress*: a change in the likelihood of producing a correct response in the future",
      "target": "In particular",
      "similarity": 0.8403
    },
    {
      "source": "*progress*: a change in the likelihood of producing a correct response in the future",
      "target": "Furthermore",
      "similarity": 0.8365
    },
    {
      "source": "CS2JWaziYr",
      "target": "that achieve the optimal similarity. In addition",
      "similarity": 0.878
    },
    {
      "source": "CS2JWaziYr",
      "target": "x33vSZUg0A",
      "similarity": 0.8419
    },
    {
      "source": "CS2JWaziYr",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8397
    },
    {
      "source": "CS2JWaziYr",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.827
    },
    {
      "source": "CS2JWaziYr",
      "target": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "similarity": 0.8203
    },
    {
      "source": "exgLs4snap",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8697
    },
    {
      "source": "exgLs4snap",
      "target": "To explore this",
      "similarity": 0.8642
    },
    {
      "source": "exgLs4snap",
      "target": "IUmj2dw5se",
      "similarity": 0.8577
    },
    {
      "source": "exgLs4snap",
      "target": "mobile devices.\"",
      "similarity": 0.8362
    },
    {
      "source": "exgLs4snap",
      "target": "several graph- and simplicial complex-based models on three topological classification",
      "similarity": 0.8335
    },
    {
      "source": "Iyrtb9EJBp",
      "target": "uZgK0tcPqd",
      "similarity": 0.8705
    },
    {
      "source": "Iyrtb9EJBp",
      "target": "lsvGqR6OTf",
      "similarity": 0.8481
    },
    {
      "source": "Iyrtb9EJBp",
      "target": "identically. Therefore",
      "similarity": 0.8432
    },
    {
      "source": "Iyrtb9EJBp",
      "target": "However",
      "similarity": 0.8285
    },
    {
      "source": "Iyrtb9EJBp",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8283
    },
    {
      "source": "NkGDNM8LB0",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8485
    },
    {
      "source": "NkGDNM8LB0",
      "target": "memorization.",
      "similarity": 0.8427
    },
    {
      "source": "NkGDNM8LB0",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8374
    },
    {
      "source": "NkGDNM8LB0",
      "target": "wSkvf2WyYz",
      "similarity": 0.8351
    },
    {
      "source": "NkGDNM8LB0",
      "target": "bc2H72hGxB",
      "similarity": 0.8325
    },
    {
      "source": "hzuumhfYSO",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.8574
    },
    {
      "source": "hzuumhfYSO",
      "target": "DL9txImSzm",
      "similarity": 0.8486
    },
    {
      "source": "hzuumhfYSO",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8292
    },
    {
      "source": "hzuumhfYSO",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8278
    },
    {
      "source": "hzuumhfYSO",
      "target": "L9eBxTCpQG",
      "similarity": 0.8259
    },
    {
      "source": "gU4ZgQNsOC",
      "target": "Neural methods have shown promising results for subgraph matching.",
      "similarity": 0.8452
    },
    {
      "source": "gU4ZgQNsOC",
      "target": "u2QdCiOgwA",
      "similarity": 0.8441
    },
    {
      "source": "gU4ZgQNsOC",
      "target": "zcTLpIfj9u",
      "similarity": 0.8378
    },
    {
      "source": "gU4ZgQNsOC",
      "target": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "similarity": 0.8375
    },
    {
      "source": "gU4ZgQNsOC",
      "target": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "similarity": 0.8367
    },
    {
      "source": "Furthermore",
      "target": "FCBbh0HCrF",
      "similarity": 0.8464
    },
    {
      "source": "Furthermore",
      "target": "GBIUbwW9D8",
      "similarity": 0.8363
    },
    {
      "source": "Furthermore",
      "target": "SG1R2H3fa1",
      "similarity": 0.8332
    },
    {
      "source": "Furthermore",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8301
    },
    {
      "source": "Furthermore",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8281
    },
    {
      "source": "m9wG6ai2Xk",
      "target": "With regards to improving Shampoo's computational efficiency",
      "similarity": 0.8697
    },
    {
      "source": "m9wG6ai2Xk",
      "target": "Furthermore",
      "similarity": 0.8504
    },
    {
      "source": "m9wG6ai2Xk",
      "target": "Moreover",
      "similarity": 0.8457
    },
    {
      "source": "m9wG6ai2Xk",
      "target": "NDLmZZWATc",
      "similarity": 0.8374
    },
    {
      "source": "m9wG6ai2Xk",
      "target": "3bcN6xlO6f",
      "similarity": 0.8372
    },
    {
      "source": "However",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8318
    },
    {
      "source": "However",
      "target": "m73tETvFkX",
      "similarity": 0.8223
    },
    {
      "source": "However",
      "target": "mun3bGqdDM",
      "similarity": 0.8201
    },
    {
      "source": "However",
      "target": "uREg3OHjLL",
      "similarity": 0.8197
    },
    {
      "source": "However",
      "target": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "similarity": 0.8192
    },
    {
      "source": "In this work",
      "target": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "similarity": 0.8532
    },
    {
      "source": "In this work",
      "target": "To integrate it with canonicalization",
      "similarity": 0.7865
    },
    {
      "source": "In this work",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.7818
    },
    {
      "source": "In this work",
      "target": "We5z3UEnUY",
      "similarity": 0.7792
    },
    {
      "source": "In this work",
      "target": "Finally",
      "similarity": 0.7783
    },
    {
      "source": "LNL7zKvm7e",
      "target": "Jyh0DR4fFE",
      "similarity": 0.8817
    },
    {
      "source": "LNL7zKvm7e",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.8805
    },
    {
      "source": "LNL7zKvm7e",
      "target": "Our findings indicate that",
      "similarity": 0.8756
    },
    {
      "source": "LNL7zKvm7e",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8687
    },
    {
      "source": "LNL7zKvm7e",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8658
    },
    {
      "source": "0e2pcSxQJS",
      "target": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "similarity": 0.8643
    },
    {
      "source": "0e2pcSxQJS",
      "target": "1Njl73JKjB",
      "similarity": 0.8477
    },
    {
      "source": "0e2pcSxQJS",
      "target": "recently garnered attention. The prevailing view suggests that stagewise dropping",
      "similarity": 0.8473
    },
    {
      "source": "0e2pcSxQJS",
      "target": "0OTVNEm9N4",
      "similarity": 0.8463
    },
    {
      "source": "0e2pcSxQJS",
      "target": "T4sMzjy7fO",
      "similarity": 0.8456
    },
    {
      "source": "XrsOu4KgDE",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8177
    },
    {
      "source": "XrsOu4KgDE",
      "target": "Finally",
      "similarity": 0.8129
    },
    {
      "source": "XrsOu4KgDE",
      "target": "l6QnSQizmN",
      "similarity": 0.8128
    },
    {
      "source": "XrsOu4KgDE",
      "target": "4xWQS2z77v",
      "similarity": 0.8114
    },
    {
      "source": "XrsOu4KgDE",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8105
    },
    {
      "source": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "target": "odU59TxdiB",
      "similarity": 0.9303
    },
    {
      "source": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "target": "Overall",
      "similarity": 0.9267
    },
    {
      "source": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.9213
    },
    {
      "source": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "target": "in a vector database",
      "similarity": 0.9139
    },
    {
      "source": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.8992
    },
    {
      "source": "l0fn10vSyM",
      "target": "WwwJfkGq0G",
      "similarity": 0.8698
    },
    {
      "source": "l0fn10vSyM",
      "target": "gfI9v7AbFg",
      "similarity": 0.8494
    },
    {
      "source": "l0fn10vSyM",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8482
    },
    {
      "source": "l0fn10vSyM",
      "target": "kX8h23UG6v",
      "similarity": 0.8456
    },
    {
      "source": "l0fn10vSyM",
      "target": "6HcnC3pPkp",
      "similarity": 0.8384
    },
    {
      "source": "PHg4rAXFVH",
      "target": "4JK2XMGUc8",
      "similarity": 0.8871
    },
    {
      "source": "PHg4rAXFVH",
      "target": "0h6v4SpLCY",
      "similarity": 0.8795
    },
    {
      "source": "PHg4rAXFVH",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8794
    },
    {
      "source": "PHg4rAXFVH",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8771
    },
    {
      "source": "PHg4rAXFVH",
      "target": "In doing so",
      "similarity": 0.8721
    },
    {
      "source": "We conduct a detailed analysis of early stopping in our algorithm",
      "target": "In this paper",
      "similarity": 0.8836
    },
    {
      "source": "We conduct a detailed analysis of early stopping in our algorithm",
      "target": "6HcnC3pPkp",
      "similarity": 0.8798
    },
    {
      "source": "We conduct a detailed analysis of early stopping in our algorithm",
      "target": "kX8h23UG6v",
      "similarity": 0.8588
    },
    {
      "source": "We conduct a detailed analysis of early stopping in our algorithm",
      "target": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "similarity": 0.8485
    },
    {
      "source": "We conduct a detailed analysis of early stopping in our algorithm",
      "target": "To systematically examine current visual temporal reasoning tasks",
      "similarity": 0.8442
    },
    {
      "source": "hoYFLRNbhc",
      "target": "2mqb8bPHeb",
      "similarity": 0.8858
    },
    {
      "source": "hoYFLRNbhc",
      "target": "9qpdDiDQ2H",
      "similarity": 0.8844
    },
    {
      "source": "hoYFLRNbhc",
      "target": "To address these challenges",
      "similarity": 0.8685
    },
    {
      "source": "hoYFLRNbhc",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8669
    },
    {
      "source": "hoYFLRNbhc",
      "target": "txD9llAYn9",
      "similarity": 0.8613
    },
    {
      "source": "However",
      "target": "dsP91M4hDL",
      "similarity": 0.8245
    },
    {
      "source": "However",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8157
    },
    {
      "source": "However",
      "target": "iyJOUELYir",
      "similarity": 0.8145
    },
    {
      "source": "However",
      "target": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "similarity": 0.8126
    },
    {
      "source": "However",
      "target": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "similarity": 0.8125
    },
    {
      "source": "In this paper",
      "target": "U3PBITXNG6",
      "similarity": 0.8682
    },
    {
      "source": "In this paper",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8669
    },
    {
      "source": "In this paper",
      "target": "HpUs2EXjOl",
      "similarity": 0.855
    },
    {
      "source": "In this paper",
      "target": "the entire observable history remained an open problem. In this work",
      "similarity": 0.8542
    },
    {
      "source": "In this paper",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.852
    },
    {
      "source": "DelTA features a multi-level memory structure that stores information across various granularities and spans",
      "target": "a two-player game and propose a novel online algorithm",
      "similarity": 0.7766
    },
    {
      "source": "DelTA features a multi-level memory structure that stores information across various granularities and spans",
      "target": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "similarity": 0.7747
    },
    {
      "source": "DelTA features a multi-level memory structure that stores information across various granularities and spans",
      "target": "In this work",
      "similarity": 0.7744
    },
    {
      "source": "DelTA features a multi-level memory structure that stores information across various granularities and spans",
      "target": "However",
      "similarity": 0.774
    },
    {
      "source": "DelTA features a multi-level memory structure that stores information across various granularities and spans",
      "target": "EDoD3DgivF",
      "similarity": 0.7715
    },
    {
      "source": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "target": "fvkElsJOsN",
      "similarity": 0.8424
    },
    {
      "source": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "target": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "similarity": 0.8418
    },
    {
      "source": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "target": "60GeEoG5kD",
      "similarity": 0.8373
    },
    {
      "source": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "target": "ajSmXqgS24",
      "similarity": 0.8335
    },
    {
      "source": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "target": "ih3BJmIZbC",
      "similarity": 0.8316
    },
    {
      "source": "DelTA employs a sentence-by-sentence translation strategy",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8878
    },
    {
      "source": "DelTA employs a sentence-by-sentence translation strategy",
      "target": "Dl3MsjaIdp",
      "similarity": 0.8768
    },
    {
      "source": "DelTA employs a sentence-by-sentence translation strategy",
      "target": "suz4utPr9Y",
      "similarity": 0.8761
    },
    {
      "source": "DelTA employs a sentence-by-sentence translation strategy",
      "target": "EEgYUccwsV",
      "similarity": 0.8707
    },
    {
      "source": "DelTA employs a sentence-by-sentence translation strategy",
      "target": "Pacmann carefully offloads limited computation and storage to the client",
      "similarity": 0.8691
    },
    {
      "source": "Furthermore",
      "target": "4vzGQcVUG8",
      "similarity": 0.8492
    },
    {
      "source": "Furthermore",
      "target": "Next",
      "similarity": 0.8162
    },
    {
      "source": "Furthermore",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8159
    },
    {
      "source": "Furthermore",
      "target": "N0ETIi580T",
      "similarity": 0.8158
    },
    {
      "source": "Furthermore",
      "target": "riTiq3i21b",
      "similarity": 0.8157
    },
    {
      "source": "The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.\"",
      "target": "In the course of this process",
      "similarity": 0.832
    },
    {
      "source": "The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.\"",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.8269
    },
    {
      "source": "The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.\"",
      "target": "vjel3nWP2a",
      "similarity": 0.8264
    },
    {
      "source": "The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.\"",
      "target": "are effective at curbing memorization",
      "similarity": 0.8166
    },
    {
      "source": "The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.\"",
      "target": "ZjOXuAfS6l",
      "similarity": 0.8109
    },
    {
      "source": "eENHKMTOfW",
      "target": "Based on the observations",
      "similarity": 0.8412
    },
    {
      "source": "eENHKMTOfW",
      "target": "4JK2XMGUc8",
      "similarity": 0.8368
    },
    {
      "source": "eENHKMTOfW",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8311
    },
    {
      "source": "eENHKMTOfW",
      "target": "pDDODPtpx9",
      "similarity": 0.8309
    },
    {
      "source": "eENHKMTOfW",
      "target": "llSiIJosDj",
      "similarity": 0.8304
    },
    {
      "source": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8528
    },
    {
      "source": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "target": "fN8yLc3eA7",
      "similarity": 0.8484
    },
    {
      "source": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "target": "VoayJihXra",
      "similarity": 0.8479
    },
    {
      "source": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "target": "wide dissemination",
      "similarity": 0.8474
    },
    {
      "source": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "target": "named Pacmann",
      "similarity": 0.8465
    },
    {
      "source": "6bKEWevgSd",
      "target": "jQP5o1VAVc",
      "similarity": 0.8822
    },
    {
      "source": "6bKEWevgSd",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8794
    },
    {
      "source": "6bKEWevgSd",
      "target": "ods",
      "similarity": 0.8766
    },
    {
      "source": "6bKEWevgSd",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.8713
    },
    {
      "source": "6bKEWevgSd",
      "target": "In response",
      "similarity": 0.8701
    },
    {
      "source": "25j2ZEgwTj",
      "target": "To this end",
      "similarity": 0.8693
    },
    {
      "source": "25j2ZEgwTj",
      "target": "AJpUZd8Clb",
      "similarity": 0.8675
    },
    {
      "source": "25j2ZEgwTj",
      "target": "We further analyze the key effects of these neurons on the image classification task",
      "similarity": 0.8505
    },
    {
      "source": "25j2ZEgwTj",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.847
    },
    {
      "source": "25j2ZEgwTj",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.8431
    },
    {
      "source": "YaBiGjuDiC",
      "target": "Based on the observations",
      "similarity": 0.7962
    },
    {
      "source": "YaBiGjuDiC",
      "target": "Ahlrf2HGJR",
      "similarity": 0.7922
    },
    {
      "source": "YaBiGjuDiC",
      "target": "Our results underscore the great promise of CD-T for efficient automated mechanistic interpretability",
      "similarity": 0.7895
    },
    {
      "source": "YaBiGjuDiC",
      "target": "txZVQRc2ab",
      "similarity": 0.7876
    },
    {
      "source": "YaBiGjuDiC",
      "target": "7El7K1DoyX",
      "similarity": 0.7857
    },
    {
      "source": "At its core",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.823
    },
    {
      "source": "At its core",
      "target": "tcsZt9ZNKD",
      "similarity": 0.821
    },
    {
      "source": "At its core",
      "target": "kxnoqaisCT",
      "similarity": 0.82
    },
    {
      "source": "At its core",
      "target": "TlAdgeoDTo",
      "similarity": 0.8187
    },
    {
      "source": "At its core",
      "target": "A1HhtITVEi",
      "similarity": 0.815
    },
    {
      "source": "(1) The probability of dispreferred (e.g.",
      "target": "YzxMu1asQi",
      "similarity": 0.8609
    },
    {
      "source": "(1) The probability of dispreferred (e.g.",
      "target": "To overcome those challenges",
      "similarity": 0.8568
    },
    {
      "source": "(1) The probability of dispreferred (e.g.",
      "target": "3E8YNv1HjU",
      "similarity": 0.8532
    },
    {
      "source": "(1) The probability of dispreferred (e.g.",
      "target": "R4q3cY3kQf",
      "similarity": 0.8518
    },
    {
      "source": "(1) The probability of dispreferred (e.g.",
      "target": "by constraining the parameter space to our proposed manifold",
      "similarity": 0.8517
    },
    {
      "source": "(2) The probability of preferred responses may decrease",
      "target": "To remedy this problem",
      "similarity": 0.8823
    },
    {
      "source": "(2) The probability of preferred responses may decrease",
      "target": "20qZK2T7fa",
      "similarity": 0.8705
    },
    {
      "source": "(2) The probability of preferred responses may decrease",
      "target": "1yJP5TVWih",
      "similarity": 0.8644
    },
    {
      "source": "(2) The probability of preferred responses may decrease",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8574
    },
    {
      "source": "(2) The probability of preferred responses may decrease",
      "target": "assessing and advancing topological methods",
      "similarity": 0.857
    },
    {
      "source": "We demystify the reasons behind these problematic behaviors: margin-based losses couple the change in the preferred probability with the gradient of the dispreferred one",
      "target": "p60Y6o85Cj",
      "similarity": 0.8364
    },
    {
      "source": "We demystify the reasons behind these problematic behaviors: margin-based losses couple the change in the preferred probability with the gradient of the dispreferred one",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.8317
    },
    {
      "source": "We demystify the reasons behind these problematic behaviors: margin-based losses couple the change in the preferred probability with the gradient of the dispreferred one",
      "target": "In this paper",
      "similarity": 0.817
    },
    {
      "source": "We demystify the reasons behind these problematic behaviors: margin-based losses couple the change in the preferred probability with the gradient of the dispreferred one",
      "target": "O6znYvxC1U",
      "similarity": 0.8091
    },
    {
      "source": "We demystify the reasons behind these problematic behaviors: margin-based losses couple the change in the preferred probability with the gradient of the dispreferred one",
      "target": "oCUYc7BzXQ",
      "similarity": 0.8069
    },
    {
      "source": "Formally",
      "target": "behavior across compute scale? We find that small- and large-scale language",
      "similarity": 0.7903
    },
    {
      "source": "Formally",
      "target": "kuYxecnlv2",
      "similarity": 0.7901
    },
    {
      "source": "Formally",
      "target": "sb1HgVDLjN",
      "similarity": 0.7805
    },
    {
      "source": "Formally",
      "target": "zY37C8d6bS",
      "similarity": 0.7795
    },
    {
      "source": "Formally",
      "target": "Based on the training dynamics",
      "similarity": 0.7724
    },
    {
      "source": "lOi6FtIwR8",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8908
    },
    {
      "source": "lOi6FtIwR8",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8858
    },
    {
      "source": "lOi6FtIwR8",
      "target": "Building on the SpiderBoost algorithm framework",
      "similarity": 0.878
    },
    {
      "source": "lOi6FtIwR8",
      "target": "SOTA LLMs",
      "similarity": 0.8741
    },
    {
      "source": "lOi6FtIwR8",
      "target": "xvhV3LvYTc",
      "similarity": 0.8705
    },
    {
      "source": "both computationally intensive and lacking in controllability and transparency",
      "target": "VoayJihXra",
      "similarity": 0.863
    },
    {
      "source": "both computationally intensive and lacking in controllability and transparency",
      "target": "relying on backward propagation",
      "similarity": 0.8595
    },
    {
      "source": "both computationally intensive and lacking in controllability and transparency",
      "target": "9qS3HzSDNv",
      "similarity": 0.8553
    },
    {
      "source": "both computationally intensive and lacking in controllability and transparency",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8446
    },
    {
      "source": "both computationally intensive and lacking in controllability and transparency",
      "target": "K7xpl3LZQp",
      "similarity": 0.8438
    },
    {
      "source": "Pj4Aid3XqL",
      "target": "uHLgDEgiS5",
      "similarity": 0.8832
    },
    {
      "source": "Pj4Aid3XqL",
      "target": "ogXkmugNZw",
      "similarity": 0.8827
    },
    {
      "source": "Pj4Aid3XqL",
      "target": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "similarity": 0.8743
    },
    {
      "source": "Pj4Aid3XqL",
      "target": "20qZK2T7fa",
      "similarity": 0.8738
    },
    {
      "source": "Pj4Aid3XqL",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8652
    },
    {
      "source": "While adding images during a second training phase effectively unlocks this capability",
      "target": "HSi4VetQLj",
      "similarity": 0.8174
    },
    {
      "source": "While adding images during a second training phase effectively unlocks this capability",
      "target": "jJXZvPe5z0",
      "similarity": 0.8094
    },
    {
      "source": "While adding images during a second training phase effectively unlocks this capability",
      "target": "VELhv9BBfn",
      "similarity": 0.7905
    },
    {
      "source": "While adding images during a second training phase effectively unlocks this capability",
      "target": "pB1XSj2y4X",
      "similarity": 0.7886
    },
    {
      "source": "While adding images during a second training phase effectively unlocks this capability",
      "target": "KSLkFYHlYg",
      "similarity": 0.7881
    },
    {
      "source": "To investigate this",
      "target": "bAFVlpFQvT",
      "similarity": 0.8093
    },
    {
      "source": "To investigate this",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8087
    },
    {
      "source": "To investigate this",
      "target": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "similarity": 0.8045
    },
    {
      "source": "To investigate this",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.803
    },
    {
      "source": "To investigate this",
      "target": "WwwJfkGq0G",
      "similarity": 0.8002
    },
    {
      "source": "We then fine-tune these models and evaluate their downstream performance on a suite of vision-language and text-only tasks.",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.9012
    },
    {
      "source": "We then fine-tune these models and evaluate their downstream performance on a suite of vision-language and text-only tasks.",
      "target": "8pusxkLEQO",
      "similarity": 0.8584
    },
    {
      "source": "We then fine-tune these models and evaluate their downstream performance on a suite of vision-language and text-only tasks.",
      "target": "Moreover",
      "similarity": 0.8542
    },
    {
      "source": "We then fine-tune these models and evaluate their downstream performance on a suite of vision-language and text-only tasks.",
      "target": "nIEjY4a2Lf",
      "similarity": 0.8378
    },
    {
      "source": "We then fine-tune these models and evaluate their downstream performance on a suite of vision-language and text-only tasks.",
      "target": "However",
      "similarity": 0.813
    },
    {
      "source": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "target": "98d7DLMGdt",
      "similarity": 0.8617
    },
    {
      "source": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8459
    },
    {
      "source": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "target": "nfKfAzkiez",
      "similarity": 0.8446
    },
    {
      "source": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "target": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "similarity": 0.8432
    },
    {
      "source": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "target": "P6IVIoGRRg",
      "similarity": 0.8395
    },
    {
      "source": "On an average of 6 diverse tasks",
      "target": "on *HumanEval",
      "similarity": 0.8409
    },
    {
      "source": "On an average of 6 diverse tasks",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.828
    },
    {
      "source": "On an average of 6 diverse tasks",
      "target": "When fine-tuned on this task",
      "similarity": 0.8244
    },
    {
      "source": "On an average of 6 diverse tasks",
      "target": "*progress*: a change in the likelihood of producing a correct response in the future",
      "similarity": 0.8222
    },
    {
      "source": "On an average of 6 diverse tasks",
      "target": "PwxYoMvmvy",
      "similarity": 0.8173
    },
    {
      "source": "VOAMTA8jKu",
      "target": "BpyHIrpUOL",
      "similarity": 0.8315
    },
    {
      "source": "VOAMTA8jKu",
      "target": "sIE2rI3ZPs",
      "similarity": 0.8234
    },
    {
      "source": "VOAMTA8jKu",
      "target": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "similarity": 0.8225
    },
    {
      "source": "VOAMTA8jKu",
      "target": "5x88lQ2MsH",
      "similarity": 0.8216
    },
    {
      "source": "VOAMTA8jKu",
      "target": "To this end",
      "similarity": 0.8192
    },
    {
      "source": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.886
    },
    {
      "source": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "target": "To address this limitation",
      "similarity": 0.8803
    },
    {
      "source": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "target": "enhance reliability. This study investigates the efficacy of such approaches",
      "similarity": 0.8767
    },
    {
      "source": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8722
    },
    {
      "source": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8642
    },
    {
      "source": "To fill this gap",
      "target": "To address this",
      "similarity": 0.8701
    },
    {
      "source": "To fill this gap",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8602
    },
    {
      "source": "To fill this gap",
      "target": "PY56Wur7S0",
      "similarity": 0.8394
    },
    {
      "source": "To fill this gap",
      "target": "4ytRL3HJrq",
      "similarity": 0.8365
    },
    {
      "source": "To fill this gap",
      "target": "uncertainty estimation and improved interpretability.\"",
      "similarity": 0.8355
    },
    {
      "source": "**DynaMath** allows us to evaluate the generalization ability of VLMs",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8388
    },
    {
      "source": "**DynaMath** allows us to evaluate the generalization ability of VLMs",
      "target": "In particular",
      "similarity": 0.7963
    },
    {
      "source": "**DynaMath** allows us to evaluate the generalization ability of VLMs",
      "target": "To benchmark current systems on visually rich document retrieval",
      "similarity": 0.7845
    },
    {
      "source": "**DynaMath** allows us to evaluate the generalization ability of VLMs",
      "target": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "similarity": 0.7845
    },
    {
      "source": "**DynaMath** allows us to evaluate the generalization ability of VLMs",
      "target": "Moreover",
      "similarity": 0.784
    },
    {
      "source": "Mv3GAYJGcW",
      "target": "HqjRlT65WX",
      "similarity": 0.8462
    },
    {
      "source": "Mv3GAYJGcW",
      "target": "zY37C8d6bS",
      "similarity": 0.8409
    },
    {
      "source": "Mv3GAYJGcW",
      "target": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "similarity": 0.8332
    },
    {
      "source": "Mv3GAYJGcW",
      "target": "We then propose deep Fourier features",
      "similarity": 0.831
    },
    {
      "source": "Mv3GAYJGcW",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8281
    },
    {
      "source": "uAtDga3q0r",
      "target": "JbRM5QKRDd",
      "similarity": 0.8138
    },
    {
      "source": "uAtDga3q0r",
      "target": "Aly68Y5Es0",
      "similarity": 0.8115
    },
    {
      "source": "uAtDga3q0r",
      "target": "tees for rank collapse prevention. We present",
      "similarity": 0.8064
    },
    {
      "source": "uAtDga3q0r",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.7985
    },
    {
      "source": "uAtDga3q0r",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.796
    },
    {
      "source": "jCDF7G3LpF",
      "target": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "similarity": 0.8479
    },
    {
      "source": "jCDF7G3LpF",
      "target": "BL4WBIfyrz",
      "similarity": 0.8475
    },
    {
      "source": "jCDF7G3LpF",
      "target": "HN8V0flwJF",
      "similarity": 0.8449
    },
    {
      "source": "jCDF7G3LpF",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8432
    },
    {
      "source": "jCDF7G3LpF",
      "target": "pCj2sLNoJq",
      "similarity": 0.8424
    },
    {
      "source": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8638
    },
    {
      "source": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "target": "nzjSvVZBIp",
      "similarity": 0.8586
    },
    {
      "source": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8528
    },
    {
      "source": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "target": "To remedy this problem",
      "similarity": 0.8524
    },
    {
      "source": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "target": "On various mathematical benchmarks",
      "similarity": 0.8492
    },
    {
      "source": "TrKRpaOk8y",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8629
    },
    {
      "source": "TrKRpaOk8y",
      "target": "1R5BcYS8EC",
      "similarity": 0.854
    },
    {
      "source": "TrKRpaOk8y",
      "target": "SRpq5OBpED",
      "similarity": 0.8539
    },
    {
      "source": "TrKRpaOk8y",
      "target": "improving model efficacy",
      "similarity": 0.851
    },
    {
      "source": "TrKRpaOk8y",
      "target": "In this setting",
      "similarity": 0.8508
    },
    {
      "source": "To address this",
      "target": "Experimentally",
      "similarity": 0.8652
    },
    {
      "source": "To address this",
      "target": "remains a largely unexplored domain.",
      "similarity": 0.8541
    },
    {
      "source": "To address this",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8523
    },
    {
      "source": "To address this",
      "target": "P4XmKjXTrM",
      "similarity": 0.8357
    },
    {
      "source": "To address this",
      "target": "AoIKgHu9Si",
      "similarity": 0.8316
    },
    {
      "source": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "target": "4anfpHj0wf",
      "similarity": 0.8763
    },
    {
      "source": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "target": "ERv8ptegFi",
      "similarity": 0.8491
    },
    {
      "source": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "target": "Specifically",
      "similarity": 0.8402
    },
    {
      "source": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8364
    },
    {
      "source": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "target": "For the diversity",
      "similarity": 0.8332
    },
    {
      "source": "This leads to our proposed LongGen",
      "target": "OFukl9Qg8P",
      "similarity": 0.8717
    },
    {
      "source": "This leads to our proposed LongGen",
      "target": "In particular",
      "similarity": 0.8688
    },
    {
      "source": "This leads to our proposed LongGen",
      "target": "Building on these insights",
      "similarity": 0.8631
    },
    {
      "source": "This leads to our proposed LongGen",
      "target": "zXCnIyX9MG",
      "similarity": 0.8557
    },
    {
      "source": "This leads to our proposed LongGen",
      "target": "PgXpOOqtyd",
      "similarity": 0.8455
    },
    {
      "source": "LongGen builds on three key insights:",
      "target": "riieAeQBJm",
      "similarity": 0.9247
    },
    {
      "source": "LongGen builds on three key insights:",
      "target": "kwCHcaeHrf",
      "similarity": 0.9176
    },
    {
      "source": "LongGen builds on three key insights:",
      "target": "models. However",
      "similarity": 0.9044
    },
    {
      "source": "LongGen builds on three key insights:",
      "target": "BL4WBIfyrz",
      "similarity": 0.8962
    },
    {
      "source": "LongGen builds on three key insights:",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8867
    },
    {
      "source": "(1) Sparse attention patterns",
      "target": "YH4M1Tbxfz",
      "similarity": 0.843
    },
    {
      "source": "(1) Sparse attention patterns",
      "target": "BPAZ6yW3K7",
      "similarity": 0.8305
    },
    {
      "source": "(1) Sparse attention patterns",
      "target": "HVtu26XDAA",
      "similarity": 0.8286
    },
    {
      "source": "(1) Sparse attention patterns",
      "target": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "similarity": 0.8284
    },
    {
      "source": "(1) Sparse attention patterns",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8279
    },
    {
      "source": "(2) It is essential for the model to have direct access to all tokens.",
      "target": "kbm6tsICar",
      "similarity": 0.8527
    },
    {
      "source": "(2) It is essential for the model to have direct access to all tokens.",
      "target": "Kwo20MWWCb",
      "similarity": 0.8499
    },
    {
      "source": "(2) It is essential for the model to have direct access to all tokens.",
      "target": "Qja5s0K3VX",
      "similarity": 0.8424
    },
    {
      "source": "(2) It is essential for the model to have direct access to all tokens.",
      "target": "Furthermore",
      "similarity": 0.8422
    },
    {
      "source": "(2) It is essential for the model to have direct access to all tokens.",
      "target": "These steps result in MxNet",
      "similarity": 0.8387
    },
    {
      "source": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "target": "7EhS3YBxjY",
      "similarity": 0.8565
    },
    {
      "source": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8405
    },
    {
      "source": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.8379
    },
    {
      "source": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.8362
    },
    {
      "source": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "target": "introduce MANTRA",
      "similarity": 0.836
    },
    {
      "source": "(3) Lightweight training on 5B long-context data is sufficient to extend the hybrid model's context length from 4K to 128K.",
      "target": "models. However",
      "similarity": 0.8959
    },
    {
      "source": "(3) Lightweight training on 5B long-context data is sufficient to extend the hybrid model's context length from 4K to 128K.",
      "target": "3E8YNv1HjU",
      "similarity": 0.8695
    },
    {
      "source": "(3) Lightweight training on 5B long-context data is sufficient to extend the hybrid model's context length from 4K to 128K.",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8573
    },
    {
      "source": "(3) Lightweight training on 5B long-context data is sufficient to extend the hybrid model's context length from 4K to 128K.",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.852
    },
    {
      "source": "(3) Lightweight training on 5B long-context data is sufficient to extend the hybrid model's context length from 4K to 128K.",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8502
    },
    {
      "source": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "target": "q2Lnyegkr8",
      "similarity": 0.8029
    },
    {
      "source": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "target": "TuOTSAiHDn",
      "similarity": 0.8024
    },
    {
      "source": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "target": "However",
      "similarity": 0.8009
    },
    {
      "source": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "target": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "similarity": 0.798
    },
    {
      "source": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "target": "For example",
      "similarity": 0.7974
    },
    {
      "source": "During training with 128K-long contexts",
      "target": "NfCEVihkdC",
      "similarity": 0.8639
    },
    {
      "source": "During training with 128K-long contexts",
      "target": "world perspective. To address this",
      "similarity": 0.8632
    },
    {
      "source": "During training with 128K-long contexts",
      "target": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "similarity": 0.8543
    },
    {
      "source": "During training with 128K-long contexts",
      "target": "2vHIHrJAcI",
      "similarity": 0.8503
    },
    {
      "source": "During training with 128K-long contexts",
      "target": "We evaluated our method on **more than 160 scenes** from the Replica",
      "similarity": 0.8024
    },
    {
      "source": "During inference",
      "target": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "similarity": 0.8245
    },
    {
      "source": "During inference",
      "target": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "similarity": 0.82
    },
    {
      "source": "During inference",
      "target": "k2uUeLCrQq",
      "similarity": 0.8164
    },
    {
      "source": "During inference",
      "target": "such data.",
      "similarity": 0.8145
    },
    {
      "source": "During inference",
      "target": "We propose several designs to address these issues.",
      "similarity": 0.8137
    },
    {
      "source": "Compared to baselines that apply KV-cache reduction techniques to full-attention long-context LLMs",
      "target": "In this paper",
      "similarity": 0.8396
    },
    {
      "source": "Compared to baselines that apply KV-cache reduction techniques to full-attention long-context LLMs",
      "target": "SOWZ59UyNc",
      "similarity": 0.8338
    },
    {
      "source": "Compared to baselines that apply KV-cache reduction techniques to full-attention long-context LLMs",
      "target": "HMrcv7Q4Ub",
      "similarity": 0.8239
    },
    {
      "source": "Compared to baselines that apply KV-cache reduction techniques to full-attention long-context LLMs",
      "target": "ohJxgRLlLt",
      "similarity": 0.8018
    },
    {
      "source": "Compared to baselines that apply KV-cache reduction techniques to full-attention long-context LLMs",
      "target": "MF7ljU8xcf",
      "similarity": 0.8012
    },
    {
      "source": "etif9j1CnG",
      "target": "and (3) *Frame Information Disparity*.",
      "similarity": 0.8437
    },
    {
      "source": "etif9j1CnG",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8305
    },
    {
      "source": "etif9j1CnG",
      "target": "NJxCpMt0sf",
      "similarity": 0.8291
    },
    {
      "source": "etif9j1CnG",
      "target": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "similarity": 0.826
    },
    {
      "source": "etif9j1CnG",
      "target": "To this end",
      "similarity": 0.8243
    },
    {
      "source": "AoIKgHu9Si",
      "target": "gsShHPxkUW",
      "similarity": 0.8532
    },
    {
      "source": "AoIKgHu9Si",
      "target": "vVxeFSR4fU",
      "similarity": 0.8484
    },
    {
      "source": "AoIKgHu9Si",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.843
    },
    {
      "source": "AoIKgHu9Si",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8413
    },
    {
      "source": "AoIKgHu9Si",
      "target": "aTYexOYlLb",
      "similarity": 0.8378
    },
    {
      "source": "k3y0oyK7sn",
      "target": "oDbiL9CLoS",
      "similarity": 0.863
    },
    {
      "source": "k3y0oyK7sn",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8529
    },
    {
      "source": "k3y0oyK7sn",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8364
    },
    {
      "source": "k3y0oyK7sn",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8342
    },
    {
      "source": "k3y0oyK7sn",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8321
    },
    {
      "source": "vyflgpwfJW",
      "target": "the Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics.",
      "similarity": 0.8114
    },
    {
      "source": "vyflgpwfJW",
      "target": "JWtrk7mprJ",
      "similarity": 0.8051
    },
    {
      "source": "vyflgpwfJW",
      "target": "9vTAkJ9Tik",
      "similarity": 0.797
    },
    {
      "source": "vyflgpwfJW",
      "target": "PY56Wur7S0",
      "similarity": 0.7943
    },
    {
      "source": "vyflgpwfJW",
      "target": "Next",
      "similarity": 0.7922
    },
    {
      "source": "XgH1wfHSX8",
      "target": "Real-world causal structures",
      "similarity": 0.8065
    },
    {
      "source": "XgH1wfHSX8",
      "target": "OhUoTMxFIH",
      "similarity": 0.7727
    },
    {
      "source": "XgH1wfHSX8",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.7707
    },
    {
      "source": "XgH1wfHSX8",
      "target": "With manifold-to-manifold hidden layers and an arbitrary last layer",
      "similarity": 0.7653
    },
    {
      "source": "XgH1wfHSX8",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.7633
    },
    {
      "source": "GQ1Tc3vHbt",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8292
    },
    {
      "source": "GQ1Tc3vHbt",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8209
    },
    {
      "source": "GQ1Tc3vHbt",
      "target": "6HcnC3pPkp",
      "similarity": 0.8156
    },
    {
      "source": "GQ1Tc3vHbt",
      "target": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "similarity": 0.8155
    },
    {
      "source": "GQ1Tc3vHbt",
      "target": "kX8h23UG6v",
      "similarity": 0.8141
    },
    {
      "source": "class that generalizes Lipschitz-smooth functions and has gained attention for",
      "target": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "similarity": 0.8524
    },
    {
      "source": "class that generalizes Lipschitz-smooth functions and has gained attention for",
      "target": "3bcN6xlO6f",
      "similarity": 0.8502
    },
    {
      "source": "class that generalizes Lipschitz-smooth functions and has gained attention for",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8485
    },
    {
      "source": "class that generalizes Lipschitz-smooth functions and has gained attention for",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8447
    },
    {
      "source": "class that generalizes Lipschitz-smooth functions and has gained attention for",
      "target": "E4LAVLXAHW",
      "similarity": 0.8441
    },
    {
      "source": "its relevance in machine learning.",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.898
    },
    {
      "source": "its relevance in machine learning.",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8684
    },
    {
      "source": "its relevance in machine learning.",
      "target": "h7GAgbLSmC",
      "similarity": 0.8647
    },
    {
      "source": "its relevance in machine learning.",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8581
    },
    {
      "source": "its relevance in machine learning.",
      "target": "F57HPKZ6KD",
      "similarity": 0.8479
    },
    {
      "source": "We provide new insights into the structure of this function class and develop",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.832
    },
    {
      "source": "We provide new insights into the structure of this function class and develop",
      "target": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "similarity": 0.8312
    },
    {
      "source": "We provide new insights into the structure of this function class and develop",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8269
    },
    {
      "source": "We provide new insights into the structure of this function class and develop",
      "target": "We provide theoretical results showing that linear function approximation",
      "similarity": 0.8239
    },
    {
      "source": "We provide new insights into the structure of this function class and develop",
      "target": "g0rnZeBguq",
      "similarity": 0.8233
    },
    {
      "source": "a principled framework for analyzing optimization methods in this setting.",
      "target": "u2QdCiOgwA",
      "similarity": 0.8852
    },
    {
      "source": "a principled framework for analyzing optimization methods in this setting.",
      "target": "JYwVijuNA7",
      "similarity": 0.8785
    },
    {
      "source": "a principled framework for analyzing optimization methods in this setting.",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8755
    },
    {
      "source": "a principled framework for analyzing optimization methods in this setting.",
      "target": "254NJe9JEw",
      "similarity": 0.8727
    },
    {
      "source": "a principled framework for analyzing optimization methods in this setting.",
      "target": "1qq1QJKM5q",
      "similarity": 0.8727
    },
    {
      "source": "While our convergence rate estimates recover existing results for minimizing",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8869
    },
    {
      "source": "While our convergence rate estimates recover existing results for minimizing",
      "target": "fine-tuning of a shallow fully-connected network following the representation.",
      "similarity": 0.8811
    },
    {
      "source": "While our convergence rate estimates recover existing results for minimizing",
      "target": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "similarity": 0.8522
    },
    {
      "source": "While our convergence rate estimates recover existing results for minimizing",
      "target": "regret learning",
      "similarity": 0.8483
    },
    {
      "source": "While our convergence rate estimates recover existing results for minimizing",
      "target": "To address this",
      "similarity": 0.8289
    },
    {
      "source": "the gradient norm in nonconvex problems",
      "target": "xKDZAW0He3",
      "similarity": 0.8551
    },
    {
      "source": "the gradient norm in nonconvex problems",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.8489
    },
    {
      "source": "the gradient norm in nonconvex problems",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8375
    },
    {
      "source": "the gradient norm in nonconvex problems",
      "target": "x1An5a3U9I",
      "similarity": 0.8236
    },
    {
      "source": "the gradient norm in nonconvex problems",
      "target": "However",
      "similarity": 0.8178
    },
    {
      "source": "the best-known complexity bounds for convex objectives.",
      "target": "To this end",
      "similarity": 0.8909
    },
    {
      "source": "the best-known complexity bounds for convex objectives.",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8887
    },
    {
      "source": "the best-known complexity bounds for convex objectives.",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8738
    },
    {
      "source": "the best-known complexity bounds for convex objectives.",
      "target": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "similarity": 0.8706
    },
    {
      "source": "the best-known complexity bounds for convex objectives.",
      "target": "7lUdo8Vuqa",
      "similarity": 0.8691
    },
    {
      "source": "Moreover",
      "target": "JAMxRSXLFz",
      "similarity": 0.8403
    },
    {
      "source": "Moreover",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8338
    },
    {
      "source": "Moreover",
      "target": "Subsequently",
      "similarity": 0.8315
    },
    {
      "source": "Moreover",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8225
    },
    {
      "source": "Moreover",
      "target": "7WaRh4gCXp",
      "similarity": 0.8205
    },
    {
      "source": "normalized gradient method achieve nearly the same complexity guarantees as",
      "target": "8sSqNntaMr",
      "similarity": 0.8424
    },
    {
      "source": "normalized gradient method achieve nearly the same complexity guarantees as",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8402
    },
    {
      "source": "normalized gradient method achieve nearly the same complexity guarantees as",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8366
    },
    {
      "source": "normalized gradient method achieve nearly the same complexity guarantees as",
      "target": "HqjRlT65WX",
      "similarity": 0.8326
    },
    {
      "source": "normalized gradient method achieve nearly the same complexity guarantees as",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.826
    },
    {
      "source": "methods that rely on explicit knowledge of $(L_0",
      "target": "instructions",
      "similarity": 0.9351
    },
    {
      "source": "methods that rely on explicit knowledge of $(L_0",
      "target": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "similarity": 0.9082
    },
    {
      "source": "methods that rely on explicit knowledge of $(L_0",
      "target": "AcVpLS86RT",
      "similarity": 0.8966
    },
    {
      "source": "methods that rely on explicit knowledge of $(L_0",
      "target": "fs2Z2z3GRx",
      "similarity": 0.8808
    },
    {
      "source": "methods that rely on explicit knowledge of $(L_0",
      "target": "E4LAVLXAHW",
      "similarity": 0.874
    },
    {
      "source": "Finally",
      "target": "gFvRRCnQvX",
      "similarity": 0.8701
    },
    {
      "source": "Finally",
      "target": "4JK2XMGUc8",
      "similarity": 0.8695
    },
    {
      "source": "Finally",
      "target": "increased their demand. However",
      "similarity": 0.8539
    },
    {
      "source": "Finally",
      "target": "44cMlQSreK",
      "similarity": 0.8504
    },
    {
      "source": "Finally",
      "target": "7HEMpBTb3R",
      "similarity": 0.8503
    },
    {
      "source": "method can be applied to $(L_0",
      "target": "To overcome these challenges",
      "similarity": 0.7869
    },
    {
      "source": "method can be applied to $(L_0",
      "target": "04qx93Viwj",
      "similarity": 0.7867
    },
    {
      "source": "method can be applied to $(L_0",
      "target": "KfeRfxTemB",
      "similarity": 0.7843
    },
    {
      "source": "method can be applied to $(L_0",
      "target": "jY5oml9fe9",
      "similarity": 0.7788
    },
    {
      "source": "method can be applied to $(L_0",
      "target": "txoJvjfI9w",
      "similarity": 0.7782
    },
    {
      "source": "previous results.\"",
      "target": "To this end",
      "similarity": 0.9097
    },
    {
      "source": "previous results.\"",
      "target": "However",
      "similarity": 0.8791
    },
    {
      "source": "previous results.\"",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8729
    },
    {
      "source": "previous results.\"",
      "target": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "similarity": 0.8692
    },
    {
      "source": "previous results.\"",
      "target": "bmbRCRiNDu",
      "similarity": 0.8686
    },
    {
      "source": "MF7ljU8xcf",
      "target": "rWui9vLhOc",
      "similarity": 0.8184
    },
    {
      "source": "MF7ljU8xcf",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8076
    },
    {
      "source": "MF7ljU8xcf",
      "target": "To overcome such limitations",
      "similarity": 0.807
    },
    {
      "source": "MF7ljU8xcf",
      "target": "YwzxpZW3p7",
      "similarity": 0.8037
    },
    {
      "source": "MF7ljU8xcf",
      "target": "S85PP4xjFD",
      "similarity": 0.8008
    },
    {
      "source": "f3QR9TEERH",
      "target": "VmJdqhuTCh",
      "similarity": 0.8455
    },
    {
      "source": "f3QR9TEERH",
      "target": "VoayJihXra",
      "similarity": 0.8438
    },
    {
      "source": "f3QR9TEERH",
      "target": "NWb128pSCb",
      "similarity": 0.8428
    },
    {
      "source": "f3QR9TEERH",
      "target": "wide dissemination",
      "similarity": 0.842
    },
    {
      "source": "f3QR9TEERH",
      "target": "tePFpDgyqg",
      "similarity": 0.8404
    },
    {
      "source": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.8387
    },
    {
      "source": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "target": "By contrasting the predictions of these two models",
      "similarity": 0.8273
    },
    {
      "source": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "target": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "similarity": 0.825
    },
    {
      "source": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "target": "FCBbh0HCrF",
      "similarity": 0.8197
    },
    {
      "source": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "target": "In this paper",
      "similarity": 0.8194
    },
    {
      "source": "Thus",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8309
    },
    {
      "source": "Thus",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8288
    },
    {
      "source": "Thus",
      "target": "IuU0wcO0mo",
      "similarity": 0.825
    },
    {
      "source": "Thus",
      "target": "TljGdvzFq2",
      "similarity": 0.818
    },
    {
      "source": "Thus",
      "target": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "similarity": 0.8167
    },
    {
      "source": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "target": "KlN00vQEY2",
      "similarity": 0.8726
    },
    {
      "source": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8559
    },
    {
      "source": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8471
    },
    {
      "source": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "target": "ISqx8giekS",
      "similarity": 0.847
    },
    {
      "source": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "target": "dRz3cizftU",
      "similarity": 0.8467
    },
    {
      "source": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "target": "riieAeQBJm",
      "similarity": 0.8936
    },
    {
      "source": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "target": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "similarity": 0.8813
    },
    {
      "source": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "target": "HN8V0flwJF",
      "similarity": 0.8737
    },
    {
      "source": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "target": "78tc3EiUrN",
      "similarity": 0.8723
    },
    {
      "source": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "target": "yIlyHJdYV3",
      "similarity": 0.8643
    },
    {
      "source": "We empirically show that compared to the state-of-the-art curriculum learning approaches and their naively modified safe versions",
      "target": "Prior methods improve accuracy using external semantic supervision",
      "similarity": 0.8449
    },
    {
      "source": "We empirically show that compared to the state-of-the-art curriculum learning approaches and their naively modified safe versions",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8414
    },
    {
      "source": "We empirically show that compared to the state-of-the-art curriculum learning approaches and their naively modified safe versions",
      "target": "7bAjVh3CG3",
      "similarity": 0.8146
    },
    {
      "source": "We empirically show that compared to the state-of-the-art curriculum learning approaches and their naively modified safe versions",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8095
    },
    {
      "source": "We empirically show that compared to the state-of-the-art curriculum learning approaches and their naively modified safe versions",
      "target": "In this work",
      "similarity": 0.8094
    },
    {
      "source": "10JOlFIPjt",
      "target": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "similarity": 0.8316
    },
    {
      "source": "10JOlFIPjt",
      "target": "- In continuous image-based control (e.g.",
      "similarity": 0.8311
    },
    {
      "source": "10JOlFIPjt",
      "target": "However",
      "similarity": 0.8236
    },
    {
      "source": "10JOlFIPjt",
      "target": "In this paper",
      "similarity": 0.8224
    },
    {
      "source": "10JOlFIPjt",
      "target": "2ea5TNVR0c",
      "similarity": 0.8156
    },
    {
      "source": "Q7EjHroO1w",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8295
    },
    {
      "source": "Q7EjHroO1w",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.819
    },
    {
      "source": "Q7EjHroO1w",
      "target": "MBBRHDuiwM",
      "similarity": 0.8047
    },
    {
      "source": "Q7EjHroO1w",
      "target": "x1An5a3U9I",
      "similarity": 0.801
    },
    {
      "source": "Q7EjHroO1w",
      "target": "m8yby1JfbU",
      "similarity": 0.7989
    },
    {
      "source": "However",
      "target": "performance in cross-family generalization when trained on data augmented by",
      "similarity": 0.8251
    },
    {
      "source": "However",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8238
    },
    {
      "source": "However",
      "target": "In this work",
      "similarity": 0.818
    },
    {
      "source": "However",
      "target": "space for $p > 1$",
      "similarity": 0.8167
    },
    {
      "source": "However",
      "target": "To fill this gap",
      "similarity": 0.8148
    },
    {
      "source": "We propose Guided Strategy Discovery (GSD)",
      "target": "FBhKUXK7od",
      "similarity": 0.8543
    },
    {
      "source": "We propose Guided Strategy Discovery (GSD)",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8418
    },
    {
      "source": "We propose Guided Strategy Discovery (GSD)",
      "target": "gFvRRCnQvX",
      "similarity": 0.8261
    },
    {
      "source": "We propose Guided Strategy Discovery (GSD)",
      "target": "gkUyYcY1W9",
      "similarity": 0.8259
    },
    {
      "source": "We propose Guided Strategy Discovery (GSD)",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.824
    },
    {
      "source": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "target": "HqjRlT65WX",
      "similarity": 0.8685
    },
    {
      "source": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8597
    },
    {
      "source": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "target": "S1Bv3068Xt",
      "similarity": 0.8587
    },
    {
      "source": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "target": "OuLgaHEmzi",
      "similarity": 0.8562
    },
    {
      "source": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8556
    },
    {
      "source": "Finally",
      "target": "90DC0IvlSs",
      "similarity": 0.7804
    },
    {
      "source": "Finally",
      "target": "We propose RAMEN",
      "similarity": 0.7788
    },
    {
      "source": "Finally",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.7706
    },
    {
      "source": "Finally",
      "target": "Fty0wTcemV",
      "similarity": 0.7662
    },
    {
      "source": "Finally",
      "target": "6F6qwdycgJ",
      "similarity": 0.7619
    },
    {
      "source": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "target": "Second",
      "similarity": 0.856
    },
    {
      "source": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.849
    },
    {
      "source": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "target": "gfI9v7AbFg",
      "similarity": 0.8479
    },
    {
      "source": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "target": "Other methods have focused on the low-budget regime",
      "similarity": 0.8427
    },
    {
      "source": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8373
    },
    {
      "source": "hxUMQ4fic3",
      "target": "Yet",
      "similarity": 0.8802
    },
    {
      "source": "hxUMQ4fic3",
      "target": "To this end",
      "similarity": 0.8755
    },
    {
      "source": "hxUMQ4fic3",
      "target": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "similarity": 0.8754
    },
    {
      "source": "hxUMQ4fic3",
      "target": "In this paper",
      "similarity": 0.8681
    },
    {
      "source": "hxUMQ4fic3",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8676
    },
    {
      "source": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "target": "AWg2tkbydO",
      "similarity": 0.8769
    },
    {
      "source": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "target": "4JK2XMGUc8",
      "similarity": 0.8729
    },
    {
      "source": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "target": "To address these challenges",
      "similarity": 0.8617
    },
    {
      "source": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8607
    },
    {
      "source": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8597
    },
    {
      "source": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "target": "Neb17mimVH",
      "similarity": 0.8756
    },
    {
      "source": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8697
    },
    {
      "source": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "target": "tDIL7UXmSS",
      "similarity": 0.8548
    },
    {
      "source": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "target": "We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present",
      "similarity": 0.8438
    },
    {
      "source": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "target": "In this paper",
      "similarity": 0.8436
    },
    {
      "source": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8579
    },
    {
      "source": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "target": "m73tETvFkX",
      "similarity": 0.8575
    },
    {
      "source": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8346
    },
    {
      "source": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.8344
    },
    {
      "source": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8334
    },
    {
      "source": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "target": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "similarity": 0.9023
    },
    {
      "source": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "target": "JSB171dSUU",
      "similarity": 0.8694
    },
    {
      "source": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8626
    },
    {
      "source": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8552
    },
    {
      "source": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "target": "pRCOZllZdT",
      "similarity": 0.8535
    },
    {
      "source": "In parallel",
      "target": "NfCEVihkdC",
      "similarity": 0.8416
    },
    {
      "source": "In parallel",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8385
    },
    {
      "source": "In parallel",
      "target": "d8hYXbxX71",
      "similarity": 0.836
    },
    {
      "source": "In parallel",
      "target": "Despite its simplicity",
      "similarity": 0.8352
    },
    {
      "source": "In parallel",
      "target": "vjel3nWP2a",
      "similarity": 0.8334
    },
    {
      "source": "To address the so-called model exploitation problem in offline model-based RL",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8111
    },
    {
      "source": "To address the so-called model exploitation problem in offline model-based RL",
      "target": "cPozlf9OaF",
      "similarity": 0.7975
    },
    {
      "source": "To address the so-called model exploitation problem in offline model-based RL",
      "target": "We continue pre-training with high-rated",
      "similarity": 0.7872
    },
    {
      "source": "To address the so-called model exploitation problem in offline model-based RL",
      "target": "PUnD86UEK5",
      "similarity": 0.7862
    },
    {
      "source": "To address the so-called model exploitation problem in offline model-based RL",
      "target": "To address this",
      "similarity": 0.7811
    },
    {
      "source": "Our empirical results in D4RL and NeoRL MuJoCo benchmarks evidence that NUNO outperforms state-of-the-art methods in low-quality datasets by up to 93% while matching or surpassing their performance by up to 55% in some high-quality counterparts.\"",
      "target": "Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation",
      "similarity": 0.7874
    },
    {
      "source": "Our empirical results in D4RL and NeoRL MuJoCo benchmarks evidence that NUNO outperforms state-of-the-art methods in low-quality datasets by up to 93% while matching or surpassing their performance by up to 55% in some high-quality counterparts.\"",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.7865
    },
    {
      "source": "Our empirical results in D4RL and NeoRL MuJoCo benchmarks evidence that NUNO outperforms state-of-the-art methods in low-quality datasets by up to 93% while matching or surpassing their performance by up to 55% in some high-quality counterparts.\"",
      "target": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "similarity": 0.7768
    },
    {
      "source": "Our empirical results in D4RL and NeoRL MuJoCo benchmarks evidence that NUNO outperforms state-of-the-art methods in low-quality datasets by up to 93% while matching or surpassing their performance by up to 55% in some high-quality counterparts.\"",
      "target": "gWgaypDBs8",
      "similarity": 0.7766
    },
    {
      "source": "Our empirical results in D4RL and NeoRL MuJoCo benchmarks evidence that NUNO outperforms state-of-the-art methods in low-quality datasets by up to 93% while matching or surpassing their performance by up to 55% in some high-quality counterparts.\"",
      "target": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "similarity": 0.7761
    },
    {
      "source": "NN6QHwgRrQ",
      "target": "Second",
      "similarity": 0.8691
    },
    {
      "source": "NN6QHwgRrQ",
      "target": "T4sMzjy7fO",
      "similarity": 0.8508
    },
    {
      "source": "NN6QHwgRrQ",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8491
    },
    {
      "source": "NN6QHwgRrQ",
      "target": "Igm9bbkzHC",
      "similarity": 0.8444
    },
    {
      "source": "NN6QHwgRrQ",
      "target": "KW8yzAOIZr",
      "similarity": 0.8442
    },
    {
      "source": "9KxnxWOBA5",
      "target": "QhxjQOMdDF",
      "similarity": 0.8556
    },
    {
      "source": "9KxnxWOBA5",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8495
    },
    {
      "source": "9KxnxWOBA5",
      "target": "EqcLAU6gyU",
      "similarity": 0.8443
    },
    {
      "source": "9KxnxWOBA5",
      "target": "pDDODPtpx9",
      "similarity": 0.837
    },
    {
      "source": "9KxnxWOBA5",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.8369
    },
    {
      "source": "FtjLUHyZAO",
      "target": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "similarity": 0.9026
    },
    {
      "source": "FtjLUHyZAO",
      "target": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "similarity": 0.8763
    },
    {
      "source": "FtjLUHyZAO",
      "target": "In this paper",
      "similarity": 0.8634
    },
    {
      "source": "FtjLUHyZAO",
      "target": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "similarity": 0.8571
    },
    {
      "source": "FtjLUHyZAO",
      "target": "Fk3eod9aaD",
      "similarity": 0.8483
    },
    {
      "source": "kRBQwlkFSP",
      "target": "fs2Z2z3GRx",
      "similarity": 0.8609
    },
    {
      "source": "kRBQwlkFSP",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.8607
    },
    {
      "source": "kRBQwlkFSP",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.8584
    },
    {
      "source": "kRBQwlkFSP",
      "target": "JytL2MrlLT",
      "similarity": 0.858
    },
    {
      "source": "kRBQwlkFSP",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8576
    },
    {
      "source": "78tc3EiUrN",
      "target": "2kGKsyhtvh",
      "similarity": 0.9073
    },
    {
      "source": "78tc3EiUrN",
      "target": "hyfe5q5TD0",
      "similarity": 0.8899
    },
    {
      "source": "78tc3EiUrN",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.8767
    },
    {
      "source": "78tc3EiUrN",
      "target": "yIlyHJdYV3",
      "similarity": 0.8751
    },
    {
      "source": "78tc3EiUrN",
      "target": "To this end",
      "similarity": 0.8744
    },
    {
      "source": "mqNKiEB6pd",
      "target": "9qS3HzSDNv",
      "similarity": 0.883
    },
    {
      "source": "mqNKiEB6pd",
      "target": "VoayJihXra",
      "similarity": 0.8814
    },
    {
      "source": "mqNKiEB6pd",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8694
    },
    {
      "source": "mqNKiEB6pd",
      "target": "relying on backward propagation",
      "similarity": 0.8663
    },
    {
      "source": "mqNKiEB6pd",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8499
    },
    {
      "source": "w3iM4WLuvy",
      "target": "In this setting",
      "similarity": 0.854
    },
    {
      "source": "w3iM4WLuvy",
      "target": "kRBQwlkFSP",
      "similarity": 0.848
    },
    {
      "source": "w3iM4WLuvy",
      "target": "uNd289HjLi",
      "similarity": 0.8381
    },
    {
      "source": "w3iM4WLuvy",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8378
    },
    {
      "source": "w3iM4WLuvy",
      "target": "Our system",
      "similarity": 0.8371
    },
    {
      "source": "oDbiL9CLoS",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8739
    },
    {
      "source": "oDbiL9CLoS",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8582
    },
    {
      "source": "oDbiL9CLoS",
      "target": "ISqx8giekS",
      "similarity": 0.8522
    },
    {
      "source": "oDbiL9CLoS",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8432
    },
    {
      "source": "oDbiL9CLoS",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.842
    },
    {
      "source": "We show that language models excel in knowledge retrieval but struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. Moreover",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8916
    },
    {
      "source": "We show that language models excel in knowledge retrieval but struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. Moreover",
      "target": "no such limitation. To understand the difference in performance",
      "similarity": 0.848
    },
    {
      "source": "We show that language models excel in knowledge retrieval but struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. Moreover",
      "target": "In contrast",
      "similarity": 0.829
    },
    {
      "source": "We show that language models excel in knowledge retrieval but struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. Moreover",
      "target": "In addition",
      "similarity": 0.8187
    },
    {
      "source": "We show that language models excel in knowledge retrieval but struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. Moreover",
      "target": "1qq1QJKM5q",
      "similarity": 0.8131
    },
    {
      "source": "Our primary contribution is a \\emph{controlled",
      "target": "tU074jg2vS",
      "similarity": 0.8571
    },
    {
      "source": "Our primary contribution is a \\emph{controlled",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8369
    },
    {
      "source": "Our primary contribution is a \\emph{controlled",
      "target": "This paper introduces WebRL",
      "similarity": 0.8337
    },
    {
      "source": "Our primary contribution is a \\emph{controlled",
      "target": "of our approaches.",
      "similarity": 0.8305
    },
    {
      "source": "Our primary contribution is a \\emph{controlled",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8283
    },
    {
      "source": "vJgJSrYPe1",
      "target": "dTkqaCKLPp",
      "similarity": 0.8486
    },
    {
      "source": "vJgJSrYPe1",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8411
    },
    {
      "source": "vJgJSrYPe1",
      "target": "Given these challenges",
      "similarity": 0.8392
    },
    {
      "source": "vJgJSrYPe1",
      "target": "Yet",
      "similarity": 0.8323
    },
    {
      "source": "vJgJSrYPe1",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.8316
    },
    {
      "source": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8568
    },
    {
      "source": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "target": "UYcUpiULmT",
      "similarity": 0.852
    },
    {
      "source": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8519
    },
    {
      "source": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "target": "hmDt068MoZ",
      "similarity": 0.8513
    },
    {
      "source": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "target": "SuH5SdOXpe",
      "similarity": 0.8491
    },
    {
      "source": "FxNNiUgtfa",
      "target": "kWRKNDU6uN",
      "similarity": 0.8655
    },
    {
      "source": "FxNNiUgtfa",
      "target": "Fk3eod9aaD",
      "similarity": 0.8448
    },
    {
      "source": "FxNNiUgtfa",
      "target": "Validated using our collected college-level circuit analysis problems",
      "similarity": 0.8332
    },
    {
      "source": "FxNNiUgtfa",
      "target": "$$",
      "similarity": 0.8209
    },
    {
      "source": "FxNNiUgtfa",
      "target": "mDKxlfraAn",
      "similarity": 0.8126
    },
    {
      "source": "More broadly",
      "target": "Traditionally",
      "similarity": 0.8613
    },
    {
      "source": "More broadly",
      "target": "7El7K1DoyX",
      "similarity": 0.8581
    },
    {
      "source": "More broadly",
      "target": "je3GZissZc",
      "similarity": 0.8572
    },
    {
      "source": "More broadly",
      "target": "In this work",
      "similarity": 0.8528
    },
    {
      "source": "More broadly",
      "target": "pDDODPtpx9",
      "similarity": 0.8508
    },
    {
      "source": "wUbum0nd9N",
      "target": "TjP1d8PP8l",
      "similarity": 0.8298
    },
    {
      "source": "wUbum0nd9N",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.8247
    },
    {
      "source": "wUbum0nd9N",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8069
    },
    {
      "source": "wUbum0nd9N",
      "target": "implementation",
      "similarity": 0.8064
    },
    {
      "source": "wUbum0nd9N",
      "target": "To guide this search",
      "similarity": 0.8058
    },
    {
      "source": "HrdVqFSn1e",
      "target": "yFGR36PLDJ",
      "similarity": 0.849
    },
    {
      "source": "HrdVqFSn1e",
      "target": "Second",
      "similarity": 0.8356
    },
    {
      "source": "HrdVqFSn1e",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8346
    },
    {
      "source": "HrdVqFSn1e",
      "target": "Together",
      "similarity": 0.8342
    },
    {
      "source": "HrdVqFSn1e",
      "target": "TbTJJNjumY",
      "similarity": 0.8324
    },
    {
      "source": "Additionally",
      "target": "bwOndfohRK",
      "similarity": 0.8076
    },
    {
      "source": "Additionally",
      "target": "8WQ7VTfPTl",
      "similarity": 0.8004
    },
    {
      "source": "Additionally",
      "target": "modeling an image caption as a \u201cbag of words\u201d. As a result",
      "similarity": 0.7915
    },
    {
      "source": "1H90Gb9rJ9",
      "target": "of natural language. However",
      "similarity": 0.8508
    },
    {
      "source": "1H90Gb9rJ9",
      "target": "SWEqzy7IQB",
      "similarity": 0.8421
    },
    {
      "source": "1H90Gb9rJ9",
      "target": "jJXZvPe5z0",
      "similarity": 0.8355
    },
    {
      "source": "1H90Gb9rJ9",
      "target": "KSLkFYHlYg",
      "similarity": 0.834
    },
    {
      "source": "1H90Gb9rJ9",
      "target": "G328D1xt4W",
      "similarity": 0.8253
    },
    {
      "source": "9juyeCqL0u",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8608
    },
    {
      "source": "9juyeCqL0u",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8264
    },
    {
      "source": "9juyeCqL0u",
      "target": "9chRqsPOGL",
      "similarity": 0.8211
    },
    {
      "source": "9juyeCqL0u",
      "target": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "similarity": 0.8146
    },
    {
      "source": "9juyeCqL0u",
      "target": "GkWA6NjePN",
      "similarity": 0.8106
    },
    {
      "source": "zpDGwcmMV4",
      "target": "HaX48yksVL",
      "similarity": 0.8605
    },
    {
      "source": "zpDGwcmMV4",
      "target": "zCZnEXF3bN",
      "similarity": 0.854
    },
    {
      "source": "zpDGwcmMV4",
      "target": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "similarity": 0.8376
    },
    {
      "source": "zpDGwcmMV4",
      "target": "this is a serious issue in practice.",
      "similarity": 0.8349
    },
    {
      "source": "zpDGwcmMV4",
      "target": "affects effectiveness in two downstream proxy model applications: data",
      "similarity": 0.8278
    },
    {
      "source": "rTCJ29pkuA",
      "target": "In this paper",
      "similarity": 0.8697
    },
    {
      "source": "rTCJ29pkuA",
      "target": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "similarity": 0.8669
    },
    {
      "source": "rTCJ29pkuA",
      "target": "Thus",
      "similarity": 0.8576
    },
    {
      "source": "rTCJ29pkuA",
      "target": "eU39PDsZtT",
      "similarity": 0.8525
    },
    {
      "source": "rTCJ29pkuA",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.8454
    },
    {
      "source": "Tn5B6Udq3E",
      "target": "il5yUQsrjC",
      "similarity": 0.8858
    },
    {
      "source": "Tn5B6Udq3E",
      "target": "RWJX5F5I9g",
      "similarity": 0.8856
    },
    {
      "source": "Tn5B6Udq3E",
      "target": "To overcome those challenges",
      "similarity": 0.8777
    },
    {
      "source": "Tn5B6Udq3E",
      "target": "pRCOZllZdT",
      "similarity": 0.8763
    },
    {
      "source": "Tn5B6Udq3E",
      "target": "In this paper",
      "similarity": 0.8733
    },
    {
      "source": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "target": "xiQNfYl33p",
      "similarity": 0.8687
    },
    {
      "source": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "target": "In preregistered experiments",
      "similarity": 0.8634
    },
    {
      "source": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8609
    },
    {
      "source": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "target": "QowsEic1sc",
      "similarity": 0.8495
    },
    {
      "source": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "target": "ed7zI29lRF",
      "similarity": 0.8491
    },
    {
      "source": "EqcLAU6gyU",
      "target": "pDDODPtpx9",
      "similarity": 0.8462
    },
    {
      "source": "EqcLAU6gyU",
      "target": "JAMxRSXLFz",
      "similarity": 0.8457
    },
    {
      "source": "EqcLAU6gyU",
      "target": "YzxMu1asQi",
      "similarity": 0.8457
    },
    {
      "source": "EqcLAU6gyU",
      "target": "ngmEcEer8a",
      "similarity": 0.8453
    },
    {
      "source": "EqcLAU6gyU",
      "target": "For example",
      "similarity": 0.8447
    },
    {
      "source": "zg3ec1TdAP",
      "target": "fuoM5YDBX4",
      "similarity": 0.8937
    },
    {
      "source": "zg3ec1TdAP",
      "target": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "similarity": 0.8748
    },
    {
      "source": "zg3ec1TdAP",
      "target": "We provide a parallelized GPU implementation of this regularizer",
      "similarity": 0.8595
    },
    {
      "source": "zg3ec1TdAP",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8538
    },
    {
      "source": "zg3ec1TdAP",
      "target": "nibeaHUEJx",
      "similarity": 0.8498
    },
    {
      "source": "NIkfix2eDQ",
      "target": "5x88lQ2MsH",
      "similarity": 0.8554
    },
    {
      "source": "NIkfix2eDQ",
      "target": "se4vjm7h4E",
      "similarity": 0.8531
    },
    {
      "source": "NIkfix2eDQ",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8489
    },
    {
      "source": "NIkfix2eDQ",
      "target": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "similarity": 0.8475
    },
    {
      "source": "NIkfix2eDQ",
      "target": "To overcome those challenges",
      "similarity": 0.8453
    },
    {
      "source": "phenomenon known as loss of plasticity.",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8783
    },
    {
      "source": "phenomenon known as loss of plasticity.",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8723
    },
    {
      "source": "phenomenon known as loss of plasticity.",
      "target": "Additionally",
      "similarity": 0.8713
    },
    {
      "source": "phenomenon known as loss of plasticity.",
      "target": "Pujt3ADZgI",
      "similarity": 0.8707
    },
    {
      "source": "phenomenon known as loss of plasticity.",
      "target": "relying on backward propagation",
      "similarity": 0.8699
    },
    {
      "source": "In this paper",
      "target": "relying on backward propagation",
      "similarity": 0.8399
    },
    {
      "source": "In this paper",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8333
    },
    {
      "source": "In this paper",
      "target": "Tv36j85SqR",
      "similarity": 0.8275
    },
    {
      "source": "In this paper",
      "target": "In particular",
      "similarity": 0.8262
    },
    {
      "source": "In this paper",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8236
    },
    {
      "source": "We provide theoretical results showing that linear function approximation",
      "target": "In preregistered experiments",
      "similarity": 0.8772
    },
    {
      "source": "We provide theoretical results showing that linear function approximation",
      "target": "xiQNfYl33p",
      "similarity": 0.8689
    },
    {
      "source": "We provide theoretical results showing that linear function approximation",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8632
    },
    {
      "source": "We provide theoretical results showing that linear function approximation",
      "target": "QowsEic1sc",
      "similarity": 0.8534
    },
    {
      "source": "We provide theoretical results showing that linear function approximation",
      "target": "All experimental resources",
      "similarity": 0.8454
    },
    {
      "source": "We then propose deep Fourier features",
      "target": "zY37C8d6bS",
      "similarity": 0.876
    },
    {
      "source": "We then propose deep Fourier features",
      "target": "HqjRlT65WX",
      "similarity": 0.8718
    },
    {
      "source": "We then propose deep Fourier features",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8468
    },
    {
      "source": "We then propose deep Fourier features",
      "target": "eHehzSDUFp",
      "similarity": 0.8419
    },
    {
      "source": "We then propose deep Fourier features",
      "target": "than existing search techniques",
      "similarity": 0.8386
    },
    {
      "source": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8527
    },
    {
      "source": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "target": "uREg3OHjLL",
      "similarity": 0.8446
    },
    {
      "source": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "target": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "similarity": 0.8423
    },
    {
      "source": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "target": "fL4qWkSmtM",
      "similarity": 0.8364
    },
    {
      "source": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8253
    },
    {
      "source": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.8327
    },
    {
      "source": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "target": "BOQpRtI4F5",
      "similarity": 0.8249
    },
    {
      "source": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "target": "WttfQGwpES",
      "similarity": 0.8145
    },
    {
      "source": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "target": "In this paper",
      "similarity": 0.8115
    },
    {
      "source": "Our empirical results show that continual learning performance can be improved by replacing ReLU activations with deep Fourier features combined with regularization.",
      "target": "7EhS3YBxjY",
      "similarity": 0.8077
    },
    {
      "source": "These results hold for different continual learning scenarios (e.g.",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8095
    },
    {
      "source": "These results hold for different continual learning scenarios (e.g.",
      "target": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "similarity": 0.8015
    },
    {
      "source": "These results hold for different continual learning scenarios (e.g.",
      "target": "In empirical evaluation on synthetic and real-world environments",
      "similarity": 0.8005
    },
    {
      "source": "These results hold for different continual learning scenarios (e.g.",
      "target": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "similarity": 0.7959
    },
    {
      "source": "These results hold for different continual learning scenarios (e.g.",
      "target": "Xbl6t6zxZs",
      "similarity": 0.7935
    },
    {
      "source": "on all major supervised learning datasets used for continual learning research",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8301
    },
    {
      "source": "on all major supervised learning datasets used for continual learning research",
      "target": "ngmEcEer8a",
      "similarity": 0.8287
    },
    {
      "source": "on all major supervised learning datasets used for continual learning research",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8255
    },
    {
      "source": "on all major supervised learning datasets used for continual learning research",
      "target": "EQgEMAD4kv",
      "similarity": 0.8226
    },
    {
      "source": "on all major supervised learning datasets used for continual learning research",
      "target": "nCrJD7qPJN",
      "similarity": 0.8224
    },
    {
      "source": "FAfxvdv1Dy",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.908
    },
    {
      "source": "FAfxvdv1Dy",
      "target": "JytL2MrlLT",
      "similarity": 0.9011
    },
    {
      "source": "FAfxvdv1Dy",
      "target": "EzrZX9bd4G",
      "similarity": 0.8941
    },
    {
      "source": "FAfxvdv1Dy",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8801
    },
    {
      "source": "FAfxvdv1Dy",
      "target": "1NprT9Kz0d",
      "similarity": 0.8687
    },
    {
      "source": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.8843
    },
    {
      "source": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "target": "$$",
      "similarity": 0.8721
    },
    {
      "source": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8356
    },
    {
      "source": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "target": "works remains elusive. Current interpretability work can extract features from",
      "similarity": 0.835
    },
    {
      "source": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "target": "VCbqXtS5YY",
      "similarity": 0.8283
    },
    {
      "source": "zcTLpIfj9u",
      "target": "pDDODPtpx9",
      "similarity": 0.8598
    },
    {
      "source": "zcTLpIfj9u",
      "target": "Jszf4et48m",
      "similarity": 0.8595
    },
    {
      "source": "zcTLpIfj9u",
      "target": "kbeX97jExm",
      "similarity": 0.8575
    },
    {
      "source": "zcTLpIfj9u",
      "target": "E4LAVLXAHW",
      "similarity": 0.8575
    },
    {
      "source": "zcTLpIfj9u",
      "target": "rwqShzb9li",
      "similarity": 0.8567
    },
    {
      "source": "GBIUbwW9D8",
      "target": "To explore this",
      "similarity": 0.86
    },
    {
      "source": "GBIUbwW9D8",
      "target": "Inspired by these findings",
      "similarity": 0.8454
    },
    {
      "source": "GBIUbwW9D8",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8426
    },
    {
      "source": "GBIUbwW9D8",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.841
    },
    {
      "source": "GBIUbwW9D8",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8403
    },
    {
      "source": "R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection",
      "target": "Other methods have focused on the low-budget regime",
      "similarity": 0.8313
    },
    {
      "source": "R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection",
      "target": "2oKkQTyfz7",
      "similarity": 0.8312
    },
    {
      "source": "R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection",
      "target": "For the diversity",
      "similarity": 0.8186
    },
    {
      "source": "R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection",
      "target": "sLKDbuyq99",
      "similarity": 0.8157
    },
    {
      "source": "R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection",
      "target": "04qx93Viwj",
      "similarity": 0.8151
    },
    {
      "source": "fCi4o83Mfs",
      "target": "Experimental results demonstrate the method\u2019s effectiveness across various tactile sensing applications",
      "similarity": 0.8483
    },
    {
      "source": "fCi4o83Mfs",
      "target": "il5yUQsrjC",
      "similarity": 0.8397
    },
    {
      "source": "fCi4o83Mfs",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8368
    },
    {
      "source": "fCi4o83Mfs",
      "target": "jqmptcSNVG",
      "similarity": 0.8366
    },
    {
      "source": "fCi4o83Mfs",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8356
    },
    {
      "source": "However",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8468
    },
    {
      "source": "However",
      "target": "1F8xTfv6ah",
      "similarity": 0.8392
    },
    {
      "source": "However",
      "target": "Finally",
      "similarity": 0.8382
    },
    {
      "source": "However",
      "target": "nYPuSzGE3X",
      "similarity": 0.8365
    },
    {
      "source": "However",
      "target": "98d7DLMGdt",
      "similarity": 0.8364
    },
    {
      "source": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "target": "pDDODPtpx9",
      "similarity": 0.8719
    },
    {
      "source": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "target": "xsELpEPn4A",
      "similarity": 0.8646
    },
    {
      "source": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8592
    },
    {
      "source": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "target": "oYemKnlIrO",
      "similarity": 0.8532
    },
    {
      "source": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8526
    },
    {
      "source": "To systematically examine current visual temporal reasoning tasks",
      "target": "6HcnC3pPkp",
      "similarity": 0.8605
    },
    {
      "source": "To systematically examine current visual temporal reasoning tasks",
      "target": "show that the proposed strategy can enhance the performance of strong pruning",
      "similarity": 0.8598
    },
    {
      "source": "To systematically examine current visual temporal reasoning tasks",
      "target": "kX8h23UG6v",
      "similarity": 0.8571
    },
    {
      "source": "To systematically examine current visual temporal reasoning tasks",
      "target": "In this paper",
      "similarity": 0.8438
    },
    {
      "source": "To systematically examine current visual temporal reasoning tasks",
      "target": "We reassess a large number of tabular ML models and techniques on TabReD. We demonstrate that evaluation on both time-based data splits and richer feature sets leads to different methods ranking",
      "similarity": 0.8392
    },
    {
      "source": "(1) *Multi-Frame Gain*",
      "target": "ThRMTCgpvo",
      "similarity": 0.8512
    },
    {
      "source": "(1) *Multi-Frame Gain*",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8483
    },
    {
      "source": "(1) *Multi-Frame Gain*",
      "target": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "similarity": 0.8482
    },
    {
      "source": "(1) *Multi-Frame Gain*",
      "target": "data",
      "similarity": 0.8471
    },
    {
      "source": "(1) *Multi-Frame Gain*",
      "target": "wide dissemination",
      "similarity": 0.8457
    },
    {
      "source": "(2) *Frame Order Sensitivity*",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8788
    },
    {
      "source": "(2) *Frame Order Sensitivity*",
      "target": "daUQ7vmGap",
      "similarity": 0.8604
    },
    {
      "source": "(2) *Frame Order Sensitivity*",
      "target": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "similarity": 0.8547
    },
    {
      "source": "(2) *Frame Order Sensitivity*",
      "target": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "similarity": 0.843
    },
    {
      "source": "(2) *Frame Order Sensitivity*",
      "target": "nCrJD7qPJN",
      "similarity": 0.8388
    },
    {
      "source": "and (3) *Frame Information Disparity*.",
      "target": "mechanism",
      "similarity": 0.8564
    },
    {
      "source": "and (3) *Frame Information Disparity*.",
      "target": "8TBGdH3t6a",
      "similarity": 0.8405
    },
    {
      "source": "and (3) *Frame Information Disparity*.",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8353
    },
    {
      "source": "and (3) *Frame Information Disparity*.",
      "target": "Neural Network (BPB-NN)",
      "similarity": 0.834
    },
    {
      "source": "and (3) *Frame Information Disparity*.",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.8306
    },
    {
      "source": "Following these principles",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.8619
    },
    {
      "source": "Following these principles",
      "target": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "similarity": 0.853
    },
    {
      "source": "Following these principles",
      "target": "gsShHPxkUW",
      "similarity": 0.8463
    },
    {
      "source": "Following these principles",
      "target": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "similarity": 0.8378
    },
    {
      "source": "Following these principles",
      "target": "Specifically",
      "similarity": 0.8343
    },
    {
      "source": "TOMATO comprises 1",
      "target": "TuOTSAiHDn",
      "similarity": 0.774
    },
    {
      "source": "TOMATO comprises 1",
      "target": "E1m5yGMOiV",
      "similarity": 0.7728
    },
    {
      "source": "TOMATO comprises 1",
      "target": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "similarity": 0.7702
    },
    {
      "source": "TOMATO comprises 1",
      "target": "CIs9x2ZRgh",
      "similarity": 0.767
    },
    {
      "source": "TOMATO comprises 1",
      "target": "In contrast",
      "similarity": 0.7592
    },
    {
      "source": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "target": "CLIP",
      "similarity": 0.8979
    },
    {
      "source": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "target": "gWgaypDBs8",
      "similarity": 0.8931
    },
    {
      "source": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "target": "L5godAOC2z",
      "similarity": 0.8471
    },
    {
      "source": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "target": "As the size of the model and data grows",
      "similarity": 0.8436
    },
    {
      "source": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.8391
    },
    {
      "source": "Moreover",
      "target": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "similarity": 0.8697
    },
    {
      "source": "Moreover",
      "target": "kam84eEmub",
      "similarity": 0.8516
    },
    {
      "source": "Moreover",
      "target": "gLa96FlWwn",
      "similarity": 0.8432
    },
    {
      "source": "Moreover",
      "target": "j9VVzueEbG",
      "similarity": 0.8362
    },
    {
      "source": "Moreover",
      "target": "WNvvwK0tut",
      "similarity": 0.8356
    },
    {
      "source": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "target": "Mamba",
      "similarity": 0.8782
    },
    {
      "source": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "target": "In this paper",
      "similarity": 0.8643
    },
    {
      "source": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "target": "mb2ryuZ3wz",
      "similarity": 0.8496
    },
    {
      "source": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "target": "C8jXEugWkq",
      "similarity": 0.8476
    },
    {
      "source": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "target": "vVxeFSR4fU",
      "similarity": 0.8265
    },
    {
      "source": "yzloNYH3QN",
      "target": "m8yby1JfbU",
      "similarity": 0.8359
    },
    {
      "source": "yzloNYH3QN",
      "target": "To guide this search",
      "similarity": 0.8342
    },
    {
      "source": "yzloNYH3QN",
      "target": "To fill this gap",
      "similarity": 0.8209
    },
    {
      "source": "yzloNYH3QN",
      "target": "To address this",
      "similarity": 0.8194
    },
    {
      "source": "yzloNYH3QN",
      "target": "jDsmB4o5S0",
      "similarity": 0.8144
    },
    {
      "source": "wWnsoLhHwt",
      "target": "v1rFkElnIn",
      "similarity": 0.9145
    },
    {
      "source": "wWnsoLhHwt",
      "target": "jTEKTdI3K9",
      "similarity": 0.8936
    },
    {
      "source": "wWnsoLhHwt",
      "target": "CkUHtnyhpY",
      "similarity": 0.8836
    },
    {
      "source": "wWnsoLhHwt",
      "target": "pq1WUegkza",
      "similarity": 0.8742
    },
    {
      "source": "wWnsoLhHwt",
      "target": "9kJperA2a4",
      "similarity": 0.8736
    },
    {
      "source": "snocoXIQXz",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.8063
    },
    {
      "source": "snocoXIQXz",
      "target": "tyEyYT267x",
      "similarity": 0.7999
    },
    {
      "source": "snocoXIQXz",
      "target": "FBhKUXK7od",
      "similarity": 0.7973
    },
    {
      "source": "snocoXIQXz",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.7932
    },
    {
      "source": "snocoXIQXz",
      "target": "gFvRRCnQvX",
      "similarity": 0.7928
    },
    {
      "source": "pQsllTesiE",
      "target": "vjel3nWP2a",
      "similarity": 0.8385
    },
    {
      "source": "pQsllTesiE",
      "target": "md9qolJwLl",
      "similarity": 0.822
    },
    {
      "source": "pQsllTesiE",
      "target": "connection component",
      "similarity": 0.8163
    },
    {
      "source": "pQsllTesiE",
      "target": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "similarity": 0.806
    },
    {
      "source": "pQsllTesiE",
      "target": "In parallel",
      "similarity": 0.8054
    },
    {
      "source": "Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8539
    },
    {
      "source": "Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably",
      "target": "cbttLtO94Q",
      "similarity": 0.8425
    },
    {
      "source": "Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably",
      "target": "4JK2XMGUc8",
      "similarity": 0.8411
    },
    {
      "source": "Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8354
    },
    {
      "source": "Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably",
      "target": "this simple method is computationally fast",
      "similarity": 0.8337
    },
    {
      "source": "AWg2tkbydO",
      "target": "PHg4rAXFVH",
      "similarity": 0.8504
    },
    {
      "source": "AWg2tkbydO",
      "target": "We address this by introducing an iterative version of CGE",
      "similarity": 0.8481
    },
    {
      "source": "AWg2tkbydO",
      "target": "JAMxRSXLFz",
      "similarity": 0.8466
    },
    {
      "source": "AWg2tkbydO",
      "target": "4JK2XMGUc8",
      "similarity": 0.8421
    },
    {
      "source": "AWg2tkbydO",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.8412
    },
    {
      "source": "HNOo4UNPBF",
      "target": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "similarity": 0.8641
    },
    {
      "source": "HNOo4UNPBF",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8352
    },
    {
      "source": "HNOo4UNPBF",
      "target": "However",
      "similarity": 0.8132
    },
    {
      "source": "HNOo4UNPBF",
      "target": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "similarity": 0.8123
    },
    {
      "source": "HNOo4UNPBF",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8095
    },
    {
      "source": "gLa96FlWwn",
      "target": "kam84eEmub",
      "similarity": 0.8548
    },
    {
      "source": "gLa96FlWwn",
      "target": "Consequently",
      "similarity": 0.8389
    },
    {
      "source": "gLa96FlWwn",
      "target": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "similarity": 0.8269
    },
    {
      "source": "gLa96FlWwn",
      "target": "To address this",
      "similarity": 0.8174
    },
    {
      "source": "gLa96FlWwn",
      "target": "Finally",
      "similarity": 0.816
    },
    {
      "source": "m73tETvFkX",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8527
    },
    {
      "source": "m73tETvFkX",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8523
    },
    {
      "source": "m73tETvFkX",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.8443
    },
    {
      "source": "m73tETvFkX",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8337
    },
    {
      "source": "m73tETvFkX",
      "target": "We are the first to identify these challenges in online VFL",
      "similarity": 0.8322
    },
    {
      "source": "1VwWi6zbxs",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8319
    },
    {
      "source": "1VwWi6zbxs",
      "target": "sLKDbuyq99",
      "similarity": 0.831
    },
    {
      "source": "1VwWi6zbxs",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8288
    },
    {
      "source": "1VwWi6zbxs",
      "target": "aXwukBD6M6",
      "similarity": 0.8269
    },
    {
      "source": "1VwWi6zbxs",
      "target": "fifXzmzeGy",
      "similarity": 0.8249
    },
    {
      "source": "Through task arithmetic",
      "target": "But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret)",
      "similarity": 0.8354
    },
    {
      "source": "Through task arithmetic",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8288
    },
    {
      "source": "Through task arithmetic",
      "target": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "similarity": 0.8285
    },
    {
      "source": "Through task arithmetic",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8221
    },
    {
      "source": "Through task arithmetic",
      "target": "dence on a transductive learning framework. To address these shortcomings",
      "similarity": 0.8204
    },
    {
      "source": "However",
      "target": "NWb128pSCb",
      "similarity": 0.861
    },
    {
      "source": "However",
      "target": "This paper proposes",
      "similarity": 0.8556
    },
    {
      "source": "However",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8398
    },
    {
      "source": "However",
      "target": "wide dissemination",
      "similarity": 0.8364
    },
    {
      "source": "However",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8325
    },
    {
      "source": "Third",
      "target": "Furthermore",
      "similarity": 0.8457
    },
    {
      "source": "Third",
      "target": "as well as natural",
      "similarity": 0.8331
    },
    {
      "source": "Third",
      "target": "0y3hGn1wOk",
      "similarity": 0.8319
    },
    {
      "source": "Third",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8254
    },
    {
      "source": "Third",
      "target": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "similarity": 0.8212
    },
    {
      "source": "Finally",
      "target": "ZJo6Radbqq",
      "similarity": 0.8675
    },
    {
      "source": "Finally",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8663
    },
    {
      "source": "Finally",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8624
    },
    {
      "source": "Finally",
      "target": "20qZK2T7fa",
      "similarity": 0.8571
    },
    {
      "source": "Finally",
      "target": "uHLgDEgiS5",
      "similarity": 0.8549
    },
    {
      "source": "Our code is available at https://github.com/katoro8989/tau-Jp_Task_Arithmetic\"",
      "target": "IuU0wcO0mo",
      "similarity": 0.8656
    },
    {
      "source": "Our code is available at https://github.com/katoro8989/tau-Jp_Task_Arithmetic\"",
      "target": "In this work",
      "similarity": 0.8615
    },
    {
      "source": "Our code is available at https://github.com/katoro8989/tau-Jp_Task_Arithmetic\"",
      "target": "Yet",
      "similarity": 0.856
    },
    {
      "source": "Our code is available at https://github.com/katoro8989/tau-Jp_Task_Arithmetic\"",
      "target": "PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization",
      "similarity": 0.8487
    },
    {
      "source": "Our code is available at https://github.com/katoro8989/tau-Jp_Task_Arithmetic\"",
      "target": "In this paper",
      "similarity": 0.8458
    },
    {
      "source": "BLWaTeucYX",
      "target": "3bcN6xlO6f",
      "similarity": 0.8806
    },
    {
      "source": "BLWaTeucYX",
      "target": "bAFVlpFQvT",
      "similarity": 0.8695
    },
    {
      "source": "BLWaTeucYX",
      "target": "Furthermore",
      "similarity": 0.865
    },
    {
      "source": "BLWaTeucYX",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8605
    },
    {
      "source": "BLWaTeucYX",
      "target": "wHebuIb6IH",
      "similarity": 0.8551
    },
    {
      "source": "efficient and automated methods for generating and modifying 3D objects. One",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8797
    },
    {
      "source": "efficient and automated methods for generating and modifying 3D objects. One",
      "target": "approximation",
      "similarity": 0.8743
    },
    {
      "source": "efficient and automated methods for generating and modifying 3D objects. One",
      "target": "RWJX5F5I9g",
      "similarity": 0.8714
    },
    {
      "source": "efficient and automated methods for generating and modifying 3D objects. One",
      "target": "JSB171dSUU",
      "similarity": 0.8609
    },
    {
      "source": "efficient and automated methods for generating and modifying 3D objects. One",
      "target": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "similarity": 0.8601
    },
    {
      "source": "approach involves using Large Language Models (LLMs) to generate Computer-",
      "target": "uHLgDEgiS5",
      "similarity": 0.8496
    },
    {
      "source": "approach involves using Large Language Models (LLMs) to generate Computer-",
      "target": "AZR4R3lw7y",
      "similarity": 0.831
    },
    {
      "source": "approach involves using Large Language Models (LLMs) to generate Computer-",
      "target": "To remedy this problem",
      "similarity": 0.8276
    },
    {
      "source": "approach involves using Large Language Models (LLMs) to generate Computer-",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8252
    },
    {
      "source": "approach involves using Large Language Models (LLMs) to generate Computer-",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8236
    },
    {
      "source": "Aided Design (CAD) scripting code",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8479
    },
    {
      "source": "Aided Design (CAD) scripting code",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8348
    },
    {
      "source": "Aided Design (CAD) scripting code",
      "target": "However",
      "similarity": 0.8287
    },
    {
      "source": "Aided Design (CAD) scripting code",
      "target": "To develop SoundCTM",
      "similarity": 0.8281
    },
    {
      "source": "Aided Design (CAD) scripting code",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8277
    },
    {
      "source": "object; however",
      "target": "rnJxelIZrq",
      "similarity": 0.8661
    },
    {
      "source": "object; however",
      "target": "ogXkmugNZw",
      "similarity": 0.8449
    },
    {
      "source": "object; however",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8386
    },
    {
      "source": "object; however",
      "target": "overhead in parameters and inference time. In this paper",
      "similarity": 0.8315
    },
    {
      "source": "object; however",
      "target": "To remedy this problem",
      "similarity": 0.8312
    },
    {
      "source": "Testing the correctness of CAD generated code is challenging due to the complexity",
      "target": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "similarity": 0.8295
    },
    {
      "source": "Testing the correctness of CAD generated code is challenging due to the complexity",
      "target": "Zk9guOl9NS",
      "similarity": 0.8288
    },
    {
      "source": "Testing the correctness of CAD generated code is challenging due to the complexity",
      "target": "7PLpiVdnUC",
      "similarity": 0.828
    },
    {
      "source": "Testing the correctness of CAD generated code is challenging due to the complexity",
      "target": "However",
      "similarity": 0.8257
    },
    {
      "source": "Testing the correctness of CAD generated code is challenging due to the complexity",
      "target": "mnna9LUg7P",
      "similarity": 0.8257
    },
    {
      "source": "and structure of 3D objects (e.g.",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8796
    },
    {
      "source": "and structure of 3D objects (e.g.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8757
    },
    {
      "source": "and structure of 3D objects (e.g.",
      "target": "U3PBITXNG6",
      "similarity": 0.8744
    },
    {
      "source": "and structure of 3D objects (e.g.",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8598
    },
    {
      "source": "and structure of 3D objects (e.g.",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8592
    },
    {
      "source": "feasible in code. In this paper",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8508
    },
    {
      "source": "feasible in code. In this paper",
      "target": "u2QdCiOgwA",
      "similarity": 0.8434
    },
    {
      "source": "feasible in code. In this paper",
      "target": "1qq1QJKM5q",
      "similarity": 0.8346
    },
    {
      "source": "feasible in code. In this paper",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8339
    },
    {
      "source": "feasible in code. In this paper",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8336
    },
    {
      "source": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "target": "GEM uses a generative model to estimate mutual information between candidate and reference responses",
      "similarity": 0.8847
    },
    {
      "source": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8666
    },
    {
      "source": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8526
    },
    {
      "source": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8456
    },
    {
      "source": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "target": "lOi6FtIwR8",
      "similarity": 0.8435
    },
    {
      "source": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8725
    },
    {
      "source": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "target": "Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge",
      "similarity": 0.8461
    },
    {
      "source": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "target": "nYjAzwor9R",
      "similarity": 0.8369
    },
    {
      "source": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8318
    },
    {
      "source": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "target": "sampling methods",
      "similarity": 0.8314
    },
    {
      "source": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "target": "However",
      "similarity": 0.8512
    },
    {
      "source": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "target": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "similarity": 0.8418
    },
    {
      "source": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "target": "In brief",
      "similarity": 0.8379
    },
    {
      "source": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "target": "To this end",
      "similarity": 0.8294
    },
    {
      "source": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8268
    },
    {
      "source": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "target": "To be precise",
      "similarity": 0.8445
    },
    {
      "source": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "target": "aXwukBD6M6",
      "similarity": 0.8384
    },
    {
      "source": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8366
    },
    {
      "source": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8303
    },
    {
      "source": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8298
    },
    {
      "source": "introduce",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8453
    },
    {
      "source": "introduce",
      "target": "SyVPiehSbg",
      "similarity": 0.8413
    },
    {
      "source": "introduce",
      "target": "NKotdPUc3L",
      "similarity": 0.8232
    },
    {
      "source": "introduce",
      "target": "hierarchical scheduling mechanism. Our evaluation of Preble with real workloads and re-",
      "similarity": 0.8213
    },
    {
      "source": "introduce",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8209
    },
    {
      "source": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "target": "ZNnmcddaB3",
      "similarity": 0.8332
    },
    {
      "source": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "target": "1yJP5TVWih",
      "similarity": 0.8253
    },
    {
      "source": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8231
    },
    {
      "source": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "target": "Finally",
      "similarity": 0.8219
    },
    {
      "source": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8197
    },
    {
      "source": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8597
    },
    {
      "source": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "target": "Real-world causal structures",
      "similarity": 0.8509
    },
    {
      "source": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "target": "KeRwLLwZaw",
      "similarity": 0.8416
    },
    {
      "source": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "target": "tU074jg2vS",
      "similarity": 0.8367
    },
    {
      "source": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "target": "While these",
      "similarity": 0.8347
    },
    {
      "source": "VLM performance by providing visual feedback",
      "target": "However",
      "similarity": 0.8397
    },
    {
      "source": "VLM performance by providing visual feedback",
      "target": "ANBuEJesgx",
      "similarity": 0.8284
    },
    {
      "source": "VLM performance by providing visual feedback",
      "target": "ssRdQimeUI",
      "similarity": 0.8242
    },
    {
      "source": "VLM performance by providing visual feedback",
      "target": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "similarity": 0.8191
    },
    {
      "source": "VLM performance by providing visual feedback",
      "target": "LuT2CVrlpU",
      "similarity": 0.8156
    },
    {
      "source": "objects",
      "target": "xiQNfYl33p",
      "similarity": 0.8531
    },
    {
      "source": "objects",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.845
    },
    {
      "source": "objects",
      "target": "hjROBHstZ3",
      "similarity": 0.8443
    },
    {
      "source": "objects",
      "target": "relying on backward propagation",
      "similarity": 0.8407
    },
    {
      "source": "objects",
      "target": "In this paper",
      "similarity": 0.837
    },
    {
      "source": "GPT-4",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8792
    },
    {
      "source": "GPT-4",
      "target": "S1Bv3068Xt",
      "similarity": 0.8733
    },
    {
      "source": "GPT-4",
      "target": "rTQNGQxm4K",
      "similarity": 0.8535
    },
    {
      "source": "GPT-4",
      "target": "5xSRg3eYZz",
      "similarity": 0.8513
    },
    {
      "source": "GPT-4",
      "target": "yitH9xAHQs",
      "similarity": 0.8439
    },
    {
      "source": "5.0% improvement in success rate compared to prior work.\"",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8763
    },
    {
      "source": "5.0% improvement in success rate compared to prior work.\"",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8714
    },
    {
      "source": "5.0% improvement in success rate compared to prior work.\"",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8675
    },
    {
      "source": "5.0% improvement in success rate compared to prior work.\"",
      "target": "Accurate risk assessment allows platforms with different safety thresholds to tailor content filtering and rejection. In this paper",
      "similarity": 0.8666
    },
    {
      "source": "5.0% improvement in success rate compared to prior work.\"",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.861
    },
    {
      "source": "U49N5V51rU",
      "target": "d8hYXbxX71",
      "similarity": 0.841
    },
    {
      "source": "U49N5V51rU",
      "target": "Wf2ndb8nhf",
      "similarity": 0.8342
    },
    {
      "source": "U49N5V51rU",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8258
    },
    {
      "source": "U49N5V51rU",
      "target": "To this end",
      "similarity": 0.8242
    },
    {
      "source": "U49N5V51rU",
      "target": "code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).\"",
      "similarity": 0.8225
    },
    {
      "source": "xzSUdw6s76",
      "target": "To address this limitation",
      "similarity": 0.9045
    },
    {
      "source": "xzSUdw6s76",
      "target": "It was numerically observed that the linear interpolation",
      "similarity": 0.8621
    },
    {
      "source": "xzSUdw6s76",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8586
    },
    {
      "source": "xzSUdw6s76",
      "target": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "similarity": 0.8471
    },
    {
      "source": "xzSUdw6s76",
      "target": "Finally",
      "similarity": 0.8463
    },
    {
      "source": "mobile devices.\"",
      "target": "Q150eWkQ4I",
      "similarity": 0.8383
    },
    {
      "source": "mobile devices.\"",
      "target": "fjEZ2LPceZ",
      "similarity": 0.8372
    },
    {
      "source": "mobile devices.\"",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8332
    },
    {
      "source": "mobile devices.\"",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8327
    },
    {
      "source": "mobile devices.\"",
      "target": "6NNA0MxhCH",
      "similarity": 0.8281
    },
    {
      "source": "FCMpUOZkxi",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.88
    },
    {
      "source": "FCMpUOZkxi",
      "target": "Bpn8q40n1n",
      "similarity": 0.8605
    },
    {
      "source": "FCMpUOZkxi",
      "target": "SqoL14HDm0",
      "similarity": 0.8518
    },
    {
      "source": "FCMpUOZkxi",
      "target": "SFN6Wm7YBI",
      "similarity": 0.83
    },
    {
      "source": "FCMpUOZkxi",
      "target": "M5t0WvjfCg",
      "similarity": 0.8276
    },
    {
      "source": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8782
    },
    {
      "source": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.876
    },
    {
      "source": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "target": "real-world datasets than prior work and",
      "similarity": 0.8684
    },
    {
      "source": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8674
    },
    {
      "source": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "target": "In this task",
      "similarity": 0.8658
    },
    {
      "source": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "target": "FPfCUJTsCn",
      "similarity": 0.8591
    },
    {
      "source": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "target": "1yJP5TVWih",
      "similarity": 0.8384
    },
    {
      "source": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "target": "B5iOSxM2I0",
      "similarity": 0.8376
    },
    {
      "source": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "target": "uHLgDEgiS5",
      "similarity": 0.8329
    },
    {
      "source": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8316
    },
    {
      "source": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "target": "AcVpLS86RT",
      "similarity": 0.8666
    },
    {
      "source": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "target": "In this task",
      "similarity": 0.8645
    },
    {
      "source": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "target": "SOTA LLMs",
      "similarity": 0.8589
    },
    {
      "source": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "target": "WzCEiBILHu",
      "similarity": 0.8554
    },
    {
      "source": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8549
    },
    {
      "source": "which",
      "target": "LqhorpRLIm",
      "similarity": 0.8476
    },
    {
      "source": "which",
      "target": "Building on these insights",
      "similarity": 0.8436
    },
    {
      "source": "which",
      "target": "iyJOUELYir",
      "similarity": 0.8417
    },
    {
      "source": "which",
      "target": "Iht4NNVqk0",
      "similarity": 0.8389
    },
    {
      "source": "which",
      "target": "CjXaMI2kUH",
      "similarity": 0.8332
    },
    {
      "source": "We establish these strong results through the adaptive budget-aware design",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.838
    },
    {
      "source": "We establish these strong results through the adaptive budget-aware design",
      "target": "PIpGN5Ko3v",
      "similarity": 0.8369
    },
    {
      "source": "We establish these strong results through the adaptive budget-aware design",
      "target": "Additionally",
      "similarity": 0.8364
    },
    {
      "source": "We establish these strong results through the adaptive budget-aware design",
      "target": "Rz0kozh3LE",
      "similarity": 0.833
    },
    {
      "source": "We establish these strong results through the adaptive budget-aware design",
      "target": "iAK9oHp4Zz",
      "similarity": 0.8279
    },
    {
      "source": "JBXO05r4AV",
      "target": "8DBTq09LgN",
      "similarity": 0.835
    },
    {
      "source": "JBXO05r4AV",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8201
    },
    {
      "source": "JBXO05r4AV",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8186
    },
    {
      "source": "JBXO05r4AV",
      "target": "Moreover",
      "similarity": 0.8177
    },
    {
      "source": "JBXO05r4AV",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8161
    },
    {
      "source": "ed7zI29lRF",
      "target": "xiQNfYl33p",
      "similarity": 0.8802
    },
    {
      "source": "ed7zI29lRF",
      "target": "exhibit a randomly chosen pair of these skills. Here",
      "similarity": 0.8615
    },
    {
      "source": "ed7zI29lRF",
      "target": "In preregistered experiments",
      "similarity": 0.8611
    },
    {
      "source": "ed7zI29lRF",
      "target": "To develop SoundCTM",
      "similarity": 0.8539
    },
    {
      "source": "ed7zI29lRF",
      "target": "QowsEic1sc",
      "similarity": 0.8484
    },
    {
      "source": "All prior work in TDS learning focuses on classification",
      "target": "Aly68Y5Es0",
      "similarity": 0.8079
    },
    {
      "source": "All prior work in TDS learning focuses on classification",
      "target": "space are required in general even for outputting a constant factor",
      "similarity": 0.8063
    },
    {
      "source": "All prior work in TDS learning focuses on classification",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8046
    },
    {
      "source": "All prior work in TDS learning focuses on classification",
      "target": "2o58Mbqkd2",
      "similarity": 0.8043
    },
    {
      "source": "All prior work in TDS learning focuses on classification",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8013
    },
    {
      "source": "q2Lnyegkr8",
      "target": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "similarity": 0.7947
    },
    {
      "source": "q2Lnyegkr8",
      "target": "In this paper",
      "similarity": 0.7933
    },
    {
      "source": "q2Lnyegkr8",
      "target": "hrqNOxpItr",
      "similarity": 0.7886
    },
    {
      "source": "q2Lnyegkr8",
      "target": "In this work",
      "similarity": 0.7872
    },
    {
      "source": "q2Lnyegkr8",
      "target": "For example",
      "similarity": 0.7838
    },
    {
      "source": "Our code is available at [`https://github.com/zhixuan-lin/forgetting-transformer`](https://github.com/zhixuan-lin/forgetting-transformer).\"",
      "target": "Theoretically",
      "similarity": 0.8468
    },
    {
      "source": "Our code is available at [`https://github.com/zhixuan-lin/forgetting-transformer`](https://github.com/zhixuan-lin/forgetting-transformer).\"",
      "target": "xJXq6FkqEw",
      "similarity": 0.8442
    },
    {
      "source": "Our code is available at [`https://github.com/zhixuan-lin/forgetting-transformer`](https://github.com/zhixuan-lin/forgetting-transformer).\"",
      "target": "MMwaQEVsAg",
      "similarity": 0.8303
    },
    {
      "source": "Our code is available at [`https://github.com/zhixuan-lin/forgetting-transformer`](https://github.com/zhixuan-lin/forgetting-transformer).\"",
      "target": "bRa4JLPzii",
      "similarity": 0.8302
    },
    {
      "source": "Our code is available at [`https://github.com/zhixuan-lin/forgetting-transformer`](https://github.com/zhixuan-lin/forgetting-transformer).\"",
      "target": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "similarity": 0.8293
    },
    {
      "source": "R4q3cY3kQf",
      "target": "To overcome those challenges",
      "similarity": 0.888
    },
    {
      "source": "R4q3cY3kQf",
      "target": "In this paper",
      "similarity": 0.8811
    },
    {
      "source": "R4q3cY3kQf",
      "target": "zCZnEXF3bN",
      "similarity": 0.8731
    },
    {
      "source": "R4q3cY3kQf",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8702
    },
    {
      "source": "R4q3cY3kQf",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8624
    },
    {
      "source": "Exploration can also be directed using intrinsic rewards",
      "target": "X1U74IwuxG",
      "similarity": 0.8645
    },
    {
      "source": "Exploration can also be directed using intrinsic rewards",
      "target": "models. However",
      "similarity": 0.859
    },
    {
      "source": "Exploration can also be directed using intrinsic rewards",
      "target": "Such models faced convergence issues due to vanishing gradient",
      "similarity": 0.8547
    },
    {
      "source": "Exploration can also be directed using intrinsic rewards",
      "target": "To this end",
      "similarity": 0.8538
    },
    {
      "source": "Exploration can also be directed using intrinsic rewards",
      "target": "To this end",
      "similarity": 0.8538
    },
    {
      "source": "When combined with Boltzmann exploration",
      "target": "CAssIgPN4I",
      "similarity": 0.8698
    },
    {
      "source": "When combined with Boltzmann exploration",
      "target": "il5yUQsrjC",
      "similarity": 0.8604
    },
    {
      "source": "When combined with Boltzmann exploration",
      "target": "hjROBHstZ3",
      "similarity": 0.8591
    },
    {
      "source": "When combined with Boltzmann exploration",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8582
    },
    {
      "source": "When combined with Boltzmann exploration",
      "target": "wide dissemination",
      "similarity": 0.8562
    },
    {
      "source": "wLmJIs1uqG",
      "target": "huge amount of instances in the real world. For richer classes of the similarity",
      "similarity": 0.8441
    },
    {
      "source": "wLmJIs1uqG",
      "target": "dEg5SdGaiq",
      "similarity": 0.8239
    },
    {
      "source": "wLmJIs1uqG",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8161
    },
    {
      "source": "wLmJIs1uqG",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.8149
    },
    {
      "source": "wLmJIs1uqG",
      "target": "3ep9ZYMZS3",
      "similarity": 0.8148
    },
    {
      "source": "aKJr5NnN8U",
      "target": "HN8V0flwJF",
      "similarity": 0.8714
    },
    {
      "source": "aKJr5NnN8U",
      "target": "features or a different but similarly useful representation.",
      "similarity": 0.8593
    },
    {
      "source": "aKJr5NnN8U",
      "target": "To this end",
      "similarity": 0.8454
    },
    {
      "source": "aKJr5NnN8U",
      "target": "yIlyHJdYV3",
      "similarity": 0.843
    },
    {
      "source": "aKJr5NnN8U",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.8408
    },
    {
      "source": "is4nCVkSFA",
      "target": "AjXkRZIvjB",
      "similarity": 0.7856
    },
    {
      "source": "is4nCVkSFA",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.7828
    },
    {
      "source": "is4nCVkSFA",
      "target": "g0rnZeBguq",
      "similarity": 0.7789
    },
    {
      "source": "is4nCVkSFA",
      "target": "uMEsKEiB7J",
      "similarity": 0.7769
    },
    {
      "source": "is4nCVkSFA",
      "target": "5pd78GmXC6",
      "similarity": 0.7767
    },
    {
      "source": "Prior research has shown that any polynomial-time algorithm under the statistical query (SQ) framework requires $\\Omega(d^{s^\\star/2}\\lor d)$ samples",
      "target": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "similarity": 0.8325
    },
    {
      "source": "Prior research has shown that any polynomial-time algorithm under the statistical query (SQ) framework requires $\\Omega(d^{s^\\star/2}\\lor d)$ samples",
      "target": "In this paper",
      "similarity": 0.8224
    },
    {
      "source": "Prior research has shown that any polynomial-time algorithm under the statistical query (SQ) framework requires $\\Omega(d^{s^\\star/2}\\lor d)$ samples",
      "target": "However",
      "similarity": 0.817
    },
    {
      "source": "Prior research has shown that any polynomial-time algorithm under the statistical query (SQ) framework requires $\\Omega(d^{s^\\star/2}\\lor d)$ samples",
      "target": "oZkqkkvdND",
      "similarity": 0.8141
    },
    {
      "source": "Prior research has shown that any polynomial-time algorithm under the statistical query (SQ) framework requires $\\Omega(d^{s^\\star/2}\\lor d)$ samples",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8127
    },
    {
      "source": "However",
      "target": "AWg2tkbydO",
      "similarity": 0.8387
    },
    {
      "source": "However",
      "target": "Our code and additional resources are available at https://structuredllm.com.\"",
      "similarity": 0.8358
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8341
    },
    {
      "source": "However",
      "target": "Building on these insights",
      "similarity": 0.8335
    },
    {
      "source": "However",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.8309
    },
    {
      "source": "Inspired by prior techniques such as label transformation and landscape smoothing for learning single-index models",
      "target": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "similarity": 0.799
    },
    {
      "source": "Inspired by prior techniques such as label transformation and landscape smoothing for learning single-index models",
      "target": "n7qGCmluZr",
      "similarity": 0.7933
    },
    {
      "source": "Inspired by prior techniques such as label transformation and landscape smoothing for learning single-index models",
      "target": "On various mathematical benchmarks",
      "similarity": 0.7841
    },
    {
      "source": "Inspired by prior techniques such as label transformation and landscape smoothing for learning single-index models",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.7797
    },
    {
      "source": "Inspired by prior techniques such as label transformation and landscape smoothing for learning single-index models",
      "target": "While many focus on post-training pruning",
      "similarity": 0.7777
    },
    {
      "source": "Our method is adaptable to a variety of loss and activation functions",
      "target": "DzbUL4AJPP",
      "similarity": 0.7942
    },
    {
      "source": "Our method is adaptable to a variety of loss and activation functions",
      "target": "against various defense mechanisms.\"",
      "similarity": 0.7929
    },
    {
      "source": "Our method is adaptable to a variety of loss and activation functions",
      "target": "4ytRL3HJrq",
      "similarity": 0.7824
    },
    {
      "source": "Our method is adaptable to a variety of loss and activation functions",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.7792
    },
    {
      "source": "Our method is adaptable to a variety of loss and activation functions",
      "target": "nsCOeCLR8e",
      "similarity": 0.7703
    },
    {
      "source": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "target": "in a vector database",
      "similarity": 0.9068
    },
    {
      "source": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.9021
    },
    {
      "source": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "target": "odU59TxdiB",
      "similarity": 0.9017
    },
    {
      "source": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.9001
    },
    {
      "source": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "target": "Overall",
      "similarity": 0.8984
    },
    {
      "source": "Furthermore",
      "target": "However",
      "similarity": 0.8489
    },
    {
      "source": "Furthermore",
      "target": "In this setting",
      "similarity": 0.8337
    },
    {
      "source": "Furthermore",
      "target": "evaluate how well fine details are learned",
      "similarity": 0.8294
    },
    {
      "source": "Furthermore",
      "target": "yp95goUAT1",
      "similarity": 0.8231
    },
    {
      "source": "Furthermore",
      "target": "TUvg5uwdeG",
      "similarity": 0.8191
    },
    {
      "source": "We derive a corresponding SQ lower bound",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.8487
    },
    {
      "source": "We derive a corresponding SQ lower bound",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8486
    },
    {
      "source": "We derive a corresponding SQ lower bound",
      "target": "Furthermore",
      "similarity": 0.8253
    },
    {
      "source": "We derive a corresponding SQ lower bound",
      "target": "We begin by investigating the canonical orthogonal projection method for data compression through principal component analysis (PCA).",
      "similarity": 0.8191
    },
    {
      "source": "We derive a corresponding SQ lower bound",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8154
    },
    {
      "source": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "target": "78tc3EiUrN",
      "similarity": 0.8719
    },
    {
      "source": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.8685
    },
    {
      "source": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "target": "hyfe5q5TD0",
      "similarity": 0.8666
    },
    {
      "source": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8613
    },
    {
      "source": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "target": "2kGKsyhtvh",
      "similarity": 0.8572
    },
    {
      "source": "Our framework",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.8579
    },
    {
      "source": "Our framework",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8549
    },
    {
      "source": "Our framework",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8515
    },
    {
      "source": "Our framework",
      "target": "hgwGi81ndj",
      "similarity": 0.8487
    },
    {
      "source": "Our framework",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8412
    },
    {
      "source": "8sSqNntaMr",
      "target": "iXbUquaWbl",
      "similarity": 0.8919
    },
    {
      "source": "8sSqNntaMr",
      "target": "traditional energy-based models",
      "similarity": 0.8595
    },
    {
      "source": "8sSqNntaMr",
      "target": "DKgAFfCs5F",
      "similarity": 0.8527
    },
    {
      "source": "8sSqNntaMr",
      "target": "states while still maintaining the ability to precisely recall recent memories with the",
      "similarity": 0.8487
    },
    {
      "source": "8sSqNntaMr",
      "target": "However",
      "similarity": 0.8287
    },
    {
      "source": "uNd289HjLi",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8868
    },
    {
      "source": "uNd289HjLi",
      "target": "JytL2MrlLT",
      "similarity": 0.8711
    },
    {
      "source": "uNd289HjLi",
      "target": "Our system",
      "similarity": 0.8613
    },
    {
      "source": "uNd289HjLi",
      "target": "Moreover",
      "similarity": 0.8611
    },
    {
      "source": "uNd289HjLi",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8608
    },
    {
      "source": "r5IXBlTCGc",
      "target": "2c7pfOqu9k",
      "similarity": 0.8646
    },
    {
      "source": "r5IXBlTCGc",
      "target": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "similarity": 0.8627
    },
    {
      "source": "r5IXBlTCGc",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8543
    },
    {
      "source": "r5IXBlTCGc",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8525
    },
    {
      "source": "r5IXBlTCGc",
      "target": "OuLgaHEmzi",
      "similarity": 0.8481
    },
    {
      "source": "4D0f16Vwc3",
      "target": "EyaH1wzmao",
      "similarity": 0.882
    },
    {
      "source": "4D0f16Vwc3",
      "target": "FXw0okNcOb",
      "similarity": 0.8819
    },
    {
      "source": "4D0f16Vwc3",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8797
    },
    {
      "source": "4D0f16Vwc3",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8535
    },
    {
      "source": "4D0f16Vwc3",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8535
    },
    {
      "source": "To address this issue",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8596
    },
    {
      "source": "To address this issue",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.854
    },
    {
      "source": "To address this issue",
      "target": "of the NTK",
      "similarity": 0.8454
    },
    {
      "source": "To address this issue",
      "target": "Subsequently",
      "similarity": 0.8449
    },
    {
      "source": "To address this issue",
      "target": "In this paper",
      "similarity": 0.8435
    },
    {
      "source": "6fDjUoEQvm",
      "target": "5qg6JPSgCj",
      "similarity": 0.8442
    },
    {
      "source": "6fDjUoEQvm",
      "target": "However",
      "similarity": 0.8121
    },
    {
      "source": "6fDjUoEQvm",
      "target": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "similarity": 0.8105
    },
    {
      "source": "6fDjUoEQvm",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.8066
    },
    {
      "source": "6fDjUoEQvm",
      "target": "generating time series of tabular data",
      "similarity": 0.806
    },
    {
      "source": "AjXkRZIvjB",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8407
    },
    {
      "source": "AjXkRZIvjB",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8402
    },
    {
      "source": "AjXkRZIvjB",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8401
    },
    {
      "source": "AjXkRZIvjB",
      "target": "5pd78GmXC6",
      "similarity": 0.8393
    },
    {
      "source": "AjXkRZIvjB",
      "target": "yRKelogz5i",
      "similarity": 0.8386
    },
    {
      "source": "Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically",
      "target": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "similarity": 0.801
    },
    {
      "source": "Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically",
      "target": "LYHEY783Np",
      "similarity": 0.7999
    },
    {
      "source": "Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically",
      "target": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "similarity": 0.7951
    },
    {
      "source": "Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically",
      "target": "GhexuBLxbO",
      "similarity": 0.7946
    },
    {
      "source": "Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically",
      "target": "However",
      "similarity": 0.7945
    },
    {
      "source": "rJ5g8ueQaI",
      "target": "To generate high-quality",
      "similarity": 0.8535
    },
    {
      "source": "rJ5g8ueQaI",
      "target": "Adapting tools from classical sampling theory",
      "similarity": 0.8528
    },
    {
      "source": "rJ5g8ueQaI",
      "target": "This toolkit consists of 300 manually collected benign multimodal queries",
      "similarity": 0.849
    },
    {
      "source": "rJ5g8ueQaI",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.8487
    },
    {
      "source": "rJ5g8ueQaI",
      "target": "d8hYXbxX71",
      "similarity": 0.8367
    },
    {
      "source": "FUaDMRVrbS",
      "target": "https://sites.google.com/view/rnd-dagger\"",
      "similarity": 0.8773
    },
    {
      "source": "FUaDMRVrbS",
      "target": "iAmR7FfMmq",
      "similarity": 0.8671
    },
    {
      "source": "FUaDMRVrbS",
      "target": "Experimentally",
      "similarity": 0.8414
    },
    {
      "source": "FUaDMRVrbS",
      "target": "Pj4Aid3XqL",
      "similarity": 0.841
    },
    {
      "source": "FUaDMRVrbS",
      "target": "AoIKgHu9Si",
      "similarity": 0.8318
    },
    {
      "source": "In this paper",
      "target": "Additionally",
      "similarity": 0.8687
    },
    {
      "source": "In this paper",
      "target": "AcVpLS86RT",
      "similarity": 0.8449
    },
    {
      "source": "In this paper",
      "target": "Mjn53GtMxi",
      "similarity": 0.8425
    },
    {
      "source": "In this paper",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.84
    },
    {
      "source": "In this paper",
      "target": "YFxfcQMLWX",
      "similarity": 0.8297
    },
    {
      "source": "Tz8Li6G2xU",
      "target": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "similarity": 0.8278
    },
    {
      "source": "Tz8Li6G2xU",
      "target": "In this work",
      "similarity": 0.8266
    },
    {
      "source": "Tz8Li6G2xU",
      "target": "Despite its simplicity",
      "similarity": 0.822
    },
    {
      "source": "Tz8Li6G2xU",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8117
    },
    {
      "source": "Tz8Li6G2xU",
      "target": "6H4jRWKFc3",
      "similarity": 0.796
    },
    {
      "source": "mDKxlfraAn",
      "target": "(including gradient-based",
      "similarity": 0.8442
    },
    {
      "source": "mDKxlfraAn",
      "target": "gFvRRCnQvX",
      "similarity": 0.8404
    },
    {
      "source": "mDKxlfraAn",
      "target": "Fk3eod9aaD",
      "similarity": 0.8403
    },
    {
      "source": "mDKxlfraAn",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.8228
    },
    {
      "source": "mDKxlfraAn",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8189
    },
    {
      "source": "54XlM8Clkg",
      "target": "yfW1x7uBS5",
      "similarity": 0.8495
    },
    {
      "source": "54XlM8Clkg",
      "target": "xsELpEPn4A",
      "similarity": 0.828
    },
    {
      "source": "54XlM8Clkg",
      "target": "In this paper",
      "similarity": 0.8262
    },
    {
      "source": "54XlM8Clkg",
      "target": "In this paper",
      "similarity": 0.8189
    },
    {
      "source": "54XlM8Clkg",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8188
    },
    {
      "source": "Antib6Uovh",
      "target": "6F6qwdycgJ",
      "similarity": 0.904
    },
    {
      "source": "Antib6Uovh",
      "target": "To address this",
      "similarity": 0.8975
    },
    {
      "source": "Antib6Uovh",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8778
    },
    {
      "source": "Antib6Uovh",
      "target": "gVkX9QMBO3",
      "similarity": 0.8744
    },
    {
      "source": "Antib6Uovh",
      "target": "AJpUZd8Clb",
      "similarity": 0.8711
    },
    {
      "source": "BksqWM8737",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.855
    },
    {
      "source": "BksqWM8737",
      "target": "In this work",
      "similarity": 0.8493
    },
    {
      "source": "BksqWM8737",
      "target": "a hypergraph",
      "similarity": 0.8365
    },
    {
      "source": "BksqWM8737",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.836
    },
    {
      "source": "BksqWM8737",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8346
    },
    {
      "source": "hwnObmOTrV",
      "target": "AJpUZd8Clb",
      "similarity": 0.8653
    },
    {
      "source": "hwnObmOTrV",
      "target": "6GATHdOi1x",
      "similarity": 0.8645
    },
    {
      "source": "hwnObmOTrV",
      "target": "To this end",
      "similarity": 0.8639
    },
    {
      "source": "hwnObmOTrV",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8604
    },
    {
      "source": "hwnObmOTrV",
      "target": "Qja5s0K3VX",
      "similarity": 0.8599
    },
    {
      "source": "VCbqXtS5YY",
      "target": "yFGR36PLDJ",
      "similarity": 0.8332
    },
    {
      "source": "VCbqXtS5YY",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8263
    },
    {
      "source": "VCbqXtS5YY",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.8227
    },
    {
      "source": "VCbqXtS5YY",
      "target": "$$",
      "similarity": 0.8213
    },
    {
      "source": "VCbqXtS5YY",
      "target": "Fk3eod9aaD",
      "similarity": 0.8109
    },
    {
      "source": "ISqx8giekS",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8459
    },
    {
      "source": "ISqx8giekS",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.844
    },
    {
      "source": "ISqx8giekS",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8439
    },
    {
      "source": "ISqx8giekS",
      "target": "KlN00vQEY2",
      "similarity": 0.8332
    },
    {
      "source": "ISqx8giekS",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8325
    },
    {
      "source": "gfI9v7AbFg",
      "target": "Second",
      "similarity": 0.8683
    },
    {
      "source": "gfI9v7AbFg",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.8555
    },
    {
      "source": "gfI9v7AbFg",
      "target": "For the diversity",
      "similarity": 0.8495
    },
    {
      "source": "gfI9v7AbFg",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8473
    },
    {
      "source": "gfI9v7AbFg",
      "target": "Instruct",
      "similarity": 0.8443
    },
    {
      "source": "eNbA8Fqir4",
      "target": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "similarity": 0.8673
    },
    {
      "source": "eNbA8Fqir4",
      "target": "higher-order models.\"",
      "similarity": 0.8238
    },
    {
      "source": "eNbA8Fqir4",
      "target": "However",
      "similarity": 0.8089
    },
    {
      "source": "eNbA8Fqir4",
      "target": "CbpWPbYHuv",
      "similarity": 0.808
    },
    {
      "source": "eNbA8Fqir4",
      "target": "VOoJEQlLW5",
      "similarity": 0.7982
    },
    {
      "source": "However",
      "target": "IuU0wcO0mo",
      "similarity": 0.8358
    },
    {
      "source": "However",
      "target": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "similarity": 0.831
    },
    {
      "source": "However",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8226
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8213
    },
    {
      "source": "However",
      "target": "eiqrnVaeIw",
      "similarity": 0.8204
    },
    {
      "source": "To address this",
      "target": "PY56Wur7S0",
      "similarity": 0.8606
    },
    {
      "source": "To address this",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8511
    },
    {
      "source": "To address this",
      "target": "Against grandmaster-level (2500 Elo) opponents",
      "similarity": 0.8432
    },
    {
      "source": "To address this",
      "target": "7GKbQ1WT1C",
      "similarity": 0.8426
    },
    {
      "source": "To address this",
      "target": "vue9P1Ypk6",
      "similarity": 0.8307
    },
    {
      "source": "As its pre-training capabilities are related to perplexity (PPL)",
      "target": "large-scale",
      "similarity": 0.8314
    },
    {
      "source": "As its pre-training capabilities are related to perplexity (PPL)",
      "target": "HqLHY4TzGj",
      "similarity": 0.8173
    },
    {
      "source": "As its pre-training capabilities are related to perplexity (PPL)",
      "target": "To be precise",
      "similarity": 0.8165
    },
    {
      "source": "As its pre-training capabilities are related to perplexity (PPL)",
      "target": "IXyfbaGlps",
      "similarity": 0.8159
    },
    {
      "source": "As its pre-training capabilities are related to perplexity (PPL)",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8128
    },
    {
      "source": "In this paper",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8427
    },
    {
      "source": "In this paper",
      "target": "To address these issues",
      "similarity": 0.8376
    },
    {
      "source": "In this paper",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8347
    },
    {
      "source": "In this paper",
      "target": "98d7DLMGdt",
      "similarity": 0.8341
    },
    {
      "source": "In this paper",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8305
    },
    {
      "source": "Our experiments validate our approach",
      "target": "EQgEMAD4kv",
      "similarity": 0.893
    },
    {
      "source": "Our experiments validate our approach",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8667
    },
    {
      "source": "Our experiments validate our approach",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8631
    },
    {
      "source": "Our experiments validate our approach",
      "target": "ngmEcEer8a",
      "similarity": 0.854
    },
    {
      "source": "Our experiments validate our approach",
      "target": "to address these failure modes",
      "similarity": 0.8528
    },
    {
      "source": "The best-performing model",
      "target": "JSB171dSUU",
      "similarity": 0.8885
    },
    {
      "source": "The best-performing model",
      "target": "jTEKTdI3K9",
      "similarity": 0.8866
    },
    {
      "source": "The best-performing model",
      "target": "To tackle this challenge",
      "similarity": 0.886
    },
    {
      "source": "The best-performing model",
      "target": "- In discrete image-based control (e.g.",
      "similarity": 0.8711
    },
    {
      "source": "The best-performing model",
      "target": "se4vjm7h4E",
      "similarity": 0.8675
    },
    {
      "source": "We continue pre-training with high-rated",
      "target": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "similarity": 0.8587
    },
    {
      "source": "We continue pre-training with high-rated",
      "target": "UvTo3tVBk2",
      "similarity": 0.8188
    },
    {
      "source": "We continue pre-training with high-rated",
      "target": "KSLkFYHlYg",
      "similarity": 0.81
    },
    {
      "source": "We continue pre-training with high-rated",
      "target": "of natural language. However",
      "similarity": 0.8077
    },
    {
      "source": "We continue pre-training with high-rated",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.803
    },
    {
      "source": "Our findings emphasize the importance of quality ranking",
      "target": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "similarity": 0.8788
    },
    {
      "source": "Our findings emphasize the importance of quality ranking",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.8611
    },
    {
      "source": "Our findings emphasize the importance of quality ranking",
      "target": "However",
      "similarity": 0.8534
    },
    {
      "source": "Our findings emphasize the importance of quality ranking",
      "target": "SOTA LLMs",
      "similarity": 0.8439
    },
    {
      "source": "Our findings emphasize the importance of quality ranking",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8293
    },
    {
      "source": "We also thoroughly analyzed our pre-training dataset",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8709
    },
    {
      "source": "We also thoroughly analyzed our pre-training dataset",
      "target": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "similarity": 0.8607
    },
    {
      "source": "We also thoroughly analyzed our pre-training dataset",
      "target": "yIlyHJdYV3",
      "similarity": 0.8586
    },
    {
      "source": "We also thoroughly analyzed our pre-training dataset",
      "target": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "similarity": 0.8572
    },
    {
      "source": "We also thoroughly analyzed our pre-training dataset",
      "target": "samples. However",
      "similarity": 0.8474
    },
    {
      "source": "Y2Dh8rWwlb",
      "target": "2TasVD7FXp",
      "similarity": 0.8835
    },
    {
      "source": "Y2Dh8rWwlb",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8587
    },
    {
      "source": "Y2Dh8rWwlb",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.839
    },
    {
      "source": "Y2Dh8rWwlb",
      "target": "8TBGdH3t6a",
      "similarity": 0.8373
    },
    {
      "source": "Y2Dh8rWwlb",
      "target": "GbgCRJedQ7",
      "similarity": 0.8349
    },
    {
      "source": "consuming process of managing large 3D assets",
      "target": "2o58Mbqkd2",
      "similarity": 0.855
    },
    {
      "source": "consuming process of managing large 3D assets",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8531
    },
    {
      "source": "consuming process of managing large 3D assets",
      "target": "In this task",
      "similarity": 0.8499
    },
    {
      "source": "consuming process of managing large 3D assets",
      "target": "TKuYWeFE6S",
      "similarity": 0.8428
    },
    {
      "source": "consuming process of managing large 3D assets",
      "target": "real-world datasets than prior work and",
      "similarity": 0.8425
    },
    {
      "source": "gaming. However",
      "target": "To this end",
      "similarity": 0.8464
    },
    {
      "source": "gaming. However",
      "target": "Reweighting (GSR)",
      "similarity": 0.8449
    },
    {
      "source": "gaming. However",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8441
    },
    {
      "source": "gaming. However",
      "target": "pDDODPtpx9",
      "similarity": 0.8386
    },
    {
      "source": "gaming. However",
      "target": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "similarity": 0.8375
    },
    {
      "source": "require manual interventions or focus only on appearance modifications without",
      "target": "VxvnV6slP0",
      "similarity": 0.8415
    },
    {
      "source": "require manual interventions or focus only on appearance modifications without",
      "target": "magnitudes in solutions preferred by SAEs.\"",
      "similarity": 0.8397
    },
    {
      "source": "require manual interventions or focus only on appearance modifications without",
      "target": "RQz7szbVDs",
      "similarity": 0.8314
    },
    {
      "source": "require manual interventions or focus only on appearance modifications without",
      "target": "dbuFJg7eaw",
      "similarity": 0.8213
    },
    {
      "source": "require manual interventions or focus only on appearance modifications without",
      "target": "lOfuvmi2HT",
      "similarity": 0.8147
    },
    {
      "source": "supporting comprehensive scene layout changes. In response",
      "target": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "similarity": 0.7861
    },
    {
      "source": "supporting comprehensive scene layout changes. In response",
      "target": "Further",
      "similarity": 0.7757
    },
    {
      "source": "supporting comprehensive scene layout changes. In response",
      "target": "a given query",
      "similarity": 0.7748
    },
    {
      "source": "supporting comprehensive scene layout changes. In response",
      "target": "6H4jRWKFc3",
      "similarity": 0.7725
    },
    {
      "source": "supporting comprehensive scene layout changes. In response",
      "target": "by focusing on efficiently solving the underlying optimization problem using a general",
      "similarity": 0.7678
    },
    {
      "source": "natural language commands",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8405
    },
    {
      "source": "natural language commands",
      "target": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "similarity": 0.8326
    },
    {
      "source": "natural language commands",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8292
    },
    {
      "source": "natural language commands",
      "target": "In this work",
      "similarity": 0.8278
    },
    {
      "source": "natural language commands",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8251
    },
    {
      "source": "EditRoom leverages Large Language Models (LLMs) for command planning and",
      "target": "fine-tuning of a shallow fully-connected network following the representation.",
      "similarity": 0.8473
    },
    {
      "source": "EditRoom leverages Large Language Models (LLMs) for command planning and",
      "target": "GySIAKEwtZ",
      "similarity": 0.8205
    },
    {
      "source": "EditRoom leverages Large Language Models (LLMs) for command planning and",
      "target": "regret learning",
      "similarity": 0.8175
    },
    {
      "source": "EditRoom leverages Large Language Models (LLMs) for command planning and",
      "target": "While our convergence rate estimates recover existing results for minimizing",
      "similarity": 0.8116
    },
    {
      "source": "EditRoom leverages Large Language Models (LLMs) for command planning and",
      "target": "klpdEThT8q",
      "similarity": 0.81
    },
    {
      "source": "generates target scenes using a diffusion-based method",
      "target": "For example",
      "similarity": 0.8621
    },
    {
      "source": "generates target scenes using a diffusion-based method",
      "target": "RWJX5F5I9g",
      "similarity": 0.8378
    },
    {
      "source": "generates target scenes using a diffusion-based method",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.822
    },
    {
      "source": "generates target scenes using a diffusion-based method",
      "target": "wNobG8bV5Q",
      "similarity": 0.8099
    },
    {
      "source": "generates target scenes using a diffusion-based method",
      "target": "approximation",
      "similarity": 0.8096
    },
    {
      "source": "the lack of data for language-guided 3D scene editing",
      "target": "Mjn53GtMxi",
      "similarity": 0.8661
    },
    {
      "source": "the lack of data for language-guided 3D scene editing",
      "target": "improving model efficacy",
      "similarity": 0.8621
    },
    {
      "source": "the lack of data for language-guided 3D scene editing",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8599
    },
    {
      "source": "the lack of data for language-guided 3D scene editing",
      "target": "JYwVijuNA7",
      "similarity": 0.8599
    },
    {
      "source": "the lack of data for language-guided 3D scene editing",
      "target": "p4cLtzk4oe",
      "similarity": 0.8587
    },
    {
      "source": "EditRoom-DB",
      "target": "KlxK4ncqWZ",
      "similarity": 0.866
    },
    {
      "source": "EditRoom-DB",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8657
    },
    {
      "source": "EditRoom-DB",
      "target": "AD5yx2xq8R",
      "similarity": 0.8578
    },
    {
      "source": "EditRoom-DB",
      "target": "instruction-relevant information from a video to complete a task. We find that the",
      "similarity": 0.8553
    },
    {
      "source": "EditRoom-DB",
      "target": "F57HPKZ6KD",
      "similarity": 0.8551
    },
    {
      "source": "other baselines across all metrics",
      "target": "However",
      "similarity": 0.895
    },
    {
      "source": "other baselines across all metrics",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8918
    },
    {
      "source": "other baselines across all metrics",
      "target": "INow59Vurm",
      "similarity": 0.886
    },
    {
      "source": "other baselines across all metrics",
      "target": "NvDRvtrGLo",
      "similarity": 0.8846
    },
    {
      "source": "other baselines across all metrics",
      "target": "bSq0XGS3kW",
      "similarity": 0.8731
    },
    {
      "source": "language-guided scene layout editing.\"",
      "target": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "similarity": 0.8818
    },
    {
      "source": "language-guided scene layout editing.\"",
      "target": "CkKEuLmRnr",
      "similarity": 0.8816
    },
    {
      "source": "language-guided scene layout editing.\"",
      "target": "6ycX677p2l",
      "similarity": 0.8815
    },
    {
      "source": "language-guided scene layout editing.\"",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8801
    },
    {
      "source": "language-guided scene layout editing.\"",
      "target": "Ultimately",
      "similarity": 0.8739
    },
    {
      "source": "9mBodivRIo",
      "target": "BPAZ6yW3K7",
      "similarity": 0.8192
    },
    {
      "source": "9mBodivRIo",
      "target": "YH4M1Tbxfz",
      "similarity": 0.8095
    },
    {
      "source": "9mBodivRIo",
      "target": "1yJP5TVWih",
      "similarity": 0.7826
    },
    {
      "source": "9mBodivRIo",
      "target": "YcUV5apdlq",
      "similarity": 0.7822
    },
    {
      "source": "9mBodivRIo",
      "target": "powerful expressiveness",
      "similarity": 0.7786
    },
    {
      "source": "To address this",
      "target": "kxnoqaisCT",
      "similarity": 0.8302
    },
    {
      "source": "To address this",
      "target": "4vzGQcVUG8",
      "similarity": 0.8255
    },
    {
      "source": "To address this",
      "target": "PY56Wur7S0",
      "similarity": 0.8232
    },
    {
      "source": "To address this",
      "target": "exgLs4snap",
      "similarity": 0.8192
    },
    {
      "source": "To address this",
      "target": "several graph- and simplicial complex-based models on three topological classification",
      "similarity": 0.8187
    },
    {
      "source": "For example",
      "target": "In this paper",
      "similarity": 0.8765
    },
    {
      "source": "For example",
      "target": "RC5FPYVQaH",
      "similarity": 0.8732
    },
    {
      "source": "For example",
      "target": "pDDODPtpx9",
      "similarity": 0.8717
    },
    {
      "source": "For example",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8674
    },
    {
      "source": "For example",
      "target": "To overcome this limitation",
      "similarity": 0.8665
    },
    {
      "source": "7GKbQ1WT1C",
      "target": "TmCcNuo03f",
      "similarity": 0.8611
    },
    {
      "source": "7GKbQ1WT1C",
      "target": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "similarity": 0.8403
    },
    {
      "source": "7GKbQ1WT1C",
      "target": "UqrFPhcmFp",
      "similarity": 0.839
    },
    {
      "source": "7GKbQ1WT1C",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8312
    },
    {
      "source": "7GKbQ1WT1C",
      "target": "PY56Wur7S0",
      "similarity": 0.8224
    },
    {
      "source": "fWRBheSJth",
      "target": "90DC0IvlSs",
      "similarity": 0.9137
    },
    {
      "source": "fWRBheSJth",
      "target": "Fty0wTcemV",
      "similarity": 0.8866
    },
    {
      "source": "fWRBheSJth",
      "target": "For TP",
      "similarity": 0.8849
    },
    {
      "source": "fWRBheSJth",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8818
    },
    {
      "source": "fWRBheSJth",
      "target": "AJpUZd8Clb",
      "similarity": 0.8776
    },
    {
      "source": "UWdPsY7agk",
      "target": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "similarity": 0.8353
    },
    {
      "source": "UWdPsY7agk",
      "target": "Despite their importance",
      "similarity": 0.8132
    },
    {
      "source": "UWdPsY7agk",
      "target": "6wOmHdwCC4",
      "similarity": 0.8041
    },
    {
      "source": "UWdPsY7agk",
      "target": "SyVPiehSbg",
      "similarity": 0.7936
    },
    {
      "source": "UWdPsY7agk",
      "target": "In this work",
      "similarity": 0.7887
    },
    {
      "source": "98d7DLMGdt",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8598
    },
    {
      "source": "98d7DLMGdt",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8549
    },
    {
      "source": "98d7DLMGdt",
      "target": "FBkpCyujtS",
      "similarity": 0.8506
    },
    {
      "source": "98d7DLMGdt",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8478
    },
    {
      "source": "98d7DLMGdt",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.847
    },
    {
      "source": "yu1vqQqKkx",
      "target": "bounded ranges",
      "similarity": 0.86
    },
    {
      "source": "yu1vqQqKkx",
      "target": "To tackle this challenge",
      "similarity": 0.8583
    },
    {
      "source": "yu1vqQqKkx",
      "target": "LLMs. Interestingly",
      "similarity": 0.8567
    },
    {
      "source": "yu1vqQqKkx",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8562
    },
    {
      "source": "yu1vqQqKkx",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8562
    },
    {
      "source": "BPgK5XW1Nb",
      "target": "L238BAx0wP",
      "similarity": 0.8753
    },
    {
      "source": "BPgK5XW1Nb",
      "target": "EDoD3DgivF",
      "similarity": 0.8583
    },
    {
      "source": "BPgK5XW1Nb",
      "target": "FhTAG591Ve",
      "similarity": 0.8486
    },
    {
      "source": "BPgK5XW1Nb",
      "target": "In offline evaluations",
      "similarity": 0.847
    },
    {
      "source": "BPgK5XW1Nb",
      "target": "uClUUJk05H",
      "similarity": 0.8438
    },
    {
      "source": "Our key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM",
      "target": "Qj1KwBZaEI",
      "similarity": 0.8434
    },
    {
      "source": "Our key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM",
      "target": "xzSUdw6s76",
      "similarity": 0.8362
    },
    {
      "source": "Our key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM",
      "target": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "similarity": 0.8319
    },
    {
      "source": "Our key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM",
      "target": "E4LAVLXAHW",
      "similarity": 0.8309
    },
    {
      "source": "Our key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8282
    },
    {
      "source": "To be specific",
      "target": "Second",
      "similarity": 0.8518
    },
    {
      "source": "To be specific",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8473
    },
    {
      "source": "To be specific",
      "target": "the entire observable history remained an open problem. In this work",
      "similarity": 0.8465
    },
    {
      "source": "To be specific",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8352
    },
    {
      "source": "To be specific",
      "target": "To address these challenges",
      "similarity": 0.8335
    },
    {
      "source": "Compared to the previous approaches using external reward models or implicit in-context learning",
      "target": "L5godAOC2z",
      "similarity": 0.8124
    },
    {
      "source": "Compared to the previous approaches using external reward models or implicit in-context learning",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.8023
    },
    {
      "source": "Compared to the previous approaches using external reward models or implicit in-context learning",
      "target": "KWH4UIoQKS",
      "similarity": 0.7926
    },
    {
      "source": "Compared to the previous approaches using external reward models or implicit in-context learning",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.79
    },
    {
      "source": "Compared to the previous approaches using external reward models or implicit in-context learning",
      "target": "trained on historical data. But since anomalies are rare and fall outside the training distribution",
      "similarity": 0.7863
    },
    {
      "source": "In addition",
      "target": "Together",
      "similarity": 0.8821
    },
    {
      "source": "In addition",
      "target": "yFGR36PLDJ",
      "similarity": 0.8796
    },
    {
      "source": "In addition",
      "target": "yORSk4Ycsa",
      "similarity": 0.8697
    },
    {
      "source": "In addition",
      "target": "First",
      "similarity": 0.8607
    },
    {
      "source": "In addition",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8384
    },
    {
      "source": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "target": "ogXkmugNZw",
      "similarity": 0.8379
    },
    {
      "source": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "target": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "similarity": 0.8276
    },
    {
      "source": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "target": "o2Igqm95SJ",
      "similarity": 0.8224
    },
    {
      "source": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "target": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "similarity": 0.8079
    },
    {
      "source": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8021
    },
    {
      "source": "For example",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8081
    },
    {
      "source": "For example",
      "target": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "similarity": 0.8009
    },
    {
      "source": "For example",
      "target": "46xYl55hdc",
      "similarity": 0.8004
    },
    {
      "source": "For example",
      "target": "0OTVNEm9N4",
      "similarity": 0.7992
    },
    {
      "source": "For example",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.7971
    },
    {
      "source": "uuriavczkL",
      "target": "tePFpDgyqg",
      "similarity": 0.8875
    },
    {
      "source": "uuriavczkL",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8491
    },
    {
      "source": "uuriavczkL",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8489
    },
    {
      "source": "uuriavczkL",
      "target": "QowsEic1sc",
      "similarity": 0.8454
    },
    {
      "source": "uuriavczkL",
      "target": "wide dissemination",
      "similarity": 0.8454
    },
    {
      "source": "8RCmNLeeXx",
      "target": "IZDiRbVSVN",
      "similarity": 0.8415
    },
    {
      "source": "8RCmNLeeXx",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.8261
    },
    {
      "source": "8RCmNLeeXx",
      "target": "Along with SketikZ",
      "similarity": 0.8205
    },
    {
      "source": "8RCmNLeeXx",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8184
    },
    {
      "source": "8RCmNLeeXx",
      "target": "To this end",
      "similarity": 0.8175
    },
    {
      "source": "SuH5SdOXpe",
      "target": "assessing and advancing topological methods",
      "similarity": 0.8711
    },
    {
      "source": "SuH5SdOXpe",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8577
    },
    {
      "source": "SuH5SdOXpe",
      "target": "m8yby1JfbU",
      "similarity": 0.851
    },
    {
      "source": "SuH5SdOXpe",
      "target": "20qZK2T7fa",
      "similarity": 0.8458
    },
    {
      "source": "SuH5SdOXpe",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8445
    },
    {
      "source": "To explore this",
      "target": "fL4qWkSmtM",
      "similarity": 0.8747
    },
    {
      "source": "To explore this",
      "target": "Inspired by these findings",
      "similarity": 0.8586
    },
    {
      "source": "To explore this",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8437
    },
    {
      "source": "To explore this",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8403
    },
    {
      "source": "To explore this",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8389
    },
    {
      "source": "of our approaches.",
      "target": "MxbEiFRf39",
      "similarity": 0.8721
    },
    {
      "source": "of our approaches.",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8617
    },
    {
      "source": "of our approaches.",
      "target": "Moreover",
      "similarity": 0.843
    },
    {
      "source": "of our approaches.",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.8413
    },
    {
      "source": "of our approaches.",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.8413
    },
    {
      "source": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8607
    },
    {
      "source": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "target": "Q5Sawm0nqo",
      "similarity": 0.8582
    },
    {
      "source": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "target": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "similarity": 0.8526
    },
    {
      "source": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8518
    },
    {
      "source": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "target": "To address this",
      "similarity": 0.835
    },
    {
      "source": "Our implementation is available at https://github.com/chris-hzc/Robustness-Reprogramming.\"",
      "target": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "similarity": 0.7744
    },
    {
      "source": "Our implementation is available at https://github.com/chris-hzc/Robustness-Reprogramming.\"",
      "target": "Specifically",
      "similarity": 0.7523
    },
    {
      "source": "Our implementation is available at https://github.com/chris-hzc/Robustness-Reprogramming.\"",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.7515
    },
    {
      "source": "3usdM1AuI3",
      "target": "ud8FtE1N4N",
      "similarity": 0.8546
    },
    {
      "source": "3usdM1AuI3",
      "target": "d8hYXbxX71",
      "similarity": 0.8396
    },
    {
      "source": "3usdM1AuI3",
      "target": "KxQRHOre9D",
      "similarity": 0.8221
    },
    {
      "source": "3usdM1AuI3",
      "target": "However",
      "similarity": 0.8191
    },
    {
      "source": "3usdM1AuI3",
      "target": "When used as a drop-in replacement for current softmax+RoPE attention systems",
      "similarity": 0.8182
    },
    {
      "source": "kam84eEmub",
      "target": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "similarity": 0.8674
    },
    {
      "source": "kam84eEmub",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.8349
    },
    {
      "source": "kam84eEmub",
      "target": "To bridge this gap",
      "similarity": 0.8212
    },
    {
      "source": "kam84eEmub",
      "target": "TjP1d8PP8l",
      "similarity": 0.8166
    },
    {
      "source": "kam84eEmub",
      "target": "In parallel",
      "similarity": 0.816
    },
    {
      "source": "wNobG8bV5Q",
      "target": "5AtlfHYCPa",
      "similarity": 0.8901
    },
    {
      "source": "wNobG8bV5Q",
      "target": "bmrYu2Ekdz",
      "similarity": 0.8801
    },
    {
      "source": "wNobG8bV5Q",
      "target": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "similarity": 0.8726
    },
    {
      "source": "wNobG8bV5Q",
      "target": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "similarity": 0.8658
    },
    {
      "source": "wNobG8bV5Q",
      "target": "RWJX5F5I9g",
      "similarity": 0.8632
    },
    {
      "source": "r0pLGGcuY6",
      "target": "3bcN6xlO6f",
      "similarity": 0.8705
    },
    {
      "source": "r0pLGGcuY6",
      "target": "Furthermore",
      "similarity": 0.8594
    },
    {
      "source": "r0pLGGcuY6",
      "target": "41uZB8bDFh",
      "similarity": 0.8558
    },
    {
      "source": "r0pLGGcuY6",
      "target": "1Z3C49JQVf",
      "similarity": 0.8545
    },
    {
      "source": "r0pLGGcuY6",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8541
    },
    {
      "source": "txoJvjfI9w",
      "target": "Finally",
      "similarity": 0.8525
    },
    {
      "source": "txoJvjfI9w",
      "target": "jY5oml9fe9",
      "similarity": 0.8496
    },
    {
      "source": "txoJvjfI9w",
      "target": "U49N5V51rU",
      "similarity": 0.8169
    },
    {
      "source": "txoJvjfI9w",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8115
    },
    {
      "source": "txoJvjfI9w",
      "target": "TtKN1TpvUu",
      "similarity": 0.8101
    },
    {
      "source": "riTiq3i21b",
      "target": "IUmj2dw5se",
      "similarity": 0.85
    },
    {
      "source": "riTiq3i21b",
      "target": "fMNRYBvcQN",
      "similarity": 0.8388
    },
    {
      "source": "riTiq3i21b",
      "target": "6NNA0MxhCH",
      "similarity": 0.837
    },
    {
      "source": "riTiq3i21b",
      "target": "We are the first to identify these challenges in online VFL",
      "similarity": 0.834
    },
    {
      "source": "riTiq3i21b",
      "target": "xI71dsS3o4",
      "similarity": 0.8267
    },
    {
      "source": "(e.g.",
      "target": "However",
      "similarity": 0.8702
    },
    {
      "source": "(e.g.",
      "target": "6GATHdOi1x",
      "similarity": 0.8695
    },
    {
      "source": "(e.g.",
      "target": "Qja5s0K3VX",
      "similarity": 0.8691
    },
    {
      "source": "(e.g.",
      "target": "htDczodFN5",
      "similarity": 0.8581
    },
    {
      "source": "(e.g.",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8537
    },
    {
      "source": "instances compared to 6% for the next best system.\"",
      "target": "T4sMzjy7fO",
      "similarity": 0.8803
    },
    {
      "source": "instances compared to 6% for the next best system.\"",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8728
    },
    {
      "source": "instances compared to 6% for the next best system.\"",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8573
    },
    {
      "source": "instances compared to 6% for the next best system.\"",
      "target": "Building on these insights",
      "similarity": 0.854
    },
    {
      "source": "instances compared to 6% for the next best system.\"",
      "target": "1Njl73JKjB",
      "similarity": 0.8444
    },
    {
      "source": "Y4aWwRh25b",
      "target": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "similarity": 0.9119
    },
    {
      "source": "Y4aWwRh25b",
      "target": "of top-k chunks",
      "similarity": 0.8611
    },
    {
      "source": "Y4aWwRh25b",
      "target": "Besides",
      "similarity": 0.8278
    },
    {
      "source": "Y4aWwRh25b",
      "target": "the same state-of-the-art long-context models (e.g.",
      "similarity": 0.8199
    },
    {
      "source": "Y4aWwRh25b",
      "target": "We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism",
      "similarity": 0.8199
    },
    {
      "source": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "target": "90DC0IvlSs",
      "similarity": 0.8978
    },
    {
      "source": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8933
    },
    {
      "source": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "target": "Fty0wTcemV",
      "similarity": 0.8882
    },
    {
      "source": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "target": "EQgEMAD4kv",
      "similarity": 0.8874
    },
    {
      "source": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "target": "BI2int5SAC",
      "similarity": 0.8824
    },
    {
      "source": "The vulnerability exists for a wide range of modern LMs that span Llama2",
      "target": "Ahlrf2HGJR",
      "similarity": 0.87
    },
    {
      "source": "The vulnerability exists for a wide range of modern LMs that span Llama2",
      "target": "bounded ranges",
      "similarity": 0.851
    },
    {
      "source": "The vulnerability exists for a wide range of modern LMs that span Llama2",
      "target": "bMC1t7eLRc",
      "similarity": 0.8481
    },
    {
      "source": "The vulnerability exists for a wide range of modern LMs that span Llama2",
      "target": "vbmSSIhKAM",
      "similarity": 0.8408
    },
    {
      "source": "The vulnerability exists for a wide range of modern LMs that span Llama2",
      "target": "Furthermore",
      "similarity": 0.8385
    },
    {
      "source": "We also study multiple effects of RAG setup on the extractability of data",
      "target": "In this work",
      "similarity": 0.8128
    },
    {
      "source": "We also study multiple effects of RAG setup on the extractability of data",
      "target": "Next",
      "similarity": 0.7989
    },
    {
      "source": "We also study multiple effects of RAG setup on the extractability of data",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.7982
    },
    {
      "source": "We also study multiple effects of RAG setup on the extractability of data",
      "target": "8DBTq09LgN",
      "similarity": 0.7973
    },
    {
      "source": "We also study multiple effects of RAG setup on the extractability of data",
      "target": "q5EZ7gKcnW",
      "similarity": 0.7963
    },
    {
      "source": "Extending our study to production RAG models",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.8441
    },
    {
      "source": "Extending our study to production RAG models",
      "target": "iXCeQ2m6vT",
      "similarity": 0.8435
    },
    {
      "source": "Extending our study to production RAG models",
      "target": "To this end",
      "similarity": 0.8434
    },
    {
      "source": "Extending our study to production RAG models",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8408
    },
    {
      "source": "Extending our study to production RAG models",
      "target": "JYwVijuNA7",
      "similarity": 0.8398
    },
    {
      "source": "PGhiPGBf47",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.8089
    },
    {
      "source": "PGhiPGBf47",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.7912
    },
    {
      "source": "PGhiPGBf47",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.7901
    },
    {
      "source": "PGhiPGBf47",
      "target": "TtKN1TpvUu",
      "similarity": 0.7898
    },
    {
      "source": "PGhiPGBf47",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.789
    },
    {
      "source": "7ohlQUbTpp",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8293
    },
    {
      "source": "7ohlQUbTpp",
      "target": "gyHoR6uFhU",
      "similarity": 0.8171
    },
    {
      "source": "7ohlQUbTpp",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8157
    },
    {
      "source": "7ohlQUbTpp",
      "target": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "similarity": 0.8153
    },
    {
      "source": "7ohlQUbTpp",
      "target": "However",
      "similarity": 0.8122
    },
    {
      "source": "kx8i1yfkRX",
      "target": "X0epAjg0hd",
      "similarity": 0.8298
    },
    {
      "source": "kx8i1yfkRX",
      "target": "Our experiments show that:",
      "similarity": 0.8257
    },
    {
      "source": "kx8i1yfkRX",
      "target": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "similarity": 0.8205
    },
    {
      "source": "kx8i1yfkRX",
      "target": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "similarity": 0.8047
    },
    {
      "source": "kx8i1yfkRX",
      "target": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "similarity": 0.8042
    },
    {
      "source": "lOfuvmi2HT",
      "target": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "similarity": 0.8571
    },
    {
      "source": "lOfuvmi2HT",
      "target": "gFvRRCnQvX",
      "similarity": 0.8075
    },
    {
      "source": "lOfuvmi2HT",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8016
    },
    {
      "source": "lOfuvmi2HT",
      "target": "RQz7szbVDs",
      "similarity": 0.7986
    },
    {
      "source": "lOfuvmi2HT",
      "target": "VCbqXtS5YY",
      "similarity": 0.7959
    },
    {
      "source": "6z4YKr0GK6",
      "target": "Reweighting (GSR)",
      "similarity": 0.8481
    },
    {
      "source": "6z4YKr0GK6",
      "target": "Usklli4gMc",
      "similarity": 0.8435
    },
    {
      "source": "6z4YKr0GK6",
      "target": "YzxMu1asQi",
      "similarity": 0.8392
    },
    {
      "source": "6z4YKr0GK6",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8322
    },
    {
      "source": "6z4YKr0GK6",
      "target": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "similarity": 0.8302
    },
    {
      "source": "tkiZQlL04w",
      "target": "spDUv05cEq",
      "similarity": 0.8282
    },
    {
      "source": "tkiZQlL04w",
      "target": "To address this",
      "similarity": 0.8217
    },
    {
      "source": "tkiZQlL04w",
      "target": "eXB5TCrAu9",
      "similarity": 0.8061
    },
    {
      "source": "tkiZQlL04w",
      "target": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "similarity": 0.7956
    },
    {
      "source": "tkiZQlL04w",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.7943
    },
    {
      "source": "JvkuZZ04O7",
      "target": "Towards doing so",
      "similarity": 0.8716
    },
    {
      "source": "JvkuZZ04O7",
      "target": "To this end",
      "similarity": 0.8691
    },
    {
      "source": "JvkuZZ04O7",
      "target": "UVnD9Ze6mF",
      "similarity": 0.8592
    },
    {
      "source": "JvkuZZ04O7",
      "target": "gY08Ou8EL7",
      "similarity": 0.8573
    },
    {
      "source": "JvkuZZ04O7",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8541
    },
    {
      "source": "VYWBMq1L7H",
      "target": "AZR4R3lw7y",
      "similarity": 0.8834
    },
    {
      "source": "VYWBMq1L7H",
      "target": "DzGe40glxs",
      "similarity": 0.8501
    },
    {
      "source": "VYWBMq1L7H",
      "target": "Based on this",
      "similarity": 0.8223
    },
    {
      "source": "VYWBMq1L7H",
      "target": "oYSsbY3G4o",
      "similarity": 0.8151
    },
    {
      "source": "VYWBMq1L7H",
      "target": "In this work",
      "similarity": 0.8139
    },
    {
      "source": "5xSRg3eYZz",
      "target": "S1Bv3068Xt",
      "similarity": 0.8924
    },
    {
      "source": "5xSRg3eYZz",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8873
    },
    {
      "source": "5xSRg3eYZz",
      "target": "rTQNGQxm4K",
      "similarity": 0.8817
    },
    {
      "source": "5xSRg3eYZz",
      "target": "HqjRlT65WX",
      "similarity": 0.8715
    },
    {
      "source": "5xSRg3eYZz",
      "target": "First",
      "similarity": 0.8707
    },
    {
      "source": "MMwaQEVsAg",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.898
    },
    {
      "source": "MMwaQEVsAg",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8839
    },
    {
      "source": "MMwaQEVsAg",
      "target": "bRa4JLPzii",
      "similarity": 0.8791
    },
    {
      "source": "MMwaQEVsAg",
      "target": "We release models",
      "similarity": 0.8653
    },
    {
      "source": "MMwaQEVsAg",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8609
    },
    {
      "source": "1Njl73JKjB",
      "target": "IQxBDLmVpT",
      "similarity": 0.8551
    },
    {
      "source": "1Njl73JKjB",
      "target": "T4sMzjy7fO",
      "similarity": 0.8549
    },
    {
      "source": "1Njl73JKjB",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8523
    },
    {
      "source": "1Njl73JKjB",
      "target": "powerful expressiveness",
      "similarity": 0.8467
    },
    {
      "source": "1Njl73JKjB",
      "target": "To overcome this limitation",
      "similarity": 0.8408
    },
    {
      "source": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "target": "In this paper",
      "similarity": 0.851
    },
    {
      "source": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "target": "In this work",
      "similarity": 0.8479
    },
    {
      "source": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "target": "71XtUhazG0",
      "similarity": 0.8402
    },
    {
      "source": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8321
    },
    {
      "source": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "target": "ScVnYBaSEw",
      "similarity": 0.8206
    },
    {
      "source": "much attention as a scalable unsupervised approach to this problem. However",
      "target": "Theoretically",
      "similarity": 0.8674
    },
    {
      "source": "much attention as a scalable unsupervised approach to this problem. However",
      "target": "onIro14tHv",
      "similarity": 0.8572
    },
    {
      "source": "much attention as a scalable unsupervised approach to this problem. However",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8552
    },
    {
      "source": "much attention as a scalable unsupervised approach to this problem. However",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8518
    },
    {
      "source": "much attention as a scalable unsupervised approach to this problem. However",
      "target": "MMwaQEVsAg",
      "similarity": 0.8479
    },
    {
      "source": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "target": "tU074jg2vS",
      "similarity": 0.8373
    },
    {
      "source": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "target": "Ke2BEL4csm",
      "similarity": 0.8332
    },
    {
      "source": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "target": "However",
      "similarity": 0.8303
    },
    {
      "source": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "target": "prompts. As such",
      "similarity": 0.8249
    },
    {
      "source": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "target": "on manually crafted video tutorials",
      "similarity": 0.8184
    },
    {
      "source": "difficult to measure the success of SAEs. To address this challenge",
      "target": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "similarity": 0.8201
    },
    {
      "source": "difficult to measure the success of SAEs. To address this challenge",
      "target": "HfWcFs7XLR",
      "similarity": 0.8171
    },
    {
      "source": "difficult to measure the success of SAEs. To address this challenge",
      "target": "Our codebase",
      "similarity": 0.814
    },
    {
      "source": "difficult to measure the success of SAEs. To address this challenge",
      "target": "6yENDA7J4G",
      "similarity": 0.8057
    },
    {
      "source": "difficult to measure the success of SAEs. To address this challenge",
      "target": "VMV8gefvq8",
      "similarity": 0.8026
    },
    {
      "source": "to evaluate SAEs on specific tasks by comparing them to supervised",
      "target": "nt8gBX58Kh",
      "similarity": 0.8024
    },
    {
      "source": "to evaluate SAEs on specific tasks by comparing them to supervised",
      "target": "Finally",
      "similarity": 0.7994
    },
    {
      "source": "to evaluate SAEs on specific tasks by comparing them to supervised",
      "target": "GtvuNrk58a",
      "similarity": 0.7961
    },
    {
      "source": "to evaluate SAEs on specific tasks by comparing them to supervised",
      "target": "Finally",
      "similarity": 0.7958
    },
    {
      "source": "to evaluate SAEs on specific tasks by comparing them to supervised",
      "target": "jY5oml9fe9",
      "similarity": 0.7939
    },
    {
      "source": "feature dictionaries computed with knowledge of the concepts relevant to the",
      "target": "Overall",
      "similarity": 0.815
    },
    {
      "source": "feature dictionaries computed with knowledge of the concepts relevant to the",
      "target": "explore the effects of calibration data",
      "similarity": 0.8075
    },
    {
      "source": "feature dictionaries computed with knowledge of the concepts relevant to the",
      "target": "NUD03NBDOE",
      "similarity": 0.8073
    },
    {
      "source": "feature dictionaries computed with knowledge of the concepts relevant to the",
      "target": "Sd4wYYOhmY",
      "similarity": 0.8068
    },
    {
      "source": "feature dictionaries computed with knowledge of the concepts relevant to the",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8017
    },
    {
      "source": "task.",
      "target": "a hypergraph",
      "similarity": 0.8811
    },
    {
      "source": "task.",
      "target": "UIFAJZ22ZF",
      "similarity": 0.86
    },
    {
      "source": "task.",
      "target": "additional structural constraints",
      "similarity": 0.8386
    },
    {
      "source": "task.",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8331
    },
    {
      "source": "task.",
      "target": "DpLFmc09pC",
      "similarity": 0.8319
    },
    {
      "source": "Specifically",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8596
    },
    {
      "source": "Specifically",
      "target": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "similarity": 0.8324
    },
    {
      "source": "Specifically",
      "target": "IXyfbaGlps",
      "similarity": 0.8303
    },
    {
      "source": "Specifically",
      "target": "OuLgaHEmzi",
      "similarity": 0.8262
    },
    {
      "source": "Specifically",
      "target": "normalized gradient method achieve nearly the same complexity guarantees as",
      "similarity": 0.8239
    },
    {
      "source": "feature dictionaries that disentangle model computations for a specific task;",
      "target": "cPD2hU35x3",
      "similarity": 0.8173
    },
    {
      "source": "feature dictionaries that disentangle model computations for a specific task;",
      "target": "HqjRlT65WX",
      "similarity": 0.816
    },
    {
      "source": "feature dictionaries that disentangle model computations for a specific task;",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8128
    },
    {
      "source": "feature dictionaries that disentangle model computations for a specific task;",
      "target": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "similarity": 0.8118
    },
    {
      "source": "feature dictionaries that disentangle model computations for a specific task;",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8098
    },
    {
      "source": "(2) use them to evaluate and contextualize the degree of disentanglement and",
      "target": "To this end",
      "similarity": 0.8886
    },
    {
      "source": "(2) use them to evaluate and contextualize the degree of disentanglement and",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8797
    },
    {
      "source": "(2) use them to evaluate and contextualize the degree of disentanglement and",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8607
    },
    {
      "source": "(2) use them to evaluate and contextualize the degree of disentanglement and",
      "target": "However",
      "similarity": 0.8604
    },
    {
      "source": "(2) use them to evaluate and contextualize the degree of disentanglement and",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.86
    },
    {
      "source": "control offered by SAE latents on this task. Importantly",
      "target": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "similarity": 0.8352
    },
    {
      "source": "control offered by SAE latents on this task. Importantly",
      "target": "PY56Wur7S0",
      "similarity": 0.8135
    },
    {
      "source": "control offered by SAE latents on this task. Importantly",
      "target": "UN6Ik6OCx8",
      "similarity": 0.8123
    },
    {
      "source": "control offered by SAE latents on this task. Importantly",
      "target": "However",
      "similarity": 0.8077
    },
    {
      "source": "control offered by SAE latents on this task. Importantly",
      "target": "fMNRYBvcQN",
      "similarity": 0.798
    },
    {
      "source": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "target": "RAyRXQjsFl",
      "similarity": 0.9022
    },
    {
      "source": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "target": "4GT9uTsAJE",
      "similarity": 0.8855
    },
    {
      "source": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "target": "{Subsequently}",
      "similarity": 0.8841
    },
    {
      "source": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "target": "mkDam1xIzW",
      "similarity": 0.884
    },
    {
      "source": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "target": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "similarity": 0.8712
    },
    {
      "source": "features or a different but similarly useful representation.",
      "target": "HPSAkIHRbb",
      "similarity": 0.8936
    },
    {
      "source": "features or a different but similarly useful representation.",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8538
    },
    {
      "source": "features or a different but similarly useful representation.",
      "target": "iOMnn1hSBO",
      "similarity": 0.8534
    },
    {
      "source": "features or a different but similarly useful representation.",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8456
    },
    {
      "source": "features or a different but similarly useful representation.",
      "target": "78tc3EiUrN",
      "similarity": 0.8446
    },
    {
      "source": "As a case study",
      "target": "is often a non-linear function",
      "similarity": 0.8844
    },
    {
      "source": "As a case study",
      "target": "4O0v4s3IzY",
      "similarity": 0.877
    },
    {
      "source": "As a case study",
      "target": "phAlw3JPms",
      "similarity": 0.8624
    },
    {
      "source": "As a case study",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.856
    },
    {
      "source": "As a case study",
      "target": "PIpGN5Ko3v",
      "similarity": 0.8539
    },
    {
      "source": "(IOI) task using GPT-2 Small",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8181
    },
    {
      "source": "(IOI) task using GPT-2 Small",
      "target": "cRnCcuLvyr",
      "similarity": 0.81
    },
    {
      "source": "(IOI) task using GPT-2 Small",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8096
    },
    {
      "source": "(IOI) task using GPT-2 Small",
      "target": "7bAjVh3CG3",
      "similarity": 0.8064
    },
    {
      "source": "(IOI) task using GPT-2 Small",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8012
    },
    {
      "source": "datasets. We find that SAEs capture interpretable features for the IOI task",
      "target": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "similarity": 0.8369
    },
    {
      "source": "datasets. We find that SAEs capture interpretable features for the IOI task",
      "target": "In addition",
      "similarity": 0.835
    },
    {
      "source": "datasets. We find that SAEs capture interpretable features for the IOI task",
      "target": "jj7b3p5kLY",
      "similarity": 0.8237
    },
    {
      "source": "datasets. We find that SAEs capture interpretable features for the IOI task",
      "target": "Our method does not require any external priors or manual labels. It completes the self-calibration process on a **single standard GPU within just 5 minutes**.",
      "similarity": 0.813
    },
    {
      "source": "datasets. We find that SAEs capture interpretable features for the IOI task",
      "target": "Thus",
      "similarity": 0.8098
    },
    {
      "source": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "target": "To address this",
      "similarity": 0.8549
    },
    {
      "source": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "target": "9RCT0ngvZP",
      "similarity": 0.8295
    },
    {
      "source": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "target": "j9VVzueEbG",
      "similarity": 0.8244
    },
    {
      "source": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "target": "Across 11 different VQ-VAE training paradigms",
      "similarity": 0.8227
    },
    {
      "source": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "target": "Finally",
      "similarity": 0.8178
    },
    {
      "source": "with supervised features in terms of disentanglement and control over the model.",
      "target": "Finally",
      "similarity": 0.8528
    },
    {
      "source": "with supervised features in terms of disentanglement and control over the model.",
      "target": "txV4dNeusx",
      "similarity": 0.8364
    },
    {
      "source": "with supervised features in terms of disentanglement and control over the model.",
      "target": "csbf1p8xUq",
      "similarity": 0.8176
    },
    {
      "source": "with supervised features in terms of disentanglement and control over the model.",
      "target": "iVMcYxTiVM",
      "similarity": 0.812
    },
    {
      "source": "with supervised features in terms of disentanglement and control over the model.",
      "target": "yLhJYvkKA0",
      "similarity": 0.8082
    },
    {
      "source": "We also exhibit",
      "target": "In this work",
      "similarity": 0.8349
    },
    {
      "source": "We also exhibit",
      "target": "IuU0wcO0mo",
      "similarity": 0.8266
    },
    {
      "source": "We also exhibit",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8239
    },
    {
      "source": "We also exhibit",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8234
    },
    {
      "source": "We also exhibit",
      "target": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "similarity": 0.8225
    },
    {
      "source": "in SAE training illustrating feature splitting and the role of feature",
      "target": "From these insights",
      "similarity": 0.8161
    },
    {
      "source": "in SAE training illustrating feature splitting and the role of feature",
      "target": "Our result significantly improves over the prior works",
      "similarity": 0.7991
    },
    {
      "source": "in SAE training illustrating feature splitting and the role of feature",
      "target": "i) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations",
      "similarity": 0.792
    },
    {
      "source": "in SAE training illustrating feature splitting and the role of feature",
      "target": "the evaluator. However",
      "similarity": 0.7899
    },
    {
      "source": "in SAE training illustrating feature splitting and the role of feature",
      "target": "ANBuEJesgx",
      "similarity": 0.7866
    },
    {
      "source": "magnitudes in solutions preferred by SAEs.\"",
      "target": "requirements and the LLM\u2019s capabilities. Through an innovative edge prediction",
      "similarity": 0.826
    },
    {
      "source": "magnitudes in solutions preferred by SAEs.\"",
      "target": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "similarity": 0.8211
    },
    {
      "source": "magnitudes in solutions preferred by SAEs.\"",
      "target": "VxvnV6slP0",
      "similarity": 0.8185
    },
    {
      "source": "magnitudes in solutions preferred by SAEs.\"",
      "target": "ofuLWn8DFZ",
      "similarity": 0.8102
    },
    {
      "source": "magnitudes in solutions preferred by SAEs.\"",
      "target": "chfJJYC3iL",
      "similarity": 0.8057
    },
    {
      "source": "fv9XU7CyN2",
      "target": "However",
      "similarity": 0.8807
    },
    {
      "source": "fv9XU7CyN2",
      "target": "yUC8pU508S",
      "similarity": 0.8771
    },
    {
      "source": "fv9XU7CyN2",
      "target": "prefix distributions",
      "similarity": 0.8756
    },
    {
      "source": "fv9XU7CyN2",
      "target": "pre-training data",
      "similarity": 0.8673
    },
    {
      "source": "fv9XU7CyN2",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8619
    },
    {
      "source": "u3TL0qxLWf",
      "target": "n2NidsYDop",
      "similarity": 0.8773
    },
    {
      "source": "u3TL0qxLWf",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8542
    },
    {
      "source": "u3TL0qxLWf",
      "target": "Our novel resource",
      "similarity": 0.8491
    },
    {
      "source": "u3TL0qxLWf",
      "target": "However",
      "similarity": 0.8415
    },
    {
      "source": "u3TL0qxLWf",
      "target": "selection of LLMs",
      "similarity": 0.8366
    },
    {
      "source": "YauQYh2k1g",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8196
    },
    {
      "source": "YauQYh2k1g",
      "target": "TjP1d8PP8l",
      "similarity": 0.8081
    },
    {
      "source": "YauQYh2k1g",
      "target": "ogXkmugNZw",
      "similarity": 0.8058
    },
    {
      "source": "YauQYh2k1g",
      "target": "wUbum0nd9N",
      "similarity": 0.7936
    },
    {
      "source": "YauQYh2k1g",
      "target": "o2Igqm95SJ",
      "similarity": 0.792
    },
    {
      "source": "nfKfAzkiez",
      "target": "P6IVIoGRRg",
      "similarity": 0.8534
    },
    {
      "source": "nfKfAzkiez",
      "target": "wsWCVrH9dv",
      "similarity": 0.8519
    },
    {
      "source": "nfKfAzkiez",
      "target": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "similarity": 0.8449
    },
    {
      "source": "nfKfAzkiez",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8424
    },
    {
      "source": "nfKfAzkiez",
      "target": "VVixJ9QavY",
      "similarity": 0.8376
    },
    {
      "source": "Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.",
      "target": "uqe5HkjbT9",
      "similarity": 0.8843
    },
    {
      "source": "Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.",
      "target": "2QdsjiNXgj",
      "similarity": 0.8509
    },
    {
      "source": "Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.",
      "target": "5oSUgTzs8Y",
      "similarity": 0.8495
    },
    {
      "source": "Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.",
      "target": "kbeX97jExm",
      "similarity": 0.844
    },
    {
      "source": "Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.",
      "target": "Metrics for probability measures",
      "similarity": 0.8422
    },
    {
      "source": "While these",
      "target": "Ke2BEL4csm",
      "similarity": 0.8383
    },
    {
      "source": "While these",
      "target": "yRKelogz5i",
      "similarity": 0.8283
    },
    {
      "source": "While these",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8241
    },
    {
      "source": "While these",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8223
    },
    {
      "source": "While these",
      "target": "Real-world causal structures",
      "similarity": 0.8218
    },
    {
      "source": "paradigms show promise",
      "target": "ofuLWn8DFZ",
      "similarity": 0.836
    },
    {
      "source": "paradigms show promise",
      "target": "*progress*: a change in the likelihood of producing a correct response in the future",
      "similarity": 0.8309
    },
    {
      "source": "paradigms show promise",
      "target": "Furthermore",
      "similarity": 0.8295
    },
    {
      "source": "paradigms show promise",
      "target": "In particular",
      "similarity": 0.8253
    },
    {
      "source": "paradigms show promise",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8246
    },
    {
      "source": "in",
      "target": "oP7arLOWix",
      "similarity": 0.8588
    },
    {
      "source": "in",
      "target": "Using this approach",
      "similarity": 0.8541
    },
    {
      "source": "in",
      "target": "gVkX9QMBO3",
      "similarity": 0.8483
    },
    {
      "source": "in",
      "target": "9EqQC2ct4H",
      "similarity": 0.8479
    },
    {
      "source": "in",
      "target": "cmfyMV45XO",
      "similarity": 0.8422
    },
    {
      "source": "improving model efficacy",
      "target": "In this setting",
      "similarity": 0.8909
    },
    {
      "source": "improving model efficacy",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.882
    },
    {
      "source": "improving model efficacy",
      "target": "Y7slJZPGCy",
      "similarity": 0.8612
    },
    {
      "source": "improving model efficacy",
      "target": "1R5BcYS8EC",
      "similarity": 0.853
    },
    {
      "source": "improving model efficacy",
      "target": "TUvg5uwdeG",
      "similarity": 0.8466
    },
    {
      "source": "In doing so",
      "target": "mkNVPGpEPm",
      "similarity": 0.9122
    },
    {
      "source": "In doing so",
      "target": "in reinforcement learning (RL)",
      "similarity": 0.9108
    },
    {
      "source": "In doing so",
      "target": "increased their demand. However",
      "similarity": 0.9093
    },
    {
      "source": "In doing so",
      "target": "0h6v4SpLCY",
      "similarity": 0.9069
    },
    {
      "source": "In doing so",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.906
    },
    {
      "source": "To address this limitation",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8821
    },
    {
      "source": "To address this limitation",
      "target": "In this work",
      "similarity": 0.8778
    },
    {
      "source": "To address this limitation",
      "target": "jxMAPMqNr5",
      "similarity": 0.8752
    },
    {
      "source": "To address this limitation",
      "target": "In contrast",
      "similarity": 0.8748
    },
    {
      "source": "To address this limitation",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8639
    },
    {
      "source": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "target": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "similarity": 0.8997
    },
    {
      "source": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "target": "Furthermore",
      "similarity": 0.8939
    },
    {
      "source": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "target": "1Z3C49JQVf",
      "similarity": 0.8895
    },
    {
      "source": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "target": "With regards to improving Shampoo's computational efficiency",
      "similarity": 0.8889
    },
    {
      "source": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "target": "wHebuIb6IH",
      "similarity": 0.8852
    },
    {
      "source": "rEQqBZIz49",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8189
    },
    {
      "source": "rEQqBZIz49",
      "target": "Recent developments of algorithms for automated conjecture generation have accelerated the discovery of formulas for specific constants.",
      "similarity": 0.818
    },
    {
      "source": "rEQqBZIz49",
      "target": "SMK0f8JoKF",
      "similarity": 0.8164
    },
    {
      "source": "rEQqBZIz49",
      "target": "D2hhkU5O48",
      "similarity": 0.8152
    },
    {
      "source": "rEQqBZIz49",
      "target": "2p03KljxE9",
      "similarity": 0.8112
    },
    {
      "source": "VoayJihXra",
      "target": "9qS3HzSDNv",
      "similarity": 0.9366
    },
    {
      "source": "VoayJihXra",
      "target": "relying on backward propagation",
      "similarity": 0.9192
    },
    {
      "source": "VoayJihXra",
      "target": "d7pr2doXn3",
      "similarity": 0.9141
    },
    {
      "source": "VoayJihXra",
      "target": "Furthermore",
      "similarity": 0.8949
    },
    {
      "source": "VoayJihXra",
      "target": "This construction process is fundamental to applying graph-based models",
      "similarity": 0.8893
    },
    {
      "source": "AJpUZd8Clb",
      "target": "To this end",
      "similarity": 0.9157
    },
    {
      "source": "AJpUZd8Clb",
      "target": "90DC0IvlSs",
      "similarity": 0.9034
    },
    {
      "source": "AJpUZd8Clb",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.893
    },
    {
      "source": "AJpUZd8Clb",
      "target": "E48QvQppIN",
      "similarity": 0.8832
    },
    {
      "source": "AJpUZd8Clb",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8825
    },
    {
      "source": "nrRkAAAufl",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.7921
    },
    {
      "source": "nrRkAAAufl",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.7635
    },
    {
      "source": "nrRkAAAufl",
      "target": "gyHoR6uFhU",
      "similarity": 0.7567
    },
    {
      "source": "nrRkAAAufl",
      "target": "1F8xTfv6ah",
      "similarity": 0.7557
    },
    {
      "source": "nrRkAAAufl",
      "target": "P6IVIoGRRg",
      "similarity": 0.7551
    },
    {
      "source": "JYTQ6ELUVO",
      "target": "To tackle this challenge",
      "similarity": 0.8743
    },
    {
      "source": "JYTQ6ELUVO",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8495
    },
    {
      "source": "JYTQ6ELUVO",
      "target": "tu3qwNjrtw",
      "similarity": 0.8448
    },
    {
      "source": "JYTQ6ELUVO",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8443
    },
    {
      "source": "JYTQ6ELUVO",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8443
    },
    {
      "source": "gVkX9QMBO3",
      "target": "To address this",
      "similarity": 0.8879
    },
    {
      "source": "gVkX9QMBO3",
      "target": "6F6qwdycgJ",
      "similarity": 0.8747
    },
    {
      "source": "gVkX9QMBO3",
      "target": "9EqQC2ct4H",
      "similarity": 0.866
    },
    {
      "source": "gVkX9QMBO3",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8575
    },
    {
      "source": "gVkX9QMBO3",
      "target": "cmfyMV45XO",
      "similarity": 0.8557
    },
    {
      "source": "UgPoHhYQ2U",
      "target": "uNomADvF3s",
      "similarity": 0.8418
    },
    {
      "source": "UgPoHhYQ2U",
      "target": "Furthermore",
      "similarity": 0.8326
    },
    {
      "source": "UgPoHhYQ2U",
      "target": "By playing against itself",
      "similarity": 0.8188
    },
    {
      "source": "UgPoHhYQ2U",
      "target": "In this paper",
      "similarity": 0.7925
    },
    {
      "source": "UgPoHhYQ2U",
      "target": "YwzxpZW3p7",
      "similarity": 0.7899
    },
    {
      "source": "Other methods have focused on the low-budget regime",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8553
    },
    {
      "source": "Other methods have focused on the low-budget regime",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8479
    },
    {
      "source": "Other methods have focused on the low-budget regime",
      "target": "explore the effects of calibration data",
      "similarity": 0.8397
    },
    {
      "source": "Other methods have focused on the low-budget regime",
      "target": "5pd78GmXC6",
      "similarity": 0.8376
    },
    {
      "source": "Other methods have focused on the low-budget regime",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8366
    },
    {
      "source": "As the line between \"\"low\"\" and \"\"high\"\" budgets varies by problem",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.855
    },
    {
      "source": "As the line between \"\"low\"\" and \"\"high\"\" budgets varies by problem",
      "target": "84WmbzikPP",
      "similarity": 0.8515
    },
    {
      "source": "As the line between \"\"low\"\" and \"\"high\"\" budgets varies by problem",
      "target": "8eNLKk5by4",
      "similarity": 0.8512
    },
    {
      "source": "As the line between \"\"low\"\" and \"\"high\"\" budgets varies by problem",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8412
    },
    {
      "source": "As the line between \"\"low\"\" and \"\"high\"\" budgets varies by problem",
      "target": "show that BoneMet can be readily adopted to build versatile",
      "similarity": 0.8408
    },
    {
      "source": "this is a serious issue in practice.",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8687
    },
    {
      "source": "this is a serious issue in practice.",
      "target": "zCZnEXF3bN",
      "similarity": 0.8584
    },
    {
      "source": "this is a serious issue in practice.",
      "target": "HaX48yksVL",
      "similarity": 0.8538
    },
    {
      "source": "this is a serious issue in practice.",
      "target": "4xWQS2z77v",
      "similarity": 0.8519
    },
    {
      "source": "this is a serious issue in practice.",
      "target": "p4cLtzk4oe",
      "similarity": 0.8487
    },
    {
      "source": "We propose *uncertainty coverage*",
      "target": "KxQRHOre9D",
      "similarity": 0.8633
    },
    {
      "source": "We propose *uncertainty coverage*",
      "target": "However",
      "similarity": 0.8609
    },
    {
      "source": "We propose *uncertainty coverage*",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8603
    },
    {
      "source": "We propose *uncertainty coverage*",
      "target": "Despite its simplicity",
      "similarity": 0.8457
    },
    {
      "source": "We propose *uncertainty coverage*",
      "target": "To improve reconstruction",
      "similarity": 0.8377
    },
    {
      "source": "an objective which generalizes a variety of low- and high-budget objectives",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8473
    },
    {
      "source": "an objective which generalizes a variety of low- and high-budget objectives",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8364
    },
    {
      "source": "an objective which generalizes a variety of low- and high-budget objectives",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8282
    },
    {
      "source": "an objective which generalizes a variety of low- and high-budget objectives",
      "target": "To address these shortcomings",
      "similarity": 0.8267
    },
    {
      "source": "an objective which generalizes a variety of low- and high-budget objectives",
      "target": "Second",
      "similarity": 0.8239
    },
    {
      "source": "as well as natural",
      "target": "Furthermore",
      "similarity": 0.8762
    },
    {
      "source": "as well as natural",
      "target": "kGvXIlIVLM",
      "similarity": 0.8407
    },
    {
      "source": "as well as natural",
      "target": "fN8yLc3eA7",
      "similarity": 0.8325
    },
    {
      "source": "as well as natural",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8205
    },
    {
      "source": "as well as natural",
      "target": "ReItdfwMcg",
      "similarity": 0.8185
    },
    {
      "source": "We call greedy optimization of the estimate Uncertainty Herding;",
      "target": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "similarity": 0.8323
    },
    {
      "source": "We call greedy optimization of the estimate Uncertainty Herding;",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8163
    },
    {
      "source": "We call greedy optimization of the estimate Uncertainty Herding;",
      "target": "These results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM",
      "similarity": 0.8157
    },
    {
      "source": "We call greedy optimization of the estimate Uncertainty Herding;",
      "target": "In this paper",
      "similarity": 0.8131
    },
    {
      "source": "We call greedy optimization of the estimate Uncertainty Herding;",
      "target": "NKotdPUc3L",
      "similarity": 0.8065
    },
    {
      "source": "this simple method is computationally fast",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8781
    },
    {
      "source": "this simple method is computationally fast",
      "target": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "similarity": 0.8541
    },
    {
      "source": "this simple method is computationally fast",
      "target": "However",
      "similarity": 0.8455
    },
    {
      "source": "this simple method is computationally fast",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.842
    },
    {
      "source": "this simple method is computationally fast",
      "target": "lsvGqR6OTf",
      "similarity": 0.8418
    },
    {
      "source": "and we prove that it nearly optimizes the distribution-level coverage.",
      "target": "We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness.  We investigate a variety of instantiations of our framework",
      "similarity": 0.8683
    },
    {
      "source": "and we prove that it nearly optimizes the distribution-level coverage.",
      "target": "In this work",
      "similarity": 0.8645
    },
    {
      "source": "and we prove that it nearly optimizes the distribution-level coverage.",
      "target": "(BoneMet) dataset",
      "similarity": 0.8641
    },
    {
      "source": "and we prove that it nearly optimizes the distribution-level coverage.",
      "target": "0fJfVOSUra",
      "similarity": 0.8595
    },
    {
      "source": "and we prove that it nearly optimizes the distribution-level coverage.",
      "target": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "similarity": 0.8546
    },
    {
      "source": "In experimental validation across a variety of active learning tasks",
      "target": "79ZkWgY2FI",
      "similarity": 0.8542
    },
    {
      "source": "In experimental validation across a variety of active learning tasks",
      "target": "FFE.\"",
      "similarity": 0.8532
    },
    {
      "source": "In experimental validation across a variety of active learning tasks",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8458
    },
    {
      "source": "In experimental validation across a variety of active learning tasks",
      "target": "Ke2BEL4csm",
      "similarity": 0.8445
    },
    {
      "source": "In experimental validation across a variety of active learning tasks",
      "target": "tU074jg2vS",
      "similarity": 0.8376
    },
    {
      "source": "our proposal matches or beats state-of-the-art performance in essentially all cases;",
      "target": "phAlw3JPms",
      "similarity": 0.8357
    },
    {
      "source": "our proposal matches or beats state-of-the-art performance in essentially all cases;",
      "target": "In this paper",
      "similarity": 0.8352
    },
    {
      "source": "our proposal matches or beats state-of-the-art performance in essentially all cases;",
      "target": "As a case study",
      "similarity": 0.8326
    },
    {
      "source": "our proposal matches or beats state-of-the-art performance in essentially all cases;",
      "target": "4O0v4s3IzY",
      "similarity": 0.8165
    },
    {
      "source": "our proposal matches or beats state-of-the-art performance in essentially all cases;",
      "target": "Qzd4BloAjQ",
      "similarity": 0.8155
    },
    {
      "source": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8309
    },
    {
      "source": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "target": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "similarity": 0.822
    },
    {
      "source": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "target": "eC2a2IndIt",
      "similarity": 0.8211
    },
    {
      "source": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "target": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "similarity": 0.8184
    },
    {
      "source": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "target": "fXJCqdUSVG",
      "similarity": 0.8115
    },
    {
      "source": "dCcY2pyNIO",
      "target": "model weights",
      "similarity": 0.9163
    },
    {
      "source": "dCcY2pyNIO",
      "target": "In particular",
      "similarity": 0.8985
    },
    {
      "source": "dCcY2pyNIO",
      "target": "il5yUQsrjC",
      "similarity": 0.8813
    },
    {
      "source": "dCcY2pyNIO",
      "target": "8eNLKk5by4",
      "similarity": 0.8643
    },
    {
      "source": "dCcY2pyNIO",
      "target": "XdRIno98gG",
      "similarity": 0.8579
    },
    {
      "source": "1qq1QJKM5q",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8818
    },
    {
      "source": "1qq1QJKM5q",
      "target": "ff2V3UR9sC",
      "similarity": 0.8811
    },
    {
      "source": "1qq1QJKM5q",
      "target": "respectively. On skill retention tasks",
      "similarity": 0.8726
    },
    {
      "source": "1qq1QJKM5q",
      "target": "L9eBxTCpQG",
      "similarity": 0.8725
    },
    {
      "source": "1qq1QJKM5q",
      "target": "eWocmTQn7H",
      "similarity": 0.8702
    },
    {
      "source": "In this paper we propose Conditionally Overlapping Mixture of ExperTs (COMET)",
      "target": "gFvRRCnQvX",
      "similarity": 0.8654
    },
    {
      "source": "In this paper we propose Conditionally Overlapping Mixture of ExperTs (COMET)",
      "target": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "similarity": 0.861
    },
    {
      "source": "In this paper we propose Conditionally Overlapping Mixture of ExperTs (COMET)",
      "target": "In light of this",
      "similarity": 0.855
    },
    {
      "source": "In this paper we propose Conditionally Overlapping Mixture of ExperTs (COMET)",
      "target": "cC3LxGZasH",
      "similarity": 0.8425
    },
    {
      "source": "In this paper we propose Conditionally Overlapping Mixture of ExperTs (COMET)",
      "target": "To address this issue",
      "similarity": 0.8423
    },
    {
      "source": "We demonstrate the effectiveness of COMET on a range of tasks",
      "target": "1tBvzOYTLF",
      "similarity": 0.859
    },
    {
      "source": "We demonstrate the effectiveness of COMET on a range of tasks",
      "target": "wgDB1QuxIA",
      "similarity": 0.8104
    },
    {
      "source": "We demonstrate the effectiveness of COMET on a range of tasks",
      "target": "of 24 OOD scenarios. Further",
      "similarity": 0.8003
    },
    {
      "source": "We demonstrate the effectiveness of COMET on a range of tasks",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.7933
    },
    {
      "source": "We demonstrate the effectiveness of COMET on a range of tasks",
      "target": "lIVRgt4nLv",
      "similarity": 0.7911
    },
    {
      "source": "KRMSH1GxUK",
      "target": "improve performance. Results are empirically validated on a 2D image regression",
      "similarity": 0.8052
    },
    {
      "source": "KRMSH1GxUK",
      "target": "Building on these insights",
      "similarity": 0.7975
    },
    {
      "source": "KRMSH1GxUK",
      "target": "U3PBITXNG6",
      "similarity": 0.7951
    },
    {
      "source": "KRMSH1GxUK",
      "target": "mzL19kKE3r",
      "similarity": 0.7936
    },
    {
      "source": "KRMSH1GxUK",
      "target": "Second",
      "similarity": 0.79
    },
    {
      "source": "WcZLG8XxhD",
      "target": "Empirically",
      "similarity": 0.7922
    },
    {
      "source": "WcZLG8XxhD",
      "target": "To effectively learn the representation of the entire surface-attributed graph",
      "similarity": 0.7846
    },
    {
      "source": "WcZLG8XxhD",
      "target": "I6UbnkUveF",
      "similarity": 0.7744
    },
    {
      "source": "WcZLG8XxhD",
      "target": "In each case",
      "similarity": 0.7738
    },
    {
      "source": "WcZLG8XxhD",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.7565
    },
    {
      "source": "We simplify and generalize past work on learning-augmented frequency estimation. Our first contribution is a learning-augmented variant of the Misra-Gries algorithm which improves upon the error of learned CountMin and learned CountSketch and achieves the state-of-the-art performance of randomized algorithms (Aamand et al.",
      "target": "xI71dsS3o4",
      "similarity": 0.7857
    },
    {
      "source": "We simplify and generalize past work on learning-augmented frequency estimation. Our first contribution is a learning-augmented variant of the Misra-Gries algorithm which improves upon the error of learned CountMin and learned CountSketch and achieves the state-of-the-art performance of randomized algorithms (Aamand et al.",
      "target": "E36NHwe7Zc",
      "similarity": 0.7829
    },
    {
      "source": "We simplify and generalize past work on learning-augmented frequency estimation. Our first contribution is a learning-augmented variant of the Misra-Gries algorithm which improves upon the error of learned CountMin and learned CountSketch and achieves the state-of-the-art performance of randomized algorithms (Aamand et al.",
      "target": "NTHMw8S1Ow",
      "similarity": 0.7819
    },
    {
      "source": "We simplify and generalize past work on learning-augmented frequency estimation. Our first contribution is a learning-augmented variant of the Misra-Gries algorithm which improves upon the error of learned CountMin and learned CountSketch and achieves the state-of-the-art performance of randomized algorithms (Aamand et al.",
      "target": "layer-progressive neuron locating",
      "similarity": 0.7813
    },
    {
      "source": "We simplify and generalize past work on learning-augmented frequency estimation. Our first contribution is a learning-augmented variant of the Misra-Gries algorithm which improves upon the error of learned CountMin and learned CountSketch and achieves the state-of-the-art performance of randomized algorithms (Aamand et al.",
      "target": "In this work",
      "similarity": 0.7783
    },
    {
      "source": "WQQyJbr5Lh",
      "target": "1qgZXeMTTU",
      "similarity": 0.8683
    },
    {
      "source": "WQQyJbr5Lh",
      "target": "DL9txImSzm",
      "similarity": 0.8607
    },
    {
      "source": "WQQyJbr5Lh",
      "target": "YFxfcQMLWX",
      "similarity": 0.8544
    },
    {
      "source": "WQQyJbr5Lh",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8531
    },
    {
      "source": "WQQyJbr5Lh",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8428
    },
    {
      "source": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "target": "Building on these insights",
      "similarity": 0.861
    },
    {
      "source": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "target": "VpWki1v2P8",
      "similarity": 0.8544
    },
    {
      "source": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "target": "xiQNfYl33p",
      "similarity": 0.8501
    },
    {
      "source": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "target": "To this end",
      "similarity": 0.8487
    },
    {
      "source": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "target": "FEZOLWexPb",
      "similarity": 0.8448
    },
    {
      "source": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "target": "9kJperA2a4",
      "similarity": 0.8551
    },
    {
      "source": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "target": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "similarity": 0.8384
    },
    {
      "source": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8375
    },
    {
      "source": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "target": "SG1R2H3fa1",
      "similarity": 0.8363
    },
    {
      "source": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "target": "Inspired by MuZero",
      "similarity": 0.8311
    },
    {
      "source": "In this paper",
      "target": "Yet",
      "similarity": 0.889
    },
    {
      "source": "In this paper",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.88
    },
    {
      "source": "In this paper",
      "target": "IuU0wcO0mo",
      "similarity": 0.8789
    },
    {
      "source": "In this paper",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8783
    },
    {
      "source": "In this paper",
      "target": "affects effectiveness in two downstream proxy model applications: data",
      "similarity": 0.8763
    },
    {
      "source": "We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome.",
      "target": "Subsequently",
      "similarity": 0.8449
    },
    {
      "source": "We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome.",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8353
    },
    {
      "source": "We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome.",
      "target": "reZKq6hjOZ",
      "similarity": 0.8309
    },
    {
      "source": "We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome.",
      "target": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "similarity": 0.8295
    },
    {
      "source": "We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome.",
      "target": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "similarity": 0.8276
    },
    {
      "source": "And we further provide a",
      "target": "UqrFPhcmFp",
      "similarity": 0.7862
    },
    {
      "source": "And we further provide a",
      "target": "PY56Wur7S0",
      "similarity": 0.7838
    },
    {
      "source": "And we further provide a",
      "target": "CI5Cj0vktS",
      "similarity": 0.7784
    },
    {
      "source": "And we further provide a",
      "target": "To address this",
      "similarity": 0.7779
    },
    {
      "source": "And we further provide a",
      "target": "G82uQztzxl",
      "similarity": 0.7779
    },
    {
      "source": "layer-progressive neuron locating",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8681
    },
    {
      "source": "layer-progressive neuron locating",
      "target": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "similarity": 0.8572
    },
    {
      "source": "layer-progressive neuron locating",
      "target": "NTHMw8S1Ow",
      "similarity": 0.8531
    },
    {
      "source": "layer-progressive neuron locating",
      "target": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "similarity": 0.8316
    },
    {
      "source": "layer-progressive neuron locating",
      "target": "Additionally",
      "similarity": 0.8304
    },
    {
      "source": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "target": "GpUv1FvZi1",
      "similarity": 0.8928
    },
    {
      "source": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "target": "We perform detailed analyses",
      "similarity": 0.8737
    },
    {
      "source": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "target": "Ax0i933gtp",
      "similarity": 0.8553
    },
    {
      "source": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "target": "TDy5Ih78b4",
      "similarity": 0.8494
    },
    {
      "source": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "target": "We evaluate performance across three integrated tasks",
      "similarity": 0.8491
    },
    {
      "source": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8363
    },
    {
      "source": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "target": "FZv3kPHTtB",
      "similarity": 0.8249
    },
    {
      "source": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "target": "To address this challenge",
      "similarity": 0.818
    },
    {
      "source": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "target": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "similarity": 0.815
    },
    {
      "source": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "target": "FFE.\"",
      "similarity": 0.8125
    },
    {
      "source": "Additionally",
      "target": "Because of this",
      "similarity": 0.8543
    },
    {
      "source": "Additionally",
      "target": "5x88lQ2MsH",
      "similarity": 0.8505
    },
    {
      "source": "Additionally",
      "target": "NIkfix2eDQ",
      "similarity": 0.8351
    },
    {
      "source": "Additionally",
      "target": "bilities",
      "similarity": 0.8344
    },
    {
      "source": "Additionally",
      "target": "We further analyze the key effects of these neurons on the image classification task",
      "similarity": 0.8252
    },
    {
      "source": "We further analyze the key effects of these neurons on the image classification task",
      "target": "iOMnn1hSBO",
      "similarity": 0.8568
    },
    {
      "source": "We further analyze the key effects of these neurons on the image classification task",
      "target": "To this end",
      "similarity": 0.8513
    },
    {
      "source": "We further analyze the key effects of these neurons on the image classification task",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8464
    },
    {
      "source": "We further analyze the key effects of these neurons on the image classification task",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.844
    },
    {
      "source": "We further analyze the key effects of these neurons on the image classification task",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.8418
    },
    {
      "source": "The project website including implementation code is available at https://foundation-model-research.github.io/NeuronPath/.\"",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8219
    },
    {
      "source": "The project website including implementation code is available at https://foundation-model-research.github.io/NeuronPath/.\"",
      "target": "mobile devices.\"",
      "similarity": 0.8199
    },
    {
      "source": "The project website including implementation code is available at https://foundation-model-research.github.io/NeuronPath/.\"",
      "target": "exgLs4snap",
      "similarity": 0.816
    },
    {
      "source": "The project website including implementation code is available at https://foundation-model-research.github.io/NeuronPath/.\"",
      "target": "fMNRYBvcQN",
      "similarity": 0.8111
    },
    {
      "source": "The project website including implementation code is available at https://foundation-model-research.github.io/NeuronPath/.\"",
      "target": "sVNfWhtaJC",
      "similarity": 0.8041
    },
    {
      "source": "RWJX5F5I9g",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8702
    },
    {
      "source": "RWJX5F5I9g",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.8697
    },
    {
      "source": "RWJX5F5I9g",
      "target": "pRCOZllZdT",
      "similarity": 0.8623
    },
    {
      "source": "RWJX5F5I9g",
      "target": "il5yUQsrjC",
      "similarity": 0.8616
    },
    {
      "source": "RWJX5F5I9g",
      "target": "9VMW4iXfKt",
      "similarity": 0.8555
    },
    {
      "source": "CkUHtnyhpY",
      "target": "v1rFkElnIn",
      "similarity": 0.8644
    },
    {
      "source": "CkUHtnyhpY",
      "target": "2vHIHrJAcI",
      "similarity": 0.8585
    },
    {
      "source": "CkUHtnyhpY",
      "target": "world perspective. To address this",
      "similarity": 0.8564
    },
    {
      "source": "CkUHtnyhpY",
      "target": "jTEKTdI3K9",
      "similarity": 0.8541
    },
    {
      "source": "CkUHtnyhpY",
      "target": "NfCEVihkdC",
      "similarity": 0.8527
    },
    {
      "source": "Neural Network (BPB-NN)",
      "target": "2TasVD7FXp",
      "similarity": 0.8412
    },
    {
      "source": "Neural Network (BPB-NN)",
      "target": "In particular",
      "similarity": 0.838
    },
    {
      "source": "Neural Network (BPB-NN)",
      "target": "mechanism",
      "similarity": 0.8247
    },
    {
      "source": "Neural Network (BPB-NN)",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8242
    },
    {
      "source": "Neural Network (BPB-NN)",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.8228
    },
    {
      "source": "goBaGHLAdP",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8395
    },
    {
      "source": "goBaGHLAdP",
      "target": "space",
      "similarity": 0.8365
    },
    {
      "source": "goBaGHLAdP",
      "target": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "similarity": 0.8289
    },
    {
      "source": "goBaGHLAdP",
      "target": "4iFSBgxvIO",
      "similarity": 0.8271
    },
    {
      "source": "goBaGHLAdP",
      "target": "9ca9eHNrdH",
      "similarity": 0.8268
    },
    {
      "source": "9Ieq8jQNAl",
      "target": "jTEKTdI3K9",
      "similarity": 0.893
    },
    {
      "source": "9Ieq8jQNAl",
      "target": "v1rFkElnIn",
      "similarity": 0.8755
    },
    {
      "source": "9Ieq8jQNAl",
      "target": "Y6LPWBo2HP",
      "similarity": 0.875
    },
    {
      "source": "9Ieq8jQNAl",
      "target": "9kJperA2a4",
      "similarity": 0.8712
    },
    {
      "source": "9Ieq8jQNAl",
      "target": "wWnsoLhHwt",
      "similarity": 0.8672
    },
    {
      "source": "Despite these potential benefits",
      "target": "Antib6Uovh",
      "similarity": 0.835
    },
    {
      "source": "Despite these potential benefits",
      "target": "cmfyMV45XO",
      "similarity": 0.8314
    },
    {
      "source": "Despite these potential benefits",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8293
    },
    {
      "source": "Despite these potential benefits",
      "target": "To address this",
      "similarity": 0.8218
    },
    {
      "source": "Despite these potential benefits",
      "target": "6F6qwdycgJ",
      "similarity": 0.8217
    },
    {
      "source": "In this paper",
      "target": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "similarity": 0.8473
    },
    {
      "source": "In this paper",
      "target": "gVnJFY8nCM",
      "similarity": 0.8444
    },
    {
      "source": "In this paper",
      "target": "We validate our approach in two tasks",
      "similarity": 0.8365
    },
    {
      "source": "In this paper",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8286
    },
    {
      "source": "In this paper",
      "target": "fMNRYBvcQN",
      "similarity": 0.8189
    },
    {
      "source": "Based on the simulated feedback",
      "target": "Lastly",
      "similarity": 0.8933
    },
    {
      "source": "Based on the simulated feedback",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8471
    },
    {
      "source": "Based on the simulated feedback",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8346
    },
    {
      "source": "Based on the simulated feedback",
      "target": "GMwRl2e9Y1",
      "similarity": 0.8233
    },
    {
      "source": "Based on the simulated feedback",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8185
    },
    {
      "source": "6HcnC3pPkp",
      "target": "kX8h23UG6v",
      "similarity": 0.9068
    },
    {
      "source": "6HcnC3pPkp",
      "target": "In this paper",
      "similarity": 0.8609
    },
    {
      "source": "6HcnC3pPkp",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.858
    },
    {
      "source": "6HcnC3pPkp",
      "target": "In this work",
      "similarity": 0.8362
    },
    {
      "source": "6HcnC3pPkp",
      "target": "MxbEiFRf39",
      "similarity": 0.8347
    },
    {
      "source": "dWsdJAXjQD",
      "target": "TljGdvzFq2",
      "similarity": 0.8225
    },
    {
      "source": "dWsdJAXjQD",
      "target": "works leads to a multifaceted problem",
      "similarity": 0.8136
    },
    {
      "source": "dWsdJAXjQD",
      "target": "composition (MoDeGPT)",
      "similarity": 0.8107
    },
    {
      "source": "dWsdJAXjQD",
      "target": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "similarity": 0.805
    },
    {
      "source": "dWsdJAXjQD",
      "target": "In this paper",
      "similarity": 0.8043
    },
    {
      "source": "However",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8517
    },
    {
      "source": "However",
      "target": "leading proprietary models (e.g.",
      "similarity": 0.835
    },
    {
      "source": "However",
      "target": "We validate our approach in two tasks",
      "similarity": 0.8327
    },
    {
      "source": "However",
      "target": "Next",
      "similarity": 0.8207
    },
    {
      "source": "However",
      "target": "dual shape representation",
      "similarity": 0.8189
    },
    {
      "source": "For example",
      "target": "254NJe9JEw",
      "similarity": 0.8628
    },
    {
      "source": "For example",
      "target": "tDIL7UXmSS",
      "similarity": 0.8571
    },
    {
      "source": "For example",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8546
    },
    {
      "source": "For example",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8514
    },
    {
      "source": "For example",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8461
    },
    {
      "source": "To this end",
      "target": "We validate our approach in two tasks",
      "similarity": 0.803
    },
    {
      "source": "To this end",
      "target": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "similarity": 0.796
    },
    {
      "source": "To this end",
      "target": "aXwukBD6M6",
      "similarity": 0.7919
    },
    {
      "source": "To this end",
      "target": "dual shape representation",
      "similarity": 0.791
    },
    {
      "source": "To this end",
      "target": "In this paper",
      "similarity": 0.7898
    },
    {
      "source": "As a first method for automated proof optimization",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.7972
    },
    {
      "source": "As a first method for automated proof optimization",
      "target": "mNVR9jJYqK",
      "similarity": 0.7847
    },
    {
      "source": "As a first method for automated proof optimization",
      "target": "vyflgpwfJW",
      "similarity": 0.7829
    },
    {
      "source": "As a first method for automated proof optimization",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.7795
    },
    {
      "source": "As a first method for automated proof optimization",
      "target": "dw9VUsSHGB",
      "similarity": 0.7741
    },
    {
      "source": "We find that naively applying LLMs to proof optimization falls short",
      "target": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "similarity": 0.8266
    },
    {
      "source": "We find that naively applying LLMs to proof optimization falls short",
      "target": "Moreover",
      "similarity": 0.8261
    },
    {
      "source": "We find that naively applying LLMs to proof optimization falls short",
      "target": "amDkNPVWcn",
      "similarity": 0.8169
    },
    {
      "source": "We find that naively applying LLMs to proof optimization falls short",
      "target": "RWJX5F5I9g",
      "similarity": 0.8138
    },
    {
      "source": "We find that naively applying LLMs to proof optimization falls short",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.8086
    },
    {
      "source": "Aly68Y5Es0",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8574
    },
    {
      "source": "Aly68Y5Es0",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8413
    },
    {
      "source": "Aly68Y5Es0",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8399
    },
    {
      "source": "Aly68Y5Es0",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8343
    },
    {
      "source": "Aly68Y5Es0",
      "target": "5pd78GmXC6",
      "similarity": 0.8335
    },
    {
      "source": "PIpGN5Ko3v",
      "target": "4O0v4s3IzY",
      "similarity": 0.8852
    },
    {
      "source": "PIpGN5Ko3v",
      "target": "is often a non-linear function",
      "similarity": 0.8826
    },
    {
      "source": "PIpGN5Ko3v",
      "target": "Our experiments verify that",
      "similarity": 0.8651
    },
    {
      "source": "PIpGN5Ko3v",
      "target": "phAlw3JPms",
      "similarity": 0.8539
    },
    {
      "source": "PIpGN5Ko3v",
      "target": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "similarity": 0.8536
    },
    {
      "source": "WOt1owGfuN",
      "target": "traditional energy-based models",
      "similarity": 0.8679
    },
    {
      "source": "WOt1owGfuN",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8518
    },
    {
      "source": "WOt1owGfuN",
      "target": "5pd78GmXC6",
      "similarity": 0.8473
    },
    {
      "source": "WOt1owGfuN",
      "target": "8enWnd6Gp3",
      "similarity": 0.8438
    },
    {
      "source": "WOt1owGfuN",
      "target": "MxbEiFRf39",
      "similarity": 0.8422
    },
    {
      "source": "or8mMhmyRV",
      "target": "03OkC0LKDD",
      "similarity": 0.8294
    },
    {
      "source": "or8mMhmyRV",
      "target": "U834XHJuqk",
      "similarity": 0.8255
    },
    {
      "source": "or8mMhmyRV",
      "target": "ROpY0qRUXL",
      "similarity": 0.8205
    },
    {
      "source": "or8mMhmyRV",
      "target": "EcrdmRT99M",
      "similarity": 0.8194
    },
    {
      "source": "or8mMhmyRV",
      "target": "78tc3EiUrN",
      "similarity": 0.8173
    },
    {
      "source": "oWdzUpOlkX",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8721
    },
    {
      "source": "oWdzUpOlkX",
      "target": "riieAeQBJm",
      "similarity": 0.8627
    },
    {
      "source": "oWdzUpOlkX",
      "target": "kwCHcaeHrf",
      "similarity": 0.8573
    },
    {
      "source": "oWdzUpOlkX",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8534
    },
    {
      "source": "oWdzUpOlkX",
      "target": "dAeET8gxqg",
      "similarity": 0.8475
    },
    {
      "source": "SQnitDuow6",
      "target": "Jszf4et48m",
      "similarity": 0.8673
    },
    {
      "source": "SQnitDuow6",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8666
    },
    {
      "source": "SQnitDuow6",
      "target": "6bKEWevgSd",
      "similarity": 0.8533
    },
    {
      "source": "SQnitDuow6",
      "target": "In response",
      "similarity": 0.8487
    },
    {
      "source": "SQnitDuow6",
      "target": "eiqrnVaeIw",
      "similarity": 0.8467
    },
    {
      "source": "In this paper",
      "target": "component of real-world software development.\"",
      "similarity": 0.8355
    },
    {
      "source": "In this paper",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8345
    },
    {
      "source": "In this paper",
      "target": "We introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution",
      "similarity": 0.834
    },
    {
      "source": "In this paper",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8271
    },
    {
      "source": "In this paper",
      "target": "calibration data is also crucial to post-training pruning",
      "similarity": 0.8237
    },
    {
      "source": "FviefuxmeW",
      "target": "Finally",
      "similarity": 0.8882
    },
    {
      "source": "FviefuxmeW",
      "target": "E48QvQppIN",
      "similarity": 0.8795
    },
    {
      "source": "FviefuxmeW",
      "target": "2pNLknCTvG",
      "similarity": 0.8677
    },
    {
      "source": "FviefuxmeW",
      "target": "In this work",
      "similarity": 0.8673
    },
    {
      "source": "FviefuxmeW",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8655
    },
    {
      "source": "pHOH8FVrTp",
      "target": "In this paper",
      "similarity": 0.8503
    },
    {
      "source": "pHOH8FVrTp",
      "target": "i3T0wvQDKg",
      "similarity": 0.8476
    },
    {
      "source": "pHOH8FVrTp",
      "target": "6VhDQP7WGX",
      "similarity": 0.8437
    },
    {
      "source": "pHOH8FVrTp",
      "target": "In this study",
      "similarity": 0.8124
    },
    {
      "source": "pHOH8FVrTp",
      "target": "BkftcwIVmR",
      "similarity": 0.8122
    },
    {
      "source": "model of the mixture specializes in distinct parts of the data distribution",
      "target": "KlN00vQEY2",
      "similarity": 0.866
    },
    {
      "source": "model of the mixture specializes in distinct parts of the data distribution",
      "target": "Beyond performance evaluations",
      "similarity": 0.8632
    },
    {
      "source": "model of the mixture specializes in distinct parts of the data distribution",
      "target": "Aye5wL6TCn",
      "similarity": 0.8627
    },
    {
      "source": "model of the mixture specializes in distinct parts of the data distribution",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8526
    },
    {
      "source": "model of the mixture specializes in distinct parts of the data distribution",
      "target": "dRz3cizftU",
      "similarity": 0.8509
    },
    {
      "source": "0uRc3CfJIQ",
      "target": "real-world datasets than prior work and",
      "similarity": 0.8854
    },
    {
      "source": "0uRc3CfJIQ",
      "target": "TKuYWeFE6S",
      "similarity": 0.8673
    },
    {
      "source": "0uRc3CfJIQ",
      "target": "oeP6OL7ouB",
      "similarity": 0.8588
    },
    {
      "source": "0uRc3CfJIQ",
      "target": "In this task",
      "similarity": 0.8349
    },
    {
      "source": "0uRc3CfJIQ",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.8244
    },
    {
      "source": "irrtPRFksw",
      "target": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "similarity": 0.8513
    },
    {
      "source": "irrtPRFksw",
      "target": "goFpCuJalN",
      "similarity": 0.8385
    },
    {
      "source": "irrtPRFksw",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8382
    },
    {
      "source": "irrtPRFksw",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8264
    },
    {
      "source": "irrtPRFksw",
      "target": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "similarity": 0.8249
    },
    {
      "source": "ULGbw2URE3",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.9087
    },
    {
      "source": "ULGbw2URE3",
      "target": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "similarity": 0.8957
    },
    {
      "source": "ULGbw2URE3",
      "target": "However",
      "similarity": 0.8757
    },
    {
      "source": "ULGbw2URE3",
      "target": "c61unr33XA",
      "similarity": 0.8586
    },
    {
      "source": "ULGbw2URE3",
      "target": "{Subsequently}",
      "similarity": 0.8538
    },
    {
      "source": "qssVptHTPN",
      "target": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "similarity": 0.8625
    },
    {
      "source": "qssVptHTPN",
      "target": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "similarity": 0.8605
    },
    {
      "source": "qssVptHTPN",
      "target": "Qzd4BloAjQ",
      "similarity": 0.856
    },
    {
      "source": "qssVptHTPN",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.8517
    },
    {
      "source": "qssVptHTPN",
      "target": "tijmpS9Vy2",
      "similarity": 0.8332
    },
    {
      "source": "6jxUsDAdAu",
      "target": "reZKq6hjOZ",
      "similarity": 0.8629
    },
    {
      "source": "6jxUsDAdAu",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8561
    },
    {
      "source": "6jxUsDAdAu",
      "target": "ymt4crbbXh",
      "similarity": 0.8439
    },
    {
      "source": "6jxUsDAdAu",
      "target": "G328D1xt4W",
      "similarity": 0.838
    },
    {
      "source": "6jxUsDAdAu",
      "target": "of the NTK",
      "similarity": 0.8298
    },
    {
      "source": "goFpCuJalN",
      "target": "HMrcv7Q4Ub",
      "similarity": 0.8477
    },
    {
      "source": "goFpCuJalN",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8223
    },
    {
      "source": "goFpCuJalN",
      "target": "generating time series of tabular data",
      "similarity": 0.8125
    },
    {
      "source": "goFpCuJalN",
      "target": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "similarity": 0.8119
    },
    {
      "source": "goFpCuJalN",
      "target": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "similarity": 0.8103
    },
    {
      "source": "DC8bsa9bzY",
      "target": "xnF2U0ro7b",
      "similarity": 0.8572
    },
    {
      "source": "DC8bsa9bzY",
      "target": "Additionally",
      "similarity": 0.8414
    },
    {
      "source": "DC8bsa9bzY",
      "target": "Finally",
      "similarity": 0.8385
    },
    {
      "source": "DC8bsa9bzY",
      "target": "cADpvQgnqg",
      "similarity": 0.834
    },
    {
      "source": "DC8bsa9bzY",
      "target": "Excitingly",
      "similarity": 0.8305
    },
    {
      "source": "raUnLe0Z04",
      "target": "FPQzXME9NK",
      "similarity": 0.8103
    },
    {
      "source": "raUnLe0Z04",
      "target": "mNVR9jJYqK",
      "similarity": 0.8096
    },
    {
      "source": "raUnLe0Z04",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.789
    },
    {
      "source": "raUnLe0Z04",
      "target": "vyflgpwfJW",
      "similarity": 0.7888
    },
    {
      "source": "raUnLe0Z04",
      "target": "1DVgysiIt7",
      "similarity": 0.7818
    },
    {
      "source": "BI2int5SAC",
      "target": "90DC0IvlSs",
      "similarity": 0.8959
    },
    {
      "source": "BI2int5SAC",
      "target": "Fty0wTcemV",
      "similarity": 0.8781
    },
    {
      "source": "BI2int5SAC",
      "target": "(1) make no assumptions on the data",
      "similarity": 0.8763
    },
    {
      "source": "BI2int5SAC",
      "target": "to address these failure modes",
      "similarity": 0.8731
    },
    {
      "source": "BI2int5SAC",
      "target": "fWRBheSJth",
      "similarity": 0.8707
    },
    {
      "source": "2PRpcmJecX",
      "target": "the introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric",
      "similarity": 0.847
    },
    {
      "source": "2PRpcmJecX",
      "target": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "similarity": 0.7921
    },
    {
      "source": "2PRpcmJecX",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.7828
    },
    {
      "source": "2PRpcmJecX",
      "target": "We introduce Spider 2.0",
      "similarity": 0.7793
    },
    {
      "source": "2PRpcmJecX",
      "target": "Real-world causal structures",
      "similarity": 0.7788
    },
    {
      "source": "LqhorpRLIm",
      "target": "Iht4NNVqk0",
      "similarity": 0.847
    },
    {
      "source": "LqhorpRLIm",
      "target": "PrefEval comprises 3",
      "similarity": 0.8245
    },
    {
      "source": "LqhorpRLIm",
      "target": "5YbuOTUFQ4",
      "similarity": 0.8073
    },
    {
      "source": "LqhorpRLIm",
      "target": "Building on these insights",
      "similarity": 0.7988
    },
    {
      "source": "LqhorpRLIm",
      "target": "8rbkePAapb",
      "similarity": 0.7952
    },
    {
      "source": "XwUrzurG94",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8332
    },
    {
      "source": "XwUrzurG94",
      "target": "By leveraging online data collection",
      "similarity": 0.8249
    },
    {
      "source": "XwUrzurG94",
      "target": "In this paper",
      "similarity": 0.819
    },
    {
      "source": "XwUrzurG94",
      "target": "such events remains limited. Given the critical importance of accurately forecasting",
      "similarity": 0.8135
    },
    {
      "source": "XwUrzurG94",
      "target": "Remarkably",
      "similarity": 0.811
    },
    {
      "source": "Mfnh1Sqdwf",
      "target": "kX8h23UG6v",
      "similarity": 0.8793
    },
    {
      "source": "Mfnh1Sqdwf",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8522
    },
    {
      "source": "Mfnh1Sqdwf",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8517
    },
    {
      "source": "Mfnh1Sqdwf",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8501
    },
    {
      "source": "Mfnh1Sqdwf",
      "target": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "similarity": 0.8498
    },
    {
      "source": "FEpAUnS7f7",
      "target": "TtKN1TpvUu",
      "similarity": 0.8964
    },
    {
      "source": "FEpAUnS7f7",
      "target": "Finally",
      "similarity": 0.8567
    },
    {
      "source": "FEpAUnS7f7",
      "target": "jY5oml9fe9",
      "similarity": 0.8504
    },
    {
      "source": "FEpAUnS7f7",
      "target": "In experiments with GPT-4",
      "similarity": 0.8485
    },
    {
      "source": "FEpAUnS7f7",
      "target": "Bpn8q40n1n",
      "similarity": 0.8469
    },
    {
      "source": "7d2JwGbxhA",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8405
    },
    {
      "source": "7d2JwGbxhA",
      "target": "nzjSvVZBIp",
      "similarity": 0.8157
    },
    {
      "source": "7d2JwGbxhA",
      "target": "rfdblE10qm",
      "similarity": 0.8143
    },
    {
      "source": "7d2JwGbxhA",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8117
    },
    {
      "source": "7d2JwGbxhA",
      "target": "m51BgoqvbP",
      "similarity": 0.8092
    },
    {
      "source": "7UgQjFEadn",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8045
    },
    {
      "source": "7UgQjFEadn",
      "target": "K2jOacHUlO",
      "similarity": 0.8017
    },
    {
      "source": "7UgQjFEadn",
      "target": "rfdblE10qm",
      "similarity": 0.8006
    },
    {
      "source": "7UgQjFEadn",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.795
    },
    {
      "source": "7UgQjFEadn",
      "target": "44z7HL4mfX",
      "similarity": 0.7947
    },
    {
      "source": "8bjspmAMBk",
      "target": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "similarity": 0.8106
    },
    {
      "source": "8bjspmAMBk",
      "target": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "similarity": 0.8088
    },
    {
      "source": "8bjspmAMBk",
      "target": "4NTrco82W0",
      "similarity": 0.8083
    },
    {
      "source": "8bjspmAMBk",
      "target": "5YbuOTUFQ4",
      "similarity": 0.8073
    },
    {
      "source": "8bjspmAMBk",
      "target": "jJXZvPe5z0",
      "similarity": 0.8009
    },
    {
      "source": "G82uQztzxl",
      "target": "However",
      "similarity": 0.8287
    },
    {
      "source": "G82uQztzxl",
      "target": "EbCUbPZjM1",
      "similarity": 0.8215
    },
    {
      "source": "G82uQztzxl",
      "target": "GhexuBLxbO",
      "similarity": 0.8114
    },
    {
      "source": "G82uQztzxl",
      "target": "However",
      "similarity": 0.8038
    },
    {
      "source": "G82uQztzxl",
      "target": "Beyond performance evaluations",
      "similarity": 0.8
    },
    {
      "source": "qFw2RFJS5g",
      "target": "N0ETIi580T",
      "similarity": 0.8253
    },
    {
      "source": "qFw2RFJS5g",
      "target": "layer-progressive neuron locating",
      "similarity": 0.8124
    },
    {
      "source": "qFw2RFJS5g",
      "target": "with compression rates of 25-30%. The compression process can be completed on",
      "similarity": 0.8119
    },
    {
      "source": "qFw2RFJS5g",
      "target": "Reducing the number of layers can decrease this delay",
      "similarity": 0.8057
    },
    {
      "source": "qFw2RFJS5g",
      "target": "UN6Ik6OCx8",
      "similarity": 0.8055
    },
    {
      "source": "msEr27EejF",
      "target": "The best-performing model",
      "similarity": 0.8672
    },
    {
      "source": "msEr27EejF",
      "target": "5AtlfHYCPa",
      "similarity": 0.8557
    },
    {
      "source": "msEr27EejF",
      "target": "For example",
      "similarity": 0.8535
    },
    {
      "source": "msEr27EejF",
      "target": "To tackle this challenge",
      "similarity": 0.8478
    },
    {
      "source": "msEr27EejF",
      "target": "Essg9kb4yx",
      "similarity": 0.8477
    },
    {
      "source": "CAssIgPN4I",
      "target": "Then",
      "similarity": 0.863
    },
    {
      "source": "CAssIgPN4I",
      "target": "eaTqsptDPL",
      "similarity": 0.8501
    },
    {
      "source": "CAssIgPN4I",
      "target": "In this work",
      "similarity": 0.8497
    },
    {
      "source": "CAssIgPN4I",
      "target": "hjROBHstZ3",
      "similarity": 0.8414
    },
    {
      "source": "CAssIgPN4I",
      "target": "wide dissemination",
      "similarity": 0.8373
    },
    {
      "source": "Kwo20MWWCb",
      "target": "nx9Z5Kva96",
      "similarity": 0.8963
    },
    {
      "source": "Kwo20MWWCb",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8778
    },
    {
      "source": "Kwo20MWWCb",
      "target": "kbm6tsICar",
      "similarity": 0.8714
    },
    {
      "source": "Kwo20MWWCb",
      "target": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "similarity": 0.8685
    },
    {
      "source": "Kwo20MWWCb",
      "target": "2mqb8bPHeb",
      "similarity": 0.8617
    },
    {
      "source": "EDoD3DgivF",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.8829
    },
    {
      "source": "EDoD3DgivF",
      "target": "L238BAx0wP",
      "similarity": 0.8481
    },
    {
      "source": "EDoD3DgivF",
      "target": "uClUUJk05H",
      "similarity": 0.8472
    },
    {
      "source": "EDoD3DgivF",
      "target": "eLLBILFRsA",
      "similarity": 0.8356
    },
    {
      "source": "EDoD3DgivF",
      "target": "In this work",
      "similarity": 0.8207
    },
    {
      "source": "iyJOUELYir",
      "target": "behavior across compute scale? We find that small- and large-scale language",
      "similarity": 0.8452
    },
    {
      "source": "iyJOUELYir",
      "target": "First",
      "similarity": 0.8312
    },
    {
      "source": "iyJOUELYir",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8303
    },
    {
      "source": "iyJOUELYir",
      "target": "UN6Ik6OCx8",
      "similarity": 0.83
    },
    {
      "source": "iyJOUELYir",
      "target": "8TBGdH3t6a",
      "similarity": 0.8268
    },
    {
      "source": "component of real-world software development.\"",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.864
    },
    {
      "source": "component of real-world software development.\"",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8639
    },
    {
      "source": "component of real-world software development.\"",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.8521
    },
    {
      "source": "component of real-world software development.\"",
      "target": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "similarity": 0.8496
    },
    {
      "source": "component of real-world software development.\"",
      "target": "7VkHffT5X2",
      "similarity": 0.8439
    },
    {
      "source": "HPSAkIHRbb",
      "target": "population shifts. In particular",
      "similarity": 0.8545
    },
    {
      "source": "HPSAkIHRbb",
      "target": "These findings highlight the significant room for improvement in current reward models.\"",
      "similarity": 0.8493
    },
    {
      "source": "HPSAkIHRbb",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8468
    },
    {
      "source": "HPSAkIHRbb",
      "target": "zcTLpIfj9u",
      "similarity": 0.8457
    },
    {
      "source": "HPSAkIHRbb",
      "target": "dqyuCsBvn9",
      "similarity": 0.8453
    },
    {
      "source": "Although existing LLM-based moderators can detect harmful content",
      "target": "7bAjVh3CG3",
      "similarity": 0.8684
    },
    {
      "source": "Although existing LLM-based moderators can detect harmful content",
      "target": "a dependency parser",
      "similarity": 0.8324
    },
    {
      "source": "Although existing LLM-based moderators can detect harmful content",
      "target": "lvw3UgeVxS",
      "similarity": 0.829
    },
    {
      "source": "Although existing LLM-based moderators can detect harmful content",
      "target": "Building on these insights",
      "similarity": 0.8208
    },
    {
      "source": "Although existing LLM-based moderators can detect harmful content",
      "target": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "similarity": 0.8204
    },
    {
      "source": "Accurate risk assessment allows platforms with different safety thresholds to tailor content filtering and rejection. In this paper",
      "target": "TljGdvzFq2",
      "similarity": 0.8554
    },
    {
      "source": "Accurate risk assessment allows platforms with different safety thresholds to tailor content filtering and rejection. In this paper",
      "target": "faceswaps",
      "similarity": 0.8499
    },
    {
      "source": "Accurate risk assessment allows platforms with different safety thresholds to tailor content filtering and rejection. In this paper",
      "target": "K7xpl3LZQp",
      "similarity": 0.8405
    },
    {
      "source": "Accurate risk assessment allows platforms with different safety thresholds to tailor content filtering and rejection. In this paper",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8375
    },
    {
      "source": "Accurate risk assessment allows platforms with different safety thresholds to tailor content filtering and rejection. In this paper",
      "target": "VoayJihXra",
      "similarity": 0.8375
    },
    {
      "source": "To address the lack of annotations on levels of severity",
      "target": "Although employing a cascaded pipeline introduces more stages",
      "similarity": 0.8521
    },
    {
      "source": "To address the lack of annotations on levels of severity",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8452
    },
    {
      "source": "To address the lack of annotations on levels of severity",
      "target": "zigzag spaghetti (ZS)",
      "similarity": 0.8451
    },
    {
      "source": "To address the lack of annotations on levels of severity",
      "target": "wsWCVrH9dv",
      "similarity": 0.8343
    },
    {
      "source": "To address the lack of annotations on levels of severity",
      "target": "TWnUgSAWNw",
      "similarity": 0.8164
    },
    {
      "source": "8TBGdH3t6a",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8549
    },
    {
      "source": "8TBGdH3t6a",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8379
    },
    {
      "source": "8TBGdH3t6a",
      "target": "aN57tSd5Us",
      "similarity": 0.8363
    },
    {
      "source": "8TBGdH3t6a",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8356
    },
    {
      "source": "8TBGdH3t6a",
      "target": "Building on these insights",
      "similarity": 0.8326
    },
    {
      "source": "din0lGfZFd",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8636
    },
    {
      "source": "din0lGfZFd",
      "target": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "similarity": 0.8467
    },
    {
      "source": "din0lGfZFd",
      "target": "HN8V0flwJF",
      "similarity": 0.844
    },
    {
      "source": "din0lGfZFd",
      "target": "the lack of data for language-guided 3D scene editing",
      "similarity": 0.8409
    },
    {
      "source": "din0lGfZFd",
      "target": "Neb17mimVH",
      "similarity": 0.8379
    },
    {
      "source": "SThJXvucjQ",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.7971
    },
    {
      "source": "SThJXvucjQ",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.7944
    },
    {
      "source": "SThJXvucjQ",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.7942
    },
    {
      "source": "SThJXvucjQ",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.7926
    },
    {
      "source": "SThJXvucjQ",
      "target": "As its pre-training capabilities are related to perplexity (PPL)",
      "similarity": 0.7914
    },
    {
      "source": "Prior work developed UCB-style",
      "target": "Based on this",
      "similarity": 0.9296
    },
    {
      "source": "Prior work developed UCB-style",
      "target": "oYSsbY3G4o",
      "similarity": 0.8514
    },
    {
      "source": "Prior work developed UCB-style",
      "target": "GtvuNrk58a",
      "similarity": 0.8473
    },
    {
      "source": "Prior work developed UCB-style",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.8219
    },
    {
      "source": "Prior work developed UCB-style",
      "target": "DzGe40glxs",
      "similarity": 0.8208
    },
    {
      "source": "algorithms for this problem in the multi-armed (Wu et al.",
      "target": "TDy5Ih78b4",
      "similarity": 0.8981
    },
    {
      "source": "algorithms for this problem in the multi-armed (Wu et al.",
      "target": "JytL2MrlLT",
      "similarity": 0.8867
    },
    {
      "source": "algorithms for this problem in the multi-armed (Wu et al.",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8846
    },
    {
      "source": "algorithms for this problem in the multi-armed (Wu et al.",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8815
    },
    {
      "source": "algorithms for this problem in the multi-armed (Wu et al.",
      "target": "1NprT9Kz0d",
      "similarity": 0.8812
    },
    {
      "source": "linear (Kazerouni et al.",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8332
    },
    {
      "source": "linear (Kazerouni et al.",
      "target": "QsA3YzNUxA",
      "similarity": 0.8312
    },
    {
      "source": "linear (Kazerouni et al.",
      "target": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "similarity": 0.8226
    },
    {
      "source": "linear (Kazerouni et al.",
      "target": "5yDS32hKJc",
      "similarity": 0.8104
    },
    {
      "source": "linear (Kazerouni et al.",
      "target": "dEg5SdGaiq",
      "similarity": 0.8084
    },
    {
      "source": "However",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8519
    },
    {
      "source": "However",
      "target": "n2NidsYDop",
      "similarity": 0.8489
    },
    {
      "source": "However",
      "target": "INqLJwqUmc",
      "similarity": 0.8478
    },
    {
      "source": "However",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8462
    },
    {
      "source": "However",
      "target": "BksqWM8737",
      "similarity": 0.8303
    },
    {
      "source": "is often a non-linear function",
      "target": "4O0v4s3IzY",
      "similarity": 0.9049
    },
    {
      "source": "is often a non-linear function",
      "target": "Our experiments verify that",
      "similarity": 0.8933
    },
    {
      "source": "is often a non-linear function",
      "target": "phAlw3JPms",
      "similarity": 0.893
    },
    {
      "source": "is often a non-linear function",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.8917
    },
    {
      "source": "is often a non-linear function",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8898
    },
    {
      "source": "In this paper",
      "target": "6qUUgw9bAZ",
      "similarity": 0.8415
    },
    {
      "source": "In this paper",
      "target": "We target data inherently supported on manifolds",
      "similarity": 0.8072
    },
    {
      "source": "In this paper",
      "target": "YOpa6dTrpt",
      "similarity": 0.8067
    },
    {
      "source": "In this paper",
      "target": "kRoWeLTpL4",
      "similarity": 0.8057
    },
    {
      "source": "In this paper",
      "target": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "similarity": 0.7981
    },
    {
      "source": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "target": "We validate our approach in two tasks",
      "similarity": 0.8577
    },
    {
      "source": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "target": "dual shape representation",
      "similarity": 0.8469
    },
    {
      "source": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8459
    },
    {
      "source": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8437
    },
    {
      "source": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "target": "Unlike prior constructions that run encrypted search on the server side",
      "similarity": 0.8387
    },
    {
      "source": "Subsequently",
      "target": "xJXq6FkqEw",
      "similarity": 0.8903
    },
    {
      "source": "Subsequently",
      "target": "ajxAJ8GUX4",
      "similarity": 0.8758
    },
    {
      "source": "Subsequently",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.874
    },
    {
      "source": "Subsequently",
      "target": "In this paper",
      "similarity": 0.8691
    },
    {
      "source": "Subsequently",
      "target": "ymt4crbbXh",
      "similarity": 0.8663
    },
    {
      "source": "Finally",
      "target": "Glm7Kj47nN",
      "similarity": 0.8696
    },
    {
      "source": "Finally",
      "target": "HN8V0flwJF",
      "similarity": 0.8402
    },
    {
      "source": "Finally",
      "target": "However",
      "similarity": 0.8282
    },
    {
      "source": "Finally",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.827
    },
    {
      "source": "Finally",
      "target": "In this work",
      "similarity": 0.8251
    },
    {
      "source": "jpSLXoRKnH",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.796
    },
    {
      "source": "jpSLXoRKnH",
      "target": "B5iOSxM2I0",
      "similarity": 0.7855
    },
    {
      "source": "jpSLXoRKnH",
      "target": "CGON8Btleu",
      "similarity": 0.7794
    },
    {
      "source": "jpSLXoRKnH",
      "target": "mDKxlfraAn",
      "similarity": 0.7716
    },
    {
      "source": "jpSLXoRKnH",
      "target": "(1) Sparse attention patterns",
      "similarity": 0.7697
    },
    {
      "source": "and performing sophisticated tasks",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8578
    },
    {
      "source": "and performing sophisticated tasks",
      "target": "VQwI055flA",
      "similarity": 0.8455
    },
    {
      "source": "and performing sophisticated tasks",
      "target": "78tc3EiUrN",
      "similarity": 0.839
    },
    {
      "source": "and performing sophisticated tasks",
      "target": "Here",
      "similarity": 0.8384
    },
    {
      "source": "and performing sophisticated tasks",
      "target": "For linear activation functions",
      "similarity": 0.8376
    },
    {
      "source": "memorization",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8496
    },
    {
      "source": "memorization",
      "target": "Real-world causal structures",
      "similarity": 0.8359
    },
    {
      "source": "memorization",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8328
    },
    {
      "source": "memorization",
      "target": "FAfxvdv1Dy",
      "similarity": 0.828
    },
    {
      "source": "memorization",
      "target": "6ouZaBzeNO",
      "similarity": 0.8244
    },
    {
      "source": "To address this challenge",
      "target": "Pacmann shows better scalability",
      "similarity": 0.8058
    },
    {
      "source": "To address this challenge",
      "target": "CbfsKHiWEn",
      "similarity": 0.7992
    },
    {
      "source": "To address this challenge",
      "target": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "similarity": 0.7962
    },
    {
      "source": "To address this challenge",
      "target": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "similarity": 0.7864
    },
    {
      "source": "To address this challenge",
      "target": "uREg3OHjLL",
      "similarity": 0.7844
    },
    {
      "source": "Through extensive experiments",
      "target": "We perform detailed analyses",
      "similarity": 0.8207
    },
    {
      "source": "Through extensive experiments",
      "target": "MKEHCx25xp",
      "similarity": 0.8206
    },
    {
      "source": "Through extensive experiments",
      "target": "Ax0i933gtp",
      "similarity": 0.818
    },
    {
      "source": "Through extensive experiments",
      "target": "sZJNkorXMk",
      "similarity": 0.8128
    },
    {
      "source": "Through extensive experiments",
      "target": "pPQPQ7Yd58",
      "similarity": 0.8048
    },
    {
      "source": "data",
      "target": "NJxCpMt0sf",
      "similarity": 0.883
    },
    {
      "source": "data",
      "target": "ThRMTCgpvo",
      "similarity": 0.873
    },
    {
      "source": "data",
      "target": "a single GPU in a few hours",
      "similarity": 0.864
    },
    {
      "source": "data",
      "target": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "similarity": 0.8547
    },
    {
      "source": "data",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8475
    },
    {
      "source": "Specifically",
      "target": "HpUs2EXjOl",
      "similarity": 0.871
    },
    {
      "source": "Specifically",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8683
    },
    {
      "source": "Specifically",
      "target": "rwqShzb9li",
      "similarity": 0.8643
    },
    {
      "source": "Specifically",
      "target": "Finally",
      "similarity": 0.8609
    },
    {
      "source": "Specifically",
      "target": "zpENPcQSj1",
      "similarity": 0.8589
    },
    {
      "source": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "target": "pre-training data",
      "similarity": 0.8609
    },
    {
      "source": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "target": "we propose the Ternary Choice MoE (TC-MoE)",
      "similarity": 0.8554
    },
    {
      "source": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "target": "JytL2MrlLT",
      "similarity": 0.851
    },
    {
      "source": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8502
    },
    {
      "source": "as critical complexity---where reliance on non-generalizable behavior peaks",
      "target": "the costliness of the labels",
      "similarity": 0.8486
    },
    {
      "source": "upper bound of LLMs' generalization capabilities.",
      "target": "mkuB677eMM",
      "similarity": 0.8406
    },
    {
      "source": "upper bound of LLMs' generalization capabilities.",
      "target": "q5EZ7gKcnW",
      "similarity": 0.8319
    },
    {
      "source": "upper bound of LLMs' generalization capabilities.",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8301
    },
    {
      "source": "upper bound of LLMs' generalization capabilities.",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8298
    },
    {
      "source": "upper bound of LLMs' generalization capabilities.",
      "target": "FCMpUOZkxi",
      "similarity": 0.8258
    },
    {
      "source": "As model size increases",
      "target": "GbgCRJedQ7",
      "similarity": 0.889
    },
    {
      "source": "As model size increases",
      "target": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "similarity": 0.8526
    },
    {
      "source": "As model size increases",
      "target": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "similarity": 0.8353
    },
    {
      "source": "As model size increases",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8275
    },
    {
      "source": "As model size increases",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.8247
    },
    {
      "source": "suggesting that larger models can handle more complex reasoning tasks before over-relying on",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8513
    },
    {
      "source": "suggesting that larger models can handle more complex reasoning tasks before over-relying on",
      "target": "6F6qwdycgJ",
      "similarity": 0.8511
    },
    {
      "source": "suggesting that larger models can handle more complex reasoning tasks before over-relying on",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8397
    },
    {
      "source": "suggesting that larger models can handle more complex reasoning tasks before over-relying on",
      "target": "4O0v4s3IzY",
      "similarity": 0.8345
    },
    {
      "source": "suggesting that larger models can handle more complex reasoning tasks before over-relying on",
      "target": "pZiyCaVuti",
      "similarity": 0.834
    },
    {
      "source": "memorization.",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8914
    },
    {
      "source": "memorization.",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8881
    },
    {
      "source": "memorization.",
      "target": "GRMfXcAAFh",
      "similarity": 0.8787
    },
    {
      "source": "memorization.",
      "target": "cADpvQgnqg",
      "similarity": 0.8765
    },
    {
      "source": "memorization.",
      "target": "Furthermore",
      "similarity": 0.8535
    },
    {
      "source": "Leveraging Scylla and the concept of critical complexity",
      "target": "cKlzKs3Nnb",
      "similarity": 0.889
    },
    {
      "source": "Leveraging Scylla and the concept of critical complexity",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8858
    },
    {
      "source": "Leveraging Scylla and the concept of critical complexity",
      "target": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "similarity": 0.8783
    },
    {
      "source": "Leveraging Scylla and the concept of critical complexity",
      "target": "PxlfzEePC0",
      "similarity": 0.868
    },
    {
      "source": "Leveraging Scylla and the concept of critical complexity",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8659
    },
    {
      "source": "both open-sourced models such as LLaMA and Qwen families",
      "target": "Finally",
      "similarity": 0.8673
    },
    {
      "source": "both open-sourced models such as LLaMA and Qwen families",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8628
    },
    {
      "source": "both open-sourced models such as LLaMA and Qwen families",
      "target": "(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories;",
      "similarity": 0.854
    },
    {
      "source": "both open-sourced models such as LLaMA and Qwen families",
      "target": "NHhjczmJjo",
      "similarity": 0.85
    },
    {
      "source": "both open-sourced models such as LLaMA and Qwen families",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8474
    },
    {
      "source": "GPT",
      "target": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "similarity": 0.827
    },
    {
      "source": "GPT",
      "target": "However",
      "similarity": 0.8236
    },
    {
      "source": "GPT",
      "target": "While existing ILP systems can successfully solve small-scale tasks",
      "similarity": 0.822
    },
    {
      "source": "GPT",
      "target": "k2uUeLCrQq",
      "similarity": 0.8175
    },
    {
      "source": "GPT",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.8133
    },
    {
      "source": "understanding of LLMs' generalization capabilities.\"",
      "target": "cfGpIcOIa5",
      "similarity": 0.8617
    },
    {
      "source": "understanding of LLMs' generalization capabilities.\"",
      "target": "Third",
      "similarity": 0.8373
    },
    {
      "source": "understanding of LLMs' generalization capabilities.\"",
      "target": "L238BAx0wP",
      "similarity": 0.8353
    },
    {
      "source": "understanding of LLMs' generalization capabilities.\"",
      "target": "uClUUJk05H",
      "similarity": 0.8353
    },
    {
      "source": "understanding of LLMs' generalization capabilities.\"",
      "target": "JMPOqoe4tl",
      "similarity": 0.8315
    },
    {
      "source": "04qx93Viwj",
      "target": "This paper introduces WebRL",
      "similarity": 0.9004
    },
    {
      "source": "04qx93Viwj",
      "target": "DPzQ5n3mNm",
      "similarity": 0.8916
    },
    {
      "source": "04qx93Viwj",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8609
    },
    {
      "source": "04qx93Viwj",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8595
    },
    {
      "source": "04qx93Viwj",
      "target": "1NprT9Kz0d",
      "similarity": 0.8573
    },
    {
      "source": "9HK2rHNAhd",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8322
    },
    {
      "source": "9HK2rHNAhd",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.8169
    },
    {
      "source": "9HK2rHNAhd",
      "target": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "similarity": 0.8141
    },
    {
      "source": "9HK2rHNAhd",
      "target": "component of real-world software development.\"",
      "similarity": 0.8084
    },
    {
      "source": "9HK2rHNAhd",
      "target": "position reveals interpretable low-rank structure across toy tasks",
      "similarity": 0.8083
    },
    {
      "source": "tyEyYT267x",
      "target": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "similarity": 0.8577
    },
    {
      "source": "tyEyYT267x",
      "target": "7HEMpBTb3R",
      "similarity": 0.8388
    },
    {
      "source": "tyEyYT267x",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8371
    },
    {
      "source": "tyEyYT267x",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.8316
    },
    {
      "source": "tyEyYT267x",
      "target": "FBhKUXK7od",
      "similarity": 0.8316
    },
    {
      "source": "lBB3eSn6fY",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8548
    },
    {
      "source": "lBB3eSn6fY",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8519
    },
    {
      "source": "lBB3eSn6fY",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8306
    },
    {
      "source": "lBB3eSn6fY",
      "target": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "similarity": 0.8295
    },
    {
      "source": "lBB3eSn6fY",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8289
    },
    {
      "source": "g3VCIM94ke",
      "target": "wmV4cIbgl6",
      "similarity": 0.9086
    },
    {
      "source": "g3VCIM94ke",
      "target": "GySIAKEwtZ",
      "similarity": 0.8418
    },
    {
      "source": "g3VCIM94ke",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8386
    },
    {
      "source": "g3VCIM94ke",
      "target": "xP1radUi32",
      "similarity": 0.8346
    },
    {
      "source": "g3VCIM94ke",
      "target": "aTYexOYlLb",
      "similarity": 0.8281
    },
    {
      "source": "roNSXZpUDN",
      "target": "fsDZwS49uY",
      "similarity": 0.8318
    },
    {
      "source": "roNSXZpUDN",
      "target": "To address this",
      "similarity": 0.8098
    },
    {
      "source": "roNSXZpUDN",
      "target": "In text generation",
      "similarity": 0.8063
    },
    {
      "source": "roNSXZpUDN",
      "target": "We demonstrate that",
      "similarity": 0.8045
    },
    {
      "source": "roNSXZpUDN",
      "target": "However",
      "similarity": 0.8031
    },
    {
      "source": "h0ZfDIrj7T",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.8324
    },
    {
      "source": "h0ZfDIrj7T",
      "target": "We release models",
      "similarity": 0.829
    },
    {
      "source": "h0ZfDIrj7T",
      "target": "SyVPiehSbg",
      "similarity": 0.8235
    },
    {
      "source": "h0ZfDIrj7T",
      "target": "GhexuBLxbO",
      "similarity": 0.821
    },
    {
      "source": "h0ZfDIrj7T",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8176
    },
    {
      "source": "DpLFmc09pC",
      "target": "In this paper",
      "similarity": 0.8495
    },
    {
      "source": "DpLFmc09pC",
      "target": "5X5Z7Ffrjb",
      "similarity": 0.8489
    },
    {
      "source": "DpLFmc09pC",
      "target": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "similarity": 0.8468
    },
    {
      "source": "DpLFmc09pC",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.8405
    },
    {
      "source": "DpLFmc09pC",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8367
    },
    {
      "source": "but remains challenging due to complex structural elements like pseudoknots and",
      "target": "RoN6M3i7gJ",
      "similarity": 0.8289
    },
    {
      "source": "but remains challenging due to complex structural elements like pseudoknots and",
      "target": "2U8owdruSQ",
      "similarity": 0.8226
    },
    {
      "source": "but remains challenging due to complex structural elements like pseudoknots and",
      "target": "5pd78GmXC6",
      "similarity": 0.8207
    },
    {
      "source": "but remains challenging due to complex structural elements like pseudoknots and",
      "target": "MxbEiFRf39",
      "similarity": 0.8168
    },
    {
      "source": "but remains challenging due to complex structural elements like pseudoknots and",
      "target": "HsHxSN23rM",
      "similarity": 0.8144
    },
    {
      "source": "limited training data. We introduce DEPfold",
      "target": "wide dissemination",
      "similarity": 0.8449
    },
    {
      "source": "limited training data. We introduce DEPfold",
      "target": "VoayJihXra",
      "similarity": 0.8302
    },
    {
      "source": "limited training data. We introduce DEPfold",
      "target": "dEg5SdGaiq",
      "similarity": 0.8293
    },
    {
      "source": "limited training data. We introduce DEPfold",
      "target": "xiQNfYl33p",
      "similarity": 0.8293
    },
    {
      "source": "limited training data. We introduce DEPfold",
      "target": "FiyS0ecSm0",
      "similarity": 0.8273
    },
    {
      "source": "re-frames RNA secondary structure prediction as a dependency parsing problem.",
      "target": "entities of a sentence (subject",
      "similarity": 0.8124
    },
    {
      "source": "re-frames RNA secondary structure prediction as a dependency parsing problem.",
      "target": "GPT-4",
      "similarity": 0.8108
    },
    {
      "source": "re-frames RNA secondary structure prediction as a dependency parsing problem.",
      "target": "oCUYc7BzXQ",
      "similarity": 0.8087
    },
    {
      "source": "re-frames RNA secondary structure prediction as a dependency parsing problem.",
      "target": "over 67 terabytes of multi-modal medical data",
      "similarity": 0.8076
    },
    {
      "source": "re-frames RNA secondary structure prediction as a dependency parsing problem.",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8055
    },
    {
      "source": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "target": "Qja5s0K3VX",
      "similarity": 0.8402
    },
    {
      "source": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "target": "x33vSZUg0A",
      "similarity": 0.8367
    },
    {
      "source": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "target": "per subject over the entire disease development phases. The dataset consists of",
      "similarity": 0.8295
    },
    {
      "source": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "target": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "similarity": 0.8289
    },
    {
      "source": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "target": "evaluate how well fine details are learned",
      "similarity": 0.8259
    },
    {
      "source": "mechanism for joint prediction of base pairings and their types",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8686
    },
    {
      "source": "mechanism for joint prediction of base pairings and their types",
      "target": "bilities",
      "similarity": 0.8527
    },
    {
      "source": "mechanism for joint prediction of base pairings and their types",
      "target": "a challenge",
      "similarity": 0.8486
    },
    {
      "source": "mechanism for joint prediction of base pairings and their types",
      "target": "fv9XU7CyN2",
      "similarity": 0.8475
    },
    {
      "source": "mechanism for joint prediction of base pairings and their types",
      "target": "BpyHIrpUOL",
      "similarity": 0.8451
    },
    {
      "source": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "target": "KlN00vQEY2",
      "similarity": 0.8501
    },
    {
      "source": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8475
    },
    {
      "source": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "target": "qIbbBSzH6n",
      "similarity": 0.8401
    },
    {
      "source": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.8372
    },
    {
      "source": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8337
    },
    {
      "source": "leverages pretrained language models to predict RNA structure. We evaluate DEPfold on both within-family and cross-family RNA datasets",
      "target": "with up to 62\\% reduction in computation time",
      "similarity": 0.8343
    },
    {
      "source": "leverages pretrained language models to predict RNA structure. We evaluate DEPfold on both within-family and cross-family RNA datasets",
      "target": "GTcEe5fayC",
      "similarity": 0.8127
    },
    {
      "source": "leverages pretrained language models to predict RNA structure. We evaluate DEPfold on both within-family and cross-family RNA datasets",
      "target": "ih3BJmIZbC",
      "similarity": 0.8051
    },
    {
      "source": "leverages pretrained language models to predict RNA structure. We evaluate DEPfold on both within-family and cross-family RNA datasets",
      "target": "an upper bound of excess risk on downstream classification tasks of representations",
      "similarity": 0.8007
    },
    {
      "source": "leverages pretrained language models to predict RNA structure. We evaluate DEPfold on both within-family and cross-family RNA datasets",
      "target": "As a byproduct of our methods",
      "similarity": 0.8003
    },
    {
      "source": "performance in cross-family generalization when trained on data augmented by",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8376
    },
    {
      "source": "performance in cross-family generalization when trained on data augmented by",
      "target": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "similarity": 0.8366
    },
    {
      "source": "performance in cross-family generalization when trained on data augmented by",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8206
    },
    {
      "source": "performance in cross-family generalization when trained on data augmented by",
      "target": "In experiments with GPT-4",
      "similarity": 0.8064
    },
    {
      "source": "performance in cross-family generalization when trained on data augmented by",
      "target": "We validate our approach in two tasks",
      "similarity": 0.8047
    },
    {
      "source": "traditional energy-based models",
      "target": "models. Our study promotes the development of more reliable evaluation methods",
      "similarity": 0.9053
    },
    {
      "source": "traditional energy-based models",
      "target": "DKgAFfCs5F",
      "similarity": 0.8841
    },
    {
      "source": "traditional energy-based models",
      "target": "UchRjcf4z7",
      "similarity": 0.8657
    },
    {
      "source": "traditional energy-based models",
      "target": "iXbUquaWbl",
      "similarity": 0.8617
    },
    {
      "source": "traditional energy-based models",
      "target": "states while still maintaining the ability to precisely recall recent memories with the",
      "similarity": 0.8575
    },
    {
      "source": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "target": "254NJe9JEw",
      "similarity": 0.8879
    },
    {
      "source": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "target": "U3PBITXNG6",
      "similarity": 0.8715
    },
    {
      "source": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8673
    },
    {
      "source": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "target": "l6QnSQizmN",
      "similarity": 0.8669
    },
    {
      "source": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8641
    },
    {
      "source": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "target": "size in stages. We show that this approach not only generalizes prior works like",
      "similarity": 0.859
    },
    {
      "source": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "target": "Qja5s0K3VX",
      "similarity": 0.8586
    },
    {
      "source": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.8578
    },
    {
      "source": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "target": "7El7K1DoyX",
      "similarity": 0.8553
    },
    {
      "source": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8529
    },
    {
      "source": "yUC8pU508S",
      "target": "However",
      "similarity": 0.9071
    },
    {
      "source": "yUC8pU508S",
      "target": "TDy5Ih78b4",
      "similarity": 0.8993
    },
    {
      "source": "yUC8pU508S",
      "target": "prefix distributions",
      "similarity": 0.8967
    },
    {
      "source": "yUC8pU508S",
      "target": "cZWCjan02B",
      "similarity": 0.8804
    },
    {
      "source": "yUC8pU508S",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8736
    },
    {
      "source": "https://github.com/Infini-AI-Lab/APE.\"",
      "target": "To develop SoundCTM",
      "similarity": 0.848
    },
    {
      "source": "https://github.com/Infini-AI-Lab/APE.\"",
      "target": "This paper proposes",
      "similarity": 0.8439
    },
    {
      "source": "https://github.com/Infini-AI-Lab/APE.\"",
      "target": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "similarity": 0.8423
    },
    {
      "source": "https://github.com/Infini-AI-Lab/APE.\"",
      "target": "Zk9guOl9NS",
      "similarity": 0.8392
    },
    {
      "source": "https://github.com/Infini-AI-Lab/APE.\"",
      "target": "wide dissemination",
      "similarity": 0.8376
    },
    {
      "source": "xoXn62FzD0",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8498
    },
    {
      "source": "xoXn62FzD0",
      "target": "works leads to a multifaceted problem",
      "similarity": 0.8363
    },
    {
      "source": "xoXn62FzD0",
      "target": "QCDdI7X3f9",
      "similarity": 0.8333
    },
    {
      "source": "xoXn62FzD0",
      "target": "ples. To our knowledge",
      "similarity": 0.8284
    },
    {
      "source": "xoXn62FzD0",
      "target": "named Pacmann",
      "similarity": 0.8253
    },
    {
      "source": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "target": "However",
      "similarity": 0.8319
    },
    {
      "source": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "target": "VIUisLx8lQ",
      "similarity": 0.8317
    },
    {
      "source": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "target": "je3GZissZc",
      "similarity": 0.8286
    },
    {
      "source": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "target": "L5godAOC2z",
      "similarity": 0.8226
    },
    {
      "source": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8193
    },
    {
      "source": "In support of the probabilistic perspective",
      "target": "zCZnEXF3bN",
      "similarity": 0.9024
    },
    {
      "source": "In support of the probabilistic perspective",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8846
    },
    {
      "source": "In support of the probabilistic perspective",
      "target": "l6QnSQizmN",
      "similarity": 0.8764
    },
    {
      "source": "In support of the probabilistic perspective",
      "target": "wHebuIb6IH",
      "similarity": 0.8742
    },
    {
      "source": "In support of the probabilistic perspective",
      "target": "SRpq5OBpED",
      "similarity": 0.8737
    },
    {
      "source": "[Our system](https://github.com/probcomp/genlm-control) builds on the framework of Lew et al. (2023) and integrates with its _language model probabilistic programming language_",
      "target": "4ktJJBvvUd",
      "similarity": 0.8504
    },
    {
      "source": "[Our system](https://github.com/probcomp/genlm-control) builds on the framework of Lew et al. (2023) and integrates with its _language model probabilistic programming language_",
      "target": "WCRQFlji2q",
      "similarity": 0.8363
    },
    {
      "source": "[Our system](https://github.com/probcomp/genlm-control) builds on the framework of Lew et al. (2023) and integrates with its _language model probabilistic programming language_",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8302
    },
    {
      "source": "[Our system](https://github.com/probcomp/genlm-control) builds on the framework of Lew et al. (2023) and integrates with its _language model probabilistic programming language_",
      "target": "To this end",
      "similarity": 0.8284
    },
    {
      "source": "[Our system](https://github.com/probcomp/genlm-control) builds on the framework of Lew et al. (2023) and integrates with its _language model probabilistic programming language_",
      "target": "FrFQpAgnGE",
      "similarity": 0.8262
    },
    {
      "source": "6NNA0MxhCH",
      "target": "IUmj2dw5se",
      "similarity": 0.8363
    },
    {
      "source": "6NNA0MxhCH",
      "target": "4vzGQcVUG8",
      "similarity": 0.8322
    },
    {
      "source": "6NNA0MxhCH",
      "target": "exgLs4snap",
      "similarity": 0.8293
    },
    {
      "source": "6NNA0MxhCH",
      "target": "TDyE2iuvyc",
      "similarity": 0.8257
    },
    {
      "source": "6NNA0MxhCH",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8215
    },
    {
      "source": "wg1PCg3CUP",
      "target": "VIUisLx8lQ",
      "similarity": 0.8403
    },
    {
      "source": "wg1PCg3CUP",
      "target": "L5godAOC2z",
      "similarity": 0.8392
    },
    {
      "source": "wg1PCg3CUP",
      "target": "L0evcuybH5",
      "similarity": 0.8346
    },
    {
      "source": "wg1PCg3CUP",
      "target": "PZYr22zFyE",
      "similarity": 0.8262
    },
    {
      "source": "wg1PCg3CUP",
      "target": "cbttLtO94Q",
      "similarity": 0.8259
    },
    {
      "source": "TId1SHe8JG",
      "target": "yZ7sn9pyqb",
      "similarity": 0.8735
    },
    {
      "source": "TId1SHe8JG",
      "target": "OuLgaHEmzi",
      "similarity": 0.849
    },
    {
      "source": "TId1SHe8JG",
      "target": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "similarity": 0.8413
    },
    {
      "source": "TId1SHe8JG",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8393
    },
    {
      "source": "TId1SHe8JG",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8321
    },
    {
      "source": "MCHuGOkExF",
      "target": "ig2wk7kK9J",
      "similarity": 0.7812
    },
    {
      "source": "MCHuGOkExF",
      "target": "TrVYEZtSQH",
      "similarity": 0.7689
    },
    {
      "source": "MCHuGOkExF",
      "target": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "similarity": 0.7685
    },
    {
      "source": "MCHuGOkExF",
      "target": "OwpLQrpdwE",
      "similarity": 0.7653
    },
    {
      "source": "MCHuGOkExF",
      "target": "ZCOwwRAaEl",
      "similarity": 0.7647
    },
    {
      "source": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8373
    },
    {
      "source": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8254
    },
    {
      "source": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.8251
    },
    {
      "source": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8192
    },
    {
      "source": "space and demonstrate how optimization-inspired techniques can enhance inference",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.8161
    },
    {
      "source": "scaling over text. Based on this perspective",
      "target": "Prior methods improve accuracy using external semantic supervision",
      "similarity": 0.8514
    },
    {
      "source": "scaling over text. Based on this perspective",
      "target": "Exploration can also be directed using intrinsic rewards",
      "similarity": 0.8503
    },
    {
      "source": "scaling over text. Based on this perspective",
      "target": "Second",
      "similarity": 0.8395
    },
    {
      "source": "scaling over text. Based on this perspective",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8375
    },
    {
      "source": "scaling over text. Based on this perspective",
      "target": "hjROBHstZ3",
      "similarity": 0.8358
    },
    {
      "source": "SEARCH (SFS)**",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.8559
    },
    {
      "source": "SEARCH (SFS)**",
      "target": "In this work",
      "similarity": 0.8516
    },
    {
      "source": "SEARCH (SFS)**",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8489
    },
    {
      "source": "SEARCH (SFS)**",
      "target": "AnL6BuWzxa",
      "similarity": 0.8477
    },
    {
      "source": "SEARCH (SFS)**",
      "target": "0fJfVOSUra",
      "similarity": 0.8469
    },
    {
      "source": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.8505
    },
    {
      "source": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "target": "First",
      "similarity": 0.8486
    },
    {
      "source": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "target": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "similarity": 0.8427
    },
    {
      "source": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "target": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "similarity": 0.8294
    },
    {
      "source": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "target": "4BFzTrIjPN",
      "similarity": 0.8293
    },
    {
      "source": "methods improve exploration and enhance efficiency. Extensive experiments",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8945
    },
    {
      "source": "methods improve exploration and enhance efficiency. Extensive experiments",
      "target": "iXCeQ2m6vT",
      "similarity": 0.871
    },
    {
      "source": "methods improve exploration and enhance efficiency. Extensive experiments",
      "target": "G5DziesYxL",
      "similarity": 0.8575
    },
    {
      "source": "methods improve exploration and enhance efficiency. Extensive experiments",
      "target": "sound",
      "similarity": 0.8565
    },
    {
      "source": "methods improve exploration and enhance efficiency. Extensive experiments",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8537
    },
    {
      "source": "on *HumanEval",
      "target": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "similarity": 0.8717
    },
    {
      "source": "on *HumanEval",
      "target": "When fine-tuned on this task",
      "similarity": 0.8308
    },
    {
      "source": "on *HumanEval",
      "target": "2c7pfOqu9k",
      "similarity": 0.8129
    },
    {
      "source": "on *HumanEval",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8084
    },
    {
      "source": "on *HumanEval",
      "target": "To overcome this",
      "similarity": 0.8048
    },
    {
      "source": "performance gains. For instance",
      "target": "YzxMu1asQi",
      "similarity": 0.8373
    },
    {
      "source": "performance gains. For instance",
      "target": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "similarity": 0.8285
    },
    {
      "source": "performance gains. For instance",
      "target": "5Y9NT6lW21",
      "similarity": 0.8256
    },
    {
      "source": "performance gains. For instance",
      "target": "by constraining the parameter space to our proposed manifold",
      "similarity": 0.8237
    },
    {
      "source": "performance gains. For instance",
      "target": "BlSIKSPhfz",
      "similarity": 0.8237
    },
    {
      "source": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "target": "tGYFikNONB",
      "similarity": 0.847
    },
    {
      "source": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "target": "non-private ANN algorithm.",
      "similarity": 0.8389
    },
    {
      "source": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "target": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "similarity": 0.8324
    },
    {
      "source": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "target": "the state-of-the-art private ANN search schemes",
      "similarity": 0.8201
    },
    {
      "source": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "target": "fXJCqdUSVG",
      "similarity": 0.8113
    },
    {
      "source": "**8.6%** and **4.3%** over the state-of-the-art",
      "target": "EzrZX9bd4G",
      "similarity": 0.9263
    },
    {
      "source": "**8.6%** and **4.3%** over the state-of-the-art",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8838
    },
    {
      "source": "**8.6%** and **4.3%** over the state-of-the-art",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8785
    },
    {
      "source": "**8.6%** and **4.3%** over the state-of-the-art",
      "target": "wHebuIb6IH",
      "similarity": 0.8741
    },
    {
      "source": "**8.6%** and **4.3%** over the state-of-the-art",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8722
    },
    {
      "source": "to find the correct solution. Furthermore",
      "target": "9kJperA2a4",
      "similarity": 0.8661
    },
    {
      "source": "to find the correct solution. Furthermore",
      "target": "ue1Tt3h1VC",
      "similarity": 0.832
    },
    {
      "source": "to find the correct solution. Furthermore",
      "target": "jTEKTdI3K9",
      "similarity": 0.8316
    },
    {
      "source": "to find the correct solution. Furthermore",
      "target": "Y6LPWBo2HP",
      "similarity": 0.83
    },
    {
      "source": "to find the correct solution. Furthermore",
      "target": "v1rFkElnIn",
      "similarity": 0.8287
    },
    {
      "source": "than existing search techniques",
      "target": "zY37C8d6bS",
      "similarity": 0.8875
    },
    {
      "source": "than existing search techniques",
      "target": "However",
      "similarity": 0.8778
    },
    {
      "source": "than existing search techniques",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8733
    },
    {
      "source": "than existing search techniques",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.871
    },
    {
      "source": "than existing search techniques",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8678
    },
    {
      "source": "sampling (Best of N)**.\"",
      "target": "WwwJfkGq0G",
      "similarity": 0.8013
    },
    {
      "source": "sampling (Best of N)**.\"",
      "target": "owP2mymrTD",
      "similarity": 0.7933
    },
    {
      "source": "sampling (Best of N)**.\"",
      "target": "1NprT9Kz0d",
      "similarity": 0.7921
    },
    {
      "source": "sampling (Best of N)**.\"",
      "target": "ExuBFYtCQU",
      "similarity": 0.7889
    },
    {
      "source": "sampling (Best of N)**.\"",
      "target": "OQqNieeivq",
      "similarity": 0.7876
    },
    {
      "source": "sZGZJhaNSe",
      "target": "In this paper",
      "similarity": 0.8616
    },
    {
      "source": "sZGZJhaNSe",
      "target": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "similarity": 0.8442
    },
    {
      "source": "sZGZJhaNSe",
      "target": "HN8V0flwJF",
      "similarity": 0.8316
    },
    {
      "source": "sZGZJhaNSe",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.8309
    },
    {
      "source": "sZGZJhaNSe",
      "target": "Q6PAnqYVpo",
      "similarity": 0.8276
    },
    {
      "source": "vWRwdmA3wU",
      "target": "GLWf2fq0bX",
      "similarity": 0.8331
    },
    {
      "source": "vWRwdmA3wU",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8286
    },
    {
      "source": "vWRwdmA3wU",
      "target": "dmCGjPFVhF",
      "similarity": 0.8212
    },
    {
      "source": "vWRwdmA3wU",
      "target": "In this work",
      "similarity": 0.8161
    },
    {
      "source": "vWRwdmA3wU",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8079
    },
    {
      "source": "SPS6HzVzyt",
      "target": "qn9tBYQHGi",
      "similarity": 0.8501
    },
    {
      "source": "SPS6HzVzyt",
      "target": "In particular",
      "similarity": 0.8445
    },
    {
      "source": "SPS6HzVzyt",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.8236
    },
    {
      "source": "SPS6HzVzyt",
      "target": "vVxeFSR4fU",
      "similarity": 0.8217
    },
    {
      "source": "SPS6HzVzyt",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8178
    },
    {
      "source": "We tie the observed context-parametric inversion to the properties of the finetuning data",
      "target": "NEu8wgPctU",
      "similarity": 0.808
    },
    {
      "source": "We tie the observed context-parametric inversion to the properties of the finetuning data",
      "target": "Additionally",
      "similarity": 0.8041
    },
    {
      "source": "We tie the observed context-parametric inversion to the properties of the finetuning data",
      "target": "First",
      "similarity": 0.7985
    },
    {
      "source": "We tie the observed context-parametric inversion to the properties of the finetuning data",
      "target": "vVxeFSR4fU",
      "similarity": 0.7938
    },
    {
      "source": "We tie the observed context-parametric inversion to the properties of the finetuning data",
      "target": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "similarity": 0.7893
    },
    {
      "source": "FJv8VMPxWi",
      "target": "To tackle this challenge",
      "similarity": 0.8306
    },
    {
      "source": "FJv8VMPxWi",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.8269
    },
    {
      "source": "FJv8VMPxWi",
      "target": "SUc1UOWndp",
      "similarity": 0.8254
    },
    {
      "source": "FJv8VMPxWi",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8189
    },
    {
      "source": "FJv8VMPxWi",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8172
    },
    {
      "source": "In this work",
      "target": "relying on backward propagation",
      "similarity": 0.8962
    },
    {
      "source": "In this work",
      "target": "VoayJihXra",
      "similarity": 0.8759
    },
    {
      "source": "In this work",
      "target": "Furthermore",
      "similarity": 0.8566
    },
    {
      "source": "In this work",
      "target": "9qS3HzSDNv",
      "similarity": 0.854
    },
    {
      "source": "In this work",
      "target": "both computationally intensive and lacking in controllability and transparency",
      "similarity": 0.8413
    },
    {
      "source": "Adapting tools from classical sampling theory",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.841
    },
    {
      "source": "Adapting tools from classical sampling theory",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8271
    },
    {
      "source": "Adapting tools from classical sampling theory",
      "target": "FBhKUXK7od",
      "similarity": 0.8222
    },
    {
      "source": "Adapting tools from classical sampling theory",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8213
    },
    {
      "source": "Adapting tools from classical sampling theory",
      "target": "This toolkit consists of 300 manually collected benign multimodal queries",
      "similarity": 0.8203
    },
    {
      "source": "Sh4FOyZRpv",
      "target": "Using this approach",
      "similarity": 0.8518
    },
    {
      "source": "Sh4FOyZRpv",
      "target": "8VtGeyJyx9",
      "similarity": 0.8371
    },
    {
      "source": "Sh4FOyZRpv",
      "target": "In response",
      "similarity": 0.8356
    },
    {
      "source": "Sh4FOyZRpv",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.826
    },
    {
      "source": "Sh4FOyZRpv",
      "target": "group-unlabeled data",
      "similarity": 0.8249
    },
    {
      "source": "4ZX2a3OKEV",
      "target": "WLSrq1254E",
      "similarity": 0.9024
    },
    {
      "source": "4ZX2a3OKEV",
      "target": "To explore real-time segmentation",
      "similarity": 0.8644
    },
    {
      "source": "4ZX2a3OKEV",
      "target": "we give an analytical example",
      "similarity": 0.8543
    },
    {
      "source": "4ZX2a3OKEV",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8519
    },
    {
      "source": "4ZX2a3OKEV",
      "target": "we propose positive-unlabeled diffusion models",
      "similarity": 0.8513
    },
    {
      "source": "However",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.833
    },
    {
      "source": "However",
      "target": "rTCJ29pkuA",
      "similarity": 0.8316
    },
    {
      "source": "However",
      "target": "NCrFA7dq8T",
      "similarity": 0.828
    },
    {
      "source": "However",
      "target": "T4sMzjy7fO",
      "similarity": 0.8253
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8248
    },
    {
      "source": "This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case.",
      "target": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "similarity": 0.8222
    },
    {
      "source": "This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case.",
      "target": "irrtPRFksw",
      "similarity": 0.8175
    },
    {
      "source": "This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case.",
      "target": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "similarity": 0.806
    },
    {
      "source": "This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case.",
      "target": "BPgK5XW1Nb",
      "similarity": 0.7953
    },
    {
      "source": "This difference in setting has caused many practical challenges as naive gradient-based approaches from supervised learning tend to diverge and cycle in the VI case.",
      "target": "improving convergence and enabling efficient gradient-based optimization",
      "similarity": 0.7944
    },
    {
      "source": "In this work",
      "target": "FSjIrOm1vz",
      "similarity": 0.8289
    },
    {
      "source": "In this work",
      "target": "Motivated by this insight",
      "similarity": 0.8008
    },
    {
      "source": "In this work",
      "target": "Analyzing these high-performing models",
      "similarity": 0.7975
    },
    {
      "source": "In this work",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.7935
    },
    {
      "source": "In this work",
      "target": "OlRjxSuSwl",
      "similarity": 0.7907
    },
    {
      "source": "We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present",
      "target": "tDIL7UXmSS",
      "similarity": 0.8931
    },
    {
      "source": "We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present",
      "target": "To this end",
      "similarity": 0.8509
    },
    {
      "source": "We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present",
      "target": "254NJe9JEw",
      "similarity": 0.8477
    },
    {
      "source": "We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8459
    },
    {
      "source": "We show that our surrogate-based approach has three main benefits: (1) under assumptions that are realistic in practice (when hidden monotone structure is present",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8451
    },
    {
      "source": "Experimentally",
      "target": "MscdsFVZrN",
      "similarity": 0.8526
    },
    {
      "source": "Experimentally",
      "target": "mnna9LUg7P",
      "similarity": 0.8489
    },
    {
      "source": "Experimentally",
      "target": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "similarity": 0.8478
    },
    {
      "source": "Experimentally",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8442
    },
    {
      "source": "Experimentally",
      "target": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "similarity": 0.8372
    },
    {
      "source": "SFN6Wm7YBI",
      "target": "To overcome such limitations",
      "similarity": 0.8579
    },
    {
      "source": "SFN6Wm7YBI",
      "target": "Bpn8q40n1n",
      "similarity": 0.85
    },
    {
      "source": "SFN6Wm7YBI",
      "target": "2fojNANZSv",
      "similarity": 0.8472
    },
    {
      "source": "SFN6Wm7YBI",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8462
    },
    {
      "source": "SFN6Wm7YBI",
      "target": "fXb9BbuyAD",
      "similarity": 0.8445
    },
    {
      "source": "This paper introduces **TORCHTITAN**$^1$",
      "target": "xiQNfYl33p",
      "similarity": 0.886
    },
    {
      "source": "This paper introduces **TORCHTITAN**$^1$",
      "target": "stacking methods. Specifically",
      "similarity": 0.8699
    },
    {
      "source": "This paper introduces **TORCHTITAN**$^1$",
      "target": "instructions",
      "similarity": 0.8688
    },
    {
      "source": "This paper introduces **TORCHTITAN**$^1$",
      "target": "Moreover",
      "similarity": 0.8688
    },
    {
      "source": "This paper introduces **TORCHTITAN**$^1$",
      "target": "Usklli4gMc",
      "similarity": 0.8667
    },
    {
      "source": "As a flexible experimental test bed",
      "target": "54XlM8Clkg",
      "similarity": 0.8027
    },
    {
      "source": "As a flexible experimental test bed",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.7824
    },
    {
      "source": "As a flexible experimental test bed",
      "target": "Through extensive experiments",
      "similarity": 0.78
    },
    {
      "source": "As a flexible experimental test bed",
      "target": "yfW1x7uBS5",
      "similarity": 0.7799
    },
    {
      "source": "As a flexible experimental test bed",
      "target": "learning has exhibited impressive capacities across various healthcare domains",
      "similarity": 0.7781
    },
    {
      "source": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "target": "tees for rank collapse prevention. We present",
      "similarity": 0.8476
    },
    {
      "source": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "target": "MxbEiFRf39",
      "similarity": 0.8439
    },
    {
      "source": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "target": "of our approaches.",
      "similarity": 0.8395
    },
    {
      "source": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "target": "6wOmHdwCC4",
      "similarity": 0.831
    },
    {
      "source": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "target": "KlN00vQEY2",
      "similarity": 0.8289
    },
    {
      "source": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8643
    },
    {
      "source": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8641
    },
    {
      "source": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "target": "Qja5s0K3VX",
      "similarity": 0.8533
    },
    {
      "source": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "target": "instructions",
      "similarity": 0.8522
    },
    {
      "source": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "target": "JYwVijuNA7",
      "similarity": 0.8521
    },
    {
      "source": "nrvoWOWcyg",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.8668
    },
    {
      "source": "nrvoWOWcyg",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8625
    },
    {
      "source": "nrvoWOWcyg",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8595
    },
    {
      "source": "nrvoWOWcyg",
      "target": "WJaUkwci9o",
      "similarity": 0.8569
    },
    {
      "source": "nrvoWOWcyg",
      "target": "latent variables",
      "similarity": 0.8561
    },
    {
      "source": "FPBce2P1er",
      "target": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "similarity": 0.8296
    },
    {
      "source": "FPBce2P1er",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8222
    },
    {
      "source": "FPBce2P1er",
      "target": "In the field of multi-objective optimization",
      "similarity": 0.8195
    },
    {
      "source": "FPBce2P1er",
      "target": "TId1SHe8JG",
      "similarity": 0.8171
    },
    {
      "source": "FPBce2P1er",
      "target": "memorization",
      "similarity": 0.8133
    },
    {
      "source": "eC2a2IndIt",
      "target": "VMV8gefvq8",
      "similarity": 0.8609
    },
    {
      "source": "eC2a2IndIt",
      "target": "Under these assumptions",
      "similarity": 0.8459
    },
    {
      "source": "eC2a2IndIt",
      "target": "Pj06mxCXPl",
      "similarity": 0.827
    },
    {
      "source": "eC2a2IndIt",
      "target": "C45YqeBDUM",
      "similarity": 0.8231
    },
    {
      "source": "eC2a2IndIt",
      "target": "LrmPGtnros",
      "similarity": 0.8083
    },
    {
      "source": "ikr5XomWHS",
      "target": "IuU0wcO0mo",
      "similarity": 0.8475
    },
    {
      "source": "ikr5XomWHS",
      "target": "In this work",
      "similarity": 0.8202
    },
    {
      "source": "ikr5XomWHS",
      "target": "We found that long distance referrals",
      "similarity": 0.8178
    },
    {
      "source": "ikr5XomWHS",
      "target": "AcVpLS86RT",
      "similarity": 0.8166
    },
    {
      "source": "ikr5XomWHS",
      "target": "However",
      "similarity": 0.8143
    },
    {
      "source": "RnJY9WcpA3",
      "target": "pZiyCaVuti",
      "similarity": 0.8723
    },
    {
      "source": "RnJY9WcpA3",
      "target": "4O0v4s3IzY",
      "similarity": 0.8539
    },
    {
      "source": "RnJY9WcpA3",
      "target": "is often a non-linear function",
      "similarity": 0.8529
    },
    {
      "source": "RnJY9WcpA3",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.8491
    },
    {
      "source": "RnJY9WcpA3",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.8489
    },
    {
      "source": "However",
      "target": "vjel3nWP2a",
      "similarity": 0.8341
    },
    {
      "source": "However",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.8096
    },
    {
      "source": "However",
      "target": "In parallel",
      "similarity": 0.8082
    },
    {
      "source": "However",
      "target": "KZu3xhPhke",
      "similarity": 0.8034
    },
    {
      "source": "However",
      "target": "O6znYvxC1U",
      "similarity": 0.8006
    },
    {
      "source": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "target": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "similarity": 0.8343
    },
    {
      "source": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8338
    },
    {
      "source": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "target": "HqjRlT65WX",
      "similarity": 0.8329
    },
    {
      "source": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "target": "behavior across compute scale? We find that small- and large-scale language",
      "similarity": 0.8315
    },
    {
      "source": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "target": "OuLgaHEmzi",
      "similarity": 0.8294
    },
    {
      "source": "To address this",
      "target": "number of parameters required for fine-tuning these models. These compression",
      "similarity": 0.8491
    },
    {
      "source": "To address this",
      "target": "Moreover",
      "similarity": 0.8263
    },
    {
      "source": "To address this",
      "target": "GkWA6NjePN",
      "similarity": 0.824
    },
    {
      "source": "To address this",
      "target": "for VLMs\"",
      "similarity": 0.8176
    },
    {
      "source": "To address this",
      "target": "xP1radUi32",
      "similarity": 0.8143
    },
    {
      "source": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8649
    },
    {
      "source": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8638
    },
    {
      "source": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "target": "1CIUkpoata",
      "similarity": 0.8502
    },
    {
      "source": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "target": "JytL2MrlLT",
      "similarity": 0.8494
    },
    {
      "source": "Our approach utilizes a transformer-based architecture trained on a diverse dataset of simulated sensor designs",
      "target": "1NprT9Kz0d",
      "similarity": 0.8445
    },
    {
      "source": "Experimental results demonstrate the method\u2019s effectiveness across various tactile sensing applications",
      "target": "4JK2XMGUc8",
      "similarity": 0.8319
    },
    {
      "source": "Experimental results demonstrate the method\u2019s effectiveness across various tactile sensing applications",
      "target": "However",
      "similarity": 0.8238
    },
    {
      "source": "Experimental results demonstrate the method\u2019s effectiveness across various tactile sensing applications",
      "target": "0h6v4SpLCY",
      "similarity": 0.823
    },
    {
      "source": "Experimental results demonstrate the method\u2019s effectiveness across various tactile sensing applications",
      "target": "mkNVPGpEPm",
      "similarity": 0.821
    },
    {
      "source": "Experimental results demonstrate the method\u2019s effectiveness across various tactile sensing applications",
      "target": "Se6MgCtRhz",
      "similarity": 0.8163
    },
    {
      "source": "6LtdZCyuZR",
      "target": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "similarity": 0.8101
    },
    {
      "source": "6LtdZCyuZR",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8065
    },
    {
      "source": "6LtdZCyuZR",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8023
    },
    {
      "source": "6LtdZCyuZR",
      "target": "However",
      "similarity": 0.8016
    },
    {
      "source": "6LtdZCyuZR",
      "target": "Neb17mimVH",
      "similarity": 0.7955
    },
    {
      "source": "YbURbViE7l",
      "target": "haJHr4UsQX",
      "similarity": 0.8013
    },
    {
      "source": "YbURbViE7l",
      "target": "X-Ray",
      "similarity": 0.7932
    },
    {
      "source": "YbURbViE7l",
      "target": "implementation",
      "similarity": 0.7928
    },
    {
      "source": "YbURbViE7l",
      "target": "Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods",
      "similarity": 0.7851
    },
    {
      "source": "YbURbViE7l",
      "target": "zZ8fgXHkXi",
      "similarity": 0.7848
    },
    {
      "source": "By defining a topology-aware method to manipulate graph orbits",
      "target": "kOJf7Dklyv",
      "similarity": 0.8236
    },
    {
      "source": "By defining a topology-aware method to manipulate graph orbits",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.8188
    },
    {
      "source": "By defining a topology-aware method to manipulate graph orbits",
      "target": "This work presents Physics-Informed Experimental Design (PIED)",
      "similarity": 0.8169
    },
    {
      "source": "By defining a topology-aware method to manipulate graph orbits",
      "target": "q5EZ7gKcnW",
      "similarity": 0.8099
    },
    {
      "source": "By defining a topology-aware method to manipulate graph orbits",
      "target": "UL2",
      "similarity": 0.8092
    },
    {
      "source": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "target": "SyVPiehSbg",
      "similarity": 0.8357
    },
    {
      "source": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "target": "space are required in general even for outputting a constant factor",
      "similarity": 0.8261
    },
    {
      "source": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "target": "Additionally",
      "similarity": 0.8249
    },
    {
      "source": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "target": "03EkqSCKuO",
      "similarity": 0.8233
    },
    {
      "source": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "target": "We release models",
      "similarity": 0.8204
    },
    {
      "source": "but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.\"",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.7958
    },
    {
      "source": "but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.\"",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.7837
    },
    {
      "source": "but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.\"",
      "target": "To address this",
      "similarity": 0.7825
    },
    {
      "source": "but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.\"",
      "target": "IuU0wcO0mo",
      "similarity": 0.7805
    },
    {
      "source": "but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.\"",
      "target": "1VwWi6zbxs",
      "similarity": 0.7802
    },
    {
      "source": "hJVdwBpWjt",
      "target": "PgXpOOqtyd",
      "similarity": 0.8255
    },
    {
      "source": "hJVdwBpWjt",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8143
    },
    {
      "source": "hJVdwBpWjt",
      "target": "However",
      "similarity": 0.8132
    },
    {
      "source": "hJVdwBpWjt",
      "target": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "similarity": 0.8121
    },
    {
      "source": "hJVdwBpWjt",
      "target": "OFukl9Qg8P",
      "similarity": 0.8116
    },
    {
      "source": "IqHeDe2lbl",
      "target": "To address this issue",
      "similarity": 0.8367
    },
    {
      "source": "IqHeDe2lbl",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8246
    },
    {
      "source": "IqHeDe2lbl",
      "target": "This helps LLMs better interpret and execute the prompts",
      "similarity": 0.8104
    },
    {
      "source": "IqHeDe2lbl",
      "target": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "similarity": 0.795
    },
    {
      "source": "IqHeDe2lbl",
      "target": "aN57tSd5Us",
      "similarity": 0.7924
    },
    {
      "source": "Equ277PBN0",
      "target": "sEMJ1PLSZR",
      "similarity": 0.8172
    },
    {
      "source": "Equ277PBN0",
      "target": "FS2nukC2jv",
      "similarity": 0.8162
    },
    {
      "source": "Equ277PBN0",
      "target": "entities of a sentence (subject",
      "similarity": 0.812
    },
    {
      "source": "Equ277PBN0",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8101
    },
    {
      "source": "Equ277PBN0",
      "target": "significant advancements in the field",
      "similarity": 0.8068
    },
    {
      "source": "IcYDRzcccP",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8161
    },
    {
      "source": "IcYDRzcccP",
      "target": "K3KrOsR6y9",
      "similarity": 0.8093
    },
    {
      "source": "IcYDRzcccP",
      "target": "FjZcwQJX8D",
      "similarity": 0.809
    },
    {
      "source": "IcYDRzcccP",
      "target": "In the field of multi-objective optimization",
      "similarity": 0.8022
    },
    {
      "source": "IcYDRzcccP",
      "target": "ogXkmugNZw",
      "similarity": 0.8022
    },
    {
      "source": "246rHKUnnf",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.8042
    },
    {
      "source": "246rHKUnnf",
      "target": "through the MLP layer. In this paper",
      "similarity": 0.8024
    },
    {
      "source": "246rHKUnnf",
      "target": "tQyh0gnfqW",
      "similarity": 0.7901
    },
    {
      "source": "246rHKUnnf",
      "target": "KWH4UIoQKS",
      "similarity": 0.7881
    },
    {
      "source": "246rHKUnnf",
      "target": "{Subsequently}",
      "similarity": 0.7854
    },
    {
      "source": "Igm9bbkzHC",
      "target": "hjROBHstZ3",
      "similarity": 0.8626
    },
    {
      "source": "Igm9bbkzHC",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8569
    },
    {
      "source": "Igm9bbkzHC",
      "target": "Second",
      "similarity": 0.8567
    },
    {
      "source": "Igm9bbkzHC",
      "target": "VoayJihXra",
      "similarity": 0.8558
    },
    {
      "source": "Igm9bbkzHC",
      "target": "KW8yzAOIZr",
      "similarity": 0.8522
    },
    {
      "source": "Choosing how sensitive the model is to its context is a fundamental functionality",
      "target": "sIE2rI3ZPs",
      "similarity": 0.8563
    },
    {
      "source": "Choosing how sensitive the model is to its context is a fundamental functionality",
      "target": "pDDODPtpx9",
      "similarity": 0.8436
    },
    {
      "source": "Choosing how sensitive the model is to its context is a fundamental functionality",
      "target": "Reweighting (GSR)",
      "similarity": 0.8395
    },
    {
      "source": "Choosing how sensitive the model is to its context is a fundamental functionality",
      "target": "First",
      "similarity": 0.8358
    },
    {
      "source": "Choosing how sensitive the model is to its context is a fundamental functionality",
      "target": "(1) When the representation dimension is regarded as the time axis",
      "similarity": 0.8334
    },
    {
      "source": "In this paper",
      "target": "nzjSvVZBIp",
      "similarity": 0.8533
    },
    {
      "source": "In this paper",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8171
    },
    {
      "source": "In this paper",
      "target": "g0rnZeBguq",
      "similarity": 0.8131
    },
    {
      "source": "In this paper",
      "target": "cfKZ5VrhXt",
      "similarity": 0.8123
    },
    {
      "source": "In this paper",
      "target": "of our proposed method through a new understanding of the contrastive loss of",
      "similarity": 0.8091
    },
    {
      "source": "To guide this search",
      "target": "uHLgDEgiS5",
      "similarity": 0.8397
    },
    {
      "source": "To guide this search",
      "target": "7WaRh4gCXp",
      "similarity": 0.8369
    },
    {
      "source": "To guide this search",
      "target": "implementation",
      "similarity": 0.8348
    },
    {
      "source": "To guide this search",
      "target": "MscdsFVZrN",
      "similarity": 0.8317
    },
    {
      "source": "To guide this search",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8314
    },
    {
      "source": "In this task",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8762
    },
    {
      "source": "In this task",
      "target": "2o58Mbqkd2",
      "similarity": 0.8671
    },
    {
      "source": "In this task",
      "target": "real-world datasets than prior work and",
      "similarity": 0.8662
    },
    {
      "source": "In this task",
      "target": "YFxfcQMLWX",
      "similarity": 0.8658
    },
    {
      "source": "In this task",
      "target": "TKuYWeFE6S",
      "similarity": 0.8649
    },
    {
      "source": "When fine-tuned on this task",
      "target": "ofuLWn8DFZ",
      "similarity": 0.8506
    },
    {
      "source": "When fine-tuned on this task",
      "target": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "similarity": 0.8325
    },
    {
      "source": "When fine-tuned on this task",
      "target": "Bl3e8HV9xW",
      "similarity": 0.8183
    },
    {
      "source": "When fine-tuned on this task",
      "target": "To overcome this",
      "similarity": 0.8039
    },
    {
      "source": "When fine-tuned on this task",
      "target": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "similarity": 0.8014
    },
    {
      "source": "Analyzing these high-performing models",
      "target": "nmvmPIi185",
      "similarity": 0.8341
    },
    {
      "source": "Analyzing these high-performing models",
      "target": "fGIqGfmgkW",
      "similarity": 0.8306
    },
    {
      "source": "Analyzing these high-performing models",
      "target": "FSjIrOm1vz",
      "similarity": 0.8282
    },
    {
      "source": "Analyzing these high-performing models",
      "target": "uxDFlPGRLX",
      "similarity": 0.8266
    },
    {
      "source": "Analyzing these high-performing models",
      "target": "OlRjxSuSwl",
      "similarity": 0.826
    },
    {
      "source": "Then",
      "target": "First",
      "similarity": 0.8658
    },
    {
      "source": "Then",
      "target": "NEu8wgPctU",
      "similarity": 0.8589
    },
    {
      "source": "Then",
      "target": "INqLJwqUmc",
      "similarity": 0.838
    },
    {
      "source": "Then",
      "target": "Additionally",
      "similarity": 0.8295
    },
    {
      "source": "Then",
      "target": "KAIqwkB3dT",
      "similarity": 0.8208
    },
    {
      "source": "Interestingly",
      "target": "For an effective feature alignment in TTA for regression",
      "similarity": 0.8736
    },
    {
      "source": "Interestingly",
      "target": "GhexuBLxbO",
      "similarity": 0.8507
    },
    {
      "source": "Interestingly",
      "target": "NHMuM84tRT",
      "similarity": 0.8481
    },
    {
      "source": "Interestingly",
      "target": "streaming model",
      "similarity": 0.8394
    },
    {
      "source": "Interestingly",
      "target": "In this paper",
      "similarity": 0.8335
    },
    {
      "source": "Finally",
      "target": "structure of their grid and not their learnable embedding. This mechanism is",
      "similarity": 0.8265
    },
    {
      "source": "Finally",
      "target": "7liN6uHAQZ",
      "similarity": 0.821
    },
    {
      "source": "Finally",
      "target": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "similarity": 0.8064
    },
    {
      "source": "Finally",
      "target": "In this work",
      "similarity": 0.8014
    },
    {
      "source": "Finally",
      "target": "6ouZaBzeNO",
      "similarity": 0.7991
    },
    {
      "source": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.9116
    },
    {
      "source": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "target": "aTYexOYlLb",
      "similarity": 0.829
    },
    {
      "source": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.8278
    },
    {
      "source": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "target": "UIFAJZ22ZF",
      "similarity": 0.821
    },
    {
      "source": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "target": "iXbUquaWbl",
      "similarity": 0.8096
    },
    {
      "source": "UIFAJZ22ZF",
      "target": "a hypergraph",
      "similarity": 0.8549
    },
    {
      "source": "UIFAJZ22ZF",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8527
    },
    {
      "source": "UIFAJZ22ZF",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8361
    },
    {
      "source": "UIFAJZ22ZF",
      "target": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "similarity": 0.8358
    },
    {
      "source": "UIFAJZ22ZF",
      "target": "additional structural constraints",
      "similarity": 0.8356
    },
    {
      "source": "MnfHxPP5gs",
      "target": "KWH4UIoQKS",
      "similarity": 0.8747
    },
    {
      "source": "MnfHxPP5gs",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8438
    },
    {
      "source": "MnfHxPP5gs",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8271
    },
    {
      "source": "MnfHxPP5gs",
      "target": "{Subsequently}",
      "similarity": 0.8208
    },
    {
      "source": "MnfHxPP5gs",
      "target": "$$",
      "similarity": 0.8201
    },
    {
      "source": "We open-source this dataset (CC-BY-4.0 license) at https://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new---1-oct-2024 and openly release the trained Reward and Instruct models at https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct .\"",
      "target": "l6QnSQizmN",
      "similarity": 0.875
    },
    {
      "source": "We open-source this dataset (CC-BY-4.0 license) at https://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new---1-oct-2024 and openly release the trained Reward and Instruct models at https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct .\"",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8524
    },
    {
      "source": "We open-source this dataset (CC-BY-4.0 license) at https://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new---1-oct-2024 and openly release the trained Reward and Instruct models at https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct .\"",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8459
    },
    {
      "source": "We open-source this dataset (CC-BY-4.0 license) at https://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new---1-oct-2024 and openly release the trained Reward and Instruct models at https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct .\"",
      "target": "G5DziesYxL",
      "similarity": 0.8451
    },
    {
      "source": "We open-source this dataset (CC-BY-4.0 license) at https://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new---1-oct-2024 and openly release the trained Reward and Instruct models at https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct .\"",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8449
    },
    {
      "source": "zXCnIyX9MG",
      "target": "PgXpOOqtyd",
      "similarity": 0.8386
    },
    {
      "source": "zXCnIyX9MG",
      "target": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "similarity": 0.838
    },
    {
      "source": "zXCnIyX9MG",
      "target": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "similarity": 0.834
    },
    {
      "source": "zXCnIyX9MG",
      "target": "Building on these insights",
      "similarity": 0.8272
    },
    {
      "source": "zXCnIyX9MG",
      "target": "1Z6PSw7OL8",
      "similarity": 0.8212
    },
    {
      "source": "ttq44QjKda",
      "target": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "similarity": 0.8323
    },
    {
      "source": "ttq44QjKda",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.8206
    },
    {
      "source": "ttq44QjKda",
      "target": "7VkHffT5X2",
      "similarity": 0.8148
    },
    {
      "source": "ttq44QjKda",
      "target": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "similarity": 0.8141
    },
    {
      "source": "ttq44QjKda",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.8129
    },
    {
      "source": "$f$-divergence loss functions",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.8529
    },
    {
      "source": "$f$-divergence loss functions",
      "target": "(1) When the representation dimension is regarded as the time axis",
      "similarity": 0.8143
    },
    {
      "source": "$f$-divergence loss functions",
      "target": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "similarity": 0.8064
    },
    {
      "source": "$f$-divergence loss functions",
      "target": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "similarity": 0.8015
    },
    {
      "source": "$f$-divergence loss functions",
      "target": "Along with SketikZ",
      "similarity": 0.7936
    },
    {
      "source": "This study provides novel theoretical insights into DRE by deriving upper and lower bounds on the $L_p$ errors through $f$-divergence loss functions.",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8344
    },
    {
      "source": "This study provides novel theoretical insights into DRE by deriving upper and lower bounds on the $L_p$ errors through $f$-divergence loss functions.",
      "target": "We also introduce an NL2CNL-P conversion tool based on LLMs",
      "similarity": 0.8171
    },
    {
      "source": "This study provides novel theoretical insights into DRE by deriving upper and lower bounds on the $L_p$ errors through $f$-divergence loss functions.",
      "target": "mPdmDYIQ7f",
      "similarity": 0.8118
    },
    {
      "source": "This study provides novel theoretical insights into DRE by deriving upper and lower bounds on the $L_p$ errors through $f$-divergence loss functions.",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8097
    },
    {
      "source": "This study provides novel theoretical insights into DRE by deriving upper and lower bounds on the $L_p$ errors through $f$-divergence loss functions.",
      "target": "DTatjJTDl1",
      "similarity": 0.8026
    },
    {
      "source": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "target": "zpENPcQSj1",
      "similarity": 0.8845
    },
    {
      "source": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "target": "In this paper",
      "similarity": 0.8679
    },
    {
      "source": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8644
    },
    {
      "source": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "target": "practice is to instead extrapolate from scaled down",
      "similarity": 0.8619
    },
    {
      "source": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8603
    },
    {
      "source": "The derived bounds are expressed as a product involving the data dimensionality and the expected value of the density ratio raised to the $p$-th power.",
      "target": "To explore real-time segmentation",
      "similarity": 0.8461
    },
    {
      "source": "The derived bounds are expressed as a product involving the data dimensionality and the expected value of the density ratio raised to the $p$-th power.",
      "target": "matched mask pairs between prediction and annotation respectively. Extensive",
      "similarity": 0.831
    },
    {
      "source": "The derived bounds are expressed as a product involving the data dimensionality and the expected value of the density ratio raised to the $p$-th power.",
      "target": "Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.\"",
      "similarity": 0.8281
    },
    {
      "source": "The derived bounds are expressed as a product involving the data dimensionality and the expected value of the density ratio raised to the $p$-th power.",
      "target": "we propose positive-unlabeled diffusion models",
      "similarity": 0.8229
    },
    {
      "source": "The derived bounds are expressed as a product involving the data dimensionality and the expected value of the density ratio raised to the $p$-th power.",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8224
    },
    {
      "source": "Notably",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8232
    },
    {
      "source": "Notably",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8164
    },
    {
      "source": "Notably",
      "target": "rnJxelIZrq",
      "similarity": 0.8159
    },
    {
      "source": "Notably",
      "target": "P4XmKjXTrM",
      "similarity": 0.8116
    },
    {
      "source": "Notably",
      "target": "high-quality labels is often required to obtain noticeable improvements. Given",
      "similarity": 0.8109
    },
    {
      "source": "This increase becomes even more pronounced as the value of $p$ grows.",
      "target": "lOi6FtIwR8",
      "similarity": 0.8669
    },
    {
      "source": "This increase becomes even more pronounced as the value of $p$ grows.",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8648
    },
    {
      "source": "This increase becomes even more pronounced as the value of $p$ grows.",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8494
    },
    {
      "source": "This increase becomes even more pronounced as the value of $p$ grows.",
      "target": "Consequently",
      "similarity": 0.842
    },
    {
      "source": "This increase becomes even more pronounced as the value of $p$ grows.",
      "target": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "similarity": 0.8286
    },
    {
      "source": "The theoretical insights are validated through numerical experiments.\"",
      "target": "(e.g.",
      "similarity": 0.8109
    },
    {
      "source": "The theoretical insights are validated through numerical experiments.\"",
      "target": "sound",
      "similarity": 0.8069
    },
    {
      "source": "The theoretical insights are validated through numerical experiments.\"",
      "target": "28%",
      "similarity": 0.8061
    },
    {
      "source": "The theoretical insights are validated through numerical experiments.\"",
      "target": "kOJf7Dklyv",
      "similarity": 0.8007
    },
    {
      "source": "The theoretical insights are validated through numerical experiments.\"",
      "target": "strategies",
      "similarity": 0.7995
    },
    {
      "source": "LWMS4pk2vK",
      "target": "3ogIALgghF",
      "similarity": 0.8507
    },
    {
      "source": "LWMS4pk2vK",
      "target": "L238BAx0wP",
      "similarity": 0.8386
    },
    {
      "source": "LWMS4pk2vK",
      "target": "eLLBILFRsA",
      "similarity": 0.8345
    },
    {
      "source": "LWMS4pk2vK",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.832
    },
    {
      "source": "LWMS4pk2vK",
      "target": "uClUUJk05H",
      "similarity": 0.8183
    },
    {
      "source": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8519
    },
    {
      "source": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "target": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "similarity": 0.8319
    },
    {
      "source": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8274
    },
    {
      "source": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.823
    },
    {
      "source": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "target": "For example",
      "similarity": 0.8223
    },
    {
      "source": "bIlnpVM4bc",
      "target": "Our model weights and code are publicly available.\"",
      "similarity": 0.871
    },
    {
      "source": "bIlnpVM4bc",
      "target": "comprehensive experiments",
      "similarity": 0.842
    },
    {
      "source": "bIlnpVM4bc",
      "target": "mainly because the unlabeled training data frequently contain such sensitive data.",
      "similarity": 0.8319
    },
    {
      "source": "bIlnpVM4bc",
      "target": "kxnoqaisCT",
      "similarity": 0.819
    },
    {
      "source": "bIlnpVM4bc",
      "target": "uQnvYP7yX9",
      "similarity": 0.8176
    },
    {
      "source": "work",
      "target": "WCRQFlji2q",
      "similarity": 0.8532
    },
    {
      "source": "work",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8482
    },
    {
      "source": "work",
      "target": "VQwI055flA",
      "similarity": 0.8473
    },
    {
      "source": "work",
      "target": "pHe4P1IVnb",
      "similarity": 0.8459
    },
    {
      "source": "work",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8437
    },
    {
      "source": "Mamba",
      "target": "In this paper",
      "similarity": 0.8721
    },
    {
      "source": "Mamba",
      "target": "mb2ryuZ3wz",
      "similarity": 0.8542
    },
    {
      "source": "Mamba",
      "target": "In this work",
      "similarity": 0.825
    },
    {
      "source": "Mamba",
      "target": "C8jXEugWkq",
      "similarity": 0.8156
    },
    {
      "source": "Mamba",
      "target": "the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability",
      "similarity": 0.8056
    },
    {
      "source": "(SWA). Samba selectively compresses a given sequence into recurrent hidden",
      "target": "txD9llAYn9",
      "similarity": 0.8593
    },
    {
      "source": "(SWA). Samba selectively compresses a given sequence into recurrent hidden",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8514
    },
    {
      "source": "(SWA). Samba selectively compresses a given sequence into recurrent hidden",
      "target": "bMC1t7eLRc",
      "similarity": 0.8504
    },
    {
      "source": "(SWA). Samba selectively compresses a given sequence into recurrent hidden",
      "target": "bRa4JLPzii",
      "similarity": 0.849
    },
    {
      "source": "(SWA). Samba selectively compresses a given sequence into recurrent hidden",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8477
    },
    {
      "source": "states while still maintaining the ability to precisely recall recent memories with the",
      "target": "iXbUquaWbl",
      "similarity": 0.8602
    },
    {
      "source": "states while still maintaining the ability to precisely recall recent memories with the",
      "target": "DKgAFfCs5F",
      "similarity": 0.8568
    },
    {
      "source": "states while still maintaining the ability to precisely recall recent memories with the",
      "target": "models. Our study promotes the development of more reliable evaluation methods",
      "similarity": 0.8404
    },
    {
      "source": "states while still maintaining the ability to precisely recall recent memories with the",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.8197
    },
    {
      "source": "states while still maintaining the ability to precisely recall recent memories with the",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8182
    },
    {
      "source": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.839
    },
    {
      "source": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "target": "27SSnLl85x",
      "similarity": 0.836
    },
    {
      "source": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8331
    },
    {
      "source": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "target": "aTYexOYlLb",
      "similarity": 0.8315
    },
    {
      "source": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8297
    },
    {
      "source": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "target": "4S2L519nIX",
      "similarity": 0.8834
    },
    {
      "source": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8769
    },
    {
      "source": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "target": "pZiyCaVuti",
      "similarity": 0.8769
    },
    {
      "source": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "target": "4O0v4s3IzY",
      "similarity": 0.8735
    },
    {
      "source": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.872
    },
    {
      "source": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "target": "However",
      "similarity": 0.8526
    },
    {
      "source": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "target": "gyHoR6uFhU",
      "similarity": 0.8487
    },
    {
      "source": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8482
    },
    {
      "source": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "target": "rK0YJwL69S",
      "similarity": 0.8331
    },
    {
      "source": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8328
    },
    {
      "source": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "target": "2ea5TNVR0c",
      "similarity": 0.8992
    },
    {
      "source": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "target": "As a first step towards a better understanding",
      "similarity": 0.8966
    },
    {
      "source": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "target": "PDnEDS244P",
      "similarity": 0.8876
    },
    {
      "source": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8863
    },
    {
      "source": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "target": "bilities",
      "similarity": 0.883
    },
    {
      "source": "finetuned on 4K-length sequences",
      "target": "stacking methods. Specifically",
      "similarity": 0.866
    },
    {
      "source": "finetuned on 4K-length sequences",
      "target": "Second",
      "similarity": 0.86
    },
    {
      "source": "finetuned on 4K-length sequences",
      "target": "JYwVijuNA7",
      "similarity": 0.8525
    },
    {
      "source": "finetuned on 4K-length sequences",
      "target": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "similarity": 0.8466
    },
    {
      "source": "finetuned on 4K-length sequences",
      "target": "xiQNfYl33p",
      "similarity": 0.8465
    },
    {
      "source": "superior retrieval extrapolation on the challenging Phonebook task compared to",
      "target": "In this paper",
      "similarity": 0.8238
    },
    {
      "source": "superior retrieval extrapolation on the challenging Phonebook task compared to",
      "target": "yfW1x7uBS5",
      "similarity": 0.8098
    },
    {
      "source": "superior retrieval extrapolation on the challenging Phonebook task compared to",
      "target": "54XlM8Clkg",
      "similarity": 0.805
    },
    {
      "source": "superior retrieval extrapolation on the challenging Phonebook task compared to",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8005
    },
    {
      "source": "superior retrieval extrapolation on the challenging Phonebook task compared to",
      "target": "TrKRpaOk8y",
      "similarity": 0.7962
    },
    {
      "source": "full-attention models. As a linear-time sequence model",
      "target": "b57IG6N20B",
      "similarity": 0.8071
    },
    {
      "source": "full-attention models. As a linear-time sequence model",
      "target": "Further",
      "similarity": 0.7957
    },
    {
      "source": "full-attention models. As a linear-time sequence model",
      "target": "by focusing on efficiently solving the underlying optimization problem using a general",
      "similarity": 0.7893
    },
    {
      "source": "full-attention models. As a linear-time sequence model",
      "target": "a given query",
      "similarity": 0.7883
    },
    {
      "source": "full-attention models. As a linear-time sequence model",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.774
    },
    {
      "source": "higher throughput compared to Transformers with grouped-query attention for user",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.866
    },
    {
      "source": "higher throughput compared to Transformers with grouped-query attention for user",
      "target": "mechanism",
      "similarity": 0.8477
    },
    {
      "source": "higher throughput compared to Transformers with grouped-query attention for user",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8403
    },
    {
      "source": "higher throughput compared to Transformers with grouped-query attention for user",
      "target": "PY56Wur7S0",
      "similarity": 0.8347
    },
    {
      "source": "higher throughput compared to Transformers with grouped-query attention for user",
      "target": "8TBGdH3t6a",
      "similarity": 0.8245
    },
    {
      "source": "prompts of 128K length",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8897
    },
    {
      "source": "prompts of 128K length",
      "target": "To address these challenges",
      "similarity": 0.8577
    },
    {
      "source": "prompts of 128K length",
      "target": "Despite its simplicity",
      "similarity": 0.8573
    },
    {
      "source": "prompts of 128K length",
      "target": "For instance",
      "similarity": 0.8545
    },
    {
      "source": "prompts of 128K length",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.8509
    },
    {
      "source": "unlimited streaming.\"",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8585
    },
    {
      "source": "unlimited streaming.\"",
      "target": "In this work",
      "similarity": 0.8503
    },
    {
      "source": "unlimited streaming.\"",
      "target": "Our findings show the potential of using these methods to predict training stability.\"",
      "similarity": 0.8468
    },
    {
      "source": "unlimited streaming.\"",
      "target": "AAXBfJNHDt",
      "similarity": 0.8433
    },
    {
      "source": "unlimited streaming.\"",
      "target": "INqLJwqUmc",
      "similarity": 0.8372
    },
    {
      "source": "4ytRL3HJrq",
      "target": "nsCOeCLR8e",
      "similarity": 0.8512
    },
    {
      "source": "4ytRL3HJrq",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.8443
    },
    {
      "source": "4ytRL3HJrq",
      "target": "xI71dsS3o4",
      "similarity": 0.8404
    },
    {
      "source": "4ytRL3HJrq",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.832
    },
    {
      "source": "4ytRL3HJrq",
      "target": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "similarity": 0.8299
    },
    {
      "source": "LBl7Hez0fF",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8621
    },
    {
      "source": "LBl7Hez0fF",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.8513
    },
    {
      "source": "LBl7Hez0fF",
      "target": "Q6PAnqYVpo",
      "similarity": 0.8402
    },
    {
      "source": "LBl7Hez0fF",
      "target": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "similarity": 0.8395
    },
    {
      "source": "LBl7Hez0fF",
      "target": "dOAkHmsjRX",
      "similarity": 0.838
    },
    {
      "source": "Ian00SaFHg",
      "target": "ULorFBST6X",
      "similarity": 0.8786
    },
    {
      "source": "Ian00SaFHg",
      "target": "xjKz6IxgCX",
      "similarity": 0.8751
    },
    {
      "source": "Ian00SaFHg",
      "target": "97rOQDPmk2",
      "similarity": 0.8715
    },
    {
      "source": "Ian00SaFHg",
      "target": "fXb9BbuyAD",
      "similarity": 0.8522
    },
    {
      "source": "Ian00SaFHg",
      "target": "it hard to decide on a proper causal discovery strategy.",
      "similarity": 0.8519
    },
    {
      "source": "MGKDBuyv4p",
      "target": "Building on these insights",
      "similarity": 0.8581
    },
    {
      "source": "MGKDBuyv4p",
      "target": "VpWki1v2P8",
      "similarity": 0.8348
    },
    {
      "source": "MGKDBuyv4p",
      "target": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "similarity": 0.8226
    },
    {
      "source": "MGKDBuyv4p",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8213
    },
    {
      "source": "MGKDBuyv4p",
      "target": "All experimental resources",
      "similarity": 0.818
    },
    {
      "source": "are effective at curbing memorization",
      "target": "jTEKTdI3K9",
      "similarity": 0.8498
    },
    {
      "source": "are effective at curbing memorization",
      "target": "wWnsoLhHwt",
      "similarity": 0.8466
    },
    {
      "source": "are effective at curbing memorization",
      "target": "vjel3nWP2a",
      "similarity": 0.8413
    },
    {
      "source": "are effective at curbing memorization",
      "target": "In this study",
      "similarity": 0.8411
    },
    {
      "source": "are effective at curbing memorization",
      "target": "qNp86ByQlN",
      "similarity": 0.8399
    },
    {
      "source": "memorized information while preserving performance on target tasks.\"",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.8908
    },
    {
      "source": "memorized information while preserving performance on target tasks.\"",
      "target": "254NJe9JEw",
      "similarity": 0.8677
    },
    {
      "source": "memorized information while preserving performance on target tasks.\"",
      "target": "iXCeQ2m6vT",
      "similarity": 0.8649
    },
    {
      "source": "memorized information while preserving performance on target tasks.\"",
      "target": "tDIL7UXmSS",
      "similarity": 0.8587
    },
    {
      "source": "memorized information while preserving performance on target tasks.\"",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8583
    },
    {
      "source": "bDt5qc7TfO",
      "target": "However",
      "similarity": 0.8493
    },
    {
      "source": "bDt5qc7TfO",
      "target": "RTHbao4Mib",
      "similarity": 0.8462
    },
    {
      "source": "bDt5qc7TfO",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.7906
    },
    {
      "source": "bDt5qc7TfO",
      "target": "We identify prototypical challenges that users face when specifying preferences",
      "similarity": 0.7797
    },
    {
      "source": "bDt5qc7TfO",
      "target": "uy4EavBEwl",
      "similarity": 0.7774
    },
    {
      "source": "ohJxgRLlLt",
      "target": "L0evcuybH5",
      "similarity": 0.877
    },
    {
      "source": "ohJxgRLlLt",
      "target": "To address this issue",
      "similarity": 0.8589
    },
    {
      "source": "ohJxgRLlLt",
      "target": "uncertainty estimation. Moreover",
      "similarity": 0.8587
    },
    {
      "source": "ohJxgRLlLt",
      "target": "cC3LxGZasH",
      "similarity": 0.8541
    },
    {
      "source": "ohJxgRLlLt",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8466
    },
    {
      "source": "szRmEM8Kx5",
      "target": "To tackle this challenge",
      "similarity": 0.8601
    },
    {
      "source": "szRmEM8Kx5",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8417
    },
    {
      "source": "szRmEM8Kx5",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8378
    },
    {
      "source": "szRmEM8Kx5",
      "target": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "similarity": 0.8251
    },
    {
      "source": "szRmEM8Kx5",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8167
    },
    {
      "source": "K3KrOsR6y9",
      "target": "The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.\"",
      "similarity": 0.8832
    },
    {
      "source": "K3KrOsR6y9",
      "target": "To enrich long documents",
      "similarity": 0.8772
    },
    {
      "source": "K3KrOsR6y9",
      "target": "20qZK2T7fa",
      "similarity": 0.8736
    },
    {
      "source": "K3KrOsR6y9",
      "target": "gsShHPxkUW",
      "similarity": 0.8643
    },
    {
      "source": "K3KrOsR6y9",
      "target": "ogXkmugNZw",
      "similarity": 0.8632
    },
    {
      "source": "wsWCVrH9dv",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8866
    },
    {
      "source": "wsWCVrH9dv",
      "target": "P6IVIoGRRg",
      "similarity": 0.8526
    },
    {
      "source": "wsWCVrH9dv",
      "target": "We conducted a comprehensive regret analysis of our proposed framework",
      "similarity": 0.8414
    },
    {
      "source": "wsWCVrH9dv",
      "target": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "similarity": 0.8384
    },
    {
      "source": "wsWCVrH9dv",
      "target": "unDQOUah0F",
      "similarity": 0.8259
    },
    {
      "source": "ZAyuwJYN8N",
      "target": "GBIUbwW9D8",
      "similarity": 0.826
    },
    {
      "source": "ZAyuwJYN8N",
      "target": "VQwI055flA",
      "similarity": 0.8214
    },
    {
      "source": "ZAyuwJYN8N",
      "target": "These steps result in MxNet",
      "similarity": 0.8179
    },
    {
      "source": "ZAyuwJYN8N",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8154
    },
    {
      "source": "ZAyuwJYN8N",
      "target": "txD9llAYn9",
      "similarity": 0.8153
    },
    {
      "source": "amDkNPVWcn",
      "target": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "similarity": 0.8324
    },
    {
      "source": "amDkNPVWcn",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.826
    },
    {
      "source": "amDkNPVWcn",
      "target": "However",
      "similarity": 0.8215
    },
    {
      "source": "amDkNPVWcn",
      "target": "HqjRlT65WX",
      "similarity": 0.8209
    },
    {
      "source": "amDkNPVWcn",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.818
    },
    {
      "source": "THqWPzL00e",
      "target": "27SSnLl85x",
      "similarity": 0.8601
    },
    {
      "source": "THqWPzL00e",
      "target": "We introduce a novel",
      "similarity": 0.8596
    },
    {
      "source": "THqWPzL00e",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8461
    },
    {
      "source": "THqWPzL00e",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8299
    },
    {
      "source": "THqWPzL00e",
      "target": "AAXBfJNHDt",
      "similarity": 0.8257
    },
    {
      "source": "Neb17mimVH",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8826
    },
    {
      "source": "Neb17mimVH",
      "target": "Conversely",
      "similarity": 0.88
    },
    {
      "source": "Neb17mimVH",
      "target": "This allows us to search for programs within a single (expanding) prompt until a sound program is found",
      "similarity": 0.8776
    },
    {
      "source": "Neb17mimVH",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8748
    },
    {
      "source": "Neb17mimVH",
      "target": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "similarity": 0.8688
    },
    {
      "source": "h0jdAboh0o",
      "target": "We empirically show that compared to the state-of-the-art curriculum learning approaches and their naively modified safe versions",
      "similarity": 0.803
    },
    {
      "source": "h0jdAboh0o",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.7884
    },
    {
      "source": "h0jdAboh0o",
      "target": "content recommendation",
      "similarity": 0.7777
    },
    {
      "source": "h0jdAboh0o",
      "target": "To address these shortcomings",
      "similarity": 0.7708
    },
    {
      "source": "h0jdAboh0o",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.7696
    },
    {
      "source": "This includes evaluating capabilities",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8602
    },
    {
      "source": "This includes evaluating capabilities",
      "target": "the costliness of the labels",
      "similarity": 0.8469
    },
    {
      "source": "This includes evaluating capabilities",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8438
    },
    {
      "source": "This includes evaluating capabilities",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.8412
    },
    {
      "source": "This includes evaluating capabilities",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.839
    },
    {
      "source": "ZTpWOwMrzQ",
      "target": "jTEKTdI3K9",
      "similarity": 0.8376
    },
    {
      "source": "ZTpWOwMrzQ",
      "target": "6guG2OlXsr",
      "similarity": 0.8364
    },
    {
      "source": "ZTpWOwMrzQ",
      "target": "9kJperA2a4",
      "similarity": 0.8157
    },
    {
      "source": "ZTpWOwMrzQ",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8142
    },
    {
      "source": "ZTpWOwMrzQ",
      "target": "The best-performing model",
      "similarity": 0.8137
    },
    {
      "source": "hmDt068MoZ",
      "target": "jckKNzYYA6",
      "similarity": 0.8799
    },
    {
      "source": "hmDt068MoZ",
      "target": "However",
      "similarity": 0.8595
    },
    {
      "source": "hmDt068MoZ",
      "target": "overhead in parameters and inference time. In this paper",
      "similarity": 0.847
    },
    {
      "source": "hmDt068MoZ",
      "target": "20qZK2T7fa",
      "similarity": 0.8286
    },
    {
      "source": "hmDt068MoZ",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8267
    },
    {
      "source": "k3gCieTXeY",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8483
    },
    {
      "source": "k3gCieTXeY",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8357
    },
    {
      "source": "k3gCieTXeY",
      "target": "YFxfcQMLWX",
      "similarity": 0.833
    },
    {
      "source": "k3gCieTXeY",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8308
    },
    {
      "source": "k3gCieTXeY",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.83
    },
    {
      "source": "Our novel resource",
      "target": "Along our analysis",
      "similarity": 0.8741
    },
    {
      "source": "Our novel resource",
      "target": "selection of LLMs",
      "similarity": 0.8405
    },
    {
      "source": "Our novel resource",
      "target": "n2NidsYDop",
      "similarity": 0.8315
    },
    {
      "source": "Our novel resource",
      "target": "Following these principles",
      "similarity": 0.8295
    },
    {
      "source": "Our novel resource",
      "target": "AoIKgHu9Si",
      "similarity": 0.8245
    },
    {
      "source": "1R5BcYS8EC",
      "target": "wHebuIb6IH",
      "similarity": 0.8754
    },
    {
      "source": "1R5BcYS8EC",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8692
    },
    {
      "source": "1R5BcYS8EC",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8676
    },
    {
      "source": "1R5BcYS8EC",
      "target": "SRpq5OBpED",
      "similarity": 0.8665
    },
    {
      "source": "1R5BcYS8EC",
      "target": "However",
      "similarity": 0.8656
    },
    {
      "source": "Our work introduces the use of language descriptions",
      "target": "Lastly",
      "similarity": 0.8006
    },
    {
      "source": "Our work introduces the use of language descriptions",
      "target": "GMwRl2e9Y1",
      "similarity": 0.7964
    },
    {
      "source": "Our work introduces the use of language descriptions",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.7958
    },
    {
      "source": "Our work introduces the use of language descriptions",
      "target": "P6IVIoGRRg",
      "similarity": 0.7943
    },
    {
      "source": "Our work introduces the use of language descriptions",
      "target": "practice is to instead extrapolate from scaled down",
      "similarity": 0.7858
    },
    {
      "source": "We argue that interacting with surrogates through text",
      "target": "6ycX677p2l",
      "similarity": 0.9008
    },
    {
      "source": "We argue that interacting with surrogates through text",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8997
    },
    {
      "source": "We argue that interacting with surrogates through text",
      "target": "However",
      "similarity": 0.8857
    },
    {
      "source": "We argue that interacting with surrogates through text",
      "target": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "similarity": 0.8849
    },
    {
      "source": "We argue that interacting with surrogates through text",
      "target": "To this end",
      "similarity": 0.8843
    },
    {
      "source": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8629
    },
    {
      "source": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "target": "NJxCpMt0sf",
      "similarity": 0.8563
    },
    {
      "source": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "target": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "similarity": 0.8556
    },
    {
      "source": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "target": "a single GPU in a few hours",
      "similarity": 0.8543
    },
    {
      "source": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "target": "Mjn53GtMxi",
      "similarity": 0.8533
    },
    {
      "source": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "target": "2c7pfOqu9k",
      "similarity": 0.8475
    },
    {
      "source": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8469
    },
    {
      "source": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8419
    },
    {
      "source": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "target": "cPD2hU35x3",
      "similarity": 0.8418
    },
    {
      "source": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "target": "HqjRlT65WX",
      "similarity": 0.8393
    },
    {
      "source": "Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.\"",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8337
    },
    {
      "source": "Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.\"",
      "target": "J9FgrqOOni",
      "similarity": 0.8245
    },
    {
      "source": "Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.\"",
      "target": "Our findings indicate that",
      "similarity": 0.8165
    },
    {
      "source": "Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.\"",
      "target": "jxMAPMqNr5",
      "similarity": 0.8162
    },
    {
      "source": "Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.\"",
      "target": "4A9IdSa1ul",
      "similarity": 0.8154
    },
    {
      "source": "oCUYc7BzXQ",
      "target": "yitH9xAHQs",
      "similarity": 0.8479
    },
    {
      "source": "oCUYc7BzXQ",
      "target": "S1Bv3068Xt",
      "similarity": 0.8431
    },
    {
      "source": "oCUYc7BzXQ",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8407
    },
    {
      "source": "oCUYc7BzXQ",
      "target": "rTQNGQxm4K",
      "similarity": 0.8388
    },
    {
      "source": "oCUYc7BzXQ",
      "target": "First",
      "similarity": 0.835
    },
    {
      "source": "4es2oO9tw1",
      "target": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "similarity": 0.879
    },
    {
      "source": "4es2oO9tw1",
      "target": "We validate our approach on benchmarks from image and medical domains",
      "similarity": 0.8728
    },
    {
      "source": "4es2oO9tw1",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8716
    },
    {
      "source": "4es2oO9tw1",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.8713
    },
    {
      "source": "4es2oO9tw1",
      "target": "rCX9l4OTCT",
      "similarity": 0.8537
    },
    {
      "source": "and model the data selection problem as trading off initial-selection cost for training gain. We run a comprehensive sweep of experiments across multiple tasks",
      "target": "6qUUgw9bAZ",
      "similarity": 0.8435
    },
    {
      "source": "and model the data selection problem as trading off initial-selection cost for training gain. We run a comprehensive sweep of experiments across multiple tasks",
      "target": "GLWf2fq0bX",
      "similarity": 0.7938
    },
    {
      "source": "and model the data selection problem as trading off initial-selection cost for training gain. We run a comprehensive sweep of experiments across multiple tasks",
      "target": "In this paper",
      "similarity": 0.7935
    },
    {
      "source": "and model the data selection problem as trading off initial-selection cost for training gain. We run a comprehensive sweep of experiments across multiple tasks",
      "target": "In this work",
      "similarity": 0.7871
    },
    {
      "source": "and model the data selection problem as trading off initial-selection cost for training gain. We run a comprehensive sweep of experiments across multiple tasks",
      "target": "Under these assumptions",
      "similarity": 0.7853
    },
    {
      "source": "7lUdo8Vuqa",
      "target": "oP7arLOWix",
      "similarity": 0.8685
    },
    {
      "source": "7lUdo8Vuqa",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8616
    },
    {
      "source": "7lUdo8Vuqa",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8595
    },
    {
      "source": "7lUdo8Vuqa",
      "target": "Qja5s0K3VX",
      "similarity": 0.8552
    },
    {
      "source": "7lUdo8Vuqa",
      "target": "6GATHdOi1x",
      "similarity": 0.8532
    },
    {
      "source": "vaJ4FObpXN",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8602
    },
    {
      "source": "vaJ4FObpXN",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8474
    },
    {
      "source": "vaJ4FObpXN",
      "target": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "similarity": 0.8473
    },
    {
      "source": "vaJ4FObpXN",
      "target": "suz4utPr9Y",
      "similarity": 0.8448
    },
    {
      "source": "vaJ4FObpXN",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8417
    },
    {
      "source": "across various domains",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8067
    },
    {
      "source": "across various domains",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8021
    },
    {
      "source": "across various domains",
      "target": "FAYIlGDBa1",
      "similarity": 0.8002
    },
    {
      "source": "across various domains",
      "target": "However",
      "similarity": 0.7988
    },
    {
      "source": "across various domains",
      "target": "cfKZ5VrhXt",
      "similarity": 0.7988
    },
    {
      "source": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "target": "p60Y6o85Cj",
      "similarity": 0.832
    },
    {
      "source": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "target": "sZQRUrvLn4",
      "similarity": 0.8291
    },
    {
      "source": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "target": "In this paper",
      "similarity": 0.818
    },
    {
      "source": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "target": "44CoQe6VCq",
      "similarity": 0.8174
    },
    {
      "source": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "target": "However",
      "similarity": 0.8172
    },
    {
      "source": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "target": "By playing against itself",
      "similarity": 0.8409
    },
    {
      "source": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "target": "71XtUhazG0",
      "similarity": 0.8399
    },
    {
      "source": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "target": "GySIAKEwtZ",
      "similarity": 0.8366
    },
    {
      "source": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "target": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "similarity": 0.8365
    },
    {
      "source": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "target": "xP1radUi32",
      "similarity": 0.8341
    },
    {
      "source": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "target": "FCBbh0HCrF",
      "similarity": 0.8378
    },
    {
      "source": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "target": "Our codebase",
      "similarity": 0.8357
    },
    {
      "source": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.8239
    },
    {
      "source": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "target": "Our approach addresses key challenges in this domain",
      "similarity": 0.8237
    },
    {
      "source": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "target": "4iFSBgxvIO",
      "similarity": 0.8226
    },
    {
      "source": "i) Exploration - $X^2$GNN generates multiple  solutions simultaneously",
      "target": "UN6Ik6OCx8",
      "similarity": 0.8385
    },
    {
      "source": "i) Exploration - $X^2$GNN generates multiple  solutions simultaneously",
      "target": "To fill this gap",
      "similarity": 0.8324
    },
    {
      "source": "i) Exploration - $X^2$GNN generates multiple  solutions simultaneously",
      "target": "unsafe",
      "similarity": 0.8288
    },
    {
      "source": "i) Exploration - $X^2$GNN generates multiple  solutions simultaneously",
      "target": "aKRADWBJ1I",
      "similarity": 0.8225
    },
    {
      "source": "i) Exploration - $X^2$GNN generates multiple  solutions simultaneously",
      "target": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "similarity": 0.8143
    },
    {
      "source": "(ii) Exploitation - $X^2$GNN  employs neural stochastic iterative refinement to exploit partial existing solutions",
      "target": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "similarity": 0.8267
    },
    {
      "source": "(ii) Exploitation - $X^2$GNN  employs neural stochastic iterative refinement to exploit partial existing solutions",
      "target": "Despite these potential benefits",
      "similarity": 0.8031
    },
    {
      "source": "(ii) Exploitation - $X^2$GNN  employs neural stochastic iterative refinement to exploit partial existing solutions",
      "target": "IZDiRbVSVN",
      "similarity": 0.8016
    },
    {
      "source": "(ii) Exploitation - $X^2$GNN  employs neural stochastic iterative refinement to exploit partial existing solutions",
      "target": "Antib6Uovh",
      "similarity": 0.8006
    },
    {
      "source": "(ii) Exploitation - $X^2$GNN  employs neural stochastic iterative refinement to exploit partial existing solutions",
      "target": "We also thoroughly analyzed our pre-training dataset",
      "similarity": 0.7866
    },
    {
      "source": "By balancing exploration and exploitation",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.9002
    },
    {
      "source": "By balancing exploration and exploitation",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8637
    },
    {
      "source": "By balancing exploration and exploitation",
      "target": "7LGmXXZXtP",
      "similarity": 0.8599
    },
    {
      "source": "By balancing exploration and exploitation",
      "target": "meKEKDhdnx",
      "similarity": 0.8569
    },
    {
      "source": "By balancing exploration and exploitation",
      "target": "tu3qwNjrtw",
      "similarity": 0.8547
    },
    {
      "source": "C06kww3Qky",
      "target": "q1UyoY3MgJ",
      "similarity": 0.881
    },
    {
      "source": "C06kww3Qky",
      "target": "To demonstrate the effectiveness of our framework",
      "similarity": 0.8794
    },
    {
      "source": "C06kww3Qky",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8725
    },
    {
      "source": "C06kww3Qky",
      "target": "xiQNfYl33p",
      "similarity": 0.8722
    },
    {
      "source": "C06kww3Qky",
      "target": "stacking methods. Specifically",
      "similarity": 0.8705
    },
    {
      "source": "qn9tBYQHGi",
      "target": "for VLMs\"",
      "similarity": 0.8391
    },
    {
      "source": "qn9tBYQHGi",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.8309
    },
    {
      "source": "qn9tBYQHGi",
      "target": "In this paper",
      "similarity": 0.8282
    },
    {
      "source": "qn9tBYQHGi",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8278
    },
    {
      "source": "qn9tBYQHGi",
      "target": "target node would not have been anomalous. Prior methods of assessing the fix",
      "similarity": 0.8276
    },
    {
      "source": "30oIfmrcFO",
      "target": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "similarity": 0.839
    },
    {
      "source": "30oIfmrcFO",
      "target": "This paper proposes",
      "similarity": 0.8367
    },
    {
      "source": "30oIfmrcFO",
      "target": "qykpnEWf2J",
      "similarity": 0.8349
    },
    {
      "source": "30oIfmrcFO",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8257
    },
    {
      "source": "30oIfmrcFO",
      "target": "MyVC4X5B2X",
      "similarity": 0.8175
    },
    {
      "source": "Q1QTxFm0Is",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8554
    },
    {
      "source": "Q1QTxFm0Is",
      "target": "Besides this primary purpose",
      "similarity": 0.8258
    },
    {
      "source": "Q1QTxFm0Is",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8239
    },
    {
      "source": "Q1QTxFm0Is",
      "target": "Despite theoretically sound",
      "similarity": 0.8232
    },
    {
      "source": "Q1QTxFm0Is",
      "target": "mnna9LUg7P",
      "similarity": 0.8165
    },
    {
      "source": "YH4M1Tbxfz",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8184
    },
    {
      "source": "YH4M1Tbxfz",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8167
    },
    {
      "source": "YH4M1Tbxfz",
      "target": "TEmE9PSC65",
      "similarity": 0.8124
    },
    {
      "source": "YH4M1Tbxfz",
      "target": "BPAZ6yW3K7",
      "similarity": 0.8123
    },
    {
      "source": "YH4M1Tbxfz",
      "target": "YcUV5apdlq",
      "similarity": 0.812
    },
    {
      "source": "for the development of effective diagnosis and prognosis solutions. While deep",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8373
    },
    {
      "source": "for the development of effective diagnosis and prognosis solutions. While deep",
      "target": "b57IG6N20B",
      "similarity": 0.831
    },
    {
      "source": "for the development of effective diagnosis and prognosis solutions. While deep",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8217
    },
    {
      "source": "for the development of effective diagnosis and prognosis solutions. While deep",
      "target": "effectiveness through experiments on various representative benchmarks. With an",
      "similarity": 0.8214
    },
    {
      "source": "for the development of effective diagnosis and prognosis solutions. While deep",
      "target": "YvKJGYL4j7",
      "similarity": 0.8206
    },
    {
      "source": "learning has exhibited impressive capacities across various healthcare domains",
      "target": "We perform detailed analyses",
      "similarity": 0.8842
    },
    {
      "source": "learning has exhibited impressive capacities across various healthcare domains",
      "target": "pPQPQ7Yd58",
      "similarity": 0.8733
    },
    {
      "source": "learning has exhibited impressive capacities across various healthcare domains",
      "target": "jj7b3p5kLY",
      "similarity": 0.8593
    },
    {
      "source": "learning has exhibited impressive capacities across various healthcare domains",
      "target": "We propose the use of principal persistence measures",
      "similarity": 0.8589
    },
    {
      "source": "learning has exhibited impressive capacities across various healthcare domains",
      "target": "Ax0i933gtp",
      "similarity": 0.8495
    },
    {
      "source": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8709
    },
    {
      "source": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8636
    },
    {
      "source": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "target": "we obtain the first",
      "similarity": 0.863
    },
    {
      "source": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "target": "riieAeQBJm",
      "similarity": 0.8595
    },
    {
      "source": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "target": "Qja5s0K3VX",
      "similarity": 0.8547
    },
    {
      "source": "large-scale",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8493
    },
    {
      "source": "large-scale",
      "target": "However",
      "similarity": 0.8341
    },
    {
      "source": "large-scale",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8284
    },
    {
      "source": "large-scale",
      "target": "HqLHY4TzGj",
      "similarity": 0.8244
    },
    {
      "source": "large-scale",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.8237
    },
    {
      "source": "(BoneMet) dataset",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.8958
    },
    {
      "source": "(BoneMet) dataset",
      "target": "0fJfVOSUra",
      "similarity": 0.8873
    },
    {
      "source": "(BoneMet) dataset",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8645
    },
    {
      "source": "(BoneMet) dataset",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8644
    },
    {
      "source": "(BoneMet) dataset",
      "target": "In this work",
      "similarity": 0.8559
    },
    {
      "source": "resource",
      "target": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "similarity": 0.8694
    },
    {
      "source": "resource",
      "target": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "similarity": 0.8516
    },
    {
      "source": "resource",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.8416
    },
    {
      "source": "resource",
      "target": "Vanilla SFT (i.e.",
      "similarity": 0.8269
    },
    {
      "source": "resource",
      "target": "In addition",
      "similarity": 0.8258
    },
    {
      "source": "advantage of BoneMet over existing human datasets is repeated sequential scans",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8679
    },
    {
      "source": "advantage of BoneMet over existing human datasets is repeated sequential scans",
      "target": "Based on this concept",
      "similarity": 0.8661
    },
    {
      "source": "advantage of BoneMet over existing human datasets is repeated sequential scans",
      "target": "2ea5TNVR0c",
      "similarity": 0.8618
    },
    {
      "source": "advantage of BoneMet over existing human datasets is repeated sequential scans",
      "target": "PDnEDS244P",
      "similarity": 0.8491
    },
    {
      "source": "advantage of BoneMet over existing human datasets is repeated sequential scans",
      "target": "As a first step towards a better understanding",
      "similarity": 0.8345
    },
    {
      "source": "per subject over the entire disease development phases. The dataset consists of",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.9055
    },
    {
      "source": "per subject over the entire disease development phases. The dataset consists of",
      "target": "6GATHdOi1x",
      "similarity": 0.8735
    },
    {
      "source": "per subject over the entire disease development phases. The dataset consists of",
      "target": "oP7arLOWix",
      "similarity": 0.8711
    },
    {
      "source": "per subject over the entire disease development phases. The dataset consists of",
      "target": "bmbRCRiNDu",
      "similarity": 0.8711
    },
    {
      "source": "per subject over the entire disease development phases. The dataset consists of",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8676
    },
    {
      "source": "over 67 terabytes of multi-modal medical data",
      "target": "Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.\"",
      "similarity": 0.8538
    },
    {
      "source": "over 67 terabytes of multi-modal medical data",
      "target": "In experiments with GPT-4",
      "similarity": 0.8398
    },
    {
      "source": "over 67 terabytes of multi-modal medical data",
      "target": "nzjSvVZBIp",
      "similarity": 0.8396
    },
    {
      "source": "over 67 terabytes of multi-modal medical data",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8325
    },
    {
      "source": "over 67 terabytes of multi-modal medical data",
      "target": "O6znYvxC1U",
      "similarity": 0.828
    },
    {
      "source": "CT scans",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8227
    },
    {
      "source": "CT scans",
      "target": "Notably",
      "similarity": 0.8177
    },
    {
      "source": "CT scans",
      "target": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "similarity": 0.8142
    },
    {
      "source": "CT scans",
      "target": "On an average of 6 diverse tasks",
      "similarity": 0.8096
    },
    {
      "source": "CT scans",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.7984
    },
    {
      "source": "analysis)",
      "target": "SOTA LLMs",
      "similarity": 0.8711
    },
    {
      "source": "analysis)",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8629
    },
    {
      "source": "analysis)",
      "target": "lOi6FtIwR8",
      "similarity": 0.8591
    },
    {
      "source": "analysis)",
      "target": "In this work",
      "similarity": 0.8589
    },
    {
      "source": "analysis)",
      "target": "enhance reliability. This study investigates the efficacy of such approaches",
      "similarity": 0.8574
    },
    {
      "source": "2024. Our BoneMet dataset is well-organized into six components",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8764
    },
    {
      "source": "2024. Our BoneMet dataset is well-organized into six components",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8567
    },
    {
      "source": "2024. Our BoneMet dataset is well-organized into six components",
      "target": "In this paper",
      "similarity": 0.8516
    },
    {
      "source": "2024. Our BoneMet dataset is well-organized into six components",
      "target": "4S2L519nIX",
      "similarity": 0.8501
    },
    {
      "source": "2024. Our BoneMet dataset is well-organized into six components",
      "target": "Yk87CwhBDx",
      "similarity": 0.848
    },
    {
      "source": "X-Ray",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.8371
    },
    {
      "source": "X-Ray",
      "target": "To be precise",
      "similarity": 0.8353
    },
    {
      "source": "X-Ray",
      "target": "d8hYXbxX71",
      "similarity": 0.8346
    },
    {
      "source": "X-Ray",
      "target": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "similarity": 0.8287
    },
    {
      "source": "X-Ray",
      "target": "RWJX5F5I9g",
      "similarity": 0.8271
    },
    {
      "source": "show that BoneMet can be readily adopted to build versatile",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8652
    },
    {
      "source": "show that BoneMet can be readily adopted to build versatile",
      "target": "uL1H29dM0c",
      "similarity": 0.8626
    },
    {
      "source": "show that BoneMet can be readily adopted to build versatile",
      "target": "8eNLKk5by4",
      "similarity": 0.8538
    },
    {
      "source": "show that BoneMet can be readily adopted to build versatile",
      "target": "84WmbzikPP",
      "similarity": 0.8538
    },
    {
      "source": "show that BoneMet can be readily adopted to build versatile",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8517
    },
    {
      "source": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "target": "To this end",
      "similarity": 0.8918
    },
    {
      "source": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "target": "First",
      "similarity": 0.8721
    },
    {
      "source": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "target": "Using this extension",
      "similarity": 0.8684
    },
    {
      "source": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8645
    },
    {
      "source": "for managing BCBM diseases in terms of diagnosis using 2D or 3D images",
      "target": "AJpUZd8Clb",
      "similarity": 0.8551
    },
    {
      "source": "disease monitoring. Our preliminary results demonstrate that BoneMet has the",
      "target": "5o9JJJPPm6",
      "similarity": 0.8469
    },
    {
      "source": "disease monitoring. Our preliminary results demonstrate that BoneMet has the",
      "target": "FZv3kPHTtB",
      "similarity": 0.8397
    },
    {
      "source": "disease monitoring. Our preliminary results demonstrate that BoneMet has the",
      "target": "2o58Mbqkd2",
      "similarity": 0.8359
    },
    {
      "source": "disease monitoring. Our preliminary results demonstrate that BoneMet has the",
      "target": "In response",
      "similarity": 0.8314
    },
    {
      "source": "disease monitoring. Our preliminary results demonstrate that BoneMet has the",
      "target": "YFxfcQMLWX",
      "similarity": 0.8297
    },
    {
      "source": "potentials to jump-start the development and fine-tuning of AI-driven solutions",
      "target": "5YbuOTUFQ4",
      "similarity": 0.8511
    },
    {
      "source": "potentials to jump-start the development and fine-tuning of AI-driven solutions",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8418
    },
    {
      "source": "potentials to jump-start the development and fine-tuning of AI-driven solutions",
      "target": "2o58Mbqkd2",
      "similarity": 0.7923
    },
    {
      "source": "potentials to jump-start the development and fine-tuning of AI-driven solutions",
      "target": "We propose RAMEN",
      "similarity": 0.7875
    },
    {
      "source": "potentials to jump-start the development and fine-tuning of AI-driven solutions",
      "target": "Using this approach",
      "similarity": 0.7794
    },
    {
      "source": "prior to their applications to human patients. To facilitate its easy access and",
      "target": "cC3LxGZasH",
      "similarity": 0.8498
    },
    {
      "source": "prior to their applications to human patients. To facilitate its easy access and",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8345
    },
    {
      "source": "prior to their applications to human patients. To facilitate its easy access and",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8335
    },
    {
      "source": "prior to their applications to human patients. To facilitate its easy access and",
      "target": "We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.",
      "similarity": 0.8242
    },
    {
      "source": "prior to their applications to human patients. To facilitate its easy access and",
      "target": "4JK2XMGUc8",
      "similarity": 0.8239
    },
    {
      "source": "wide dissemination",
      "target": "FiyS0ecSm0",
      "similarity": 0.8915
    },
    {
      "source": "wide dissemination",
      "target": "VoayJihXra",
      "similarity": 0.8799
    },
    {
      "source": "wide dissemination",
      "target": "hjROBHstZ3",
      "similarity": 0.8778
    },
    {
      "source": "wide dissemination",
      "target": "named Pacmann",
      "similarity": 0.8765
    },
    {
      "source": "wide dissemination",
      "target": "To develop SoundCTM",
      "similarity": 0.8738
    },
    {
      "source": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "target": "To this end",
      "similarity": 0.8571
    },
    {
      "source": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8476
    },
    {
      "source": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8457
    },
    {
      "source": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "target": "JYwVijuNA7",
      "similarity": 0.8452
    },
    {
      "source": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "target": "oYemKnlIrO",
      "similarity": 0.8442
    },
    {
      "source": "filtered by specific time frames; and (ii) develop and train large-scale AI models for",
      "target": "Second",
      "similarity": 0.8143
    },
    {
      "source": "filtered by specific time frames; and (ii) develop and train large-scale AI models for",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.7945
    },
    {
      "source": "filtered by specific time frames; and (ii) develop and train large-scale AI models for",
      "target": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "similarity": 0.794
    },
    {
      "source": "filtered by specific time frames; and (ii) develop and train large-scale AI models for",
      "target": "To investigate this",
      "similarity": 0.7839
    },
    {
      "source": "filtered by specific time frames; and (ii) develop and train large-scale AI models for",
      "target": "We leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models.",
      "similarity": 0.7822
    },
    {
      "source": "precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.\"",
      "target": "ZkFMe3OPfw",
      "similarity": 0.8607
    },
    {
      "source": "precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.\"",
      "target": "However",
      "similarity": 0.7982
    },
    {
      "source": "precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.\"",
      "target": "H0qIWXXLUR",
      "similarity": 0.796
    },
    {
      "source": "precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.\"",
      "target": "Besides this primary purpose",
      "similarity": 0.7919
    },
    {
      "source": "precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.\"",
      "target": "mkuB677eMM",
      "similarity": 0.7904
    },
    {
      "source": "5yDS32hKJc",
      "target": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "similarity": 0.8403
    },
    {
      "source": "5yDS32hKJc",
      "target": "mqNKiEB6pd",
      "similarity": 0.8292
    },
    {
      "source": "5yDS32hKJc",
      "target": "QsA3YzNUxA",
      "similarity": 0.8178
    },
    {
      "source": "5yDS32hKJc",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8172
    },
    {
      "source": "5yDS32hKJc",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8143
    },
    {
      "source": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "target": "JWtrk7mprJ",
      "similarity": 0.8343
    },
    {
      "source": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "target": "aKRADWBJ1I",
      "similarity": 0.8265
    },
    {
      "source": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "target": "TjP1d8PP8l",
      "similarity": 0.8258
    },
    {
      "source": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "target": "Moreover",
      "similarity": 0.8184
    },
    {
      "source": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "target": "To bridge this gap",
      "similarity": 0.8178
    },
    {
      "source": "SyVPiehSbg",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8503
    },
    {
      "source": "SyVPiehSbg",
      "target": "space are required in general even for outputting a constant factor",
      "similarity": 0.8501
    },
    {
      "source": "SyVPiehSbg",
      "target": "P6IVIoGRRg",
      "similarity": 0.8465
    },
    {
      "source": "SyVPiehSbg",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8432
    },
    {
      "source": "SyVPiehSbg",
      "target": "Aye5wL6TCn",
      "similarity": 0.8395
    },
    {
      "source": "friHAl5ofG",
      "target": "tXUkT709OJ",
      "similarity": 0.8453
    },
    {
      "source": "friHAl5ofG",
      "target": "yLhJYvkKA0",
      "similarity": 0.8301
    },
    {
      "source": "friHAl5ofG",
      "target": "wLnls9LS3x",
      "similarity": 0.8259
    },
    {
      "source": "friHAl5ofG",
      "target": "DwqoBkj2Mw",
      "similarity": 0.8217
    },
    {
      "source": "friHAl5ofG",
      "target": "N4NhVN30ph",
      "similarity": 0.8175
    },
    {
      "source": "7bAjVh3CG3",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.865
    },
    {
      "source": "7bAjVh3CG3",
      "target": "h1XoHOd19I",
      "similarity": 0.861
    },
    {
      "source": "7bAjVh3CG3",
      "target": "relying on backward propagation",
      "similarity": 0.8482
    },
    {
      "source": "7bAjVh3CG3",
      "target": "cRnCcuLvyr",
      "similarity": 0.8472
    },
    {
      "source": "7bAjVh3CG3",
      "target": "faceswaps",
      "similarity": 0.8459
    },
    {
      "source": "We show that GRAIN reconstructs up to 80\\% of all graphs exactly",
      "target": "TljGdvzFq2",
      "similarity": 0.8585
    },
    {
      "source": "We show that GRAIN reconstructs up to 80\\% of all graphs exactly",
      "target": "composition (MoDeGPT)",
      "similarity": 0.8547
    },
    {
      "source": "We show that GRAIN reconstructs up to 80\\% of all graphs exactly",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8296
    },
    {
      "source": "We show that GRAIN reconstructs up to 80\\% of all graphs exactly",
      "target": "254NJe9JEw",
      "similarity": 0.824
    },
    {
      "source": "We show that GRAIN reconstructs up to 80\\% of all graphs exactly",
      "target": "extreme weather forecasts to enhance their practical utility\"",
      "similarity": 0.8212
    },
    {
      "source": "MscdsFVZrN",
      "target": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "similarity": 0.9105
    },
    {
      "source": "MscdsFVZrN",
      "target": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "similarity": 0.8528
    },
    {
      "source": "MscdsFVZrN",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8503
    },
    {
      "source": "MscdsFVZrN",
      "target": "GdbQyFOUlJ",
      "similarity": 0.8415
    },
    {
      "source": "MscdsFVZrN",
      "target": "HqjRlT65WX",
      "similarity": 0.8412
    },
    {
      "source": "PY56Wur7S0",
      "target": "xI71dsS3o4",
      "similarity": 0.8634
    },
    {
      "source": "PY56Wur7S0",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8575
    },
    {
      "source": "PY56Wur7S0",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8528
    },
    {
      "source": "PY56Wur7S0",
      "target": "uncertainty estimation and improved interpretability.\"",
      "similarity": 0.8455
    },
    {
      "source": "PY56Wur7S0",
      "target": "UN6Ik6OCx8",
      "similarity": 0.8424
    },
    {
      "source": "In this paper",
      "target": "kX8h23UG6v",
      "similarity": 0.8614
    },
    {
      "source": "In this paper",
      "target": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "similarity": 0.841
    },
    {
      "source": "In this paper",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8329
    },
    {
      "source": "In this paper",
      "target": "compression has become increasingly crucial for reducing costs and improving",
      "similarity": 0.8322
    },
    {
      "source": "In this paper",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.832
    },
    {
      "source": "We further guide the policy and value estimation by executing each line and annotating it with its results on the given examples.",
      "target": "NCrFA7dq8T",
      "similarity": 0.8696
    },
    {
      "source": "We further guide the policy and value estimation by executing each line and annotating it with its results on the given examples.",
      "target": "B8akWa62Da",
      "similarity": 0.8429
    },
    {
      "source": "We further guide the policy and value estimation by executing each line and annotating it with its results on the given examples.",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8289
    },
    {
      "source": "We further guide the policy and value estimation by executing each line and annotating it with its results on the given examples.",
      "target": "T4sMzjy7fO",
      "similarity": 0.8185
    },
    {
      "source": "We further guide the policy and value estimation by executing each line and annotating it with its results on the given examples.",
      "target": "instances compared to 6% for the next best system.\"",
      "similarity": 0.8147
    },
    {
      "source": "This allows us to search for programs within a single (expanding) prompt until a sound program is found",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8459
    },
    {
      "source": "This allows us to search for programs within a single (expanding) prompt until a sound program is found",
      "target": "In this setting",
      "similarity": 0.8384
    },
    {
      "source": "This allows us to search for programs within a single (expanding) prompt until a sound program is found",
      "target": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "similarity": 0.8326
    },
    {
      "source": "This allows us to search for programs within a single (expanding) prompt until a sound program is found",
      "target": "HN0CYZbAPw",
      "similarity": 0.8305
    },
    {
      "source": "This allows us to search for programs within a single (expanding) prompt until a sound program is found",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8267
    },
    {
      "source": "We evaluate within-prompt search on straight-line Python code generation using five benchmarks across different domains (strings",
      "target": "Regret",
      "similarity": 0.8172
    },
    {
      "source": "We evaluate within-prompt search on straight-line Python code generation using five benchmarks across different domains (strings",
      "target": "IDxZhXrpNf",
      "similarity": 0.804
    },
    {
      "source": "We evaluate within-prompt search on straight-line Python code generation using five benchmarks across different domains (strings",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.7979
    },
    {
      "source": "We evaluate within-prompt search on straight-line Python code generation using five benchmarks across different domains (strings",
      "target": "NHMuM84tRT",
      "similarity": 0.7943
    },
    {
      "source": "We evaluate within-prompt search on straight-line Python code generation using five benchmarks across different domains (strings",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.7922
    },
    {
      "source": "We show that the model uses the execution results to guide the search and that within-prompt search performs well at low token budgets.",
      "target": "ZadnlOHsHv",
      "similarity": 0.8095
    },
    {
      "source": "We show that the model uses the execution results to guide the search and that within-prompt search performs well at low token budgets.",
      "target": "FEZOLWexPb",
      "similarity": 0.8089
    },
    {
      "source": "We show that the model uses the execution results to guide the search and that within-prompt search performs well at low token budgets.",
      "target": "sound",
      "similarity": 0.8058
    },
    {
      "source": "We show that the model uses the execution results to guide the search and that within-prompt search performs well at low token budgets.",
      "target": "UL2",
      "similarity": 0.8034
    },
    {
      "source": "We show that the model uses the execution results to guide the search and that within-prompt search performs well at low token budgets.",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8027
    },
    {
      "source": "We also analyze how the model behaves as a policy and value",
      "target": "97rOQDPmk2",
      "similarity": 0.8817
    },
    {
      "source": "We also analyze how the model behaves as a policy and value",
      "target": "Moreover",
      "similarity": 0.8607
    },
    {
      "source": "We also analyze how the model behaves as a policy and value",
      "target": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "similarity": 0.8503
    },
    {
      "source": "We also analyze how the model behaves as a policy and value",
      "target": "As a highlight",
      "similarity": 0.8436
    },
    {
      "source": "We also analyze how the model behaves as a policy and value",
      "target": "mOpNrrV2zH",
      "similarity": 0.8387
    },
    {
      "source": "7PLpiVdnUC",
      "target": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "similarity": 0.8712
    },
    {
      "source": "7PLpiVdnUC",
      "target": "kxnoqaisCT",
      "similarity": 0.8699
    },
    {
      "source": "7PLpiVdnUC",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8487
    },
    {
      "source": "7PLpiVdnUC",
      "target": "To explore this",
      "similarity": 0.8234
    },
    {
      "source": "7PLpiVdnUC",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8194
    },
    {
      "source": "3n6DYH3cIP",
      "target": "Q0s6kgrUMr",
      "similarity": 0.8445
    },
    {
      "source": "3n6DYH3cIP",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8139
    },
    {
      "source": "3n6DYH3cIP",
      "target": "590yfqz1LE",
      "similarity": 0.8063
    },
    {
      "source": "3n6DYH3cIP",
      "target": "From a practical standpoint",
      "similarity": 0.805
    },
    {
      "source": "3n6DYH3cIP",
      "target": "HN8V0flwJF",
      "similarity": 0.8028
    },
    {
      "source": "iAmR7FfMmq",
      "target": "https://sites.google.com/view/rnd-dagger\"",
      "similarity": 0.8749
    },
    {
      "source": "iAmR7FfMmq",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8266
    },
    {
      "source": "iAmR7FfMmq",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8217
    },
    {
      "source": "iAmR7FfMmq",
      "target": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "similarity": 0.8028
    },
    {
      "source": "iAmR7FfMmq",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8024
    },
    {
      "source": "KfeRfxTemB",
      "target": "04qx93Viwj",
      "similarity": 0.8552
    },
    {
      "source": "KfeRfxTemB",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8335
    },
    {
      "source": "KfeRfxTemB",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8282
    },
    {
      "source": "KfeRfxTemB",
      "target": "In this paper",
      "similarity": 0.8207
    },
    {
      "source": "KfeRfxTemB",
      "target": "xQCXInDq0m",
      "similarity": 0.8198
    },
    {
      "source": "yp95goUAT1",
      "target": "zpENPcQSj1",
      "similarity": 0.863
    },
    {
      "source": "yp95goUAT1",
      "target": "TUvg5uwdeG",
      "similarity": 0.8538
    },
    {
      "source": "yp95goUAT1",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8512
    },
    {
      "source": "yp95goUAT1",
      "target": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "similarity": 0.8488
    },
    {
      "source": "yp95goUAT1",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8411
    },
    {
      "source": "27SSnLl85x",
      "target": "We introduce a novel",
      "similarity": 0.8655
    },
    {
      "source": "27SSnLl85x",
      "target": "selection of LLMs",
      "similarity": 0.8546
    },
    {
      "source": "27SSnLl85x",
      "target": "additional structural constraints",
      "similarity": 0.848
    },
    {
      "source": "27SSnLl85x",
      "target": "However",
      "similarity": 0.8434
    },
    {
      "source": "27SSnLl85x",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8372
    },
    {
      "source": "LvDwwAgMEW",
      "target": "Further",
      "similarity": 0.8563
    },
    {
      "source": "LvDwwAgMEW",
      "target": "vVHc8bGRns",
      "similarity": 0.8535
    },
    {
      "source": "LvDwwAgMEW",
      "target": "We propose RAMEN",
      "similarity": 0.8066
    },
    {
      "source": "LvDwwAgMEW",
      "target": "Against grandmaster-level (2500 Elo) opponents",
      "similarity": 0.8014
    },
    {
      "source": "LvDwwAgMEW",
      "target": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "similarity": 0.8006
    },
    {
      "source": "tasks by using labeled examples or natural language prompts.",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8063
    },
    {
      "source": "tasks by using labeled examples or natural language prompts.",
      "target": "ed7zI29lRF",
      "similarity": 0.7941
    },
    {
      "source": "tasks by using labeled examples or natural language prompts.",
      "target": "pq1WUegkza",
      "similarity": 0.7926
    },
    {
      "source": "tasks by using labeled examples or natural language prompts.",
      "target": "MJNywBdSDy",
      "similarity": 0.7905
    },
    {
      "source": "tasks by using labeled examples or natural language prompts.",
      "target": "baselines (e.g.",
      "similarity": 0.7896
    },
    {
      "source": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "target": "In this work",
      "similarity": 0.8191
    },
    {
      "source": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "target": "task.",
      "similarity": 0.8175
    },
    {
      "source": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "target": "unlimited streaming.\"",
      "similarity": 0.8155
    },
    {
      "source": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8151
    },
    {
      "source": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.8123
    },
    {
      "source": "We identify prototypical challenges that users face when specifying preferences",
      "target": "Finally",
      "similarity": 0.8329
    },
    {
      "source": "We identify prototypical challenges that users face when specifying preferences",
      "target": "AoIKgHu9Si",
      "similarity": 0.8259
    },
    {
      "source": "We identify prototypical challenges that users face when specifying preferences",
      "target": "remains a largely unexplored domain.",
      "similarity": 0.8198
    },
    {
      "source": "We identify prototypical challenges that users face when specifying preferences",
      "target": "ThhQyIruEs",
      "similarity": 0.8084
    },
    {
      "source": "We identify prototypical challenges that users face when specifying preferences",
      "target": "ogXkmugNZw",
      "similarity": 0.805
    },
    {
      "source": "content recommendation",
      "target": "3RSLW9YSgk",
      "similarity": 0.823
    },
    {
      "source": "content recommendation",
      "target": "30oIfmrcFO",
      "similarity": 0.8088
    },
    {
      "source": "content recommendation",
      "target": "5yDS32hKJc",
      "similarity": 0.7973
    },
    {
      "source": "content recommendation",
      "target": "We propose several designs to address these issues.",
      "similarity": 0.7961
    },
    {
      "source": "content recommendation",
      "target": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "similarity": 0.794
    },
    {
      "source": "In preregistered experiments",
      "target": "xiQNfYl33p",
      "similarity": 0.9116
    },
    {
      "source": "In preregistered experiments",
      "target": "Stick-breaking also performs well at length generalisation",
      "similarity": 0.877
    },
    {
      "source": "In preregistered experiments",
      "target": "QowsEic1sc",
      "similarity": 0.8753
    },
    {
      "source": "In preregistered experiments",
      "target": "rdAbEn5DZt",
      "similarity": 0.8596
    },
    {
      "source": "In preregistered experiments",
      "target": "relying on backward propagation",
      "similarity": 0.8567
    },
    {
      "source": "i1NNCrRxdM",
      "target": "6ycX677p2l",
      "similarity": 0.8783
    },
    {
      "source": "i1NNCrRxdM",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8777
    },
    {
      "source": "i1NNCrRxdM",
      "target": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "similarity": 0.8718
    },
    {
      "source": "i1NNCrRxdM",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8717
    },
    {
      "source": "i1NNCrRxdM",
      "target": "Ultimately",
      "similarity": 0.8689
    },
    {
      "source": "NEu8wgPctU",
      "target": "First",
      "similarity": 0.8731
    },
    {
      "source": "NEu8wgPctU",
      "target": "INqLJwqUmc",
      "similarity": 0.8337
    },
    {
      "source": "NEu8wgPctU",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.8327
    },
    {
      "source": "NEu8wgPctU",
      "target": "GkWA6NjePN",
      "similarity": 0.823
    },
    {
      "source": "NEu8wgPctU",
      "target": "wmV4cIbgl6",
      "similarity": 0.8226
    },
    {
      "source": "eeJz7eDWKO",
      "target": "suz4utPr9Y",
      "similarity": 0.864
    },
    {
      "source": "eeJz7eDWKO",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8446
    },
    {
      "source": "eeJz7eDWKO",
      "target": "Dl3MsjaIdp",
      "similarity": 0.8394
    },
    {
      "source": "eeJz7eDWKO",
      "target": "K4FAFNRpko",
      "similarity": 0.8336
    },
    {
      "source": "eeJz7eDWKO",
      "target": "EEgYUccwsV",
      "similarity": 0.8333
    },
    {
      "source": "As such",
      "target": "yFGR36PLDJ",
      "similarity": 0.8299
    },
    {
      "source": "As such",
      "target": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "similarity": 0.8239
    },
    {
      "source": "As such",
      "target": "HrdVqFSn1e",
      "similarity": 0.8239
    },
    {
      "source": "As such",
      "target": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "similarity": 0.8195
    },
    {
      "source": "As such",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8174
    },
    {
      "source": "Finding an accurate approximation to this posterior is challenging",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.8452
    },
    {
      "source": "Finding an accurate approximation to this posterior is challenging",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8368
    },
    {
      "source": "Finding an accurate approximation to this posterior is challenging",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.8367
    },
    {
      "source": "Finding an accurate approximation to this posterior is challenging",
      "target": "X6y5CC44HM",
      "similarity": 0.8334
    },
    {
      "source": "Finding an accurate approximation to this posterior is challenging",
      "target": "For instance",
      "similarity": 0.8301
    },
    {
      "source": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8312
    },
    {
      "source": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "target": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "similarity": 0.8198
    },
    {
      "source": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "target": "8enWnd6Gp3",
      "similarity": 0.8012
    },
    {
      "source": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "target": "Then",
      "similarity": 0.7969
    },
    {
      "source": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.7955
    },
    {
      "source": "Yet",
      "target": "of our proposed method through a new understanding of the contrastive loss of",
      "similarity": 0.8364
    },
    {
      "source": "Yet",
      "target": "We then leverage a popular data compression technique",
      "similarity": 0.8263
    },
    {
      "source": "Yet",
      "target": "This helps LLMs better interpret and execute the prompts",
      "similarity": 0.819
    },
    {
      "source": "Yet",
      "target": "a two-player game and propose a novel online algorithm",
      "similarity": 0.8103
    },
    {
      "source": "Yet",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8098
    },
    {
      "source": "To address these limitations",
      "target": "bmbRCRiNDu",
      "similarity": 0.8326
    },
    {
      "source": "To address these limitations",
      "target": "uqe5HkjbT9",
      "similarity": 0.8312
    },
    {
      "source": "To address these limitations",
      "target": "zpENPcQSj1",
      "similarity": 0.8295
    },
    {
      "source": "To address these limitations",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8281
    },
    {
      "source": "To address these limitations",
      "target": "G5DziesYxL",
      "similarity": 0.8273
    },
    {
      "source": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "target": "590yfqz1LE",
      "similarity": 0.8868
    },
    {
      "source": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "target": "HpUs2EXjOl",
      "similarity": 0.8597
    },
    {
      "source": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8543
    },
    {
      "source": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8504
    },
    {
      "source": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "target": "BpyHIrpUOL",
      "similarity": 0.8491
    },
    {
      "source": "FSjIrOm1vz",
      "target": "Motivated by this insight",
      "similarity": 0.8497
    },
    {
      "source": "FSjIrOm1vz",
      "target": "uxDFlPGRLX",
      "similarity": 0.8413
    },
    {
      "source": "FSjIrOm1vz",
      "target": "The library is based on a new representation that we propose for organizing the formulas of mathematical constants:",
      "similarity": 0.8399
    },
    {
      "source": "FSjIrOm1vz",
      "target": "uqWM9hBDAE",
      "similarity": 0.8393
    },
    {
      "source": "FSjIrOm1vz",
      "target": "kGvXIlIVLM",
      "similarity": 0.8352
    },
    {
      "source": "Tv36j85SqR",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8468
    },
    {
      "source": "Tv36j85SqR",
      "target": "Igm9bbkzHC",
      "similarity": 0.8394
    },
    {
      "source": "Tv36j85SqR",
      "target": "nibeaHUEJx",
      "similarity": 0.8344
    },
    {
      "source": "Tv36j85SqR",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8276
    },
    {
      "source": "Tv36j85SqR",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8269
    },
    {
      "source": "m8yby1JfbU",
      "target": "By incorporating generative models into the BOED framework",
      "similarity": 0.8888
    },
    {
      "source": "m8yby1JfbU",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8835
    },
    {
      "source": "m8yby1JfbU",
      "target": "As a highlight",
      "similarity": 0.8657
    },
    {
      "source": "m8yby1JfbU",
      "target": "aXwukBD6M6",
      "similarity": 0.8646
    },
    {
      "source": "m8yby1JfbU",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8604
    },
    {
      "source": "the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability",
      "target": "1CLzLXSFNn",
      "similarity": 0.8132
    },
    {
      "source": "the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability",
      "target": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "similarity": 0.8119
    },
    {
      "source": "the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability",
      "target": "In this paper",
      "similarity": 0.7917
    },
    {
      "source": "the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability",
      "target": "Tpjq66xwTq",
      "similarity": 0.7832
    },
    {
      "source": "the need for robust and scalable evaluation of their performance becomes increasingly critical. The traditional human expert-based evaluation of VLMs has limitations in consistency and scalability",
      "target": "In this work",
      "similarity": 0.781
    },
    {
      "source": "such as employing VLMs to evaluate VLMs. However",
      "target": "leading proprietary models (e.g.",
      "similarity": 0.8488
    },
    {
      "source": "such as employing VLMs to evaluate VLMs. However",
      "target": "1Z6PSw7OL8",
      "similarity": 0.8437
    },
    {
      "source": "such as employing VLMs to evaluate VLMs. However",
      "target": "JTji0Jfh5a",
      "similarity": 0.841
    },
    {
      "source": "such as employing VLMs to evaluate VLMs. However",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.8325
    },
    {
      "source": "such as employing VLMs to evaluate VLMs. However",
      "target": "8TBGdH3t6a",
      "similarity": 0.8274
    },
    {
      "source": "judges remains underexplored. Existing methods often rely on a single VLM as",
      "target": "In practice",
      "similarity": 0.8787
    },
    {
      "source": "judges remains underexplored. Existing methods often rely on a single VLM as",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8321
    },
    {
      "source": "judges remains underexplored. Existing methods often rely on a single VLM as",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8251
    },
    {
      "source": "judges remains underexplored. Existing methods often rely on a single VLM as",
      "target": "DL9txImSzm",
      "similarity": 0.8224
    },
    {
      "source": "judges remains underexplored. Existing methods often rely on a single VLM as",
      "target": "254NJe9JEw",
      "similarity": 0.822
    },
    {
      "source": "the evaluator. However",
      "target": "fXb9BbuyAD",
      "similarity": 0.8255
    },
    {
      "source": "the evaluator. However",
      "target": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "similarity": 0.8241
    },
    {
      "source": "the evaluator. However",
      "target": "ference network to approximate the posterior distribution of the latent variables.",
      "similarity": 0.8218
    },
    {
      "source": "the evaluator. However",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8201
    },
    {
      "source": "the evaluator. However",
      "target": "XdRIno98gG",
      "similarity": 0.8193
    },
    {
      "source": "model may lack the ability to fully understand the content and may have inherent",
      "target": "Thus",
      "similarity": 0.8191
    },
    {
      "source": "model may lack the ability to fully understand the content and may have inherent",
      "target": "eU39PDsZtT",
      "similarity": 0.8165
    },
    {
      "source": "model may lack the ability to fully understand the content and may have inherent",
      "target": "rTCJ29pkuA",
      "similarity": 0.8157
    },
    {
      "source": "model may lack the ability to fully understand the content and may have inherent",
      "target": "riTiq3i21b",
      "similarity": 0.8121
    },
    {
      "source": "model may lack the ability to fully understand the content and may have inherent",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.8111
    },
    {
      "source": "biases",
      "target": "ReItdfwMcg",
      "similarity": 0.8729
    },
    {
      "source": "biases",
      "target": "Furthermore",
      "similarity": 0.8239
    },
    {
      "source": "biases",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8215
    },
    {
      "source": "biases",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8198
    },
    {
      "source": "biases",
      "target": "CAssIgPN4I",
      "similarity": 0.8134
    },
    {
      "source": "enhance reliability. This study investigates the efficacy of such approaches",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8729
    },
    {
      "source": "enhance reliability. This study investigates the efficacy of such approaches",
      "target": "SOTA LLMs",
      "similarity": 0.8638
    },
    {
      "source": "enhance reliability. This study investigates the efficacy of such approaches",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8621
    },
    {
      "source": "enhance reliability. This study investigates the efficacy of such approaches",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8553
    },
    {
      "source": "enhance reliability. This study investigates the efficacy of such approaches",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.855
    },
    {
      "source": "findings reveal that incorporating collective judgments from such a mixed pool",
      "target": "JUr0YOMvZA",
      "similarity": 0.8879
    },
    {
      "source": "findings reveal that incorporating collective judgments from such a mixed pool",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.884
    },
    {
      "source": "findings reveal that incorporating collective judgments from such a mixed pool",
      "target": "relying on backward propagation",
      "similarity": 0.8527
    },
    {
      "source": "findings reveal that incorporating collective judgments from such a mixed pool",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8479
    },
    {
      "source": "findings reveal that incorporating collective judgments from such a mixed pool",
      "target": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "similarity": 0.8471
    },
    {
      "source": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8523
    },
    {
      "source": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "target": "However",
      "similarity": 0.8443
    },
    {
      "source": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8405
    },
    {
      "source": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "target": "4BFzTrIjPN",
      "similarity": 0.8337
    },
    {
      "source": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "target": "oZkqkkvdND",
      "similarity": 0.8324
    },
    {
      "source": "less reliable judges can introduce noise",
      "target": "4JK2XMGUc8",
      "similarity": 0.8451
    },
    {
      "source": "less reliable judges can introduce noise",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8442
    },
    {
      "source": "less reliable judges can introduce noise",
      "target": "cC3LxGZasH",
      "similarity": 0.8287
    },
    {
      "source": "less reliable judges can introduce noise",
      "target": "increased their demand. However",
      "similarity": 0.8278
    },
    {
      "source": "less reliable judges can introduce noise",
      "target": "In doing so",
      "similarity": 0.8196
    },
    {
      "source": "outcomes. To explore the factors that impact evaluation reliability",
      "target": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "similarity": 0.8104
    },
    {
      "source": "outcomes. To explore the factors that impact evaluation reliability",
      "target": "uqWM9hBDAE",
      "similarity": 0.8091
    },
    {
      "source": "outcomes. To explore the factors that impact evaluation reliability",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.805
    },
    {
      "source": "outcomes. To explore the factors that impact evaluation reliability",
      "target": "Furthermore",
      "similarity": 0.8044
    },
    {
      "source": "outcomes. To explore the factors that impact evaluation reliability",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.7982
    },
    {
      "source": "an underperforming VLM judge",
      "target": "pZiyCaVuti",
      "similarity": 0.8594
    },
    {
      "source": "an underperforming VLM judge",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8491
    },
    {
      "source": "an underperforming VLM judge",
      "target": "74vnDs1R97",
      "similarity": 0.8483
    },
    {
      "source": "an underperforming VLM judge",
      "target": "rAoEub6Nw2",
      "similarity": 0.8358
    },
    {
      "source": "an underperforming VLM judge",
      "target": "4xWQS2z77v",
      "similarity": 0.8354
    },
    {
      "source": "findings stress the limitations of collective thought approaches and highlight the",
      "target": "BkftcwIVmR",
      "similarity": 0.8572
    },
    {
      "source": "findings stress the limitations of collective thought approaches and highlight the",
      "target": "uhaLuZcCjH",
      "similarity": 0.8541
    },
    {
      "source": "findings stress the limitations of collective thought approaches and highlight the",
      "target": "To address these challenges",
      "similarity": 0.853
    },
    {
      "source": "findings stress the limitations of collective thought approaches and highlight the",
      "target": "s9zoyICZ4k",
      "similarity": 0.8415
    },
    {
      "source": "findings stress the limitations of collective thought approaches and highlight the",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.836
    },
    {
      "source": "need for more advanced methods that can account for the reliability of individual",
      "target": "20qZK2T7fa",
      "similarity": 0.8734
    },
    {
      "source": "need for more advanced methods that can account for the reliability of individual",
      "target": "2fojNANZSv",
      "similarity": 0.8543
    },
    {
      "source": "need for more advanced methods that can account for the reliability of individual",
      "target": "assessing and advancing topological methods",
      "similarity": 0.8529
    },
    {
      "source": "need for more advanced methods that can account for the reliability of individual",
      "target": "ogXkmugNZw",
      "similarity": 0.8492
    },
    {
      "source": "need for more advanced methods that can account for the reliability of individual",
      "target": "uHLgDEgiS5",
      "similarity": 0.8484
    },
    {
      "source": "models. Our study promotes the development of more reliable evaluation methods",
      "target": "DKgAFfCs5F",
      "similarity": 0.856
    },
    {
      "source": "models. Our study promotes the development of more reliable evaluation methods",
      "target": "WOt1owGfuN",
      "similarity": 0.8328
    },
    {
      "source": "models. Our study promotes the development of more reliable evaluation methods",
      "target": "iXbUquaWbl",
      "similarity": 0.8313
    },
    {
      "source": "models. Our study promotes the development of more reliable evaluation methods",
      "target": "UchRjcf4z7",
      "similarity": 0.8312
    },
    {
      "source": "models. Our study promotes the development of more reliable evaluation methods",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.8249
    },
    {
      "source": "for VLMs\"",
      "target": "In this work",
      "similarity": 0.8228
    },
    {
      "source": "for VLMs\"",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.8215
    },
    {
      "source": "for VLMs\"",
      "target": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "similarity": 0.8187
    },
    {
      "source": "for VLMs\"",
      "target": "In this paper",
      "similarity": 0.8108
    },
    {
      "source": "for VLMs\"",
      "target": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "similarity": 0.8103
    },
    {
      "source": "AZR4R3lw7y",
      "target": "DzGe40glxs",
      "similarity": 0.8605
    },
    {
      "source": "AZR4R3lw7y",
      "target": "oYSsbY3G4o",
      "similarity": 0.8287
    },
    {
      "source": "AZR4R3lw7y",
      "target": "In this work",
      "similarity": 0.8217
    },
    {
      "source": "AZR4R3lw7y",
      "target": "and adversarial samples and rejecting them. Empirical validation of the approach",
      "similarity": 0.8154
    },
    {
      "source": "AZR4R3lw7y",
      "target": "behavior across compute scale? We find that small- and large-scale language",
      "similarity": 0.8099
    },
    {
      "source": "in each task and facilitating CL overall. Additionally",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.829
    },
    {
      "source": "in each task and facilitating CL overall. Additionally",
      "target": "MBBRHDuiwM",
      "similarity": 0.8285
    },
    {
      "source": "in each task and facilitating CL overall. Additionally",
      "target": "4es2oO9tw1",
      "similarity": 0.8247
    },
    {
      "source": "in each task and facilitating CL overall. Additionally",
      "target": "b24n2LS2BJ",
      "similarity": 0.8189
    },
    {
      "source": "in each task and facilitating CL overall. Additionally",
      "target": "mXHTifc1Fn",
      "similarity": 0.8162
    },
    {
      "source": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "target": "pCj2sLNoJq",
      "similarity": 0.8754
    },
    {
      "source": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "target": "riieAeQBJm",
      "similarity": 0.8749
    },
    {
      "source": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "target": "extreme weather forecasts to enhance their practical utility\"",
      "similarity": 0.8645
    },
    {
      "source": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "target": "BL4WBIfyrz",
      "similarity": 0.863
    },
    {
      "source": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8584
    },
    {
      "source": "4FWAwZtd2n",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.9066
    },
    {
      "source": "4FWAwZtd2n",
      "target": "llSiIJosDj",
      "similarity": 0.8811
    },
    {
      "source": "4FWAwZtd2n",
      "target": "Reweighting (GSR)",
      "similarity": 0.8604
    },
    {
      "source": "4FWAwZtd2n",
      "target": "YslOW2SO6S",
      "similarity": 0.8549
    },
    {
      "source": "4FWAwZtd2n",
      "target": "To this end",
      "similarity": 0.8498
    },
    {
      "source": "eHfq8Q3LeD",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8586
    },
    {
      "source": "eHfq8Q3LeD",
      "target": "0fJfVOSUra",
      "similarity": 0.8553
    },
    {
      "source": "eHfq8Q3LeD",
      "target": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "similarity": 0.8521
    },
    {
      "source": "eHfq8Q3LeD",
      "target": "WCRQFlji2q",
      "similarity": 0.8503
    },
    {
      "source": "eHfq8Q3LeD",
      "target": "In this work",
      "similarity": 0.8454
    },
    {
      "source": "jxMAPMqNr5",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8843
    },
    {
      "source": "jxMAPMqNr5",
      "target": "Yet",
      "similarity": 0.8784
    },
    {
      "source": "jxMAPMqNr5",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8686
    },
    {
      "source": "jxMAPMqNr5",
      "target": "4YzVF9isgD",
      "similarity": 0.8677
    },
    {
      "source": "jxMAPMqNr5",
      "target": "zCZnEXF3bN",
      "similarity": 0.8615
    },
    {
      "source": "However",
      "target": "Code",
      "similarity": 0.88
    },
    {
      "source": "However",
      "target": "To mitigate such Attention Drift issue",
      "similarity": 0.8569
    },
    {
      "source": "However",
      "target": "OuLgaHEmzi",
      "similarity": 0.8261
    },
    {
      "source": "However",
      "target": "kxnoqaisCT",
      "similarity": 0.8165
    },
    {
      "source": "However",
      "target": "aliasing if pushed too far",
      "similarity": 0.8148
    },
    {
      "source": "To overcome this limitation",
      "target": "IQxBDLmVpT",
      "similarity": 0.8979
    },
    {
      "source": "To overcome this limitation",
      "target": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "similarity": 0.8817
    },
    {
      "source": "To overcome this limitation",
      "target": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "similarity": 0.8622
    },
    {
      "source": "To overcome this limitation",
      "target": "RC5FPYVQaH",
      "similarity": 0.8608
    },
    {
      "source": "To overcome this limitation",
      "target": "J9FgrqOOni",
      "similarity": 0.8608
    },
    {
      "source": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8838
    },
    {
      "source": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "target": "1durmugh3I",
      "similarity": 0.8554
    },
    {
      "source": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "target": "WttfQGwpES",
      "similarity": 0.844
    },
    {
      "source": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.8424
    },
    {
      "source": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8421
    },
    {
      "source": "In addition",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8953
    },
    {
      "source": "In addition",
      "target": "TDy5Ih78b4",
      "similarity": 0.8929
    },
    {
      "source": "In addition",
      "target": "However",
      "similarity": 0.8915
    },
    {
      "source": "In addition",
      "target": "a challenge",
      "similarity": 0.8899
    },
    {
      "source": "In addition",
      "target": "cZWCjan02B",
      "similarity": 0.884
    },
    {
      "source": "To the best of our knowledge",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8712
    },
    {
      "source": "To the best of our knowledge",
      "target": "gY08Ou8EL7",
      "similarity": 0.8603
    },
    {
      "source": "To the best of our knowledge",
      "target": "kbm6tsICar",
      "similarity": 0.8572
    },
    {
      "source": "To the best of our knowledge",
      "target": "nx9Z5Kva96",
      "similarity": 0.8518
    },
    {
      "source": "To the best of our knowledge",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8516
    },
    {
      "source": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "target": "In each case",
      "similarity": 0.8245
    },
    {
      "source": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "target": "PgXpOOqtyd",
      "similarity": 0.8155
    },
    {
      "source": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "target": "spDUv05cEq",
      "similarity": 0.8142
    },
    {
      "source": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8074
    },
    {
      "source": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "target": "CjXaMI2kUH",
      "similarity": 0.8063
    },
    {
      "source": "eNQp79A5Oz",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8751
    },
    {
      "source": "eNQp79A5Oz",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8642
    },
    {
      "source": "eNQp79A5Oz",
      "target": "Moreover",
      "similarity": 0.8597
    },
    {
      "source": "eNQp79A5Oz",
      "target": "E4LAVLXAHW",
      "similarity": 0.8579
    },
    {
      "source": "eNQp79A5Oz",
      "target": "Furthermore",
      "similarity": 0.857
    },
    {
      "source": "uHLgDEgiS5",
      "target": "ogXkmugNZw",
      "similarity": 0.8647
    },
    {
      "source": "uHLgDEgiS5",
      "target": "To remedy this problem",
      "similarity": 0.8641
    },
    {
      "source": "uHLgDEgiS5",
      "target": "1yJP5TVWih",
      "similarity": 0.8569
    },
    {
      "source": "uHLgDEgiS5",
      "target": "20qZK2T7fa",
      "similarity": 0.853
    },
    {
      "source": "uHLgDEgiS5",
      "target": "implementation",
      "similarity": 0.8527
    },
    {
      "source": "cnKhHxN3xj",
      "target": "unlimited streaming.\"",
      "similarity": 0.8078
    },
    {
      "source": "cnKhHxN3xj",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.7905
    },
    {
      "source": "cnKhHxN3xj",
      "target": "INqLJwqUmc",
      "similarity": 0.789
    },
    {
      "source": "cnKhHxN3xj",
      "target": "bsFWJ0Kget",
      "similarity": 0.7885
    },
    {
      "source": "cnKhHxN3xj",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.7849
    },
    {
      "source": "4dAgG8ma3B",
      "target": "kbm6tsICar",
      "similarity": 0.8715
    },
    {
      "source": "4dAgG8ma3B",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8696
    },
    {
      "source": "4dAgG8ma3B",
      "target": "To this end",
      "similarity": 0.8675
    },
    {
      "source": "4dAgG8ma3B",
      "target": "We release models",
      "similarity": 0.8669
    },
    {
      "source": "4dAgG8ma3B",
      "target": "Interestingly",
      "similarity": 0.8632
    },
    {
      "source": "nDmwloEl3N",
      "target": "Besides this primary purpose",
      "similarity": 0.8695
    },
    {
      "source": "nDmwloEl3N",
      "target": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "similarity": 0.8264
    },
    {
      "source": "nDmwloEl3N",
      "target": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "similarity": 0.8191
    },
    {
      "source": "nDmwloEl3N",
      "target": "(including gradient-based",
      "similarity": 0.8177
    },
    {
      "source": "nDmwloEl3N",
      "target": "L0evcuybH5",
      "similarity": 0.8169
    },
    {
      "source": "As models are becoming larger to capture more complex capabilities",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8665
    },
    {
      "source": "As models are becoming larger to capture more complex capabilities",
      "target": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "similarity": 0.856
    },
    {
      "source": "As models are becoming larger to capture more complex capabilities",
      "target": "xsELpEPn4A",
      "similarity": 0.8558
    },
    {
      "source": "As models are becoming larger to capture more complex capabilities",
      "target": "wHebuIb6IH",
      "similarity": 0.8539
    },
    {
      "source": "As models are becoming larger to capture more complex capabilities",
      "target": "Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single",
      "similarity": 0.8493
    },
    {
      "source": "Therefore",
      "target": "CvGqMD5OtX",
      "similarity": 0.8332
    },
    {
      "source": "Therefore",
      "target": "component of real-world software development.\"",
      "similarity": 0.818
    },
    {
      "source": "Therefore",
      "target": "hNjCVVm0EQ",
      "similarity": 0.8145
    },
    {
      "source": "Therefore",
      "target": "7VkHffT5X2",
      "similarity": 0.8137
    },
    {
      "source": "Therefore",
      "target": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "similarity": 0.8122
    },
    {
      "source": "To address this gap",
      "target": "ZNnmcddaB3",
      "similarity": 0.8392
    },
    {
      "source": "To address this gap",
      "target": "TjP1d8PP8l",
      "similarity": 0.8186
    },
    {
      "source": "To address this gap",
      "target": "Finally",
      "similarity": 0.8174
    },
    {
      "source": "To address this gap",
      "target": "To integrate it with canonicalization",
      "similarity": 0.8143
    },
    {
      "source": "To address this gap",
      "target": "w8LMtFY97b",
      "similarity": 0.8128
    },
    {
      "source": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "target": "However",
      "similarity": 0.843
    },
    {
      "source": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "target": "2ET561DyPe",
      "similarity": 0.8328
    },
    {
      "source": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "target": "f3QR9TEERH",
      "similarity": 0.8325
    },
    {
      "source": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8255
    },
    {
      "source": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8238
    },
    {
      "source": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "target": "gjRhw5S3A4",
      "similarity": 0.8693
    },
    {
      "source": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8467
    },
    {
      "source": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "target": "FBhKUXK7od",
      "similarity": 0.8449
    },
    {
      "source": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "target": "gkUyYcY1W9",
      "similarity": 0.8391
    },
    {
      "source": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "target": "work endeavors to apply a graph-based approach for the contextual and adaptive",
      "similarity": 0.8374
    },
    {
      "source": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "target": "solution. For $p = 1$",
      "similarity": 0.8965
    },
    {
      "source": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8748
    },
    {
      "source": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "target": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "similarity": 0.8735
    },
    {
      "source": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "target": "jj7b3p5kLY",
      "similarity": 0.867
    },
    {
      "source": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "target": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "similarity": 0.8667
    },
    {
      "source": "Notably",
      "target": "In real-world scenarios",
      "similarity": 0.9227
    },
    {
      "source": "Notably",
      "target": "gFvRRCnQvX",
      "similarity": 0.8435
    },
    {
      "source": "Notably",
      "target": "U834XHJuqk",
      "similarity": 0.8373
    },
    {
      "source": "Notably",
      "target": "GeUK3zGreN",
      "similarity": 0.8196
    },
    {
      "source": "Notably",
      "target": "contextual interactions among tasks",
      "similarity": 0.8174
    },
    {
      "source": "It surpasses both CNN-based and Transformer Diffusion Policies by an average of $57\\%$ across 4 benchmarks",
      "target": "This gap is probably due to the difficulty of jointly solving different problems",
      "similarity": 0.8383
    },
    {
      "source": "It surpasses both CNN-based and Transformer Diffusion Policies by an average of $57\\%$ across 4 benchmarks",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.8232
    },
    {
      "source": "It surpasses both CNN-based and Transformer Diffusion Policies by an average of $57\\%$ across 4 benchmarks",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.7974
    },
    {
      "source": "It surpasses both CNN-based and Transformer Diffusion Policies by an average of $57\\%$ across 4 benchmarks",
      "target": "xvhV3LvYTc",
      "similarity": 0.7748
    },
    {
      "source": "It surpasses both CNN-based and Transformer Diffusion Policies by an average of $57\\%$ across 4 benchmarks",
      "target": "ExuBFYtCQU",
      "similarity": 0.772
    },
    {
      "source": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "target": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "similarity": 0.8745
    },
    {
      "source": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "target": "gsShHPxkUW",
      "similarity": 0.8594
    },
    {
      "source": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "target": "84WmbzikPP",
      "similarity": 0.8546
    },
    {
      "source": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "target": "8eNLKk5by4",
      "similarity": 0.8503
    },
    {
      "source": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "target": "Together",
      "similarity": 0.8443
    },
    {
      "source": "hSZaCIznB2",
      "target": "GeUK3zGreN",
      "similarity": 0.8773
    },
    {
      "source": "hSZaCIznB2",
      "target": "ZGqd0cbBvm",
      "similarity": 0.8479
    },
    {
      "source": "hSZaCIznB2",
      "target": "U834XHJuqk",
      "similarity": 0.8439
    },
    {
      "source": "hSZaCIznB2",
      "target": "Despite this",
      "similarity": 0.8412
    },
    {
      "source": "hSZaCIznB2",
      "target": "f7O3hITh5s",
      "similarity": 0.8362
    },
    {
      "source": "2TasVD7FXp",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8507
    },
    {
      "source": "2TasVD7FXp",
      "target": "mechanism",
      "similarity": 0.845
    },
    {
      "source": "2TasVD7FXp",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8368
    },
    {
      "source": "2TasVD7FXp",
      "target": "bBoetBIN2R",
      "similarity": 0.8335
    },
    {
      "source": "2TasVD7FXp",
      "target": "8TBGdH3t6a",
      "similarity": 0.8288
    },
    {
      "source": "1X1R7P6yzt",
      "target": "n2NidsYDop",
      "similarity": 0.8241
    },
    {
      "source": "1X1R7P6yzt",
      "target": "aTYexOYlLb",
      "similarity": 0.8125
    },
    {
      "source": "1X1R7P6yzt",
      "target": "bsFWJ0Kget",
      "similarity": 0.8066
    },
    {
      "source": "1X1R7P6yzt",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8055
    },
    {
      "source": "1X1R7P6yzt",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8037
    },
    {
      "source": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "target": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "similarity": 0.8525
    },
    {
      "source": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "target": "wFD16gwpze",
      "similarity": 0.8497
    },
    {
      "source": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "target": "1durmugh3I",
      "similarity": 0.847
    },
    {
      "source": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "target": "entities of a sentence (subject",
      "similarity": 0.8353
    },
    {
      "source": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "target": "However",
      "similarity": 0.8236
    },
    {
      "source": "1qGkuxI9UX",
      "target": "Yet",
      "similarity": 0.8697
    },
    {
      "source": "1qGkuxI9UX",
      "target": "aMBSY2ebPw",
      "similarity": 0.8586
    },
    {
      "source": "1qGkuxI9UX",
      "target": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "similarity": 0.8557
    },
    {
      "source": "1qGkuxI9UX",
      "target": "pDDODPtpx9",
      "similarity": 0.8532
    },
    {
      "source": "1qGkuxI9UX",
      "target": "Usklli4gMc",
      "similarity": 0.8529
    },
    {
      "source": "Xbl6t6zxZs",
      "target": "KW8yzAOIZr",
      "similarity": 0.8677
    },
    {
      "source": "Xbl6t6zxZs",
      "target": "CI4sCBMXjP",
      "similarity": 0.8649
    },
    {
      "source": "Xbl6t6zxZs",
      "target": "gyHoR6uFhU",
      "similarity": 0.8543
    },
    {
      "source": "Xbl6t6zxZs",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.829
    },
    {
      "source": "Xbl6t6zxZs",
      "target": "KxQRHOre9D",
      "similarity": 0.8249
    },
    {
      "source": "oYemKnlIrO",
      "target": "hyfe5q5TD0",
      "similarity": 0.8829
    },
    {
      "source": "oYemKnlIrO",
      "target": "Usklli4gMc",
      "similarity": 0.8741
    },
    {
      "source": "oYemKnlIrO",
      "target": "To this end",
      "similarity": 0.8701
    },
    {
      "source": "oYemKnlIrO",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8681
    },
    {
      "source": "oYemKnlIrO",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8602
    },
    {
      "source": "4ub9gpx9xw",
      "target": "FXw0okNcOb",
      "similarity": 0.8723
    },
    {
      "source": "4ub9gpx9xw",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.863
    },
    {
      "source": "4ub9gpx9xw",
      "target": "Qja5s0K3VX",
      "similarity": 0.8596
    },
    {
      "source": "4ub9gpx9xw",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8589
    },
    {
      "source": "4ub9gpx9xw",
      "target": "bilities",
      "similarity": 0.8585
    },
    {
      "source": "xnssGv9rpW",
      "target": "However",
      "similarity": 0.8168
    },
    {
      "source": "xnssGv9rpW",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8133
    },
    {
      "source": "xnssGv9rpW",
      "target": "FBkpCyujtS",
      "similarity": 0.8121
    },
    {
      "source": "xnssGv9rpW",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.812
    },
    {
      "source": "xnssGv9rpW",
      "target": "Second",
      "similarity": 0.8114
    },
    {
      "source": "IF0Q9KY3p2",
      "target": "To this end",
      "similarity": 0.85
    },
    {
      "source": "IF0Q9KY3p2",
      "target": "However",
      "similarity": 0.836
    },
    {
      "source": "IF0Q9KY3p2",
      "target": "90DC0IvlSs",
      "similarity": 0.8209
    },
    {
      "source": "IF0Q9KY3p2",
      "target": "AJpUZd8Clb",
      "similarity": 0.8201
    },
    {
      "source": "IF0Q9KY3p2",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8192
    },
    {
      "source": "uE84MGbKD7",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8086
    },
    {
      "source": "uE84MGbKD7",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8033
    },
    {
      "source": "uE84MGbKD7",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8006
    },
    {
      "source": "uE84MGbKD7",
      "target": "txZVQRc2ab",
      "similarity": 0.8001
    },
    {
      "source": "uE84MGbKD7",
      "target": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "similarity": 0.7958
    },
    {
      "source": "GEM uses a generative model to estimate mutual information between candidate and reference responses",
      "target": "5pd78GmXC6",
      "similarity": 0.8328
    },
    {
      "source": "GEM uses a generative model to estimate mutual information between candidate and reference responses",
      "target": "However",
      "similarity": 0.8234
    },
    {
      "source": "GEM uses a generative model to estimate mutual information between candidate and reference responses",
      "target": "AjXkRZIvjB",
      "similarity": 0.8171
    },
    {
      "source": "GEM uses a generative model to estimate mutual information between candidate and reference responses",
      "target": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "similarity": 0.8119
    },
    {
      "source": "GEM uses a generative model to estimate mutual information between candidate and reference responses",
      "target": "2U8owdruSQ",
      "similarity": 0.8079
    },
    {
      "source": "We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.  Because GRE-bench is based upon GEM",
      "target": "FPfCUJTsCn",
      "similarity": 0.8379
    },
    {
      "source": "We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.  Because GRE-bench is based upon GEM",
      "target": "B5iOSxM2I0",
      "similarity": 0.826
    },
    {
      "source": "We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.  Because GRE-bench is based upon GEM",
      "target": "To address this issue",
      "similarity": 0.8084
    },
    {
      "source": "We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.  Because GRE-bench is based upon GEM",
      "target": "Theoretically",
      "similarity": 0.8063
    },
    {
      "source": "We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.  Because GRE-bench is based upon GEM",
      "target": "To bridge this gap",
      "similarity": 0.805
    },
    {
      "source": "vVhZh9ZpIM",
      "target": "potential algorithms to solve one task",
      "similarity": 0.7966
    },
    {
      "source": "vVhZh9ZpIM",
      "target": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "similarity": 0.7948
    },
    {
      "source": "vVhZh9ZpIM",
      "target": "JDm7oIcx4Y",
      "similarity": 0.794
    },
    {
      "source": "vVhZh9ZpIM",
      "target": "This paper proposes",
      "similarity": 0.7842
    },
    {
      "source": "vVhZh9ZpIM",
      "target": "VoayJihXra",
      "similarity": 0.7836
    },
    {
      "source": "WfxPVtYRlL",
      "target": "YFxfcQMLWX",
      "similarity": 0.8357
    },
    {
      "source": "WfxPVtYRlL",
      "target": "In this task",
      "similarity": 0.8336
    },
    {
      "source": "WfxPVtYRlL",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8325
    },
    {
      "source": "WfxPVtYRlL",
      "target": "This paper introduces *data taggants*",
      "similarity": 0.8324
    },
    {
      "source": "WfxPVtYRlL",
      "target": "2pNLknCTvG",
      "similarity": 0.8299
    },
    {
      "source": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "target": "b24n2LS2BJ",
      "similarity": 0.8595
    },
    {
      "source": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "target": "8sfc8MwG5v",
      "similarity": 0.8504
    },
    {
      "source": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "target": "m8yby1JfbU",
      "similarity": 0.8375
    },
    {
      "source": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "target": "ZJo6Radbqq",
      "similarity": 0.8353
    },
    {
      "source": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "target": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "similarity": 0.8313
    },
    {
      "source": "In this work we identify ''implicitly-defined'' GNNs as a class of architectures which is provably robust to asynchronous ''hogwild'' inference",
      "target": "JAMxRSXLFz",
      "similarity": 0.8769
    },
    {
      "source": "In this work we identify ''implicitly-defined'' GNNs as a class of architectures which is provably robust to asynchronous ''hogwild'' inference",
      "target": "PHg4rAXFVH",
      "similarity": 0.8456
    },
    {
      "source": "In this work we identify ''implicitly-defined'' GNNs as a class of architectures which is provably robust to asynchronous ''hogwild'' inference",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8425
    },
    {
      "source": "In this work we identify ''implicitly-defined'' GNNs as a class of architectures which is provably robust to asynchronous ''hogwild'' inference",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8355
    },
    {
      "source": "In this work we identify ''implicitly-defined'' GNNs as a class of architectures which is provably robust to asynchronous ''hogwild'' inference",
      "target": "Subsequently",
      "similarity": 0.835
    },
    {
      "source": "We then propose a novel implicitly-defined GNN architecture",
      "target": "Despite this",
      "similarity": 0.8362
    },
    {
      "source": "We then propose a novel implicitly-defined GNN architecture",
      "target": "hSZaCIznB2",
      "similarity": 0.8235
    },
    {
      "source": "We then propose a novel implicitly-defined GNN architecture",
      "target": "U834XHJuqk",
      "similarity": 0.8134
    },
    {
      "source": "We then propose a novel implicitly-defined GNN architecture",
      "target": "ZGqd0cbBvm",
      "similarity": 0.8096
    },
    {
      "source": "We then propose a novel implicitly-defined GNN architecture",
      "target": "GeUK3zGreN",
      "similarity": 0.8059
    },
    {
      "source": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "target": "also study the necessity of this condition via ablation studies and analytical exam-",
      "similarity": 0.91
    },
    {
      "source": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "target": "qFZnAC4GHR",
      "similarity": 0.8887
    },
    {
      "source": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.8773
    },
    {
      "source": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "target": "improve performance. Results are empirically validated on a 2D image regression",
      "similarity": 0.8622
    },
    {
      "source": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "target": "dEg5SdGaiq",
      "similarity": 0.8577
    },
    {
      "source": "WJaUkwci9o",
      "target": "cADpvQgnqg",
      "similarity": 0.8673
    },
    {
      "source": "WJaUkwci9o",
      "target": "YcUV5apdlq",
      "similarity": 0.8524
    },
    {
      "source": "WJaUkwci9o",
      "target": "ispjankYab",
      "similarity": 0.8507
    },
    {
      "source": "WJaUkwci9o",
      "target": "xQVxo9dSID",
      "similarity": 0.8504
    },
    {
      "source": "WJaUkwci9o",
      "target": "depth-wise",
      "similarity": 0.8473
    },
    {
      "source": "0y3hGn1wOk",
      "target": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "similarity": 0.8744
    },
    {
      "source": "0y3hGn1wOk",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8254
    },
    {
      "source": "0y3hGn1wOk",
      "target": "Furthermore",
      "similarity": 0.823
    },
    {
      "source": "0y3hGn1wOk",
      "target": "kGvXIlIVLM",
      "similarity": 0.8174
    },
    {
      "source": "0y3hGn1wOk",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.8112
    },
    {
      "source": "CKXul9iX77",
      "target": "It is especially difficult to generate videos with coherent narratives based on text.",
      "similarity": 0.8622
    },
    {
      "source": "CKXul9iX77",
      "target": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "similarity": 0.8262
    },
    {
      "source": "CKXul9iX77",
      "target": "Fk3eod9aaD",
      "similarity": 0.8069
    },
    {
      "source": "CKXul9iX77",
      "target": "(including gradient-based",
      "similarity": 0.7979
    },
    {
      "source": "CKXul9iX77",
      "target": "MBBRHDuiwM",
      "similarity": 0.7955
    },
    {
      "source": "MKEHCx25xp",
      "target": "In this paper",
      "similarity": 0.8139
    },
    {
      "source": "MKEHCx25xp",
      "target": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "similarity": 0.8128
    },
    {
      "source": "MKEHCx25xp",
      "target": "54XlM8Clkg",
      "similarity": 0.8014
    },
    {
      "source": "MKEHCx25xp",
      "target": "yfW1x7uBS5",
      "similarity": 0.801
    },
    {
      "source": "MKEHCx25xp",
      "target": "N1L5TgtkAw",
      "similarity": 0.7965
    },
    {
      "source": "HD6bWcj87Y",
      "target": "This paper proposes",
      "similarity": 0.8506
    },
    {
      "source": "HD6bWcj87Y",
      "target": "named Pacmann",
      "similarity": 0.8488
    },
    {
      "source": "HD6bWcj87Y",
      "target": "m51BgoqvbP",
      "similarity": 0.8453
    },
    {
      "source": "HD6bWcj87Y",
      "target": "such events remains limited. Given the critical importance of accurately forecasting",
      "similarity": 0.8425
    },
    {
      "source": "HD6bWcj87Y",
      "target": "We provide a parallelized GPU implementation of this regularizer",
      "similarity": 0.841
    },
    {
      "source": "T2d0geb6y0",
      "target": "Refresh (HRRR) data",
      "similarity": 0.8841
    },
    {
      "source": "T2d0geb6y0",
      "target": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "similarity": 0.8706
    },
    {
      "source": "T2d0geb6y0",
      "target": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "similarity": 0.8673
    },
    {
      "source": "T2d0geb6y0",
      "target": "bcTjW5kS4W",
      "similarity": 0.8669
    },
    {
      "source": "T2d0geb6y0",
      "target": "J9FgrqOOni",
      "similarity": 0.8608
    },
    {
      "source": "In this paper",
      "target": "YzxMu1asQi",
      "similarity": 0.8893
    },
    {
      "source": "In this paper",
      "target": "applicability in BCBM diseases is consistently hindered by the lack of an open",
      "similarity": 0.853
    },
    {
      "source": "In this paper",
      "target": "Reweighting (GSR)",
      "similarity": 0.8519
    },
    {
      "source": "In this paper",
      "target": "dTkqaCKLPp",
      "similarity": 0.8466
    },
    {
      "source": "In this paper",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8455
    },
    {
      "source": "DKgAFfCs5F",
      "target": "iXbUquaWbl",
      "similarity": 0.877
    },
    {
      "source": "DKgAFfCs5F",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8277
    },
    {
      "source": "DKgAFfCs5F",
      "target": "Ian00SaFHg",
      "similarity": 0.8268
    },
    {
      "source": "DKgAFfCs5F",
      "target": "it hard to decide on a proper causal discovery strategy.",
      "similarity": 0.8265
    },
    {
      "source": "DKgAFfCs5F",
      "target": "fXb9BbuyAD",
      "similarity": 0.8258
    },
    {
      "source": "UyhRtB4hjN",
      "target": "SOTA LLMs",
      "similarity": 0.8623
    },
    {
      "source": "UyhRtB4hjN",
      "target": "6ldD8Y4gBQ",
      "similarity": 0.8438
    },
    {
      "source": "UyhRtB4hjN",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8388
    },
    {
      "source": "UyhRtB4hjN",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8381
    },
    {
      "source": "UyhRtB4hjN",
      "target": "U3PBITXNG6",
      "similarity": 0.8361
    },
    {
      "source": "To address these challenges",
      "target": "RWJX5F5I9g",
      "similarity": 0.8304
    },
    {
      "source": "To address these challenges",
      "target": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "similarity": 0.8169
    },
    {
      "source": "To address these challenges",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.816
    },
    {
      "source": "To address these challenges",
      "target": "wNobG8bV5Q",
      "similarity": 0.8112
    },
    {
      "source": "To address these challenges",
      "target": "approximation",
      "similarity": 0.8093
    },
    {
      "source": "To this end",
      "target": "iOMnn1hSBO",
      "similarity": 0.8903
    },
    {
      "source": "To this end",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8902
    },
    {
      "source": "To this end",
      "target": "FrFQpAgnGE",
      "similarity": 0.89
    },
    {
      "source": "To this end",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8887
    },
    {
      "source": "To this end",
      "target": "WCRQFlji2q",
      "similarity": 0.8879
    },
    {
      "source": "fn36V5qsCw",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8304
    },
    {
      "source": "fn36V5qsCw",
      "target": "UYcUpiULmT",
      "similarity": 0.8302
    },
    {
      "source": "fn36V5qsCw",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.8263
    },
    {
      "source": "fn36V5qsCw",
      "target": "rK0YJwL69S",
      "similarity": 0.8232
    },
    {
      "source": "fn36V5qsCw",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8142
    },
    {
      "source": "FDaHjwInXO",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.8386
    },
    {
      "source": "FDaHjwInXO",
      "target": "In a client-server setting",
      "similarity": 0.8275
    },
    {
      "source": "FDaHjwInXO",
      "target": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "similarity": 0.8125
    },
    {
      "source": "FDaHjwInXO",
      "target": "On various mathematical benchmarks",
      "similarity": 0.8109
    },
    {
      "source": "FDaHjwInXO",
      "target": "JeLqFpFzwX",
      "similarity": 0.8072
    },
    {
      "source": "IeRcpsdY7P",
      "target": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "similarity": 0.8501
    },
    {
      "source": "IeRcpsdY7P",
      "target": "KSLkFYHlYg",
      "similarity": 0.8314
    },
    {
      "source": "IeRcpsdY7P",
      "target": "FrFQpAgnGE",
      "similarity": 0.8293
    },
    {
      "source": "IeRcpsdY7P",
      "target": "To explore real-time segmentation",
      "similarity": 0.828
    },
    {
      "source": "IeRcpsdY7P",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8236
    },
    {
      "source": "DShqJA1Z64",
      "target": "JvkuZZ04O7",
      "similarity": 0.8466
    },
    {
      "source": "DShqJA1Z64",
      "target": "UVnD9Ze6mF",
      "similarity": 0.8448
    },
    {
      "source": "DShqJA1Z64",
      "target": "gY08Ou8EL7",
      "similarity": 0.8377
    },
    {
      "source": "DShqJA1Z64",
      "target": "ogjBpZ8uSi",
      "similarity": 0.8284
    },
    {
      "source": "DShqJA1Z64",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.813
    },
    {
      "source": "yIlyHJdYV3",
      "target": "For linear activation functions",
      "similarity": 0.8908
    },
    {
      "source": "yIlyHJdYV3",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8884
    },
    {
      "source": "yIlyHJdYV3",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8874
    },
    {
      "source": "yIlyHJdYV3",
      "target": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "similarity": 0.8832
    },
    {
      "source": "yIlyHJdYV3",
      "target": "FrFQpAgnGE",
      "similarity": 0.8813
    },
    {
      "source": "KZu3xhPhke",
      "target": "ZjOXuAfS6l",
      "similarity": 0.8491
    },
    {
      "source": "KZu3xhPhke",
      "target": "JbRM5QKRDd",
      "similarity": 0.8449
    },
    {
      "source": "KZu3xhPhke",
      "target": "Markov Decision Processes (POMDPs) with large observation spaces. Recent",
      "similarity": 0.842
    },
    {
      "source": "KZu3xhPhke",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8387
    },
    {
      "source": "KZu3xhPhke",
      "target": "show that the proposed strategy can enhance the performance of strong pruning",
      "similarity": 0.8338
    },
    {
      "source": "t8fu5m8R5m",
      "target": "GTcEe5fayC",
      "similarity": 0.8533
    },
    {
      "source": "t8fu5m8R5m",
      "target": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "similarity": 0.8493
    },
    {
      "source": "t8fu5m8R5m",
      "target": "ajSmXqgS24",
      "similarity": 0.8368
    },
    {
      "source": "t8fu5m8R5m",
      "target": "YcUV5apdlq",
      "similarity": 0.8351
    },
    {
      "source": "t8fu5m8R5m",
      "target": "In this work",
      "similarity": 0.8301
    },
    {
      "source": "tGYFikNONB",
      "target": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "similarity": 0.8392
    },
    {
      "source": "tGYFikNONB",
      "target": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "similarity": 0.8364
    },
    {
      "source": "tGYFikNONB",
      "target": "In addition",
      "similarity": 0.8204
    },
    {
      "source": "tGYFikNONB",
      "target": "GbgCRJedQ7",
      "similarity": 0.8196
    },
    {
      "source": "tGYFikNONB",
      "target": "eGqQyTAbXC",
      "similarity": 0.8143
    },
    {
      "source": "EyaH1wzmao",
      "target": "dOAkHmsjRX",
      "similarity": 0.8959
    },
    {
      "source": "EyaH1wzmao",
      "target": "For TP",
      "similarity": 0.872
    },
    {
      "source": "EyaH1wzmao",
      "target": "relying on backward propagation",
      "similarity": 0.8687
    },
    {
      "source": "EyaH1wzmao",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8618
    },
    {
      "source": "EyaH1wzmao",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8594
    },
    {
      "source": "Formulas that connect different constants often bring great insight by hinting at connections between previously disparate fields.",
      "target": "For the task of story writing with known prefixes and suffixes",
      "similarity": 0.8377
    },
    {
      "source": "Formulas that connect different constants often bring great insight by hinting at connections between previously disparate fields.",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8197
    },
    {
      "source": "Formulas that connect different constants often bring great insight by hinting at connections between previously disparate fields.",
      "target": "FBhKUXK7od",
      "similarity": 0.8172
    },
    {
      "source": "Formulas that connect different constants often bring great insight by hinting at connections between previously disparate fields.",
      "target": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "similarity": 0.8007
    },
    {
      "source": "Formulas that connect different constants often bring great insight by hinting at connections between previously disparate fields.",
      "target": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "similarity": 0.8002
    },
    {
      "source": "Discoveries of such relations",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.8535
    },
    {
      "source": "Discoveries of such relations",
      "target": "First",
      "similarity": 0.8529
    },
    {
      "source": "Discoveries of such relations",
      "target": "Ym2RNPX6la",
      "similarity": 0.8459
    },
    {
      "source": "Discoveries of such relations",
      "target": "jDsmB4o5S0",
      "similarity": 0.8448
    },
    {
      "source": "Discoveries of such relations",
      "target": "7WaRh4gCXp",
      "similarity": 0.8412
    },
    {
      "source": "Recent developments of algorithms for automated conjecture generation have accelerated the discovery of formulas for specific constants.",
      "target": "Furthermore",
      "similarity": 0.8589
    },
    {
      "source": "Recent developments of algorithms for automated conjecture generation have accelerated the discovery of formulas for specific constants.",
      "target": "GbgCRJedQ7",
      "similarity": 0.8393
    },
    {
      "source": "Recent developments of algorithms for automated conjecture generation have accelerated the discovery of formulas for specific constants.",
      "target": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "similarity": 0.8253
    },
    {
      "source": "Recent developments of algorithms for automated conjecture generation have accelerated the discovery of formulas for specific constants.",
      "target": "Ev4iw23gdI",
      "similarity": 0.8201
    },
    {
      "source": "Recent developments of algorithms for automated conjecture generation have accelerated the discovery of formulas for specific constants.",
      "target": "As model size increases",
      "similarity": 0.8158
    },
    {
      "source": "Yet",
      "target": "models. However",
      "similarity": 0.8854
    },
    {
      "source": "Yet",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8843
    },
    {
      "source": "Yet",
      "target": "in order to be solved. In this paper",
      "similarity": 0.876
    },
    {
      "source": "Yet",
      "target": "to fully understand the compositional properties of the human language",
      "similarity": 0.8661
    },
    {
      "source": "Yet",
      "target": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "similarity": 0.8649
    },
    {
      "source": "In this paper",
      "target": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "similarity": 0.8592
    },
    {
      "source": "In this paper",
      "target": "To tackle this problem",
      "similarity": 0.8574
    },
    {
      "source": "In this paper",
      "target": "tu3qwNjrtw",
      "similarity": 0.8562
    },
    {
      "source": "In this paper",
      "target": "Despite theoretically sound",
      "similarity": 0.8553
    },
    {
      "source": "In this paper",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8482
    },
    {
      "source": "The library is based on a new representation that we propose for organizing the formulas of mathematical constants:",
      "target": "kGvXIlIVLM",
      "similarity": 0.8204
    },
    {
      "source": "The library is based on a new representation that we propose for organizing the formulas of mathematical constants:",
      "target": "propose to cache and reuse KV state of prompts. However",
      "similarity": 0.8191
    },
    {
      "source": "The library is based on a new representation that we propose for organizing the formulas of mathematical constants:",
      "target": "Motivated by this insight",
      "similarity": 0.8121
    },
    {
      "source": "The library is based on a new representation that we propose for organizing the formulas of mathematical constants:",
      "target": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "similarity": 0.8028
    },
    {
      "source": "The library is based on a new representation that we propose for organizing the formulas of mathematical constants:",
      "target": "% shows to be stealthy and robust",
      "similarity": 0.8
    },
    {
      "source": "a hypergraph",
      "target": "additional structural constraints",
      "similarity": 0.8717
    },
    {
      "source": "a hypergraph",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8581
    },
    {
      "source": "a hypergraph",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8425
    },
    {
      "source": "a hypergraph",
      "target": "In this work",
      "similarity": 0.8415
    },
    {
      "source": "a hypergraph",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8344
    },
    {
      "source": "Using this representation",
      "target": "L9eBxTCpQG",
      "similarity": 0.8169
    },
    {
      "source": "Using this representation",
      "target": "cfKZ5VrhXt",
      "similarity": 0.8073
    },
    {
      "source": "Using this representation",
      "target": "QowsEic1sc",
      "similarity": 0.8063
    },
    {
      "source": "Using this representation",
      "target": "over 67 terabytes of multi-modal medical data",
      "similarity": 0.8063
    },
    {
      "source": "Using this representation",
      "target": "relying on backward propagation",
      "similarity": 0.8061
    },
    {
      "source": "The latter formulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan",
      "target": "Further",
      "similarity": 0.8523
    },
    {
      "source": "The latter formulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan",
      "target": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "similarity": 0.8065
    },
    {
      "source": "The latter formulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan",
      "target": "compositional benchmarks",
      "similarity": 0.7895
    },
    {
      "source": "The latter formulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan",
      "target": "a given query",
      "similarity": 0.7812
    },
    {
      "source": "The latter formulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan",
      "target": "On MSC",
      "similarity": 0.7786
    },
    {
      "source": "The code supporting this library is a public",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8286
    },
    {
      "source": "The code supporting this library is a public",
      "target": "In this paper",
      "similarity": 0.8223
    },
    {
      "source": "The code supporting this library is a public",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8193
    },
    {
      "source": "The code supporting this library is a public",
      "target": "We further show that the density of long-distance referrals",
      "similarity": 0.8126
    },
    {
      "source": "The code supporting this library is a public",
      "target": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "similarity": 0.8105
    },
    {
      "source": "hyfe5q5TD0",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.8649
    },
    {
      "source": "hyfe5q5TD0",
      "target": "In this work",
      "similarity": 0.8644
    },
    {
      "source": "hyfe5q5TD0",
      "target": "dsP91M4hDL",
      "similarity": 0.8584
    },
    {
      "source": "hyfe5q5TD0",
      "target": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "similarity": 0.8581
    },
    {
      "source": "hyfe5q5TD0",
      "target": "stacking methods. Specifically",
      "similarity": 0.8527
    },
    {
      "source": "293V3bJbmE",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8492
    },
    {
      "source": "293V3bJbmE",
      "target": "However",
      "similarity": 0.8464
    },
    {
      "source": "293V3bJbmE",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8456
    },
    {
      "source": "293V3bJbmE",
      "target": "NDLmZZWATc",
      "similarity": 0.8441
    },
    {
      "source": "293V3bJbmE",
      "target": "y9A2TpaGsE",
      "similarity": 0.8435
    },
    {
      "source": "KSBx6FBZpE",
      "target": "bhK7U37VW8",
      "similarity": 0.805
    },
    {
      "source": "KSBx6FBZpE",
      "target": "$\\mathrm{poly}(n) \\cdot \\tilde O(d/\\kappa^q)$ for $p > 1$",
      "similarity": 0.8034
    },
    {
      "source": "KSBx6FBZpE",
      "target": "FFE.\"",
      "similarity": 0.8026
    },
    {
      "source": "KSBx6FBZpE",
      "target": "tU074jg2vS",
      "similarity": 0.7989
    },
    {
      "source": "KSBx6FBZpE",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.7986
    },
    {
      "source": "6ycX677p2l",
      "target": "Our findings indicate that",
      "similarity": 0.8815
    },
    {
      "source": "6ycX677p2l",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8689
    },
    {
      "source": "6ycX677p2l",
      "target": "Es4RPNDtmq",
      "similarity": 0.8667
    },
    {
      "source": "6ycX677p2l",
      "target": "7mlvOHL6qJ",
      "similarity": 0.862
    },
    {
      "source": "6ycX677p2l",
      "target": "However",
      "similarity": 0.8612
    },
    {
      "source": "Dl3MsjaIdp",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8878
    },
    {
      "source": "Dl3MsjaIdp",
      "target": "EEgYUccwsV",
      "similarity": 0.876
    },
    {
      "source": "Dl3MsjaIdp",
      "target": "suz4utPr9Y",
      "similarity": 0.8745
    },
    {
      "source": "Dl3MsjaIdp",
      "target": "Pacmann carefully offloads limited computation and storage to the client",
      "similarity": 0.8693
    },
    {
      "source": "Dl3MsjaIdp",
      "target": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "similarity": 0.8688
    },
    {
      "source": "9VMW4iXfKt",
      "target": "wNobG8bV5Q",
      "similarity": 0.8382
    },
    {
      "source": "9VMW4iXfKt",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.8222
    },
    {
      "source": "9VMW4iXfKt",
      "target": "pRCOZllZdT",
      "similarity": 0.8172
    },
    {
      "source": "9VMW4iXfKt",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8166
    },
    {
      "source": "9VMW4iXfKt",
      "target": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "similarity": 0.8065
    },
    {
      "source": "ywFOSIT9ik",
      "target": "8sfc8MwG5v",
      "similarity": 0.8501
    },
    {
      "source": "ywFOSIT9ik",
      "target": "MBBRHDuiwM",
      "similarity": 0.8446
    },
    {
      "source": "ywFOSIT9ik",
      "target": "We validate our approach on benchmarks from image and medical domains",
      "similarity": 0.8224
    },
    {
      "source": "ywFOSIT9ik",
      "target": "It contains three fundamental sub-tasks: interactive segmentation",
      "similarity": 0.8148
    },
    {
      "source": "ywFOSIT9ik",
      "target": "In this paper",
      "similarity": 0.8128
    },
    {
      "source": "XKv29sMyjF",
      "target": "However",
      "similarity": 0.8482
    },
    {
      "source": "XKv29sMyjF",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8406
    },
    {
      "source": "XKv29sMyjF",
      "target": "HN8V0flwJF",
      "similarity": 0.8355
    },
    {
      "source": "XKv29sMyjF",
      "target": "Reweighting (GSR)",
      "similarity": 0.8353
    },
    {
      "source": "XKv29sMyjF",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8348
    },
    {
      "source": "To address this issue",
      "target": "M5t0WvjfCg",
      "similarity": 0.8429
    },
    {
      "source": "To address this issue",
      "target": "W0nydevOlG",
      "similarity": 0.8169
    },
    {
      "source": "To address this issue",
      "target": "sZQRUrvLn4",
      "similarity": 0.8132
    },
    {
      "source": "To address this issue",
      "target": "LLaMA-3-8B-based SFT model",
      "similarity": 0.8014
    },
    {
      "source": "To address this issue",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.7946
    },
    {
      "source": "It employs a data-free masking strategy to facilitate the communication-efficient query-focused knowledge transformation while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments",
      "target": "To supplement the text information in VLM trained on correlations with vision data",
      "similarity": 0.8455
    },
    {
      "source": "It employs a data-free masking strategy to facilitate the communication-efficient query-focused knowledge transformation while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8103
    },
    {
      "source": "It employs a data-free masking strategy to facilitate the communication-efficient query-focused knowledge transformation while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8079
    },
    {
      "source": "It employs a data-free masking strategy to facilitate the communication-efficient query-focused knowledge transformation while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments",
      "target": "In this paper",
      "similarity": 0.8009
    },
    {
      "source": "It employs a data-free masking strategy to facilitate the communication-efficient query-focused knowledge transformation while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments",
      "target": "D2hhkU5O48",
      "similarity": 0.7996
    },
    {
      "source": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "target": "While existing T2S distillation models address this limitation through $1$-step generation",
      "similarity": 0.8516
    },
    {
      "source": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "target": "Aye5wL6TCn",
      "similarity": 0.8254
    },
    {
      "source": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "target": "In this work",
      "similarity": 0.8166
    },
    {
      "source": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "target": "Beyond performance evaluations",
      "similarity": 0.8126
    },
    {
      "source": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "target": "However",
      "similarity": 0.8121
    },
    {
      "source": "ikkvC1UnnE",
      "target": "Neb17mimVH",
      "similarity": 0.8267
    },
    {
      "source": "ikkvC1UnnE",
      "target": "We develop a novel offline model-based RL approach that particularly shines in low-quality data regimes while maintaining competitive performance on high-quality datasets.",
      "similarity": 0.8195
    },
    {
      "source": "ikkvC1UnnE",
      "target": "0e2pcSxQJS",
      "similarity": 0.819
    },
    {
      "source": "ikkvC1UnnE",
      "target": "HN0CYZbAPw",
      "similarity": 0.8166
    },
    {
      "source": "ikkvC1UnnE",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.815
    },
    {
      "source": "However",
      "target": "RTHbao4Mib",
      "similarity": 0.8561
    },
    {
      "source": "However",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8146
    },
    {
      "source": "However",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8014
    },
    {
      "source": "However",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8013
    },
    {
      "source": "However",
      "target": "remains a largely unexplored domain.",
      "similarity": 0.7987
    },
    {
      "source": "Building on the SpiderBoost algorithm framework",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8977
    },
    {
      "source": "Building on the SpiderBoost algorithm framework",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8906
    },
    {
      "source": "Building on the SpiderBoost algorithm framework",
      "target": "SOTA LLMs",
      "similarity": 0.8815
    },
    {
      "source": "Building on the SpiderBoost algorithm framework",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8528
    },
    {
      "source": "Building on the SpiderBoost algorithm framework",
      "target": "However",
      "similarity": 0.8514
    },
    {
      "source": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8704
    },
    {
      "source": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "target": "For example",
      "similarity": 0.8666
    },
    {
      "source": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "target": "JSB171dSUU",
      "similarity": 0.8557
    },
    {
      "source": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8541
    },
    {
      "source": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "target": "pDDODPtpx9",
      "similarity": 0.8513
    },
    {
      "source": "This improved bound matches the state-of-the-art for finding a FOSP",
      "target": "je3GZissZc",
      "similarity": 0.8787
    },
    {
      "source": "This improved bound matches the state-of-the-art for finding a FOSP",
      "target": "jqmptcSNVG",
      "similarity": 0.8691
    },
    {
      "source": "This improved bound matches the state-of-the-art for finding a FOSP",
      "target": "7El7K1DoyX",
      "similarity": 0.8538
    },
    {
      "source": "This improved bound matches the state-of-the-art for finding a FOSP",
      "target": "Tn5B6Udq3E",
      "similarity": 0.842
    },
    {
      "source": "This improved bound matches the state-of-the-art for finding a FOSP",
      "target": "il5yUQsrjC",
      "similarity": 0.8297
    },
    {
      "source": "SMK0f8JoKF",
      "target": "Bl3e8HV9xW",
      "similarity": 0.8597
    },
    {
      "source": "SMK0f8JoKF",
      "target": "In this paper",
      "similarity": 0.8424
    },
    {
      "source": "SMK0f8JoKF",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8385
    },
    {
      "source": "SMK0f8JoKF",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8343
    },
    {
      "source": "SMK0f8JoKF",
      "target": "However",
      "similarity": 0.8327
    },
    {
      "source": "In this work",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.831
    },
    {
      "source": "In this work",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8287
    },
    {
      "source": "In this work",
      "target": "Specifically",
      "similarity": 0.8274
    },
    {
      "source": "In this work",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8264
    },
    {
      "source": "In this work",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8208
    },
    {
      "source": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8449
    },
    {
      "source": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "target": "7VkHffT5X2",
      "similarity": 0.8246
    },
    {
      "source": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8211
    },
    {
      "source": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "target": "wxPnuFp8fZ",
      "similarity": 0.8195
    },
    {
      "source": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.8175
    },
    {
      "source": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.8292
    },
    {
      "source": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8233
    },
    {
      "source": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8232
    },
    {
      "source": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "target": "For the diversity",
      "similarity": 0.8223
    },
    {
      "source": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "target": "irrtPRFksw",
      "similarity": 0.8221
    },
    {
      "source": "Our results challenge the traditional interpretation of how LLMs understand language",
      "target": "4JK2XMGUc8",
      "similarity": 0.9046
    },
    {
      "source": "Our results challenge the traditional interpretation of how LLMs understand language",
      "target": "increased their demand. However",
      "similarity": 0.9009
    },
    {
      "source": "Our results challenge the traditional interpretation of how LLMs understand language",
      "target": "0h6v4SpLCY",
      "similarity": 0.9003
    },
    {
      "source": "Our results challenge the traditional interpretation of how LLMs understand language",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8956
    },
    {
      "source": "Our results challenge the traditional interpretation of how LLMs understand language",
      "target": "In doing so",
      "similarity": 0.8898
    },
    {
      "source": "m51BgoqvbP",
      "target": "wide dissemination",
      "similarity": 0.8593
    },
    {
      "source": "m51BgoqvbP",
      "target": "Zk9guOl9NS",
      "similarity": 0.8525
    },
    {
      "source": "m51BgoqvbP",
      "target": "FiyS0ecSm0",
      "similarity": 0.8479
    },
    {
      "source": "m51BgoqvbP",
      "target": "hjROBHstZ3",
      "similarity": 0.8449
    },
    {
      "source": "m51BgoqvbP",
      "target": "ples. To our knowledge",
      "similarity": 0.8443
    },
    {
      "source": "kSdWcw5mkp",
      "target": "QKBu1BOAwd",
      "similarity": 0.8513
    },
    {
      "source": "kSdWcw5mkp",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8493
    },
    {
      "source": "kSdWcw5mkp",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8488
    },
    {
      "source": "kSdWcw5mkp",
      "target": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "similarity": 0.8467
    },
    {
      "source": "kSdWcw5mkp",
      "target": "F57HPKZ6KD",
      "similarity": 0.8441
    },
    {
      "source": "v4MTnPiYXY",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8567
    },
    {
      "source": "v4MTnPiYXY",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8514
    },
    {
      "source": "v4MTnPiYXY",
      "target": "7lUdo8Vuqa",
      "similarity": 0.8492
    },
    {
      "source": "v4MTnPiYXY",
      "target": "Qja5s0K3VX",
      "similarity": 0.8475
    },
    {
      "source": "v4MTnPiYXY",
      "target": "per subject over the entire disease development phases. The dataset consists of",
      "similarity": 0.8467
    },
    {
      "source": "i45NQb2iKO",
      "target": "It contains three fundamental sub-tasks: interactive segmentation",
      "similarity": 0.8383
    },
    {
      "source": "i45NQb2iKO",
      "target": "ULorFBST6X",
      "similarity": 0.8232
    },
    {
      "source": "i45NQb2iKO",
      "target": "that",
      "similarity": 0.8208
    },
    {
      "source": "i45NQb2iKO",
      "target": "gVnJFY8nCM",
      "similarity": 0.803
    },
    {
      "source": "i45NQb2iKO",
      "target": "Ian00SaFHg",
      "similarity": 0.8001
    },
    {
      "source": "h3wbI8Uk1Z",
      "target": "JytL2MrlLT",
      "similarity": 0.874
    },
    {
      "source": "h3wbI8Uk1Z",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8677
    },
    {
      "source": "h3wbI8Uk1Z",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8676
    },
    {
      "source": "h3wbI8Uk1Z",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.857
    },
    {
      "source": "h3wbI8Uk1Z",
      "target": "41uZB8bDFh",
      "similarity": 0.8565
    },
    {
      "source": "for several tasks that explicitly or implicitly require this capability",
      "target": "L238BAx0wP",
      "similarity": 0.8416
    },
    {
      "source": "for several tasks that explicitly or implicitly require this capability",
      "target": "uClUUJk05H",
      "similarity": 0.841
    },
    {
      "source": "for several tasks that explicitly or implicitly require this capability",
      "target": "eLLBILFRsA",
      "similarity": 0.8324
    },
    {
      "source": "for several tasks that explicitly or implicitly require this capability",
      "target": "sYNWqQYJhz",
      "similarity": 0.811
    },
    {
      "source": "for several tasks that explicitly or implicitly require this capability",
      "target": "In this work",
      "similarity": 0.8088
    },
    {
      "source": "Conversely",
      "target": "riieAeQBJm",
      "similarity": 0.8806
    },
    {
      "source": "Conversely",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8753
    },
    {
      "source": "Conversely",
      "target": "Yet",
      "similarity": 0.8703
    },
    {
      "source": "Conversely",
      "target": "In this paper",
      "similarity": 0.8694
    },
    {
      "source": "Conversely",
      "target": "hxUMQ4fic3",
      "similarity": 0.8637
    },
    {
      "source": "cVyELMpMRS",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8247
    },
    {
      "source": "cVyELMpMRS",
      "target": "hgwGi81ndj",
      "similarity": 0.8211
    },
    {
      "source": "cVyELMpMRS",
      "target": "group-unlabeled data",
      "similarity": 0.8169
    },
    {
      "source": "cVyELMpMRS",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8147
    },
    {
      "source": "cVyELMpMRS",
      "target": "To make this efficient",
      "similarity": 0.814
    },
    {
      "source": "kWRKNDU6uN",
      "target": "fully utilizes the contextual information among tasks",
      "similarity": 0.8547
    },
    {
      "source": "kWRKNDU6uN",
      "target": "$$",
      "similarity": 0.8146
    },
    {
      "source": "kWRKNDU6uN",
      "target": "awvJBtB2op",
      "similarity": 0.8049
    },
    {
      "source": "kWRKNDU6uN",
      "target": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "similarity": 0.8037
    },
    {
      "source": "kWRKNDU6uN",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.7971
    },
    {
      "source": "rwqShzb9li",
      "target": "from computer vision to speech and natural language processing",
      "similarity": 0.8925
    },
    {
      "source": "rwqShzb9li",
      "target": "E4LAVLXAHW",
      "similarity": 0.8716
    },
    {
      "source": "rwqShzb9li",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8663
    },
    {
      "source": "rwqShzb9li",
      "target": "AcVpLS86RT",
      "similarity": 0.8642
    },
    {
      "source": "rwqShzb9li",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8633
    },
    {
      "source": "LuT2CVrlpU",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8672
    },
    {
      "source": "LuT2CVrlpU",
      "target": "Furthermore",
      "similarity": 0.862
    },
    {
      "source": "LuT2CVrlpU",
      "target": "3) We train the model through compression-based auto-regression",
      "similarity": 0.8583
    },
    {
      "source": "LuT2CVrlpU",
      "target": "In addition",
      "similarity": 0.8449
    },
    {
      "source": "LuT2CVrlpU",
      "target": "as representations of instances. In this work",
      "similarity": 0.8443
    },
    {
      "source": "u2QdCiOgwA",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8926
    },
    {
      "source": "u2QdCiOgwA",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8723
    },
    {
      "source": "u2QdCiOgwA",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8636
    },
    {
      "source": "u2QdCiOgwA",
      "target": "JYwVijuNA7",
      "similarity": 0.8565
    },
    {
      "source": "u2QdCiOgwA",
      "target": "1qq1QJKM5q",
      "similarity": 0.8562
    },
    {
      "source": "Listening ability",
      "target": "jckKNzYYA6",
      "similarity": 0.8679
    },
    {
      "source": "Listening ability",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8537
    },
    {
      "source": "Listening ability",
      "target": "overhead in parameters and inference time. In this paper",
      "similarity": 0.8308
    },
    {
      "source": "Listening ability",
      "target": "Finally",
      "similarity": 0.8294
    },
    {
      "source": "Listening ability",
      "target": "20qZK2T7fa",
      "similarity": 0.8241
    },
    {
      "source": "Y6LPWBo2HP",
      "target": "jTEKTdI3K9",
      "similarity": 0.8965
    },
    {
      "source": "Y6LPWBo2HP",
      "target": "For example",
      "similarity": 0.8725
    },
    {
      "source": "Y6LPWBo2HP",
      "target": "JSB171dSUU",
      "similarity": 0.8641
    },
    {
      "source": "Y6LPWBo2HP",
      "target": "pq1WUegkza",
      "similarity": 0.8628
    },
    {
      "source": "Y6LPWBo2HP",
      "target": "- In discrete image-based control (e.g.",
      "similarity": 0.8606
    },
    {
      "source": "yfW1x7uBS5",
      "target": "NvDRvtrGLo",
      "similarity": 0.8592
    },
    {
      "source": "yfW1x7uBS5",
      "target": "However",
      "similarity": 0.8537
    },
    {
      "source": "yfW1x7uBS5",
      "target": "bSq0XGS3kW",
      "similarity": 0.8428
    },
    {
      "source": "yfW1x7uBS5",
      "target": "other baselines across all metrics",
      "similarity": 0.8411
    },
    {
      "source": "yfW1x7uBS5",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8392
    },
    {
      "source": "In response",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8759
    },
    {
      "source": "In response",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.8735
    },
    {
      "source": "In response",
      "target": "1qq1QJKM5q",
      "similarity": 0.868
    },
    {
      "source": "In response",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8633
    },
    {
      "source": "In response",
      "target": "QWunLKbBGF",
      "similarity": 0.8607
    },
    {
      "source": "FBkpCyujtS",
      "target": "To address these challenges",
      "similarity": 0.8446
    },
    {
      "source": "FBkpCyujtS",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8303
    },
    {
      "source": "FBkpCyujtS",
      "target": "5pd78GmXC6",
      "similarity": 0.8294
    },
    {
      "source": "FBkpCyujtS",
      "target": "kRBQwlkFSP",
      "similarity": 0.8291
    },
    {
      "source": "FBkpCyujtS",
      "target": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "similarity": 0.8267
    },
    {
      "source": "Jyh0DR4fFE",
      "target": "Es4RPNDtmq",
      "similarity": 0.8692
    },
    {
      "source": "Jyh0DR4fFE",
      "target": "Our findings indicate that",
      "similarity": 0.8578
    },
    {
      "source": "Jyh0DR4fFE",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.8529
    },
    {
      "source": "Jyh0DR4fFE",
      "target": "6ycX677p2l",
      "similarity": 0.852
    },
    {
      "source": "Jyh0DR4fFE",
      "target": "Refresh (HRRR) data",
      "similarity": 0.8507
    },
    {
      "source": "2fojNANZSv",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8647
    },
    {
      "source": "2fojNANZSv",
      "target": "EW6bNEqalF",
      "similarity": 0.8639
    },
    {
      "source": "2fojNANZSv",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8527
    },
    {
      "source": "2fojNANZSv",
      "target": "fXb9BbuyAD",
      "similarity": 0.8461
    },
    {
      "source": "2fojNANZSv",
      "target": "mnna9LUg7P",
      "similarity": 0.8455
    },
    {
      "source": "d8hYXbxX71",
      "target": "In our approach",
      "similarity": 0.8963
    },
    {
      "source": "d8hYXbxX71",
      "target": "To this end",
      "similarity": 0.8682
    },
    {
      "source": "d8hYXbxX71",
      "target": "ud8FtE1N4N",
      "similarity": 0.8661
    },
    {
      "source": "d8hYXbxX71",
      "target": "Wf2ndb8nhf",
      "similarity": 0.8538
    },
    {
      "source": "d8hYXbxX71",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8306
    },
    {
      "source": "NJxCpMt0sf",
      "target": "ThRMTCgpvo",
      "similarity": 0.8658
    },
    {
      "source": "NJxCpMt0sf",
      "target": "Yet",
      "similarity": 0.8646
    },
    {
      "source": "NJxCpMt0sf",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8547
    },
    {
      "source": "NJxCpMt0sf",
      "target": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "similarity": 0.8534
    },
    {
      "source": "NJxCpMt0sf",
      "target": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "similarity": 0.8479
    },
    {
      "source": "OGfyzExd69",
      "target": "We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations",
      "similarity": 0.854
    },
    {
      "source": "OGfyzExd69",
      "target": "Qja5s0K3VX",
      "similarity": 0.848
    },
    {
      "source": "OGfyzExd69",
      "target": "1qq1QJKM5q",
      "similarity": 0.8444
    },
    {
      "source": "OGfyzExd69",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8433
    },
    {
      "source": "OGfyzExd69",
      "target": "bmbRCRiNDu",
      "similarity": 0.8425
    },
    {
      "source": "44z7HL4mfX",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8115
    },
    {
      "source": "44z7HL4mfX",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8038
    },
    {
      "source": "44z7HL4mfX",
      "target": "7ohlQUbTpp",
      "similarity": 0.8038
    },
    {
      "source": "44z7HL4mfX",
      "target": "We then fine-tune these models and evaluate their downstream performance on a suite of vision-language and text-only tasks.",
      "similarity": 0.7944
    },
    {
      "source": "44z7HL4mfX",
      "target": "Xbl6t6zxZs",
      "similarity": 0.7927
    },
    {
      "source": "exhibit a randomly chosen pair of these skills. Here",
      "target": "Zk9guOl9NS",
      "similarity": 0.8413
    },
    {
      "source": "exhibit a randomly chosen pair of these skills. Here",
      "target": "To develop SoundCTM",
      "similarity": 0.8408
    },
    {
      "source": "exhibit a randomly chosen pair of these skills. Here",
      "target": "wide dissemination",
      "similarity": 0.8408
    },
    {
      "source": "exhibit a randomly chosen pair of these skills. Here",
      "target": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "similarity": 0.8382
    },
    {
      "source": "exhibit a randomly chosen pair of these skills. Here",
      "target": "xiQNfYl33p",
      "similarity": 0.8375
    },
    {
      "source": "Vanilla SFT (i.e.",
      "target": "YslOW2SO6S",
      "similarity": 0.8752
    },
    {
      "source": "Vanilla SFT (i.e.",
      "target": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "similarity": 0.856
    },
    {
      "source": "Vanilla SFT (i.e.",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8529
    },
    {
      "source": "Vanilla SFT (i.e.",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8497
    },
    {
      "source": "Vanilla SFT (i.e.",
      "target": "In addition",
      "similarity": 0.843
    },
    {
      "source": "The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.\"",
      "target": "gsShHPxkUW",
      "similarity": 0.8358
    },
    {
      "source": "The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.\"",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8316
    },
    {
      "source": "The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.\"",
      "target": "ogXkmugNZw",
      "similarity": 0.8302
    },
    {
      "source": "The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.\"",
      "target": "hmDt068MoZ",
      "similarity": 0.8167
    },
    {
      "source": "The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.\"",
      "target": "However",
      "similarity": 0.8134
    },
    {
      "source": "Sf4ep9Udjf",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8237
    },
    {
      "source": "Sf4ep9Udjf",
      "target": "b57IG6N20B",
      "similarity": 0.8107
    },
    {
      "source": "Sf4ep9Udjf",
      "target": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "similarity": 0.8055
    },
    {
      "source": "Sf4ep9Udjf",
      "target": "behavior across compute scale? We find that small- and large-scale language",
      "similarity": 0.8053
    },
    {
      "source": "Sf4ep9Udjf",
      "target": "vl7kf0YHwj",
      "similarity": 0.8023
    },
    {
      "source": "xGs7Ch3Vyo",
      "target": "owP2mymrTD",
      "similarity": 0.825
    },
    {
      "source": "xGs7Ch3Vyo",
      "target": "00SnKBGTsz",
      "similarity": 0.8249
    },
    {
      "source": "xGs7Ch3Vyo",
      "target": "Real-world causal structures",
      "similarity": 0.8221
    },
    {
      "source": "xGs7Ch3Vyo",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8178
    },
    {
      "source": "xGs7Ch3Vyo",
      "target": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "similarity": 0.8101
    },
    {
      "source": "jwsPS8yRe4",
      "target": "Notably",
      "similarity": 0.823
    },
    {
      "source": "jwsPS8yRe4",
      "target": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "similarity": 0.8176
    },
    {
      "source": "jwsPS8yRe4",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8108
    },
    {
      "source": "jwsPS8yRe4",
      "target": "nYPuSzGE3X",
      "similarity": 0.8102
    },
    {
      "source": "jwsPS8yRe4",
      "target": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "similarity": 0.8087
    },
    {
      "source": "bmrYu2Ekdz",
      "target": "5AtlfHYCPa",
      "similarity": 0.9289
    },
    {
      "source": "bmrYu2Ekdz",
      "target": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "similarity": 0.8933
    },
    {
      "source": "bmrYu2Ekdz",
      "target": "pDDODPtpx9",
      "similarity": 0.8609
    },
    {
      "source": "bmrYu2Ekdz",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8492
    },
    {
      "source": "bmrYu2Ekdz",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8477
    },
    {
      "source": "Crucially",
      "target": "In this work",
      "similarity": 0.8439
    },
    {
      "source": "Crucially",
      "target": "In this work",
      "similarity": 0.839
    },
    {
      "source": "Crucially",
      "target": "For the diversity",
      "similarity": 0.83
    },
    {
      "source": "Crucially",
      "target": "4anfpHj0wf",
      "similarity": 0.82
    },
    {
      "source": "Crucially",
      "target": "gfI9v7AbFg",
      "similarity": 0.8182
    },
    {
      "source": "Our findings show the potential of using these methods to predict training stability.\"",
      "target": "7xCSK9BLPy",
      "similarity": 0.8616
    },
    {
      "source": "Our findings show the potential of using these methods to predict training stability.\"",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8428
    },
    {
      "source": "Our findings show the potential of using these methods to predict training stability.\"",
      "target": "a hypergraph",
      "similarity": 0.8238
    },
    {
      "source": "Our findings show the potential of using these methods to predict training stability.\"",
      "target": "In this work",
      "similarity": 0.8162
    },
    {
      "source": "Our findings show the potential of using these methods to predict training stability.\"",
      "target": "UIFAJZ22ZF",
      "similarity": 0.8115
    },
    {
      "source": "wFD16gwpze",
      "target": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "similarity": 0.8957
    },
    {
      "source": "wFD16gwpze",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8372
    },
    {
      "source": "wFD16gwpze",
      "target": "than existing search techniques",
      "similarity": 0.8257
    },
    {
      "source": "wFD16gwpze",
      "target": "WttfQGwpES",
      "similarity": 0.8186
    },
    {
      "source": "wFD16gwpze",
      "target": "1durmugh3I",
      "similarity": 0.818
    },
    {
      "source": "For linear activation functions",
      "target": "78tc3EiUrN",
      "similarity": 0.8563
    },
    {
      "source": "For linear activation functions",
      "target": "2kGKsyhtvh",
      "similarity": 0.8531
    },
    {
      "source": "For linear activation functions",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8507
    },
    {
      "source": "For linear activation functions",
      "target": "samples. However",
      "similarity": 0.8472
    },
    {
      "source": "For linear activation functions",
      "target": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "similarity": 0.8439
    },
    {
      "source": "KxQRHOre9D",
      "target": "At the inference stage",
      "similarity": 0.8419
    },
    {
      "source": "KxQRHOre9D",
      "target": "However",
      "similarity": 0.8375
    },
    {
      "source": "KxQRHOre9D",
      "target": "In this work",
      "similarity": 0.8335
    },
    {
      "source": "KxQRHOre9D",
      "target": "v7YrIjpkTF",
      "similarity": 0.827
    },
    {
      "source": "KxQRHOre9D",
      "target": "X-Ray",
      "similarity": 0.8255
    },
    {
      "source": "benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective.\"",
      "target": "However",
      "similarity": 0.8457
    },
    {
      "source": "benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective.\"",
      "target": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "similarity": 0.8455
    },
    {
      "source": "benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective.\"",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8183
    },
    {
      "source": "benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective.\"",
      "target": "Next",
      "similarity": 0.8083
    },
    {
      "source": "benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective.\"",
      "target": "jY5oml9fe9",
      "similarity": 0.8062
    },
    {
      "source": "tn2mjzjSyR",
      "target": "uhaLuZcCjH",
      "similarity": 0.8799
    },
    {
      "source": "tn2mjzjSyR",
      "target": "s9zoyICZ4k",
      "similarity": 0.8778
    },
    {
      "source": "tn2mjzjSyR",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8627
    },
    {
      "source": "tn2mjzjSyR",
      "target": "To address these challenges",
      "similarity": 0.8563
    },
    {
      "source": "tn2mjzjSyR",
      "target": "the state-of-the-art private ANN search schemes",
      "similarity": 0.8469
    },
    {
      "source": "Our approach involves three key steps: i) defining atomic reasoning action modules that can be composed into various reasoning action trajectories; ii) searching for the optimal action trajectory for each training question through iterative exploration and evaluation for the specific task-solving LLM; and iii) using the collected optimal trajectories to train an LLM to plan for the reasoning trajectories of unseen questions. In particular",
      "target": "To explore real-time segmentation",
      "similarity": 0.873
    },
    {
      "source": "Our approach involves three key steps: i) defining atomic reasoning action modules that can be composed into various reasoning action trajectories; ii) searching for the optimal action trajectory for each training question through iterative exploration and evaluation for the specific task-solving LLM; and iii) using the collected optimal trajectories to train an LLM to plan for the reasoning trajectories of unseen questions. In particular",
      "target": "VQwI055flA",
      "similarity": 0.8463
    },
    {
      "source": "Our approach involves three key steps: i) defining atomic reasoning action modules that can be composed into various reasoning action trajectories; ii) searching for the optimal action trajectory for each training question through iterative exploration and evaluation for the specific task-solving LLM; and iii) using the collected optimal trajectories to train an LLM to plan for the reasoning trajectories of unseen questions. In particular",
      "target": "GBfYgjOfSe",
      "similarity": 0.8411
    },
    {
      "source": "Our approach involves three key steps: i) defining atomic reasoning action modules that can be composed into various reasoning action trajectories; ii) searching for the optimal action trajectory for each training question through iterative exploration and evaluation for the specific task-solving LLM; and iii) using the collected optimal trajectories to train an LLM to plan for the reasoning trajectories of unseen questions. In particular",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8405
    },
    {
      "source": "Our approach involves three key steps: i) defining atomic reasoning action modules that can be composed into various reasoning action trajectories; ii) searching for the optimal action trajectory for each training question through iterative exploration and evaluation for the specific task-solving LLM; and iii) using the collected optimal trajectories to train an LLM to plan for the reasoning trajectories of unseen questions. In particular",
      "target": "AsAy7CROLs",
      "similarity": 0.8403
    },
    {
      "source": "dqyuCsBvn9",
      "target": "Jszf4et48m",
      "similarity": 0.8694
    },
    {
      "source": "dqyuCsBvn9",
      "target": "dAeET8gxqg",
      "similarity": 0.8532
    },
    {
      "source": "dqyuCsBvn9",
      "target": "riieAeQBJm",
      "similarity": 0.8518
    },
    {
      "source": "dqyuCsBvn9",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8513
    },
    {
      "source": "dqyuCsBvn9",
      "target": "We found that long distance referrals",
      "similarity": 0.845
    },
    {
      "source": "INyi7qUdjZ",
      "target": "Y5LjYI4N6P",
      "similarity": 0.8524
    },
    {
      "source": "INyi7qUdjZ",
      "target": "FrFQpAgnGE",
      "similarity": 0.8498
    },
    {
      "source": "INyi7qUdjZ",
      "target": "Our experiments demonstrate that LongPackis highly scalable",
      "similarity": 0.8484
    },
    {
      "source": "INyi7qUdjZ",
      "target": "eGqQyTAbXC",
      "similarity": 0.84
    },
    {
      "source": "INyi7qUdjZ",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8344
    },
    {
      "source": "zBbZ2vdLzH",
      "target": "PY56Wur7S0",
      "similarity": 0.8261
    },
    {
      "source": "zBbZ2vdLzH",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.822
    },
    {
      "source": "zBbZ2vdLzH",
      "target": "odvSjn416y",
      "similarity": 0.8192
    },
    {
      "source": "zBbZ2vdLzH",
      "target": "WoPovNkM5h",
      "similarity": 0.8158
    },
    {
      "source": "zBbZ2vdLzH",
      "target": "Our result significantly improves over the prior works",
      "similarity": 0.8123
    },
    {
      "source": "IuU0wcO0mo",
      "target": "VpWki1v2P8",
      "similarity": 0.8875
    },
    {
      "source": "IuU0wcO0mo",
      "target": "In this work",
      "similarity": 0.8859
    },
    {
      "source": "IuU0wcO0mo",
      "target": "eiqrnVaeIw",
      "similarity": 0.8857
    },
    {
      "source": "IuU0wcO0mo",
      "target": "Pujt3ADZgI",
      "similarity": 0.8753
    },
    {
      "source": "IuU0wcO0mo",
      "target": "je3GZissZc",
      "similarity": 0.873
    },
    {
      "source": "Hcb2cgPbMg",
      "target": "we give an analytical example",
      "similarity": 0.8198
    },
    {
      "source": "Hcb2cgPbMg",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8059
    },
    {
      "source": "Hcb2cgPbMg",
      "target": "To explore real-time segmentation",
      "similarity": 0.8044
    },
    {
      "source": "Hcb2cgPbMg",
      "target": "74vnDs1R97",
      "similarity": 0.7951
    },
    {
      "source": "Hcb2cgPbMg",
      "target": "6HcnC3pPkp",
      "similarity": 0.7859
    },
    {
      "source": "kbm6tsICar",
      "target": "nx9Z5Kva96",
      "similarity": 0.8884
    },
    {
      "source": "kbm6tsICar",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8773
    },
    {
      "source": "kbm6tsICar",
      "target": "We release models",
      "similarity": 0.8733
    },
    {
      "source": "kbm6tsICar",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8695
    },
    {
      "source": "kbm6tsICar",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8658
    },
    {
      "source": "vQhn4wrQ6j",
      "target": "Tkkrm3pA35",
      "similarity": 0.9019
    },
    {
      "source": "vQhn4wrQ6j",
      "target": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "similarity": 0.8759
    },
    {
      "source": "vQhn4wrQ6j",
      "target": "slO3xTt4CG",
      "similarity": 0.8564
    },
    {
      "source": "vQhn4wrQ6j",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8558
    },
    {
      "source": "vQhn4wrQ6j",
      "target": "C45YqeBDUM",
      "similarity": 0.8451
    },
    {
      "source": "Pujt3ADZgI",
      "target": "instructions",
      "similarity": 0.8963
    },
    {
      "source": "Pujt3ADZgI",
      "target": "AcVpLS86RT",
      "similarity": 0.8872
    },
    {
      "source": "Pujt3ADZgI",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.879
    },
    {
      "source": "Pujt3ADZgI",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8738
    },
    {
      "source": "Pujt3ADZgI",
      "target": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "similarity": 0.8727
    },
    {
      "source": "in aligning large language models (LLMs) with human preferences. Prevalent",
      "target": "TOiageVNru",
      "similarity": 0.8196
    },
    {
      "source": "in aligning large language models (LLMs) with human preferences. Prevalent",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.8004
    },
    {
      "source": "in aligning large language models (LLMs) with human preferences. Prevalent",
      "target": "However",
      "similarity": 0.7914
    },
    {
      "source": "in aligning large language models (LLMs) with human preferences. Prevalent",
      "target": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "similarity": 0.7838
    },
    {
      "source": "in aligning large language models (LLMs) with human preferences. Prevalent",
      "target": "In this paper",
      "similarity": 0.7828
    },
    {
      "source": "RLHF approaches are reward-based",
      "target": "VmJdqhuTCh",
      "similarity": 0.8518
    },
    {
      "source": "RLHF approaches are reward-based",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8354
    },
    {
      "source": "RLHF approaches are reward-based",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8337
    },
    {
      "source": "RLHF approaches are reward-based",
      "target": "f3QR9TEERH",
      "similarity": 0.8328
    },
    {
      "source": "RLHF approaches are reward-based",
      "target": "VoayJihXra",
      "similarity": 0.8321
    },
    {
      "source": "this paper",
      "target": "E48QvQppIN",
      "similarity": 0.8342
    },
    {
      "source": "this paper",
      "target": "Based on the observations",
      "similarity": 0.83
    },
    {
      "source": "this paper",
      "target": "jxMAPMqNr5",
      "similarity": 0.8271
    },
    {
      "source": "this paper",
      "target": "To address this limitation",
      "similarity": 0.8271
    },
    {
      "source": "this paper",
      "target": "population shifts. In particular",
      "similarity": 0.8261
    },
    {
      "source": "it from a game-theoretic perspective. Specifically",
      "target": "Thus",
      "similarity": 0.8558
    },
    {
      "source": "it from a game-theoretic perspective. Specifically",
      "target": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "similarity": 0.8546
    },
    {
      "source": "it from a game-theoretic perspective. Specifically",
      "target": "To tackle this challenge",
      "similarity": 0.8525
    },
    {
      "source": "it from a game-theoretic perspective. Specifically",
      "target": "as representations of instances. In this work",
      "similarity": 0.8476
    },
    {
      "source": "it from a game-theoretic perspective. Specifically",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8422
    },
    {
      "source": "a two-player game and propose a novel online algorithm",
      "target": "SVRRQ8goQo",
      "similarity": 0.8467
    },
    {
      "source": "a two-player game and propose a novel online algorithm",
      "target": "However",
      "similarity": 0.8159
    },
    {
      "source": "a two-player game and propose a novel online algorithm",
      "target": "aliasing if pushed too far",
      "similarity": 0.8125
    },
    {
      "source": "a two-player game and propose a novel online algorithm",
      "target": "ZadnlOHsHv",
      "similarity": 0.8122
    },
    {
      "source": "a two-player game and propose a novel online algorithm",
      "target": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "similarity": 0.8119
    },
    {
      "source": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "target": "than existing search techniques",
      "similarity": 0.8517
    },
    {
      "source": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8495
    },
    {
      "source": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8479
    },
    {
      "source": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "target": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "similarity": 0.8469
    },
    {
      "source": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8449
    },
    {
      "source": "regret learning",
      "target": "KRnsX5Em3W",
      "similarity": 0.8434
    },
    {
      "source": "regret learning",
      "target": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "similarity": 0.8327
    },
    {
      "source": "regret learning",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8263
    },
    {
      "source": "regret learning",
      "target": "fine-tuning of a shallow fully-connected network following the representation.",
      "similarity": 0.8245
    },
    {
      "source": "regret learning",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.7972
    },
    {
      "source": "INPO bypasses the need for estimating the expected win rate for individual responses",
      "target": "YFxfcQMLWX",
      "similarity": 0.8665
    },
    {
      "source": "INPO bypasses the need for estimating the expected win rate for individual responses",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8474
    },
    {
      "source": "INPO bypasses the need for estimating the expected win rate for individual responses",
      "target": "DL9txImSzm",
      "similarity": 0.846
    },
    {
      "source": "INPO bypasses the need for estimating the expected win rate for individual responses",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8394
    },
    {
      "source": "INPO bypasses the need for estimating the expected win rate for individual responses",
      "target": "Using this approach",
      "similarity": 0.8392
    },
    {
      "source": "we introduce a new loss objective that is directly minimized over a preference",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8445
    },
    {
      "source": "we introduce a new loss objective that is directly minimized over a preference",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.843
    },
    {
      "source": "we introduce a new loss objective that is directly minimized over a preference",
      "target": "SQnitDuow6",
      "similarity": 0.8344
    },
    {
      "source": "we introduce a new loss objective that is directly minimized over a preference",
      "target": "E4LAVLXAHW",
      "similarity": 0.8315
    },
    {
      "source": "we introduce a new loss objective that is directly minimized over a preference",
      "target": "Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks.",
      "similarity": 0.8304
    },
    {
      "source": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "target": "For TP",
      "similarity": 0.8724
    },
    {
      "source": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "target": "BI2int5SAC",
      "similarity": 0.8681
    },
    {
      "source": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "target": "90DC0IvlSs",
      "similarity": 0.8631
    },
    {
      "source": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "target": "JUr0YOMvZA",
      "similarity": 0.8583
    },
    {
      "source": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "target": "EyaH1wzmao",
      "similarity": 0.8573
    },
    {
      "source": "effectiveness through experiments on various representative benchmarks. With an",
      "target": "OuLgaHEmzi",
      "similarity": 0.8393
    },
    {
      "source": "effectiveness through experiments on various representative benchmarks. With an",
      "target": "YvKJGYL4j7",
      "similarity": 0.8376
    },
    {
      "source": "effectiveness through experiments on various representative benchmarks. With an",
      "target": "The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations",
      "similarity": 0.8376
    },
    {
      "source": "effectiveness through experiments on various representative benchmarks. With an",
      "target": "HqjRlT65WX",
      "similarity": 0.8367
    },
    {
      "source": "effectiveness through experiments on various representative benchmarks. With an",
      "target": "S1Bv3068Xt",
      "similarity": 0.836
    },
    {
      "source": "LLaMA-3-8B-based SFT model",
      "target": "Yet",
      "similarity": 0.8367
    },
    {
      "source": "LLaMA-3-8B-based SFT model",
      "target": "dTkqaCKLPp",
      "similarity": 0.8287
    },
    {
      "source": "LLaMA-3-8B-based SFT model",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8265
    },
    {
      "source": "LLaMA-3-8B-based SFT model",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.823
    },
    {
      "source": "LLaMA-3-8B-based SFT model",
      "target": "v1rFkElnIn",
      "similarity": 0.8229
    },
    {
      "source": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "target": "K2jOacHUlO",
      "similarity": 0.8431
    },
    {
      "source": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "target": "lfPkGWXLLf",
      "similarity": 0.8324
    },
    {
      "source": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "target": "m73tETvFkX",
      "similarity": 0.8298
    },
    {
      "source": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8264
    },
    {
      "source": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8226
    },
    {
      "source": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "target": "instructions",
      "similarity": 0.8933
    },
    {
      "source": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "target": "fs2Z2z3GRx",
      "similarity": 0.8644
    },
    {
      "source": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "target": "E4LAVLXAHW",
      "similarity": 0.8627
    },
    {
      "source": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "target": "However",
      "similarity": 0.861
    },
    {
      "source": "improvement over the state-of-the-art online RLHF algorithms.\"",
      "target": "eNQp79A5Oz",
      "similarity": 0.8551
    },
    {
      "source": "jlhBFm7T2J",
      "target": "Here",
      "similarity": 0.856
    },
    {
      "source": "jlhBFm7T2J",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.852
    },
    {
      "source": "jlhBFm7T2J",
      "target": "X6y5CC44HM",
      "similarity": 0.8515
    },
    {
      "source": "jlhBFm7T2J",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8506
    },
    {
      "source": "jlhBFm7T2J",
      "target": "44cMlQSreK",
      "similarity": 0.8457
    },
    {
      "source": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "target": "To this end",
      "similarity": 0.914
    },
    {
      "source": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "target": "iOMnn1hSBO",
      "similarity": 0.8823
    },
    {
      "source": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8797
    },
    {
      "source": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8784
    },
    {
      "source": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "target": "TUvg5uwdeG",
      "similarity": 0.8728
    },
    {
      "source": "In particular",
      "target": "7LGmXXZXtP",
      "similarity": 0.8753
    },
    {
      "source": "In particular",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8521
    },
    {
      "source": "In particular",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8479
    },
    {
      "source": "In particular",
      "target": "gI0kPklUKS",
      "similarity": 0.8449
    },
    {
      "source": "In particular",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8436
    },
    {
      "source": "Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn",
      "target": "GPT",
      "similarity": 0.8133
    },
    {
      "source": "Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn",
      "target": "L5godAOC2z",
      "similarity": 0.7948
    },
    {
      "source": "Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn",
      "target": "aWLQTbfFgV",
      "similarity": 0.7915
    },
    {
      "source": "Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn",
      "target": "On an average of 6 diverse tasks",
      "similarity": 0.7863
    },
    {
      "source": "Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.7854
    },
    {
      "source": "Our experiments verify that",
      "target": "4O0v4s3IzY",
      "similarity": 0.8759
    },
    {
      "source": "Our experiments verify that",
      "target": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "similarity": 0.8588
    },
    {
      "source": "Our experiments verify that",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.8459
    },
    {
      "source": "Our experiments verify that",
      "target": "phAlw3JPms",
      "similarity": 0.8449
    },
    {
      "source": "Our experiments verify that",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8447
    },
    {
      "source": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "target": "DL9txImSzm",
      "similarity": 0.8703
    },
    {
      "source": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "target": "SuHScQv5gP",
      "similarity": 0.8675
    },
    {
      "source": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8638
    },
    {
      "source": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8608
    },
    {
      "source": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "target": "YFxfcQMLWX",
      "similarity": 0.8559
    },
    {
      "source": "Finally",
      "target": "NHhjczmJjo",
      "similarity": 0.9318
    },
    {
      "source": "Finally",
      "target": "i7jAYFYDcM",
      "similarity": 0.8838
    },
    {
      "source": "Finally",
      "target": "Yk87CwhBDx",
      "similarity": 0.8741
    },
    {
      "source": "Finally",
      "target": "In this paper",
      "similarity": 0.8692
    },
    {
      "source": "Finally",
      "target": "In this paper",
      "similarity": 0.8671
    },
    {
      "source": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "target": "reZKq6hjOZ",
      "similarity": 0.8968
    },
    {
      "source": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "target": "G328D1xt4W",
      "similarity": 0.8861
    },
    {
      "source": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.868
    },
    {
      "source": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "target": "ymt4crbbXh",
      "similarity": 0.8504
    },
    {
      "source": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "target": "daUQ7vmGap",
      "similarity": 0.8491
    },
    {
      "source": "FS2nukC2jv",
      "target": "HqjRlT65WX",
      "similarity": 0.8637
    },
    {
      "source": "FS2nukC2jv",
      "target": "n2NidsYDop",
      "similarity": 0.8439
    },
    {
      "source": "FS2nukC2jv",
      "target": "For example",
      "similarity": 0.8416
    },
    {
      "source": "FS2nukC2jv",
      "target": "KAIqwkB3dT",
      "similarity": 0.8359
    },
    {
      "source": "FS2nukC2jv",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8345
    },
    {
      "source": "wAXsx2MYgV",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8345
    },
    {
      "source": "wAXsx2MYgV",
      "target": "PgXpOOqtyd",
      "similarity": 0.8289
    },
    {
      "source": "wAXsx2MYgV",
      "target": "Building on this benchmark",
      "similarity": 0.8063
    },
    {
      "source": "wAXsx2MYgV",
      "target": "which",
      "similarity": 0.8036
    },
    {
      "source": "wAXsx2MYgV",
      "target": "OFukl9Qg8P",
      "similarity": 0.8033
    },
    {
      "source": "Qja5s0K3VX",
      "target": "p4cLtzk4oe",
      "similarity": 0.9082
    },
    {
      "source": "Qja5s0K3VX",
      "target": "oP7arLOWix",
      "similarity": 0.8925
    },
    {
      "source": "Qja5s0K3VX",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8883
    },
    {
      "source": "Qja5s0K3VX",
      "target": "6GATHdOi1x",
      "similarity": 0.8856
    },
    {
      "source": "Qja5s0K3VX",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.883
    },
    {
      "source": "in reinforcement learning (RL)",
      "target": "0h6v4SpLCY",
      "similarity": 0.9153
    },
    {
      "source": "in reinforcement learning (RL)",
      "target": "increased their demand. However",
      "similarity": 0.9062
    },
    {
      "source": "in reinforcement learning (RL)",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.9006
    },
    {
      "source": "in reinforcement learning (RL)",
      "target": "mkNVPGpEPm",
      "similarity": 0.898
    },
    {
      "source": "in reinforcement learning (RL)",
      "target": "4JK2XMGUc8",
      "similarity": 0.8957
    },
    {
      "source": "Markov Decision Processes (POMDPs) with large observation spaces. Recent",
      "target": "JbRM5QKRDd",
      "similarity": 0.8828
    },
    {
      "source": "Markov Decision Processes (POMDPs) with large observation spaces. Recent",
      "target": "ZjOXuAfS6l",
      "similarity": 0.8573
    },
    {
      "source": "Markov Decision Processes (POMDPs) with large observation spaces. Recent",
      "target": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "similarity": 0.8451
    },
    {
      "source": "Markov Decision Processes (POMDPs) with large observation spaces. Recent",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8435
    },
    {
      "source": "Markov Decision Processes (POMDPs) with large observation spaces. Recent",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8301
    },
    {
      "source": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "target": "HqjRlT65WX",
      "similarity": 0.8576
    },
    {
      "source": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8459
    },
    {
      "source": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8388
    },
    {
      "source": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "target": "First",
      "similarity": 0.8378
    },
    {
      "source": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "target": "8y5Uf6oEiB",
      "similarity": 0.8367
    },
    {
      "source": "framework and identified important coverage assumptions (called belief and outcome coverage) that enable accurate OPE of memoryless policies with polynomial sample complexities",
      "target": "FPfCUJTsCn",
      "similarity": 0.8281
    },
    {
      "source": "framework and identified important coverage assumptions (called belief and outcome coverage) that enable accurate OPE of memoryless policies with polynomial sample complexities",
      "target": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "similarity": 0.8205
    },
    {
      "source": "framework and identified important coverage assumptions (called belief and outcome coverage) that enable accurate OPE of memoryless policies with polynomial sample complexities",
      "target": "To bridge this gap",
      "similarity": 0.8161
    },
    {
      "source": "framework and identified important coverage assumptions (called belief and outcome coverage) that enable accurate OPE of memoryless policies with polynomial sample complexities",
      "target": "(1) Sparse attention patterns",
      "similarity": 0.8128
    },
    {
      "source": "framework and identified important coverage assumptions (called belief and outcome coverage) that enable accurate OPE of memoryless policies with polynomial sample complexities",
      "target": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "similarity": 0.8084
    },
    {
      "source": "the entire observable history remained an open problem. In this work",
      "target": "U3PBITXNG6",
      "similarity": 0.8624
    },
    {
      "source": "the entire observable history remained an open problem. In this work",
      "target": "HpUs2EXjOl",
      "similarity": 0.8618
    },
    {
      "source": "the entire observable history remained an open problem. In this work",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8493
    },
    {
      "source": "the entire observable history remained an open problem. In this work",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8459
    },
    {
      "source": "the entire observable history remained an open problem. In this work",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8449
    },
    {
      "source": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8193
    },
    {
      "source": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "target": "UN6Ik6OCx8",
      "similarity": 0.815
    },
    {
      "source": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8109
    },
    {
      "source": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.8081
    },
    {
      "source": "information-theoretic hardness for model-free OPE of history-dependent policies in",
      "target": "To fill this gap",
      "similarity": 0.8067
    },
    {
      "source": "several settings",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8383
    },
    {
      "source": "several settings",
      "target": "Real-world causal structures",
      "similarity": 0.8334
    },
    {
      "source": "several settings",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.824
    },
    {
      "source": "several settings",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8214
    },
    {
      "source": "several settings",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8184
    },
    {
      "source": "policy (memoryless vs. history-dependent) and/or the state-revealing property of",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8274
    },
    {
      "source": "policy (memoryless vs. history-dependent) and/or the state-revealing property of",
      "target": "tGYFikNONB",
      "similarity": 0.8038
    },
    {
      "source": "policy (memoryless vs. history-dependent) and/or the state-revealing property of",
      "target": "For instance",
      "similarity": 0.8021
    },
    {
      "source": "policy (memoryless vs. history-dependent) and/or the state-revealing property of",
      "target": "L14sqcrUC3",
      "similarity": 0.7999
    },
    {
      "source": "policy (memoryless vs. history-dependent) and/or the state-revealing property of",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.7979
    },
    {
      "source": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "target": "5AtlfHYCPa",
      "similarity": 0.879
    },
    {
      "source": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "target": "pDDODPtpx9",
      "similarity": 0.8575
    },
    {
      "source": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8468
    },
    {
      "source": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8385
    },
    {
      "source": "the POMDP (single-step vs. multi-step revealing). We further show that some hardness can be circumvented by a natural model-based algorithm\u2014whose analysis has surprisingly eluded the literature despite the algorithm\u2019s simplicity\u2014demonstrating",
      "target": "pRCOZllZdT",
      "similarity": 0.838
    },
    {
      "source": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8588
    },
    {
      "source": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "target": "KlN00vQEY2",
      "similarity": 0.8479
    },
    {
      "source": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8424
    },
    {
      "source": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8403
    },
    {
      "source": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8374
    },
    {
      "source": "jY5oml9fe9",
      "target": "Finally",
      "similarity": 0.8847
    },
    {
      "source": "jY5oml9fe9",
      "target": "Bpn8q40n1n",
      "similarity": 0.8611
    },
    {
      "source": "jY5oml9fe9",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8525
    },
    {
      "source": "jY5oml9fe9",
      "target": "TtKN1TpvUu",
      "similarity": 0.8365
    },
    {
      "source": "jY5oml9fe9",
      "target": "UL2",
      "similarity": 0.8331
    },
    {
      "source": "4VHiptx7xe",
      "target": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "similarity": 0.8505
    },
    {
      "source": "4VHiptx7xe",
      "target": "1qGkuxI9UX",
      "similarity": 0.841
    },
    {
      "source": "4VHiptx7xe",
      "target": "Usklli4gMc",
      "similarity": 0.8396
    },
    {
      "source": "4VHiptx7xe",
      "target": "Reweighting (GSR)",
      "similarity": 0.838
    },
    {
      "source": "4VHiptx7xe",
      "target": "Mjn53GtMxi",
      "similarity": 0.8306
    },
    {
      "source": "gyHoR6uFhU",
      "target": "KW8yzAOIZr",
      "similarity": 0.8422
    },
    {
      "source": "gyHoR6uFhU",
      "target": "mzL19kKE3r",
      "similarity": 0.8359
    },
    {
      "source": "gyHoR6uFhU",
      "target": "uMEsKEiB7J",
      "similarity": 0.8235
    },
    {
      "source": "gyHoR6uFhU",
      "target": "CI4sCBMXjP",
      "similarity": 0.819
    },
    {
      "source": "gyHoR6uFhU",
      "target": "dkrEoT68by",
      "similarity": 0.817
    },
    {
      "source": "rvXdGL4pCJ",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8368
    },
    {
      "source": "rvXdGL4pCJ",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8362
    },
    {
      "source": "rvXdGL4pCJ",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8332
    },
    {
      "source": "rvXdGL4pCJ",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8311
    },
    {
      "source": "rvXdGL4pCJ",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.831
    },
    {
      "source": "XAjfjizaKs",
      "target": "ogXkmugNZw",
      "similarity": 0.8553
    },
    {
      "source": "XAjfjizaKs",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8416
    },
    {
      "source": "XAjfjizaKs",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8393
    },
    {
      "source": "XAjfjizaKs",
      "target": "Additionally",
      "similarity": 0.8255
    },
    {
      "source": "XAjfjizaKs",
      "target": "o2Igqm95SJ",
      "similarity": 0.8245
    },
    {
      "source": "NCrFA7dq8T",
      "target": "B8akWa62Da",
      "similarity": 0.873
    },
    {
      "source": "NCrFA7dq8T",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8627
    },
    {
      "source": "NCrFA7dq8T",
      "target": "T4sMzjy7fO",
      "similarity": 0.8483
    },
    {
      "source": "NCrFA7dq8T",
      "target": "Building on these insights",
      "similarity": 0.8357
    },
    {
      "source": "NCrFA7dq8T",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8309
    },
    {
      "source": "yVGGtsOgc7",
      "target": "IXyfbaGlps",
      "similarity": 0.8418
    },
    {
      "source": "yVGGtsOgc7",
      "target": "However",
      "similarity": 0.829
    },
    {
      "source": "yVGGtsOgc7",
      "target": "Moreover",
      "similarity": 0.8264
    },
    {
      "source": "yVGGtsOgc7",
      "target": "This study highlights a major",
      "similarity": 0.8249
    },
    {
      "source": "yVGGtsOgc7",
      "target": "WNvvwK0tut",
      "similarity": 0.8132
    },
    {
      "source": "61ss5RA1MM",
      "target": "wUtXB43Chi",
      "similarity": 0.8399
    },
    {
      "source": "61ss5RA1MM",
      "target": "bAFVlpFQvT",
      "similarity": 0.8204
    },
    {
      "source": "61ss5RA1MM",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8151
    },
    {
      "source": "61ss5RA1MM",
      "target": "HN8V0flwJF",
      "similarity": 0.8095
    },
    {
      "source": "61ss5RA1MM",
      "target": "U3PBITXNG6",
      "similarity": 0.8087
    },
    {
      "source": "FAYIlGDBa1",
      "target": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "similarity": 0.8295
    },
    {
      "source": "FAYIlGDBa1",
      "target": "44hcrfzydU",
      "similarity": 0.829
    },
    {
      "source": "FAYIlGDBa1",
      "target": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "similarity": 0.825
    },
    {
      "source": "FAYIlGDBa1",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8238
    },
    {
      "source": "FAYIlGDBa1",
      "target": "AcVpLS86RT",
      "similarity": 0.8229
    },
    {
      "source": "DwqoBkj2Mw",
      "target": "yLhJYvkKA0",
      "similarity": 0.9018
    },
    {
      "source": "DwqoBkj2Mw",
      "target": "tXUkT709OJ",
      "similarity": 0.869
    },
    {
      "source": "DwqoBkj2Mw",
      "target": "{Subsequently}",
      "similarity": 0.8593
    },
    {
      "source": "DwqoBkj2Mw",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8489
    },
    {
      "source": "DwqoBkj2Mw",
      "target": "nDTvP6tBMd",
      "similarity": 0.8461
    },
    {
      "source": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "target": "sZJNkorXMk",
      "similarity": 0.8927
    },
    {
      "source": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "target": "SRpq5OBpED",
      "similarity": 0.8798
    },
    {
      "source": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "target": "In this setting",
      "similarity": 0.8744
    },
    {
      "source": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "target": "xsELpEPn4A",
      "similarity": 0.874
    },
    {
      "source": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "target": "J9VogDTa1W",
      "similarity": 0.8689
    },
    {
      "source": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "target": "In this paper",
      "similarity": 0.8747
    },
    {
      "source": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "target": "pDDODPtpx9",
      "similarity": 0.8729
    },
    {
      "source": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "target": "zCZnEXF3bN",
      "similarity": 0.8673
    },
    {
      "source": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8671
    },
    {
      "source": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "target": "J9VogDTa1W",
      "similarity": 0.8625
    },
    {
      "source": "1jcnvghayD",
      "target": "In this work",
      "similarity": 0.8666
    },
    {
      "source": "1jcnvghayD",
      "target": "In this work",
      "similarity": 0.8289
    },
    {
      "source": "1jcnvghayD",
      "target": "m5qpn0KTMZ",
      "similarity": 0.8287
    },
    {
      "source": "1jcnvghayD",
      "target": "DzGe40glxs",
      "similarity": 0.8272
    },
    {
      "source": "1jcnvghayD",
      "target": "GtvuNrk58a",
      "similarity": 0.8257
    },
    {
      "source": "E48QvQppIN",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.895
    },
    {
      "source": "E48QvQppIN",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.892
    },
    {
      "source": "E48QvQppIN",
      "target": "2pNLknCTvG",
      "similarity": 0.8698
    },
    {
      "source": "E48QvQppIN",
      "target": "Finally",
      "similarity": 0.865
    },
    {
      "source": "E48QvQppIN",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8602
    },
    {
      "source": "DTatjJTDl1",
      "target": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "similarity": 0.8642
    },
    {
      "source": "DTatjJTDl1",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8609
    },
    {
      "source": "DTatjJTDl1",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8566
    },
    {
      "source": "DTatjJTDl1",
      "target": "introduce MANTRA",
      "similarity": 0.8432
    },
    {
      "source": "DTatjJTDl1",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.842
    },
    {
      "source": "bsFWJ0Kget",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8823
    },
    {
      "source": "bsFWJ0Kget",
      "target": "OuLgaHEmzi",
      "similarity": 0.867
    },
    {
      "source": "bsFWJ0Kget",
      "target": "n2NidsYDop",
      "similarity": 0.8634
    },
    {
      "source": "bsFWJ0Kget",
      "target": "INqLJwqUmc",
      "similarity": 0.8545
    },
    {
      "source": "bsFWJ0Kget",
      "target": "This work introduces EqNIO",
      "similarity": 0.847
    },
    {
      "source": "accuracy and computational efficiency\"",
      "target": "5pd78GmXC6",
      "similarity": 0.8498
    },
    {
      "source": "accuracy and computational efficiency\"",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8484
    },
    {
      "source": "accuracy and computational efficiency\"",
      "target": "SqZ0KY4qBD",
      "similarity": 0.844
    },
    {
      "source": "accuracy and computational efficiency\"",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8438
    },
    {
      "source": "accuracy and computational efficiency\"",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8416
    },
    {
      "source": "oZkqkkvdND",
      "target": "dw9VUsSHGB",
      "similarity": 0.8421
    },
    {
      "source": "oZkqkkvdND",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.838
    },
    {
      "source": "oZkqkkvdND",
      "target": "However",
      "similarity": 0.835
    },
    {
      "source": "oZkqkkvdND",
      "target": "O0sQ9CPzai",
      "similarity": 0.8338
    },
    {
      "source": "oZkqkkvdND",
      "target": "generating time series of tabular data",
      "similarity": 0.831
    },
    {
      "source": "4BFzTrIjPN",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.864
    },
    {
      "source": "4BFzTrIjPN",
      "target": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "similarity": 0.8406
    },
    {
      "source": "4BFzTrIjPN",
      "target": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "similarity": 0.8315
    },
    {
      "source": "4BFzTrIjPN",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8301
    },
    {
      "source": "4BFzTrIjPN",
      "target": "6qUUgw9bAZ",
      "similarity": 0.8212
    },
    {
      "source": "vjel3nWP2a",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.8476
    },
    {
      "source": "vjel3nWP2a",
      "target": "QAAsnSRwgu",
      "similarity": 0.8379
    },
    {
      "source": "vjel3nWP2a",
      "target": "qNp86ByQlN",
      "similarity": 0.835
    },
    {
      "source": "vjel3nWP2a",
      "target": "ZjOXuAfS6l",
      "similarity": 0.8321
    },
    {
      "source": "vjel3nWP2a",
      "target": "KZu3xhPhke",
      "similarity": 0.8277
    },
    {
      "source": "590yfqz1LE",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8668
    },
    {
      "source": "590yfqz1LE",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8628
    },
    {
      "source": "590yfqz1LE",
      "target": "To this end",
      "similarity": 0.8622
    },
    {
      "source": "590yfqz1LE",
      "target": "AJpUZd8Clb",
      "similarity": 0.8606
    },
    {
      "source": "590yfqz1LE",
      "target": "pDDODPtpx9",
      "similarity": 0.8597
    },
    {
      "source": "ZGqd0cbBvm",
      "target": "Despite this",
      "similarity": 0.8416
    },
    {
      "source": "ZGqd0cbBvm",
      "target": "U834XHJuqk",
      "similarity": 0.8164
    },
    {
      "source": "ZGqd0cbBvm",
      "target": "Moreover",
      "similarity": 0.8161
    },
    {
      "source": "ZGqd0cbBvm",
      "target": "03OkC0LKDD",
      "similarity": 0.8119
    },
    {
      "source": "ZGqd0cbBvm",
      "target": "This work presents Physics-Informed Experimental Design (PIED)",
      "similarity": 0.8102
    },
    {
      "source": "I6UbnkUveF",
      "target": "In this paper",
      "similarity": 0.7754
    },
    {
      "source": "I6UbnkUveF",
      "target": "We show that the model uses the execution results to guide the search and that within-prompt search performs well at low token budgets.",
      "similarity": 0.7687
    },
    {
      "source": "I6UbnkUveF",
      "target": "HZgZrtIreg",
      "similarity": 0.7565
    },
    {
      "source": "I6UbnkUveF",
      "target": "JV8zULNh24",
      "similarity": 0.7521
    },
    {
      "source": "SRpq5OBpED",
      "target": "IDJUscOjM3",
      "similarity": 0.8736
    },
    {
      "source": "SRpq5OBpED",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8671
    },
    {
      "source": "SRpq5OBpED",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8654
    },
    {
      "source": "SRpq5OBpED",
      "target": "3E8YNv1HjU",
      "similarity": 0.8635
    },
    {
      "source": "SRpq5OBpED",
      "target": "xsELpEPn4A",
      "similarity": 0.8623
    },
    {
      "source": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "target": "GhexuBLxbO",
      "similarity": 0.8335
    },
    {
      "source": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "target": "T7bmHkwzS6",
      "similarity": 0.8332
    },
    {
      "source": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "target": "e5mTvjXG9u",
      "similarity": 0.8332
    },
    {
      "source": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8247
    },
    {
      "source": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8202
    },
    {
      "source": "related solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically",
      "target": "1F8xTfv6ah",
      "similarity": 0.8583
    },
    {
      "source": "related solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically",
      "target": "xnF2U0ro7b",
      "similarity": 0.8344
    },
    {
      "source": "related solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically",
      "target": "We conducted a comprehensive regret analysis of our proposed framework",
      "similarity": 0.827
    },
    {
      "source": "related solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically",
      "target": "P6IVIoGRRg",
      "similarity": 0.826
    },
    {
      "source": "related solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8242
    },
    {
      "source": "few-shot reconstruction and forecasting of synthetic dynamical systems",
      "target": "relying on backward propagation",
      "similarity": 0.8411
    },
    {
      "source": "few-shot reconstruction and forecasting of synthetic dynamical systems",
      "target": "9qS3HzSDNv",
      "similarity": 0.8314
    },
    {
      "source": "few-shot reconstruction and forecasting of synthetic dynamical systems",
      "target": "K7xpl3LZQp",
      "similarity": 0.8297
    },
    {
      "source": "few-shot reconstruction and forecasting of synthetic dynamical systems",
      "target": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "similarity": 0.8267
    },
    {
      "source": "few-shot reconstruction and forecasting of synthetic dynamical systems",
      "target": "works leads to a multifaceted problem",
      "similarity": 0.8143
    },
    {
      "source": "3ep9ZYMZS3",
      "target": "huge amount of instances in the real world. For richer classes of the similarity",
      "similarity": 0.8178
    },
    {
      "source": "3ep9ZYMZS3",
      "target": "Extensive experiments on MuJoCo",
      "similarity": 0.795
    },
    {
      "source": "3ep9ZYMZS3",
      "target": "We find that naively applying LLMs to proof optimization falls short",
      "similarity": 0.793
    },
    {
      "source": "3ep9ZYMZS3",
      "target": "bIlnpVM4bc",
      "similarity": 0.7923
    },
    {
      "source": "3ep9ZYMZS3",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.79
    },
    {
      "source": "1durmugh3I",
      "target": "However",
      "similarity": 0.8717
    },
    {
      "source": "1durmugh3I",
      "target": "WttfQGwpES",
      "similarity": 0.8463
    },
    {
      "source": "1durmugh3I",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.8365
    },
    {
      "source": "1durmugh3I",
      "target": "However",
      "similarity": 0.8316
    },
    {
      "source": "1durmugh3I",
      "target": "yR47RmND1m",
      "similarity": 0.8311
    },
    {
      "source": "r8J3DSD5kF",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8548
    },
    {
      "source": "r8J3DSD5kF",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8544
    },
    {
      "source": "r8J3DSD5kF",
      "target": "97rOQDPmk2",
      "similarity": 0.8527
    },
    {
      "source": "r8J3DSD5kF",
      "target": "Ian00SaFHg",
      "similarity": 0.8433
    },
    {
      "source": "r8J3DSD5kF",
      "target": "xjKz6IxgCX",
      "similarity": 0.8429
    },
    {
      "source": "But current methods using still face length generalisation challenges.",
      "target": "IIsTO4P3Ag",
      "similarity": 0.9096
    },
    {
      "source": "But current methods using still face length generalisation challenges.",
      "target": "Zzs3JwknAY",
      "similarity": 0.7947
    },
    {
      "source": "But current methods using still face length generalisation challenges.",
      "target": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator",
      "similarity": 0.7615
    },
    {
      "source": "But current methods using still face length generalisation challenges.",
      "target": "DpLFmc09pC",
      "similarity": 0.7615
    },
    {
      "source": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "target": "additional structural constraints",
      "similarity": 0.8151
    },
    {
      "source": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "target": "qn9tBYQHGi",
      "similarity": 0.8094
    },
    {
      "source": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "target": "In this work",
      "similarity": 0.8022
    },
    {
      "source": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "target": "UIFAJZ22ZF",
      "similarity": 0.8018
    },
    {
      "source": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.8001
    },
    {
      "source": "The method works as follows: For each token before the current",
      "target": "d7pr2doXn3",
      "similarity": 0.8529
    },
    {
      "source": "The method works as follows: For each token before the current",
      "target": "To this end",
      "similarity": 0.849
    },
    {
      "source": "The method works as follows: For each token before the current",
      "target": "faceswaps",
      "similarity": 0.8478
    },
    {
      "source": "The method works as follows: For each token before the current",
      "target": "To this end",
      "similarity": 0.8467
    },
    {
      "source": "The method works as follows: For each token before the current",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8463
    },
    {
      "source": "We repeat this on the remaining stick",
      "target": "In practice",
      "similarity": 0.8606
    },
    {
      "source": "We repeat this on the remaining stick",
      "target": "6GATHdOi1x",
      "similarity": 0.86
    },
    {
      "source": "We repeat this on the remaining stick",
      "target": "sound",
      "similarity": 0.8584
    },
    {
      "source": "We repeat this on the remaining stick",
      "target": "YFxfcQMLWX",
      "similarity": 0.8523
    },
    {
      "source": "We repeat this on the remaining stick",
      "target": "254NJe9JEw",
      "similarity": 0.8521
    },
    {
      "source": "This process naturally incorporates recency bias",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.8223
    },
    {
      "source": "This process naturally incorporates recency bias",
      "target": "aKJr5NnN8U",
      "similarity": 0.8147
    },
    {
      "source": "This process naturally incorporates recency bias",
      "target": "a given query",
      "similarity": 0.8145
    },
    {
      "source": "This process naturally incorporates recency bias",
      "target": "ExuBFYtCQU",
      "similarity": 0.8136
    },
    {
      "source": "This process naturally incorporates recency bias",
      "target": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "similarity": 0.8097
    },
    {
      "source": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "target": "Subsequently",
      "similarity": 0.8528
    },
    {
      "source": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8526
    },
    {
      "source": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "target": "In particular",
      "similarity": 0.8519
    },
    {
      "source": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "target": "To tackle this challenge",
      "similarity": 0.8487
    },
    {
      "source": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "target": "yu1vqQqKkx",
      "similarity": 0.8461
    },
    {
      "source": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "target": "GdbQyFOUlJ",
      "similarity": 0.8674
    },
    {
      "source": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "target": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "similarity": 0.8612
    },
    {
      "source": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8363
    },
    {
      "source": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8306
    },
    {
      "source": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "target": "gsShHPxkUW",
      "similarity": 0.8296
    },
    {
      "source": "When used as a drop-in replacement for current softmax+RoPE attention systems",
      "target": "To this end",
      "similarity": 0.8484
    },
    {
      "source": "When used as a drop-in replacement for current softmax+RoPE attention systems",
      "target": "ud8FtE1N4N",
      "similarity": 0.8002
    },
    {
      "source": "When used as a drop-in replacement for current softmax+RoPE attention systems",
      "target": "Wf2ndb8nhf",
      "similarity": 0.7987
    },
    {
      "source": "When used as a drop-in replacement for current softmax+RoPE attention systems",
      "target": "In this work",
      "similarity": 0.7899
    },
    {
      "source": "When used as a drop-in replacement for current softmax+RoPE attention systems",
      "target": "d8hYXbxX71",
      "similarity": 0.7892
    },
    {
      "source": "Stick-breaking also performs well at length generalisation",
      "target": "All experimental resources",
      "similarity": 0.871
    },
    {
      "source": "Stick-breaking also performs well at length generalisation",
      "target": "xiQNfYl33p",
      "similarity": 0.8702
    },
    {
      "source": "Stick-breaking also performs well at length generalisation",
      "target": "Second",
      "similarity": 0.8701
    },
    {
      "source": "Stick-breaking also performs well at length generalisation",
      "target": "QowsEic1sc",
      "similarity": 0.8645
    },
    {
      "source": "Stick-breaking also performs well at length generalisation",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8634
    },
    {
      "source": "uxDFlPGRLX",
      "target": "Furthermore",
      "similarity": 0.8528
    },
    {
      "source": "uxDFlPGRLX",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8171
    },
    {
      "source": "uxDFlPGRLX",
      "target": "ReItdfwMcg",
      "similarity": 0.8165
    },
    {
      "source": "uxDFlPGRLX",
      "target": "6z4YKr0GK6",
      "similarity": 0.8115
    },
    {
      "source": "uxDFlPGRLX",
      "target": "CS2JWaziYr",
      "similarity": 0.8111
    },
    {
      "source": "iXbUquaWbl",
      "target": "novel decomposition approach. Our experiments show that MoDeGPT",
      "similarity": 0.845
    },
    {
      "source": "iXbUquaWbl",
      "target": "S1Bv3068Xt",
      "similarity": 0.8419
    },
    {
      "source": "iXbUquaWbl",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8352
    },
    {
      "source": "iXbUquaWbl",
      "target": "HqjRlT65WX",
      "similarity": 0.8351
    },
    {
      "source": "iXbUquaWbl",
      "target": "fXb9BbuyAD",
      "similarity": 0.8334
    },
    {
      "source": "To address these challenges",
      "target": "For instance",
      "similarity": 0.8872
    },
    {
      "source": "To address these challenges",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8649
    },
    {
      "source": "To address these challenges",
      "target": "uZgK0tcPqd",
      "similarity": 0.8627
    },
    {
      "source": "To address these challenges",
      "target": "2mqb8bPHeb",
      "similarity": 0.8597
    },
    {
      "source": "To address these challenges",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8565
    },
    {
      "source": "ac93gRzxxV",
      "target": "To overcome these challenges",
      "similarity": 0.8386
    },
    {
      "source": "ac93gRzxxV",
      "target": "PQpvhUrA1C",
      "similarity": 0.8168
    },
    {
      "source": "ac93gRzxxV",
      "target": "G328D1xt4W",
      "similarity": 0.8166
    },
    {
      "source": "ac93gRzxxV",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8129
    },
    {
      "source": "ac93gRzxxV",
      "target": "jJXZvPe5z0",
      "similarity": 0.8109
    },
    {
      "source": "To address this",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8669
    },
    {
      "source": "To address this",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8411
    },
    {
      "source": "To address this",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8304
    },
    {
      "source": "To address this",
      "target": "$p\\in[2",
      "similarity": 0.8222
    },
    {
      "source": "To address this",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8196
    },
    {
      "source": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "target": "To tackle this challenge",
      "similarity": 0.8633
    },
    {
      "source": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "target": "per subject over the entire disease development phases. The dataset consists of",
      "similarity": 0.8481
    },
    {
      "source": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "target": "as representations of instances. In this work",
      "similarity": 0.8446
    },
    {
      "source": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "target": "U42TkrEDzb",
      "similarity": 0.8426
    },
    {
      "source": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "target": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "similarity": 0.8413
    },
    {
      "source": "Our code and additional resources are available at https://structuredllm.com.\"",
      "target": "Finally",
      "similarity": 0.8593
    },
    {
      "source": "Our code and additional resources are available at https://structuredllm.com.\"",
      "target": "In this paper",
      "similarity": 0.8547
    },
    {
      "source": "Our code and additional resources are available at https://structuredllm.com.\"",
      "target": "NHhjczmJjo",
      "similarity": 0.8491
    },
    {
      "source": "Our code and additional resources are available at https://structuredllm.com.\"",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8423
    },
    {
      "source": "Our code and additional resources are available at https://structuredllm.com.\"",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.8379
    },
    {
      "source": "fGIqGfmgkW",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8739
    },
    {
      "source": "fGIqGfmgkW",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8723
    },
    {
      "source": "fGIqGfmgkW",
      "target": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "similarity": 0.8704
    },
    {
      "source": "fGIqGfmgkW",
      "target": "odU59TxdiB",
      "similarity": 0.8702
    },
    {
      "source": "fGIqGfmgkW",
      "target": "ki7b0qD11r",
      "similarity": 0.8683
    },
    {
      "source": "L9eBxTCpQG",
      "target": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "similarity": 0.8879
    },
    {
      "source": "L9eBxTCpQG",
      "target": "respectively. On skill retention tasks",
      "similarity": 0.8463
    },
    {
      "source": "L9eBxTCpQG",
      "target": "ff2V3UR9sC",
      "similarity": 0.8453
    },
    {
      "source": "L9eBxTCpQG",
      "target": "jjfve2gIXe",
      "similarity": 0.8398
    },
    {
      "source": "L9eBxTCpQG",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8384
    },
    {
      "source": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "target": "Mjn53GtMxi",
      "similarity": 0.8797
    },
    {
      "source": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "target": "instructions",
      "similarity": 0.8763
    },
    {
      "source": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "target": "In this work",
      "similarity": 0.8744
    },
    {
      "source": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "target": "AcVpLS86RT",
      "similarity": 0.8743
    },
    {
      "source": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "target": "0fJfVOSUra",
      "similarity": 0.87
    },
    {
      "source": "0GzqVqCKns",
      "target": "Our novel resource",
      "similarity": 0.8077
    },
    {
      "source": "0GzqVqCKns",
      "target": "u3TL0qxLWf",
      "similarity": 0.8031
    },
    {
      "source": "0GzqVqCKns",
      "target": "dence on a transductive learning framework. To address these shortcomings",
      "similarity": 0.7986
    },
    {
      "source": "0GzqVqCKns",
      "target": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "similarity": 0.7982
    },
    {
      "source": "0GzqVqCKns",
      "target": "Along our analysis",
      "similarity": 0.7961
    },
    {
      "source": "daUQ7vmGap",
      "target": "G328D1xt4W",
      "similarity": 0.8481
    },
    {
      "source": "daUQ7vmGap",
      "target": "Previous methods of *self-reflection* have been proven limited due to the models\u2019 inherent fixed thinking patterns.",
      "similarity": 0.8458
    },
    {
      "source": "daUQ7vmGap",
      "target": "tfO07iz0b9",
      "similarity": 0.8362
    },
    {
      "source": "daUQ7vmGap",
      "target": "JAMxRSXLFz",
      "similarity": 0.8358
    },
    {
      "source": "daUQ7vmGap",
      "target": "Second",
      "similarity": 0.8353
    },
    {
      "source": "4anfpHj0wf",
      "target": "ERv8ptegFi",
      "similarity": 0.8647
    },
    {
      "source": "4anfpHj0wf",
      "target": "H9UnNgdq0g",
      "similarity": 0.8487
    },
    {
      "source": "4anfpHj0wf",
      "target": "5pd78GmXC6",
      "similarity": 0.8464
    },
    {
      "source": "4anfpHj0wf",
      "target": "Second",
      "similarity": 0.8445
    },
    {
      "source": "4anfpHj0wf",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8419
    },
    {
      "source": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "target": "lgsyLSsDRe",
      "similarity": 0.8613
    },
    {
      "source": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "target": "It is especially difficult to generate videos with coherent narratives based on text.",
      "similarity": 0.8604
    },
    {
      "source": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "target": "v1B4aet9ct",
      "similarity": 0.8448
    },
    {
      "source": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8414
    },
    {
      "source": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "target": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "similarity": 0.8382
    },
    {
      "source": "In this paper",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8596
    },
    {
      "source": "In this paper",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8576
    },
    {
      "source": "In this paper",
      "target": "04qx93Viwj",
      "similarity": 0.855
    },
    {
      "source": "In this paper",
      "target": "1NprT9Kz0d",
      "similarity": 0.8493
    },
    {
      "source": "In this paper",
      "target": "EzrZX9bd4G",
      "similarity": 0.8399
    },
    {
      "source": "By directly learning to stochastically interpolate between noise and data point sets",
      "target": "frozen nonlinear manifolds",
      "similarity": 0.8733
    },
    {
      "source": "By directly learning to stochastically interpolate between noise and data point sets",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8715
    },
    {
      "source": "By directly learning to stochastically interpolate between noise and data point sets",
      "target": "h8yg0hT96f",
      "similarity": 0.8649
    },
    {
      "source": "By directly learning to stochastically interpolate between noise and data point sets",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8593
    },
    {
      "source": "By directly learning to stochastically interpolate between noise and data point sets",
      "target": "tu3qwNjrtw",
      "similarity": 0.8533
    },
    {
      "source": "Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.\"",
      "target": "4O0v4s3IzY",
      "similarity": 0.8686
    },
    {
      "source": "Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.\"",
      "target": "Moreover",
      "similarity": 0.8648
    },
    {
      "source": "Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.\"",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.8543
    },
    {
      "source": "Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.\"",
      "target": "is often a non-linear function",
      "similarity": 0.8489
    },
    {
      "source": "Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.\"",
      "target": "scale FMs are leveraged for multiple downstream tasks",
      "similarity": 0.844
    },
    {
      "source": "vVxeFSR4fU",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.9048
    },
    {
      "source": "vVxeFSR4fU",
      "target": "gsShHPxkUW",
      "similarity": 0.8679
    },
    {
      "source": "vVxeFSR4fU",
      "target": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "similarity": 0.855
    },
    {
      "source": "vVxeFSR4fU",
      "target": "In this paper",
      "similarity": 0.8539
    },
    {
      "source": "vVxeFSR4fU",
      "target": "In this work",
      "similarity": 0.8531
    },
    {
      "source": "y9A2TpaGsE",
      "target": "Using tools from the Wasserstein geometry",
      "similarity": 0.8781
    },
    {
      "source": "y9A2TpaGsE",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8439
    },
    {
      "source": "y9A2TpaGsE",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8414
    },
    {
      "source": "y9A2TpaGsE",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8411
    },
    {
      "source": "y9A2TpaGsE",
      "target": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "similarity": 0.8401
    },
    {
      "source": "JV8zULNh24",
      "target": "Third",
      "similarity": 0.8777
    },
    {
      "source": "JV8zULNh24",
      "target": "cfGpIcOIa5",
      "similarity": 0.8236
    },
    {
      "source": "JV8zULNh24",
      "target": "understanding of LLMs' generalization capabilities.\"",
      "similarity": 0.8166
    },
    {
      "source": "JV8zULNh24",
      "target": "However",
      "similarity": 0.8122
    },
    {
      "source": "JV8zULNh24",
      "target": "JMPOqoe4tl",
      "similarity": 0.8112
    },
    {
      "source": "fXb9BbuyAD",
      "target": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "similarity": 0.8664
    },
    {
      "source": "fXb9BbuyAD",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8631
    },
    {
      "source": "fXb9BbuyAD",
      "target": "mnna9LUg7P",
      "similarity": 0.863
    },
    {
      "source": "fXb9BbuyAD",
      "target": "BCP5nAHXqs",
      "similarity": 0.8615
    },
    {
      "source": "fXb9BbuyAD",
      "target": "Moreover",
      "similarity": 0.8596
    },
    {
      "source": "bSq0XGS3kW",
      "target": "NvDRvtrGLo",
      "similarity": 0.9146
    },
    {
      "source": "bSq0XGS3kW",
      "target": "INow59Vurm",
      "similarity": 0.9054
    },
    {
      "source": "bSq0XGS3kW",
      "target": "7nyJBVCTGQ",
      "similarity": 0.9045
    },
    {
      "source": "bSq0XGS3kW",
      "target": "avSocG0oFA",
      "similarity": 0.9035
    },
    {
      "source": "bSq0XGS3kW",
      "target": "However",
      "similarity": 0.9027
    },
    {
      "source": "lfPkGWXLLf",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8522
    },
    {
      "source": "lfPkGWXLLf",
      "target": "K2jOacHUlO",
      "similarity": 0.8394
    },
    {
      "source": "lfPkGWXLLf",
      "target": "uREg3OHjLL",
      "similarity": 0.8331
    },
    {
      "source": "lfPkGWXLLf",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8316
    },
    {
      "source": "lfPkGWXLLf",
      "target": "We are the first to identify these challenges in online VFL",
      "similarity": 0.8237
    },
    {
      "source": "5qg6JPSgCj",
      "target": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "similarity": 0.8835
    },
    {
      "source": "5qg6JPSgCj",
      "target": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "similarity": 0.8325
    },
    {
      "source": "5qg6JPSgCj",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8204
    },
    {
      "source": "5qg6JPSgCj",
      "target": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "similarity": 0.8176
    },
    {
      "source": "5qg6JPSgCj",
      "target": "9kJperA2a4",
      "similarity": 0.8156
    },
    {
      "source": "EbCUbPZjM1",
      "target": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "similarity": 0.8108
    },
    {
      "source": "EbCUbPZjM1",
      "target": "Unlike prior constructions that run encrypted search on the server side",
      "similarity": 0.8072
    },
    {
      "source": "EbCUbPZjM1",
      "target": "MxbEiFRf39",
      "similarity": 0.8066
    },
    {
      "source": "EbCUbPZjM1",
      "target": "fZK6AQXlUU",
      "similarity": 0.8036
    },
    {
      "source": "EbCUbPZjM1",
      "target": "We validate our approach in two tasks",
      "similarity": 0.8032
    },
    {
      "source": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "target": "g6v09VxgFw",
      "similarity": 0.8554
    },
    {
      "source": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8482
    },
    {
      "source": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "target": "98d7DLMGdt",
      "similarity": 0.8428
    },
    {
      "source": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "target": "In particular",
      "similarity": 0.8391
    },
    {
      "source": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "target": "NKotdPUc3L",
      "similarity": 0.8374
    },
    {
      "source": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8721
    },
    {
      "source": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "target": "distribution shifts show our framework produces concept-based interpretations",
      "similarity": 0.8662
    },
    {
      "source": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "target": "eHehzSDUFp",
      "similarity": 0.8486
    },
    {
      "source": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8429
    },
    {
      "source": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "target": "First",
      "similarity": 0.8373
    },
    {
      "source": "spDUv05cEq",
      "target": "wCOJpXm0Me",
      "similarity": 0.8414
    },
    {
      "source": "spDUv05cEq",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.8396
    },
    {
      "source": "spDUv05cEq",
      "target": "eXB5TCrAu9",
      "similarity": 0.8386
    },
    {
      "source": "spDUv05cEq",
      "target": "UyU8ETswPg",
      "similarity": 0.835
    },
    {
      "source": "spDUv05cEq",
      "target": "GFgn2LprFR",
      "similarity": 0.8223
    },
    {
      "source": "GkWA6NjePN",
      "target": "vVxeFSR4fU",
      "similarity": 0.8494
    },
    {
      "source": "GkWA6NjePN",
      "target": "kSISSDUYFh",
      "similarity": 0.8429
    },
    {
      "source": "GkWA6NjePN",
      "target": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "similarity": 0.8395
    },
    {
      "source": "GkWA6NjePN",
      "target": "C8jXEugWkq",
      "similarity": 0.8327
    },
    {
      "source": "GkWA6NjePN",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8323
    },
    {
      "source": "2ET561DyPe",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8841
    },
    {
      "source": "2ET561DyPe",
      "target": "Es4RPNDtmq",
      "similarity": 0.8775
    },
    {
      "source": "2ET561DyPe",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8676
    },
    {
      "source": "2ET561DyPe",
      "target": "However",
      "similarity": 0.8672
    },
    {
      "source": "2ET561DyPe",
      "target": "KD5nJUgeW4",
      "similarity": 0.8631
    },
    {
      "source": "9cQB1Hwrtw",
      "target": "models. However",
      "similarity": 0.8724
    },
    {
      "source": "9cQB1Hwrtw",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8707
    },
    {
      "source": "9cQB1Hwrtw",
      "target": "pDDODPtpx9",
      "similarity": 0.8703
    },
    {
      "source": "9cQB1Hwrtw",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.869
    },
    {
      "source": "9cQB1Hwrtw",
      "target": "To this end",
      "similarity": 0.8662
    },
    {
      "source": "We analyze the algorithm that the transformer has learned through a novel mechanistic interpretability technique that enables us to extract the computation graph from the trained model. We find that for each vertex in the input graph",
      "target": "mTCbq2QssD",
      "similarity": 0.8037
    },
    {
      "source": "We analyze the algorithm that the transformer has learned through a novel mechanistic interpretability technique that enables us to extract the computation graph from the trained model. We find that for each vertex in the input graph",
      "target": "NTHMw8S1Ow",
      "similarity": 0.8022
    },
    {
      "source": "We analyze the algorithm that the transformer has learned through a novel mechanistic interpretability technique that enables us to extract the computation graph from the trained model. We find that for each vertex in the input graph",
      "target": "xI71dsS3o4",
      "similarity": 0.802
    },
    {
      "source": "We analyze the algorithm that the transformer has learned through a novel mechanistic interpretability technique that enables us to extract the computation graph from the trained model. We find that for each vertex in the input graph",
      "target": "PY56Wur7S0",
      "similarity": 0.8018
    },
    {
      "source": "We analyze the algorithm that the transformer has learned through a novel mechanistic interpretability technique that enables us to extract the computation graph from the trained model. We find that for each vertex in the input graph",
      "target": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "similarity": 0.7991
    },
    {
      "source": "However",
      "target": "ZjOXuAfS6l",
      "similarity": 0.8765
    },
    {
      "source": "However",
      "target": "wfLuiDjQ0u",
      "similarity": 0.83
    },
    {
      "source": "However",
      "target": "vjel3nWP2a",
      "similarity": 0.8027
    },
    {
      "source": "However",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.7999
    },
    {
      "source": "However",
      "target": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "similarity": 0.7996
    },
    {
      "source": "lsvGqR6OTf",
      "target": "In this paper",
      "similarity": 0.8161
    },
    {
      "source": "lsvGqR6OTf",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8155
    },
    {
      "source": "lsvGqR6OTf",
      "target": "je3GZissZc",
      "similarity": 0.8122
    },
    {
      "source": "lsvGqR6OTf",
      "target": "C06kww3Qky",
      "similarity": 0.8115
    },
    {
      "source": "lsvGqR6OTf",
      "target": "wg1PCg3CUP",
      "similarity": 0.8108
    },
    {
      "source": "aWLQTbfFgV",
      "target": "L5godAOC2z",
      "similarity": 0.852
    },
    {
      "source": "aWLQTbfFgV",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.8261
    },
    {
      "source": "aWLQTbfFgV",
      "target": "As the size of the model and data grows",
      "similarity": 0.8245
    },
    {
      "source": "aWLQTbfFgV",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.8227
    },
    {
      "source": "aWLQTbfFgV",
      "target": "CLIP",
      "similarity": 0.819
    },
    {
      "source": "NKotdPUc3L",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8837
    },
    {
      "source": "NKotdPUc3L",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.852
    },
    {
      "source": "NKotdPUc3L",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.843
    },
    {
      "source": "NKotdPUc3L",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8408
    },
    {
      "source": "NKotdPUc3L",
      "target": "the entire observable history remained an open problem. In this work",
      "similarity": 0.8402
    },
    {
      "source": "S1Bv3068Xt",
      "target": "rTQNGQxm4K",
      "similarity": 0.9135
    },
    {
      "source": "S1Bv3068Xt",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8896
    },
    {
      "source": "S1Bv3068Xt",
      "target": "HqjRlT65WX",
      "similarity": 0.8826
    },
    {
      "source": "S1Bv3068Xt",
      "target": "OuLgaHEmzi",
      "similarity": 0.8656
    },
    {
      "source": "S1Bv3068Xt",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8615
    },
    {
      "source": "JeLqFpFzwX",
      "target": "In a client-server setting",
      "similarity": 0.8096
    },
    {
      "source": "JeLqFpFzwX",
      "target": "Testing the correctness of CAD generated code is challenging due to the complexity",
      "similarity": 0.8084
    },
    {
      "source": "JeLqFpFzwX",
      "target": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "similarity": 0.8065
    },
    {
      "source": "JeLqFpFzwX",
      "target": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "similarity": 0.8052
    },
    {
      "source": "JeLqFpFzwX",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.8018
    },
    {
      "source": "c61unr33XA",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.9045
    },
    {
      "source": "c61unr33XA",
      "target": "{Subsequently}",
      "similarity": 0.8926
    },
    {
      "source": "c61unr33XA",
      "target": "yLhJYvkKA0",
      "similarity": 0.8871
    },
    {
      "source": "c61unr33XA",
      "target": "Lut5t3qElA",
      "similarity": 0.8823
    },
    {
      "source": "c61unr33XA",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8769
    },
    {
      "source": "OhUoTMxFIH",
      "target": "yRKelogz5i",
      "similarity": 0.8246
    },
    {
      "source": "OhUoTMxFIH",
      "target": "Jjr2Odj8DJ",
      "similarity": 0.8242
    },
    {
      "source": "OhUoTMxFIH",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8242
    },
    {
      "source": "OhUoTMxFIH",
      "target": "4anfpHj0wf",
      "similarity": 0.8228
    },
    {
      "source": "OhUoTMxFIH",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8204
    },
    {
      "source": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "target": "generating time series of tabular data",
      "similarity": 0.8185
    },
    {
      "source": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "target": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "similarity": 0.8179
    },
    {
      "source": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "target": "Pacmann shows better scalability",
      "similarity": 0.8147
    },
    {
      "source": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "target": "6fDjUoEQvm",
      "similarity": 0.8035
    },
    {
      "source": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "target": "Next",
      "similarity": 0.8009
    },
    {
      "source": "CxXGvKRDnL",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8115
    },
    {
      "source": "CxXGvKRDnL",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8042
    },
    {
      "source": "CxXGvKRDnL",
      "target": "irrtPRFksw",
      "similarity": 0.8042
    },
    {
      "source": "CxXGvKRDnL",
      "target": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "similarity": 0.798
    },
    {
      "source": "CxXGvKRDnL",
      "target": "However",
      "similarity": 0.7967
    },
    {
      "source": "3UKOzGWCVY",
      "target": "KnoS9XxIlK",
      "similarity": 0.8546
    },
    {
      "source": "3UKOzGWCVY",
      "target": "bSq0XGS3kW",
      "similarity": 0.8252
    },
    {
      "source": "3UKOzGWCVY",
      "target": "INow59Vurm",
      "similarity": 0.8076
    },
    {
      "source": "3UKOzGWCVY",
      "target": "NvDRvtrGLo",
      "similarity": 0.7992
    },
    {
      "source": "3UKOzGWCVY",
      "target": "7nyJBVCTGQ",
      "similarity": 0.7933
    },
    {
      "source": "hjROBHstZ3",
      "target": "xiQNfYl33p",
      "similarity": 0.8793
    },
    {
      "source": "hjROBHstZ3",
      "target": "Second",
      "similarity": 0.8741
    },
    {
      "source": "hjROBHstZ3",
      "target": "VoayJihXra",
      "similarity": 0.8676
    },
    {
      "source": "hjROBHstZ3",
      "target": "eiqrnVaeIw",
      "similarity": 0.86
    },
    {
      "source": "hjROBHstZ3",
      "target": "To this end",
      "similarity": 0.86
    },
    {
      "source": "In this work",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8354
    },
    {
      "source": "In this work",
      "target": "wUtXB43Chi",
      "similarity": 0.8186
    },
    {
      "source": "In this work",
      "target": "bAFVlpFQvT",
      "similarity": 0.8137
    },
    {
      "source": "In this work",
      "target": "HZgZrtIreg",
      "similarity": 0.8077
    },
    {
      "source": "In this work",
      "target": "To address this",
      "similarity": 0.8077
    },
    {
      "source": "Empirically",
      "target": "huuKoVQnB0",
      "similarity": 0.8345
    },
    {
      "source": "Empirically",
      "target": "FEpAUnS7f7",
      "similarity": 0.8209
    },
    {
      "source": "Empirically",
      "target": "NCrFA7dq8T",
      "similarity": 0.8046
    },
    {
      "source": "Empirically",
      "target": "In parallel",
      "similarity": 0.7947
    },
    {
      "source": "Empirically",
      "target": "TtKN1TpvUu",
      "similarity": 0.7911
    },
    {
      "source": "bhK7U37VW8",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.7886
    },
    {
      "source": "bhK7U37VW8",
      "target": "cation",
      "similarity": 0.7872
    },
    {
      "source": "bhK7U37VW8",
      "target": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "similarity": 0.7852
    },
    {
      "source": "bhK7U37VW8",
      "target": "FFE.\"",
      "similarity": 0.7836
    },
    {
      "source": "bhK7U37VW8",
      "target": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "similarity": 0.7807
    },
    {
      "source": "NTHMw8S1Ow",
      "target": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "similarity": 0.8809
    },
    {
      "source": "NTHMw8S1Ow",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8651
    },
    {
      "source": "NTHMw8S1Ow",
      "target": "mTCbq2QssD",
      "similarity": 0.8488
    },
    {
      "source": "NTHMw8S1Ow",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8479
    },
    {
      "source": "NTHMw8S1Ow",
      "target": "KAIqwkB3dT",
      "similarity": 0.8443
    },
    {
      "source": "NHhjczmJjo",
      "target": "Yk87CwhBDx",
      "similarity": 0.87
    },
    {
      "source": "NHhjczmJjo",
      "target": "is often a non-linear function",
      "similarity": 0.864
    },
    {
      "source": "NHhjczmJjo",
      "target": "i7jAYFYDcM",
      "similarity": 0.8635
    },
    {
      "source": "NHhjczmJjo",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8613
    },
    {
      "source": "NHhjczmJjo",
      "target": "In this paper",
      "similarity": 0.86
    },
    {
      "source": "hlvLM3GX8R",
      "target": "TUvg5uwdeG",
      "similarity": 0.8764
    },
    {
      "source": "hlvLM3GX8R",
      "target": "Without labeled calibration data for target domains",
      "similarity": 0.8518
    },
    {
      "source": "hlvLM3GX8R",
      "target": "6GATHdOi1x",
      "similarity": 0.8451
    },
    {
      "source": "hlvLM3GX8R",
      "target": "xPTzjpIQNp",
      "similarity": 0.8448
    },
    {
      "source": "hlvLM3GX8R",
      "target": "In this setting",
      "similarity": 0.8412
    },
    {
      "source": "To do this successfully",
      "target": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "similarity": 0.7909
    },
    {
      "source": "To do this successfully",
      "target": "We5z3UEnUY",
      "similarity": 0.7865
    },
    {
      "source": "To do this successfully",
      "target": "extreme weather",
      "similarity": 0.7848
    },
    {
      "source": "To do this successfully",
      "target": "oYSsbY3G4o",
      "similarity": 0.7829
    },
    {
      "source": "To do this successfully",
      "target": "TuOTSAiHDn",
      "similarity": 0.7806
    },
    {
      "source": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "target": "However",
      "similarity": 0.8639
    },
    {
      "source": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8578
    },
    {
      "source": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "target": "Towards doing so",
      "similarity": 0.8548
    },
    {
      "source": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8538
    },
    {
      "source": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "target": "Furthermore",
      "similarity": 0.852
    },
    {
      "source": "In this work",
      "target": "Finally",
      "similarity": 0.8764
    },
    {
      "source": "In this work",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8713
    },
    {
      "source": "In this work",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8697
    },
    {
      "source": "In this work",
      "target": "2pNLknCTvG",
      "similarity": 0.8588
    },
    {
      "source": "In this work",
      "target": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "similarity": 0.8574
    },
    {
      "source": "We introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution",
      "target": "calibration data is also crucial to post-training pruning",
      "similarity": 0.8327
    },
    {
      "source": "We introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution",
      "target": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "similarity": 0.8298
    },
    {
      "source": "We introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution",
      "target": "of extreme weather events",
      "similarity": 0.8253
    },
    {
      "source": "We introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution",
      "target": "component of real-world software development.\"",
      "similarity": 0.8248
    },
    {
      "source": "We introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution",
      "target": "fMTPkDEhLQ",
      "similarity": 0.818
    },
    {
      "source": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "target": "bAFVlpFQvT",
      "similarity": 0.8189
    },
    {
      "source": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "target": "rWui9vLhOc",
      "similarity": 0.817
    },
    {
      "source": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8164
    },
    {
      "source": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "target": "eIB1UZFcFg",
      "similarity": 0.8086
    },
    {
      "source": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "target": "kO0DgO07hW",
      "similarity": 0.8035
    },
    {
      "source": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "target": "gFvRRCnQvX",
      "similarity": 0.8952
    },
    {
      "source": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8856
    },
    {
      "source": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "target": "To address this issue",
      "similarity": 0.8718
    },
    {
      "source": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "target": "increased their demand. However",
      "similarity": 0.8678
    },
    {
      "source": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "target": "In light of this",
      "similarity": 0.8675
    },
    {
      "source": "To address these shortcomings",
      "target": "5pd78GmXC6",
      "similarity": 0.8244
    },
    {
      "source": "To address these shortcomings",
      "target": "In this work",
      "similarity": 0.8115
    },
    {
      "source": "To address these shortcomings",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8067
    },
    {
      "source": "To address these shortcomings",
      "target": "AjXkRZIvjB",
      "similarity": 0.8029
    },
    {
      "source": "To address these shortcomings",
      "target": "4anfpHj0wf",
      "similarity": 0.8002
    },
    {
      "source": "To validate OvercookedV2",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8408
    },
    {
      "source": "To validate OvercookedV2",
      "target": "dTkqaCKLPp",
      "similarity": 0.8391
    },
    {
      "source": "To validate OvercookedV2",
      "target": "B5iOSxM2I0",
      "similarity": 0.8363
    },
    {
      "source": "To validate OvercookedV2",
      "target": "T2d0geb6y0",
      "similarity": 0.8279
    },
    {
      "source": "To validate OvercookedV2",
      "target": "(1) Sparse attention patterns",
      "similarity": 0.825
    },
    {
      "source": "We hope that OvercookedV2 will help benchmark the next generation of ZSC algorithms and advance collaboration between AI agents and humans.\"",
      "target": "gradual stacking and layer dropping (Reddi et al.",
      "similarity": 0.8434
    },
    {
      "source": "We hope that OvercookedV2 will help benchmark the next generation of ZSC algorithms and advance collaboration between AI agents and humans.\"",
      "target": "using only a 4K context window",
      "similarity": 0.8359
    },
    {
      "source": "We hope that OvercookedV2 will help benchmark the next generation of ZSC algorithms and advance collaboration between AI agents and humans.\"",
      "target": "SUc1UOWndp",
      "similarity": 0.8009
    },
    {
      "source": "We hope that OvercookedV2 will help benchmark the next generation of ZSC algorithms and advance collaboration between AI agents and humans.\"",
      "target": "To tackle this challenge",
      "similarity": 0.7977
    },
    {
      "source": "We hope that OvercookedV2 will help benchmark the next generation of ZSC algorithms and advance collaboration between AI agents and humans.\"",
      "target": "lS2SGfWizd",
      "similarity": 0.7952
    },
    {
      "source": "7liN6uHAQZ",
      "target": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "similarity": 0.8827
    },
    {
      "source": "7liN6uHAQZ",
      "target": "6ouZaBzeNO",
      "similarity": 0.8691
    },
    {
      "source": "7liN6uHAQZ",
      "target": "connection component",
      "similarity": 0.8521
    },
    {
      "source": "7liN6uHAQZ",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.8356
    },
    {
      "source": "7liN6uHAQZ",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8324
    },
    {
      "source": "r9oqHOdoHf",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8258
    },
    {
      "source": "r9oqHOdoHf",
      "target": "R4q3cY3kQf",
      "similarity": 0.8134
    },
    {
      "source": "r9oqHOdoHf",
      "target": "7bAjVh3CG3",
      "similarity": 0.812
    },
    {
      "source": "r9oqHOdoHf",
      "target": "d7pr2doXn3",
      "similarity": 0.8114
    },
    {
      "source": "r9oqHOdoHf",
      "target": "pRCOZllZdT",
      "similarity": 0.8088
    },
    {
      "source": "Fty0wTcemV",
      "target": "90DC0IvlSs",
      "similarity": 0.9145
    },
    {
      "source": "Fty0wTcemV",
      "target": "AJpUZd8Clb",
      "similarity": 0.8701
    },
    {
      "source": "Fty0wTcemV",
      "target": "For TP",
      "similarity": 0.8639
    },
    {
      "source": "Fty0wTcemV",
      "target": "(1) make no assumptions on the data",
      "similarity": 0.8631
    },
    {
      "source": "Fty0wTcemV",
      "target": "Through experiments across various datasets and settings",
      "similarity": 0.8581
    },
    {
      "source": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "target": "ZadnlOHsHv",
      "similarity": 0.8649
    },
    {
      "source": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "target": "FEZOLWexPb",
      "similarity": 0.8527
    },
    {
      "source": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "target": "2ea5TNVR0c",
      "similarity": 0.8424
    },
    {
      "source": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "target": "Based on this concept",
      "similarity": 0.8415
    },
    {
      "source": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "target": "PDnEDS244P",
      "similarity": 0.8261
    },
    {
      "source": "jjfve2gIXe",
      "target": "jQP5o1VAVc",
      "similarity": 0.8664
    },
    {
      "source": "jjfve2gIXe",
      "target": "1qq1QJKM5q",
      "similarity": 0.8591
    },
    {
      "source": "jjfve2gIXe",
      "target": "In response",
      "similarity": 0.8532
    },
    {
      "source": "jjfve2gIXe",
      "target": "in a vector database",
      "similarity": 0.8522
    },
    {
      "source": "jjfve2gIXe",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.8508
    },
    {
      "source": "tU074jg2vS",
      "target": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "similarity": 0.8528
    },
    {
      "source": "tU074jg2vS",
      "target": "prompts. As such",
      "similarity": 0.8396
    },
    {
      "source": "tU074jg2vS",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8351
    },
    {
      "source": "tU074jg2vS",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8347
    },
    {
      "source": "tU074jg2vS",
      "target": "79ZkWgY2FI",
      "similarity": 0.8346
    },
    {
      "source": "JDm7oIcx4Y",
      "target": "This paper proposes",
      "similarity": 0.8673
    },
    {
      "source": "JDm7oIcx4Y",
      "target": "VmJdqhuTCh",
      "similarity": 0.866
    },
    {
      "source": "JDm7oIcx4Y",
      "target": "named Pacmann",
      "similarity": 0.8581
    },
    {
      "source": "JDm7oIcx4Y",
      "target": "VoayJihXra",
      "similarity": 0.8545
    },
    {
      "source": "JDm7oIcx4Y",
      "target": "qykpnEWf2J",
      "similarity": 0.8474
    },
    {
      "source": "Such models faced convergence issues due to vanishing gradient",
      "target": "To this end",
      "similarity": 0.8789
    },
    {
      "source": "Such models faced convergence issues due to vanishing gradient",
      "target": "bilities",
      "similarity": 0.8692
    },
    {
      "source": "Such models faced convergence issues due to vanishing gradient",
      "target": "AJpUZd8Clb",
      "similarity": 0.8621
    },
    {
      "source": "Such models faced convergence issues due to vanishing gradient",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8618
    },
    {
      "source": "Such models faced convergence issues due to vanishing gradient",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8608
    },
    {
      "source": "However",
      "target": "To this end",
      "similarity": 0.877
    },
    {
      "source": "However",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8651
    },
    {
      "source": "However",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8526
    },
    {
      "source": "However",
      "target": "AJpUZd8Clb",
      "similarity": 0.8478
    },
    {
      "source": "However",
      "target": "previous results.\"",
      "similarity": 0.8433
    },
    {
      "source": "Taking advantage of residual-like architectural designs",
      "target": "hovDbX4Gh6",
      "similarity": 0.846
    },
    {
      "source": "Taking advantage of residual-like architectural designs",
      "target": "In this paper",
      "similarity": 0.8432
    },
    {
      "source": "Taking advantage of residual-like architectural designs",
      "target": "VoayJihXra",
      "similarity": 0.8326
    },
    {
      "source": "Taking advantage of residual-like architectural designs",
      "target": "potential algorithms to solve one task",
      "similarity": 0.8318
    },
    {
      "source": "Taking advantage of residual-like architectural designs",
      "target": "hjROBHstZ3",
      "similarity": 0.8312
    },
    {
      "source": "Through an extensive empirical study on a large selection of tasks and models",
      "target": "instructions",
      "similarity": 0.887
    },
    {
      "source": "Through an extensive empirical study on a large selection of tasks and models",
      "target": "across new LLMs and different tasks because of their limited ability to leverage",
      "similarity": 0.8869
    },
    {
      "source": "Through an extensive empirical study on a large selection of tasks and models",
      "target": "254NJe9JEw",
      "similarity": 0.8788
    },
    {
      "source": "Through an extensive empirical study on a large selection of tasks and models",
      "target": "dOAkHmsjRX",
      "similarity": 0.8761
    },
    {
      "source": "Through an extensive empirical study on a large selection of tasks and models",
      "target": "For TP",
      "similarity": 0.8744
    },
    {
      "source": "ykuc5q381b",
      "target": "To enrich long documents",
      "similarity": 0.8645
    },
    {
      "source": "ykuc5q381b",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8381
    },
    {
      "source": "ykuc5q381b",
      "target": "Moreover",
      "similarity": 0.8275
    },
    {
      "source": "ykuc5q381b",
      "target": "20qZK2T7fa",
      "similarity": 0.8274
    },
    {
      "source": "ykuc5q381b",
      "target": "As a highlight",
      "similarity": 0.8209
    },
    {
      "source": "dsHpulHpOK",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8208
    },
    {
      "source": "dsHpulHpOK",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.8161
    },
    {
      "source": "dsHpulHpOK",
      "target": "Next",
      "similarity": 0.816
    },
    {
      "source": "dsHpulHpOK",
      "target": "iyJOUELYir",
      "similarity": 0.8157
    },
    {
      "source": "dsHpulHpOK",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8101
    },
    {
      "source": "KeRwLLwZaw",
      "target": "Real-world causal structures",
      "similarity": 0.85
    },
    {
      "source": "KeRwLLwZaw",
      "target": "RZwtbg3qYD",
      "similarity": 0.839
    },
    {
      "source": "KeRwLLwZaw",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8275
    },
    {
      "source": "KeRwLLwZaw",
      "target": "6ouZaBzeNO",
      "similarity": 0.8238
    },
    {
      "source": "KeRwLLwZaw",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8238
    },
    {
      "source": "YzxMu1asQi",
      "target": "llSiIJosDj",
      "similarity": 0.8882
    },
    {
      "source": "YzxMu1asQi",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8639
    },
    {
      "source": "YzxMu1asQi",
      "target": "pDDODPtpx9",
      "similarity": 0.8627
    },
    {
      "source": "YzxMu1asQi",
      "target": "To this end",
      "similarity": 0.8568
    },
    {
      "source": "YzxMu1asQi",
      "target": "254NJe9JEw",
      "similarity": 0.8525
    },
    {
      "source": "EzrZX9bd4G",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.9011
    },
    {
      "source": "EzrZX9bd4G",
      "target": "pre-training data",
      "similarity": 0.8765
    },
    {
      "source": "EzrZX9bd4G",
      "target": "J9VogDTa1W",
      "similarity": 0.8687
    },
    {
      "source": "EzrZX9bd4G",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8671
    },
    {
      "source": "EzrZX9bd4G",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.862
    },
    {
      "source": "Tpjq66xwTq",
      "target": "In this paper",
      "similarity": 0.8786
    },
    {
      "source": "Tpjq66xwTq",
      "target": "In this work",
      "similarity": 0.875
    },
    {
      "source": "Tpjq66xwTq",
      "target": "ScVnYBaSEw",
      "similarity": 0.8517
    },
    {
      "source": "Tpjq66xwTq",
      "target": "target node would not have been anomalous. Prior methods of assessing the fix",
      "similarity": 0.8395
    },
    {
      "source": "Tpjq66xwTq",
      "target": "By playing against itself",
      "similarity": 0.838
    },
    {
      "source": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "target": "JSB171dSUU",
      "similarity": 0.878
    },
    {
      "source": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8741
    },
    {
      "source": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8687
    },
    {
      "source": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8674
    },
    {
      "source": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "target": "while ensuring safety during learning.\"",
      "similarity": 0.8624
    },
    {
      "source": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "target": "First",
      "similarity": 0.8508
    },
    {
      "source": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.85
    },
    {
      "source": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "target": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "similarity": 0.8472
    },
    {
      "source": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "target": "This corresponds to",
      "similarity": 0.8465
    },
    {
      "source": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "target": "P4XmKjXTrM",
      "similarity": 0.8454
    },
    {
      "source": "In this work",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8698
    },
    {
      "source": "In this work",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8531
    },
    {
      "source": "In this work",
      "target": "FBhKUXK7od",
      "similarity": 0.8334
    },
    {
      "source": "In this work",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.8298
    },
    {
      "source": "In this work",
      "target": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "similarity": 0.8286
    },
    {
      "source": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8297
    },
    {
      "source": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8282
    },
    {
      "source": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "target": "a linearly separable noisy dataset.",
      "similarity": 0.8234
    },
    {
      "source": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "target": "on the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d",
      "similarity": 0.8158
    },
    {
      "source": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "target": "x$",
      "similarity": 0.8133
    },
    {
      "source": "We validate our approach in two tasks",
      "target": "dual shape representation",
      "similarity": 0.8646
    },
    {
      "source": "We validate our approach in two tasks",
      "target": "Unlike prior constructions that run encrypted search on the server side",
      "similarity": 0.8559
    },
    {
      "source": "We validate our approach in two tasks",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8396
    },
    {
      "source": "We validate our approach in two tasks",
      "target": "iVxxgZlXh6",
      "similarity": 0.8273
    },
    {
      "source": "We validate our approach in two tasks",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8178
    },
    {
      "source": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "target": "fuoM5YDBX4",
      "similarity": 0.8486
    },
    {
      "source": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "target": "OhauMUNW8T",
      "similarity": 0.8468
    },
    {
      "source": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "target": "models. However",
      "similarity": 0.8455
    },
    {
      "source": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "target": "Yet",
      "similarity": 0.8443
    },
    {
      "source": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8411
    },
    {
      "source": "We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8237
    },
    {
      "source": "We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.",
      "target": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "similarity": 0.8198
    },
    {
      "source": "We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.",
      "target": "NGKQoaqLpo",
      "similarity": 0.8177
    },
    {
      "source": "We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.",
      "target": "To address this",
      "similarity": 0.8155
    },
    {
      "source": "We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8119
    },
    {
      "source": "Our work opens up new opportunities for accelerated mechanical design enhanced by neural networks for the built environment.\"",
      "target": "gWgaypDBs8",
      "similarity": 0.7861
    },
    {
      "source": "Our work opens up new opportunities for accelerated mechanical design enhanced by neural networks for the built environment.\"",
      "target": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "similarity": 0.7834
    },
    {
      "source": "Our work opens up new opportunities for accelerated mechanical design enhanced by neural networks for the built environment.\"",
      "target": "p6ncr0eTKE",
      "similarity": 0.7762
    },
    {
      "source": "Our work opens up new opportunities for accelerated mechanical design enhanced by neural networks for the built environment.\"",
      "target": "To do this successfully",
      "similarity": 0.7735
    },
    {
      "source": "Our work opens up new opportunities for accelerated mechanical design enhanced by neural networks for the built environment.\"",
      "target": "q87GUkdQBm",
      "similarity": 0.7734
    },
    {
      "source": "JUr0YOMvZA",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.8741
    },
    {
      "source": "JUr0YOMvZA",
      "target": "BI2int5SAC",
      "similarity": 0.8494
    },
    {
      "source": "JUr0YOMvZA",
      "target": "kmgrlG9TR0",
      "similarity": 0.8472
    },
    {
      "source": "JUr0YOMvZA",
      "target": "90DC0IvlSs",
      "similarity": 0.8456
    },
    {
      "source": "JUr0YOMvZA",
      "target": "Q6PAnqYVpo",
      "similarity": 0.8387
    },
    {
      "source": "2e4ECh0ikn",
      "target": "ogXkmugNZw",
      "similarity": 0.8006
    },
    {
      "source": "2e4ECh0ikn",
      "target": "Our experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.",
      "similarity": 0.7773
    },
    {
      "source": "2e4ECh0ikn",
      "target": "XAjfjizaKs",
      "similarity": 0.7719
    },
    {
      "source": "2e4ECh0ikn",
      "target": "Finally",
      "similarity": 0.7697
    },
    {
      "source": "2e4ECh0ikn",
      "target": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "similarity": 0.7681
    },
    {
      "source": "iXCeQ2m6vT",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.8664
    },
    {
      "source": "iXCeQ2m6vT",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8609
    },
    {
      "source": "iXCeQ2m6vT",
      "target": "1qq1QJKM5q",
      "similarity": 0.8578
    },
    {
      "source": "iXCeQ2m6vT",
      "target": "FXw0okNcOb",
      "similarity": 0.8553
    },
    {
      "source": "iXCeQ2m6vT",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8533
    },
    {
      "source": "zl3pfz4VCV",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.863
    },
    {
      "source": "zl3pfz4VCV",
      "target": "MxbEiFRf39",
      "similarity": 0.8534
    },
    {
      "source": "zl3pfz4VCV",
      "target": "5pd78GmXC6",
      "similarity": 0.8328
    },
    {
      "source": "zl3pfz4VCV",
      "target": "m73tETvFkX",
      "similarity": 0.8273
    },
    {
      "source": "zl3pfz4VCV",
      "target": "6HcnC3pPkp",
      "similarity": 0.8215
    },
    {
      "source": "Our findings indicate that",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8805
    },
    {
      "source": "Our findings indicate that",
      "target": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "similarity": 0.8694
    },
    {
      "source": "Our findings indicate that",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8694
    },
    {
      "source": "Our findings indicate that",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.8653
    },
    {
      "source": "Our findings indicate that",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8651
    },
    {
      "source": "Massive benchmarks often impose high computational demands",
      "target": "Fs9EabmQrJ",
      "similarity": 0.8632
    },
    {
      "source": "Massive benchmarks often impose high computational demands",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8548
    },
    {
      "source": "Massive benchmarks often impose high computational demands",
      "target": "2ET561DyPe",
      "similarity": 0.8457
    },
    {
      "source": "Massive benchmarks often impose high computational demands",
      "target": "jxMAPMqNr5",
      "similarity": 0.844
    },
    {
      "source": "Massive benchmarks often impose high computational demands",
      "target": "To address this limitation",
      "similarity": 0.8433
    },
    {
      "source": "We further optimize tasks such as retrieval by sampling hard negatives",
      "target": "riieAeQBJm",
      "similarity": 0.89
    },
    {
      "source": "We further optimize tasks such as retrieval by sampling hard negatives",
      "target": "kwCHcaeHrf",
      "similarity": 0.8833
    },
    {
      "source": "We further optimize tasks such as retrieval by sampling hard negatives",
      "target": "dAeET8gxqg",
      "similarity": 0.8741
    },
    {
      "source": "We further optimize tasks such as retrieval by sampling hard negatives",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8736
    },
    {
      "source": "We further optimize tasks such as retrieval by sampling hard negatives",
      "target": "BL4WBIfyrz",
      "similarity": 0.8728
    },
    {
      "source": "1NprT9Kz0d",
      "target": "JytL2MrlLT",
      "similarity": 0.8928
    },
    {
      "source": "1NprT9Kz0d",
      "target": "This paper introduces WebRL",
      "similarity": 0.8849
    },
    {
      "source": "1NprT9Kz0d",
      "target": "pre-training data",
      "similarity": 0.8815
    },
    {
      "source": "1NprT9Kz0d",
      "target": "WwwJfkGq0G",
      "similarity": 0.8571
    },
    {
      "source": "1NprT9Kz0d",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8502
    },
    {
      "source": "PJNhZoCjLh",
      "target": "0fJfVOSUra",
      "similarity": 0.8515
    },
    {
      "source": "PJNhZoCjLh",
      "target": "1qGkuxI9UX",
      "similarity": 0.8492
    },
    {
      "source": "PJNhZoCjLh",
      "target": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "similarity": 0.8408
    },
    {
      "source": "PJNhZoCjLh",
      "target": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "similarity": 0.8398
    },
    {
      "source": "PJNhZoCjLh",
      "target": "se4vjm7h4E",
      "similarity": 0.8376
    },
    {
      "source": "WWXjMYZxfH",
      "target": "To bridge this gap in understanding",
      "similarity": 0.8996
    },
    {
      "source": "WWXjMYZxfH",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8378
    },
    {
      "source": "WWXjMYZxfH",
      "target": "mOpNrrV2zH",
      "similarity": 0.8301
    },
    {
      "source": "WWXjMYZxfH",
      "target": "To enrich long documents",
      "similarity": 0.8266
    },
    {
      "source": "WWXjMYZxfH",
      "target": "20qZK2T7fa",
      "similarity": 0.822
    },
    {
      "source": "5x88lQ2MsH",
      "target": "Because of this",
      "similarity": 0.8825
    },
    {
      "source": "5x88lQ2MsH",
      "target": "pDDODPtpx9",
      "similarity": 0.848
    },
    {
      "source": "5x88lQ2MsH",
      "target": "BpyHIrpUOL",
      "similarity": 0.8467
    },
    {
      "source": "5x88lQ2MsH",
      "target": "To this end",
      "similarity": 0.8464
    },
    {
      "source": "5x88lQ2MsH",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8426
    },
    {
      "source": "7PGluppo4k",
      "target": "such events remains limited. Given the critical importance of accurately forecasting",
      "similarity": 0.8129
    },
    {
      "source": "7PGluppo4k",
      "target": "named Pacmann",
      "similarity": 0.8111
    },
    {
      "source": "7PGluppo4k",
      "target": "nIEjY4a2Lf",
      "similarity": 0.7908
    },
    {
      "source": "7PGluppo4k",
      "target": "This paper proposes",
      "similarity": 0.7889
    },
    {
      "source": "7PGluppo4k",
      "target": "bIlnpVM4bc",
      "similarity": 0.7884
    },
    {
      "source": "INqLJwqUmc",
      "target": "n2NidsYDop",
      "similarity": 0.8848
    },
    {
      "source": "INqLJwqUmc",
      "target": "KAIqwkB3dT",
      "similarity": 0.871
    },
    {
      "source": "INqLJwqUmc",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8587
    },
    {
      "source": "INqLJwqUmc",
      "target": "AAXBfJNHDt",
      "similarity": 0.8547
    },
    {
      "source": "INqLJwqUmc",
      "target": "First",
      "similarity": 0.847
    },
    {
      "source": "Q5Sawm0nqo",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8457
    },
    {
      "source": "Q5Sawm0nqo",
      "target": "tRNKe2Vgqt",
      "similarity": 0.8354
    },
    {
      "source": "Q5Sawm0nqo",
      "target": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "similarity": 0.8274
    },
    {
      "source": "Q5Sawm0nqo",
      "target": "Igm9bbkzHC",
      "similarity": 0.8157
    },
    {
      "source": "Q5Sawm0nqo",
      "target": "Yet",
      "similarity": 0.8115
    },
    {
      "source": "l6QnSQizmN",
      "target": "zCZnEXF3bN",
      "similarity": 0.888
    },
    {
      "source": "l6QnSQizmN",
      "target": "ff2V3UR9sC",
      "similarity": 0.8753
    },
    {
      "source": "l6QnSQizmN",
      "target": "affects effectiveness in two downstream proxy model applications: data",
      "similarity": 0.8712
    },
    {
      "source": "l6QnSQizmN",
      "target": "p4cLtzk4oe",
      "similarity": 0.864
    },
    {
      "source": "l6QnSQizmN",
      "target": "In this paper",
      "similarity": 0.8605
    },
    {
      "source": "We present Locally Constrained Policy Optimization (LCPO)",
      "target": "4O0v4s3IzY",
      "similarity": 0.837
    },
    {
      "source": "We present Locally Constrained Policy Optimization (LCPO)",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8336
    },
    {
      "source": "We present Locally Constrained Policy Optimization (LCPO)",
      "target": "Additionally",
      "similarity": 0.8298
    },
    {
      "source": "We present Locally Constrained Policy Optimization (LCPO)",
      "target": "is often a non-linear function",
      "similarity": 0.8293
    },
    {
      "source": "We present Locally Constrained Policy Optimization (LCPO)",
      "target": "Our experiments verify that",
      "similarity": 0.8284
    },
    {
      "source": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "target": "H0qIWXXLUR",
      "similarity": 0.8386
    },
    {
      "source": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8371
    },
    {
      "source": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "target": "kxnoqaisCT",
      "similarity": 0.837
    },
    {
      "source": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "target": "jlhBFm7T2J",
      "similarity": 0.8335
    },
    {
      "source": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "target": "S85PP4xjFD",
      "similarity": 0.8262
    },
    {
      "source": "7FHSPd3SRE",
      "target": "GpdO9r73xT",
      "similarity": 0.8405
    },
    {
      "source": "7FHSPd3SRE",
      "target": "This enables the network to adaptively reuse parameters across tasks",
      "similarity": 0.8364
    },
    {
      "source": "7FHSPd3SRE",
      "target": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "similarity": 0.8289
    },
    {
      "source": "7FHSPd3SRE",
      "target": "latent variables",
      "similarity": 0.8268
    },
    {
      "source": "7FHSPd3SRE",
      "target": "70B-base from 8K to 128K tokens",
      "similarity": 0.8221
    },
    {
      "source": "jmN1zXMq0O",
      "target": "4JK2XMGUc8",
      "similarity": 0.8963
    },
    {
      "source": "jmN1zXMq0O",
      "target": "increased their demand. However",
      "similarity": 0.8857
    },
    {
      "source": "jmN1zXMq0O",
      "target": "0h6v4SpLCY",
      "similarity": 0.8824
    },
    {
      "source": "jmN1zXMq0O",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8768
    },
    {
      "source": "jmN1zXMq0O",
      "target": "In doing so",
      "similarity": 0.8699
    },
    {
      "source": "tQyh0gnfqW",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.8629
    },
    {
      "source": "tQyh0gnfqW",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8417
    },
    {
      "source": "tQyh0gnfqW",
      "target": "Inspired by MuZero",
      "similarity": 0.8388
    },
    {
      "source": "tQyh0gnfqW",
      "target": "In this paper",
      "similarity": 0.8321
    },
    {
      "source": "tQyh0gnfqW",
      "target": "mkDam1xIzW",
      "similarity": 0.8291
    },
    {
      "source": "Recently proposed diffusion bridge models provide a potential solution",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.836
    },
    {
      "source": "Recently proposed diffusion bridge models provide a potential solution",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8328
    },
    {
      "source": "Recently proposed diffusion bridge models provide a potential solution",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8267
    },
    {
      "source": "Recently proposed diffusion bridge models provide a potential solution",
      "target": "jCPak79Kev",
      "similarity": 0.8255
    },
    {
      "source": "Recently proposed diffusion bridge models provide a potential solution",
      "target": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "similarity": 0.8213
    },
    {
      "source": "Furthermore",
      "target": "1F8xTfv6ah",
      "similarity": 0.8207
    },
    {
      "source": "Furthermore",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8202
    },
    {
      "source": "Furthermore",
      "target": "Second",
      "similarity": 0.8186
    },
    {
      "source": "Furthermore",
      "target": "Tkkrm3pA35",
      "similarity": 0.8148
    },
    {
      "source": "Furthermore",
      "target": "Ax3uliEBVR",
      "similarity": 0.8141
    },
    {
      "source": "To overcome these limitations",
      "target": "Yet",
      "similarity": 0.8748
    },
    {
      "source": "To overcome these limitations",
      "target": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "similarity": 0.8562
    },
    {
      "source": "To overcome these limitations",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.846
    },
    {
      "source": "To overcome these limitations",
      "target": "HpUs2EXjOl",
      "similarity": 0.8216
    },
    {
      "source": "To overcome these limitations",
      "target": "Despite their importance",
      "similarity": 0.8145
    },
    {
      "source": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "target": "eLLBILFRsA",
      "similarity": 0.8631
    },
    {
      "source": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "target": "L238BAx0wP",
      "similarity": 0.8477
    },
    {
      "source": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "target": "3ogIALgghF",
      "similarity": 0.8412
    },
    {
      "source": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8336
    },
    {
      "source": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "target": "cfGpIcOIa5",
      "similarity": 0.831
    },
    {
      "source": "Furthermore",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8714
    },
    {
      "source": "Furthermore",
      "target": "By playing against itself",
      "similarity": 0.8638
    },
    {
      "source": "Furthermore",
      "target": "uNomADvF3s",
      "similarity": 0.8504
    },
    {
      "source": "Furthermore",
      "target": "oYemKnlIrO",
      "similarity": 0.8369
    },
    {
      "source": "Furthermore",
      "target": "To this end",
      "similarity": 0.8365
    },
    {
      "source": "To demonstrate the effectiveness of our framework",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8699
    },
    {
      "source": "To demonstrate the effectiveness of our framework",
      "target": "xiQNfYl33p",
      "similarity": 0.8661
    },
    {
      "source": "To demonstrate the effectiveness of our framework",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8656
    },
    {
      "source": "To demonstrate the effectiveness of our framework",
      "target": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "similarity": 0.8651
    },
    {
      "source": "To demonstrate the effectiveness of our framework",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.8597
    },
    {
      "source": "Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation",
      "target": "Compared to Multi-head Latent Attention (MLA)",
      "similarity": 0.8288
    },
    {
      "source": "Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation",
      "target": "5RUM1aIdok",
      "similarity": 0.8198
    },
    {
      "source": "Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation",
      "target": "CLIP",
      "similarity": 0.8144
    },
    {
      "source": "Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation",
      "target": "gWgaypDBs8",
      "similarity": 0.8121
    },
    {
      "source": "Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.8113
    },
    {
      "source": "t6QHYUOQL7",
      "target": "eiqrnVaeIw",
      "similarity": 0.8697
    },
    {
      "source": "t6QHYUOQL7",
      "target": "In this work",
      "similarity": 0.8571
    },
    {
      "source": "t6QHYUOQL7",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8559
    },
    {
      "source": "t6QHYUOQL7",
      "target": "IuU0wcO0mo",
      "similarity": 0.8538
    },
    {
      "source": "t6QHYUOQL7",
      "target": "no such limitation. To understand the difference in performance",
      "similarity": 0.8534
    },
    {
      "source": "Previous methods of *self-reflection* have been proven limited due to the models\u2019 inherent fixed thinking patterns.",
      "target": "To tackle this challenge",
      "similarity": 0.821
    },
    {
      "source": "Previous methods of *self-reflection* have been proven limited due to the models\u2019 inherent fixed thinking patterns.",
      "target": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "similarity": 0.8183
    },
    {
      "source": "Previous methods of *self-reflection* have been proven limited due to the models\u2019 inherent fixed thinking patterns.",
      "target": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "similarity": 0.818
    },
    {
      "source": "Previous methods of *self-reflection* have been proven limited due to the models\u2019 inherent fixed thinking patterns.",
      "target": "Moreover",
      "similarity": 0.8152
    },
    {
      "source": "Previous methods of *self-reflection* have been proven limited due to the models\u2019 inherent fixed thinking patterns.",
      "target": "edge insertion graph stream",
      "similarity": 0.8148
    },
    {
      "source": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "target": "For example",
      "similarity": 0.8598
    },
    {
      "source": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "target": "Es4RPNDtmq",
      "similarity": 0.8571
    },
    {
      "source": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "target": "J9FgrqOOni",
      "similarity": 0.8561
    },
    {
      "source": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "target": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "similarity": 0.8529
    },
    {
      "source": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "target": "Refresh (HRRR) data",
      "similarity": 0.8529
    },
    {
      "source": "In this paper",
      "target": "kNHVViEPWK",
      "similarity": 0.7821
    },
    {
      "source": "In this paper",
      "target": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "similarity": 0.7776
    },
    {
      "source": "In this paper",
      "target": "KSLkFYHlYg",
      "similarity": 0.77
    },
    {
      "source": "In this paper",
      "target": "VELhv9BBfn",
      "similarity": 0.7686
    },
    {
      "source": "In this paper",
      "target": "NtwFghsJne",
      "similarity": 0.7676
    },
    {
      "source": "fMTPkDEhLQ",
      "target": "7VkHffT5X2",
      "similarity": 0.8585
    },
    {
      "source": "fMTPkDEhLQ",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8531
    },
    {
      "source": "fMTPkDEhLQ",
      "target": "of extreme weather events",
      "similarity": 0.8324
    },
    {
      "source": "fMTPkDEhLQ",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8217
    },
    {
      "source": "fMTPkDEhLQ",
      "target": "CvGqMD5OtX",
      "similarity": 0.8207
    },
    {
      "source": "OFukl9Qg8P",
      "target": "Building on these insights",
      "similarity": 0.8414
    },
    {
      "source": "OFukl9Qg8P",
      "target": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "similarity": 0.8258
    },
    {
      "source": "OFukl9Qg8P",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8242
    },
    {
      "source": "OFukl9Qg8P",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8237
    },
    {
      "source": "OFukl9Qg8P",
      "target": "zXCnIyX9MG",
      "similarity": 0.8209
    },
    {
      "source": "G4wARwjF8M",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8422
    },
    {
      "source": "G4wARwjF8M",
      "target": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "similarity": 0.8418
    },
    {
      "source": "G4wARwjF8M",
      "target": "xiQNfYl33p",
      "similarity": 0.8413
    },
    {
      "source": "G4wARwjF8M",
      "target": "rdAbEn5DZt",
      "similarity": 0.8374
    },
    {
      "source": "G4wARwjF8M",
      "target": "zGzs5SIwT8",
      "similarity": 0.8321
    },
    {
      "source": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "target": "F57HPKZ6KD",
      "similarity": 0.897
    },
    {
      "source": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8969
    },
    {
      "source": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8849
    },
    {
      "source": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "target": "VQwI055flA",
      "similarity": 0.8769
    },
    {
      "source": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "target": "Here",
      "similarity": 0.8723
    },
    {
      "source": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8456
    },
    {
      "source": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "target": "IUmj2dw5se",
      "similarity": 0.8387
    },
    {
      "source": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8358
    },
    {
      "source": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "target": "kxnoqaisCT",
      "similarity": 0.8346
    },
    {
      "source": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8337
    },
    {
      "source": "Motivated by this insight",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8277
    },
    {
      "source": "Motivated by this insight",
      "target": "RWJX5F5I9g",
      "similarity": 0.8188
    },
    {
      "source": "Motivated by this insight",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8174
    },
    {
      "source": "Motivated by this insight",
      "target": "uqWM9hBDAE",
      "similarity": 0.8172
    },
    {
      "source": "Motivated by this insight",
      "target": "il5yUQsrjC",
      "similarity": 0.8087
    },
    {
      "source": "CkKEuLmRnr",
      "target": "F57HPKZ6KD",
      "similarity": 0.8795
    },
    {
      "source": "CkKEuLmRnr",
      "target": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "similarity": 0.8749
    },
    {
      "source": "CkKEuLmRnr",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8744
    },
    {
      "source": "CkKEuLmRnr",
      "target": "4ktJJBvvUd",
      "similarity": 0.8628
    },
    {
      "source": "CkKEuLmRnr",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8594
    },
    {
      "source": "potential algorithms to solve one task",
      "target": "For production-level generation",
      "similarity": 0.8726
    },
    {
      "source": "potential algorithms to solve one task",
      "target": "other baselines across all metrics",
      "similarity": 0.8661
    },
    {
      "source": "potential algorithms to solve one task",
      "target": "KD5nJUgeW4",
      "similarity": 0.8656
    },
    {
      "source": "potential algorithms to solve one task",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8647
    },
    {
      "source": "potential algorithms to solve one task",
      "target": "However",
      "similarity": 0.8641
    },
    {
      "source": "KSLkFYHlYg",
      "target": "AnL6BuWzxa",
      "similarity": 0.8804
    },
    {
      "source": "KSLkFYHlYg",
      "target": "of natural language. However",
      "similarity": 0.8757
    },
    {
      "source": "KSLkFYHlYg",
      "target": "HSi4VetQLj",
      "similarity": 0.8614
    },
    {
      "source": "KSLkFYHlYg",
      "target": "To address these limitations",
      "similarity": 0.8497
    },
    {
      "source": "KSLkFYHlYg",
      "target": "pB1XSj2y4X",
      "similarity": 0.8372
    },
    {
      "source": "IUmj2dw5se",
      "target": "xI71dsS3o4",
      "similarity": 0.8436
    },
    {
      "source": "IUmj2dw5se",
      "target": "fMNRYBvcQN",
      "similarity": 0.8407
    },
    {
      "source": "IUmj2dw5se",
      "target": "PY56Wur7S0",
      "similarity": 0.8402
    },
    {
      "source": "IUmj2dw5se",
      "target": "agHddsQhsL",
      "similarity": 0.8275
    },
    {
      "source": "IUmj2dw5se",
      "target": "UN6Ik6OCx8",
      "similarity": 0.8269
    },
    {
      "source": "71pur4y8gs",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8354
    },
    {
      "source": "71pur4y8gs",
      "target": "TvGPP8i18S",
      "similarity": 0.8329
    },
    {
      "source": "71pur4y8gs",
      "target": "k2uUeLCrQq",
      "similarity": 0.8323
    },
    {
      "source": "71pur4y8gs",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8321
    },
    {
      "source": "71pur4y8gs",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.8307
    },
    {
      "source": "GFgn2LprFR",
      "target": "sound",
      "similarity": 0.8325
    },
    {
      "source": "GFgn2LprFR",
      "target": "kNHVViEPWK",
      "similarity": 0.8285
    },
    {
      "source": "GFgn2LprFR",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8279
    },
    {
      "source": "GFgn2LprFR",
      "target": "8rbkePAapb",
      "similarity": 0.8252
    },
    {
      "source": "GFgn2LprFR",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8198
    },
    {
      "source": "https://sites.google.com/view/rnd-dagger\"",
      "target": "Pj4Aid3XqL",
      "similarity": 0.856
    },
    {
      "source": "https://sites.google.com/view/rnd-dagger\"",
      "target": "P9VdRQOyqu",
      "similarity": 0.8332
    },
    {
      "source": "https://sites.google.com/view/rnd-dagger\"",
      "target": "Following these principles",
      "similarity": 0.8215
    },
    {
      "source": "https://sites.google.com/view/rnd-dagger\"",
      "target": "tpYeermigp",
      "similarity": 0.8182
    },
    {
      "source": "https://sites.google.com/view/rnd-dagger\"",
      "target": "Moreover",
      "similarity": 0.8156
    },
    {
      "source": "txD9llAYn9",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8765
    },
    {
      "source": "txD9llAYn9",
      "target": "Furthermore",
      "similarity": 0.8722
    },
    {
      "source": "txD9llAYn9",
      "target": "VQwI055flA",
      "similarity": 0.8718
    },
    {
      "source": "txD9llAYn9",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.867
    },
    {
      "source": "txD9llAYn9",
      "target": "WCRQFlji2q",
      "similarity": 0.8666
    },
    {
      "source": "4sDicVEy6M",
      "target": "Third",
      "similarity": 0.8441
    },
    {
      "source": "4sDicVEy6M",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.842
    },
    {
      "source": "4sDicVEy6M",
      "target": "KlN00vQEY2",
      "similarity": 0.8399
    },
    {
      "source": "4sDicVEy6M",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8349
    },
    {
      "source": "4sDicVEy6M",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8329
    },
    {
      "source": "9RCT0ngvZP",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8222
    },
    {
      "source": "9RCT0ngvZP",
      "target": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "similarity": 0.8156
    },
    {
      "source": "9RCT0ngvZP",
      "target": "8TBGdH3t6a",
      "similarity": 0.8059
    },
    {
      "source": "9RCT0ngvZP",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8011
    },
    {
      "source": "9RCT0ngvZP",
      "target": "d23EVDRJ6g",
      "similarity": 0.7993
    },
    {
      "source": "5i6ZZUjCA9",
      "target": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "similarity": 0.8594
    },
    {
      "source": "5i6ZZUjCA9",
      "target": "To address this",
      "similarity": 0.8208
    },
    {
      "source": "5i6ZZUjCA9",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8192
    },
    {
      "source": "5i6ZZUjCA9",
      "target": "yFGR36PLDJ",
      "similarity": 0.8177
    },
    {
      "source": "5i6ZZUjCA9",
      "target": "However",
      "similarity": 0.8146
    },
    {
      "source": "In this paper",
      "target": "Based on this",
      "similarity": 0.8033
    },
    {
      "source": "In this paper",
      "target": "tQyh0gnfqW",
      "similarity": 0.7938
    },
    {
      "source": "In this paper",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.7875
    },
    {
      "source": "In this paper",
      "target": "Second",
      "similarity": 0.7866
    },
    {
      "source": "In this paper",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.7858
    },
    {
      "source": "The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8107
    },
    {
      "source": "The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations",
      "target": "cmfyMV45XO",
      "similarity": 0.8074
    },
    {
      "source": "The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations",
      "target": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "similarity": 0.8059
    },
    {
      "source": "The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8057
    },
    {
      "source": "The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations",
      "target": "r5IXBlTCGc",
      "similarity": 0.8045
    },
    {
      "source": "To integrate it with canonicalization",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8299
    },
    {
      "source": "To integrate it with canonicalization",
      "target": "CtM5xjRSfm",
      "similarity": 0.7997
    },
    {
      "source": "To integrate it with canonicalization",
      "target": "1yJP5TVWih",
      "similarity": 0.7988
    },
    {
      "source": "To integrate it with canonicalization",
      "target": "aN57tSd5Us",
      "similarity": 0.7981
    },
    {
      "source": "To integrate it with canonicalization",
      "target": "Our experiments show that a LLaMA3-8B model",
      "similarity": 0.7973
    },
    {
      "source": "We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.846
    },
    {
      "source": "We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function",
      "target": "In this work",
      "similarity": 0.8384
    },
    {
      "source": "We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function",
      "target": "fWRBheSJth",
      "similarity": 0.8346
    },
    {
      "source": "We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function",
      "target": "90DC0IvlSs",
      "similarity": 0.8318
    },
    {
      "source": "We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8243
    },
    {
      "source": "2U8owdruSQ",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8593
    },
    {
      "source": "2U8owdruSQ",
      "target": "However",
      "similarity": 0.8589
    },
    {
      "source": "2U8owdruSQ",
      "target": "In preregistered experiments",
      "similarity": 0.8444
    },
    {
      "source": "2U8owdruSQ",
      "target": "QowsEic1sc",
      "similarity": 0.8355
    },
    {
      "source": "2U8owdruSQ",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8355
    },
    {
      "source": "Mjn53GtMxi",
      "target": "Plugging in the offline algorithm that returns the exact optimal solution",
      "similarity": 0.9078
    },
    {
      "source": "Mjn53GtMxi",
      "target": "AcVpLS86RT",
      "similarity": 0.8913
    },
    {
      "source": "Mjn53GtMxi",
      "target": "To this end",
      "similarity": 0.8776
    },
    {
      "source": "Mjn53GtMxi",
      "target": "G5DziesYxL",
      "similarity": 0.8768
    },
    {
      "source": "Mjn53GtMxi",
      "target": "YFxfcQMLWX",
      "similarity": 0.8735
    },
    {
      "source": "TuOTSAiHDn",
      "target": "E1m5yGMOiV",
      "similarity": 0.8426
    },
    {
      "source": "TuOTSAiHDn",
      "target": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "similarity": 0.8119
    },
    {
      "source": "TuOTSAiHDn",
      "target": "qykpnEWf2J",
      "similarity": 0.7991
    },
    {
      "source": "TuOTSAiHDn",
      "target": "f3QR9TEERH",
      "similarity": 0.7772
    },
    {
      "source": "TuOTSAiHDn",
      "target": "CIs9x2ZRgh",
      "similarity": 0.7765
    },
    {
      "source": "purpose reasoning tasks (GENERAL REASONING: +2.51%).\"",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.7722
    },
    {
      "source": "purpose reasoning tasks (GENERAL REASONING: +2.51%).\"",
      "target": "zigzag spaghetti (ZS)",
      "similarity": 0.7615
    },
    {
      "source": "purpose reasoning tasks (GENERAL REASONING: +2.51%).\"",
      "target": "Interestingly",
      "similarity": 0.7614
    },
    {
      "source": "purpose reasoning tasks (GENERAL REASONING: +2.51%).\"",
      "target": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "similarity": 0.7579
    },
    {
      "source": "purpose reasoning tasks (GENERAL REASONING: +2.51%).\"",
      "target": "In this paper",
      "similarity": 0.7561
    },
    {
      "source": "GbgCRJedQ7",
      "target": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "similarity": 0.8839
    },
    {
      "source": "GbgCRJedQ7",
      "target": "Reweighting (GSR)",
      "similarity": 0.8428
    },
    {
      "source": "GbgCRJedQ7",
      "target": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "similarity": 0.8343
    },
    {
      "source": "GbgCRJedQ7",
      "target": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "similarity": 0.8338
    },
    {
      "source": "GbgCRJedQ7",
      "target": "PDnEDS244P",
      "similarity": 0.825
    },
    {
      "source": "baselines (e.g.",
      "target": "Extensive evaluations using MNIST",
      "similarity": 0.8696
    },
    {
      "source": "baselines (e.g.",
      "target": "Building on these insights",
      "similarity": 0.8279
    },
    {
      "source": "baselines (e.g.",
      "target": "ZadnlOHsHv",
      "similarity": 0.8229
    },
    {
      "source": "baselines (e.g.",
      "target": "To develop SoundCTM",
      "similarity": 0.8167
    },
    {
      "source": "baselines (e.g.",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8164
    },
    {
      "source": "tnB94WQGrn",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8519
    },
    {
      "source": "tnB94WQGrn",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8314
    },
    {
      "source": "tnB94WQGrn",
      "target": "component of real-world software development.\"",
      "similarity": 0.8251
    },
    {
      "source": "tnB94WQGrn",
      "target": "KeRwLLwZaw",
      "similarity": 0.8233
    },
    {
      "source": "tnB94WQGrn",
      "target": "In this paper",
      "similarity": 0.8214
    },
    {
      "source": "MeGDmZjUXy",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8245
    },
    {
      "source": "MeGDmZjUXy",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8234
    },
    {
      "source": "MeGDmZjUXy",
      "target": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "similarity": 0.8143
    },
    {
      "source": "MeGDmZjUXy",
      "target": "In experimental validation across a variety of active learning tasks",
      "similarity": 0.8123
    },
    {
      "source": "MeGDmZjUXy",
      "target": "FFE.\"",
      "similarity": 0.8121
    },
    {
      "source": "The prevailing practice in alignment often relies on human preference data (e.g.",
      "target": "{Subsequently}",
      "similarity": 0.8309
    },
    {
      "source": "The prevailing practice in alignment often relies on human preference data (e.g.",
      "target": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "similarity": 0.828
    },
    {
      "source": "The prevailing practice in alignment often relies on human preference data (e.g.",
      "target": "c61unr33XA",
      "similarity": 0.8275
    },
    {
      "source": "The prevailing practice in alignment often relies on human preference data (e.g.",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.8217
    },
    {
      "source": "The prevailing practice in alignment often relies on human preference data (e.g.",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8198
    },
    {
      "source": "We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism",
      "target": "Besides",
      "similarity": 0.8471
    },
    {
      "source": "We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism",
      "target": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "similarity": 0.8464
    },
    {
      "source": "We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism",
      "target": "of top-k chunks",
      "similarity": 0.8181
    },
    {
      "source": "We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism",
      "target": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "similarity": 0.8062
    },
    {
      "source": "We evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism",
      "target": "mnna9LUg7P",
      "similarity": 0.8048
    },
    {
      "source": "ogjBpZ8uSi",
      "target": "UVnD9Ze6mF",
      "similarity": 0.9227
    },
    {
      "source": "ogjBpZ8uSi",
      "target": "gY08Ou8EL7",
      "similarity": 0.8838
    },
    {
      "source": "ogjBpZ8uSi",
      "target": "fmJUYgmMbL",
      "similarity": 0.8716
    },
    {
      "source": "ogjBpZ8uSi",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8444
    },
    {
      "source": "ogjBpZ8uSi",
      "target": "JvkuZZ04O7",
      "similarity": 0.8397
    },
    {
      "source": "To benchmark current systems on visually rich document retrieval",
      "target": "However",
      "similarity": 0.8343
    },
    {
      "source": "To benchmark current systems on visually rich document retrieval",
      "target": "On the other hand",
      "similarity": 0.8328
    },
    {
      "source": "To benchmark current systems on visually rich document retrieval",
      "target": "WNvvwK0tut",
      "similarity": 0.8253
    },
    {
      "source": "To benchmark current systems on visually rich document retrieval",
      "target": "CtM5xjRSfm",
      "similarity": 0.8181
    },
    {
      "source": "To benchmark current systems on visually rich document retrieval",
      "target": "ZNnmcddaB3",
      "similarity": 0.8166
    },
    {
      "source": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "target": "lOi6FtIwR8",
      "similarity": 0.8435
    },
    {
      "source": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8162
    },
    {
      "source": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8137
    },
    {
      "source": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "target": "7liN6uHAQZ",
      "similarity": 0.8131
    },
    {
      "source": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "target": "6ouZaBzeNO",
      "similarity": 0.8114
    },
    {
      "source": "We release models",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8932
    },
    {
      "source": "We release models",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8888
    },
    {
      "source": "We release models",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.878
    },
    {
      "source": "We release models",
      "target": "FrFQpAgnGE",
      "similarity": 0.8755
    },
    {
      "source": "We release models",
      "target": "To this end",
      "similarity": 0.874
    },
    {
      "source": "p60Y6o85Cj",
      "target": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "similarity": 0.8572
    },
    {
      "source": "p60Y6o85Cj",
      "target": "In this paper",
      "similarity": 0.8512
    },
    {
      "source": "p60Y6o85Cj",
      "target": "OQqNieeivq",
      "similarity": 0.8485
    },
    {
      "source": "p60Y6o85Cj",
      "target": "owP2mymrTD",
      "similarity": 0.8405
    },
    {
      "source": "p60Y6o85Cj",
      "target": "7bAjVh3CG3",
      "similarity": 0.8228
    },
    {
      "source": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "target": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "similarity": 0.8596
    },
    {
      "source": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "target": "vRvVVb0NAz",
      "similarity": 0.8513
    },
    {
      "source": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8279
    },
    {
      "source": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "target": "q3EbOXb4y1",
      "similarity": 0.8234
    },
    {
      "source": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.816
    },
    {
      "source": "QAAsnSRwgu",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8159
    },
    {
      "source": "QAAsnSRwgu",
      "target": "However",
      "similarity": 0.8067
    },
    {
      "source": "QAAsnSRwgu",
      "target": "KxQRHOre9D",
      "similarity": 0.8054
    },
    {
      "source": "QAAsnSRwgu",
      "target": "In this work",
      "similarity": 0.8007
    },
    {
      "source": "QAAsnSRwgu",
      "target": "connection component",
      "similarity": 0.8005
    },
    {
      "source": "Our system",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8528
    },
    {
      "source": "Our system",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.852
    },
    {
      "source": "Our system",
      "target": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "similarity": 0.8495
    },
    {
      "source": "Our system",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8448
    },
    {
      "source": "Our system",
      "target": "JytL2MrlLT",
      "similarity": 0.8428
    },
    {
      "source": "T4LtGj7us1",
      "target": "2pNLknCTvG",
      "similarity": 0.8542
    },
    {
      "source": "T4LtGj7us1",
      "target": "E48QvQppIN",
      "similarity": 0.8469
    },
    {
      "source": "T4LtGj7us1",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8367
    },
    {
      "source": "T4LtGj7us1",
      "target": "5o9JJJPPm6",
      "similarity": 0.8267
    },
    {
      "source": "T4LtGj7us1",
      "target": "WfxPVtYRlL",
      "similarity": 0.8241
    },
    {
      "source": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "target": "L5godAOC2z",
      "similarity": 0.8147
    },
    {
      "source": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "target": "gWgaypDBs8",
      "similarity": 0.812
    },
    {
      "source": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.812
    },
    {
      "source": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "target": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "similarity": 0.8063
    },
    {
      "source": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "target": "5RUM1aIdok",
      "similarity": 0.7982
    },
    {
      "source": "1Z3C49JQVf",
      "target": "3bcN6xlO6f",
      "similarity": 0.8753
    },
    {
      "source": "1Z3C49JQVf",
      "target": "We found that long distance referrals",
      "similarity": 0.8721
    },
    {
      "source": "1Z3C49JQVf",
      "target": "8EfxjTCg2k",
      "similarity": 0.8712
    },
    {
      "source": "1Z3C49JQVf",
      "target": "wHebuIb6IH",
      "similarity": 0.8705
    },
    {
      "source": "1Z3C49JQVf",
      "target": "je3GZissZc",
      "similarity": 0.868
    },
    {
      "source": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "target": "gsShHPxkUW",
      "similarity": 0.9085
    },
    {
      "source": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8747
    },
    {
      "source": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.865
    },
    {
      "source": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "target": "ogXkmugNZw",
      "similarity": 0.8625
    },
    {
      "source": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.8612
    },
    {
      "source": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8221
    },
    {
      "source": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "target": "a dependency parser",
      "similarity": 0.8213
    },
    {
      "source": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "target": "lfPkGWXLLf",
      "similarity": 0.8209
    },
    {
      "source": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "target": "7bAjVh3CG3",
      "similarity": 0.8207
    },
    {
      "source": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "target": "kxnoqaisCT",
      "similarity": 0.8191
    },
    {
      "source": "To alleviate the problem",
      "target": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "similarity": 0.8442
    },
    {
      "source": "To alleviate the problem",
      "target": "ispjankYab",
      "similarity": 0.8044
    },
    {
      "source": "To alleviate the problem",
      "target": "YUYJsHOf3c",
      "similarity": 0.7996
    },
    {
      "source": "To alleviate the problem",
      "target": "EMMnAd3apQ",
      "similarity": 0.7986
    },
    {
      "source": "To alleviate the problem",
      "target": "iDcWYtYUwX",
      "similarity": 0.7979
    },
    {
      "source": "However",
      "target": "Ahlrf2HGJR",
      "similarity": 0.861
    },
    {
      "source": "However",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8487
    },
    {
      "source": "However",
      "target": "TWnUgSAWNw",
      "similarity": 0.8463
    },
    {
      "source": "However",
      "target": "To this end",
      "similarity": 0.8428
    },
    {
      "source": "However",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8382
    },
    {
      "source": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "target": "KAIqwkB3dT",
      "similarity": 0.8686
    },
    {
      "source": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.863
    },
    {
      "source": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "target": "5xSRg3eYZz",
      "similarity": 0.8591
    },
    {
      "source": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "target": "HqjRlT65WX",
      "similarity": 0.8537
    },
    {
      "source": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "target": "However",
      "similarity": 0.8523
    },
    {
      "source": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "target": "P6IVIoGRRg",
      "similarity": 0.885
    },
    {
      "source": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "target": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "similarity": 0.8781
    },
    {
      "source": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "target": "We conducted a comprehensive regret analysis of our proposed framework",
      "similarity": 0.865
    },
    {
      "source": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "target": "WKW5TG8ItY",
      "similarity": 0.8564
    },
    {
      "source": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "target": "1F8xTfv6ah",
      "similarity": 0.8417
    },
    {
      "source": "Our threat model poses a serious threat in training machine learning models with third-party datasets",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.8599
    },
    {
      "source": "Our threat model poses a serious threat in training machine learning models with third-party datasets",
      "target": "As the size of the model and data grows",
      "similarity": 0.8529
    },
    {
      "source": "Our threat model poses a serious threat in training machine learning models with third-party datasets",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8246
    },
    {
      "source": "Our threat model poses a serious threat in training machine learning models with third-party datasets",
      "target": "L5godAOC2z",
      "similarity": 0.8048
    },
    {
      "source": "Our threat model poses a serious threat in training machine learning models with third-party datasets",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.8038
    },
    {
      "source": "tDIL7UXmSS",
      "target": "To this end",
      "similarity": 0.8848
    },
    {
      "source": "tDIL7UXmSS",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.8828
    },
    {
      "source": "tDIL7UXmSS",
      "target": "For TP",
      "similarity": 0.8709
    },
    {
      "source": "tDIL7UXmSS",
      "target": "254NJe9JEw",
      "similarity": 0.8705
    },
    {
      "source": "tDIL7UXmSS",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8696
    },
    {
      "source": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "target": "0fJfVOSUra",
      "similarity": 0.8541
    },
    {
      "source": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "target": "First",
      "similarity": 0.8448
    },
    {
      "source": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "target": "1qGkuxI9UX",
      "similarity": 0.8442
    },
    {
      "source": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "target": "flows which includes transshipment ($p = 1$)",
      "similarity": 0.8395
    },
    {
      "source": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "target": "VoayJihXra",
      "similarity": 0.8386
    },
    {
      "source": "The popular $k$-means++ algorithm is simply a $k$-round $D^2$-sampling process",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8793
    },
    {
      "source": "The popular $k$-means++ algorithm is simply a $k$-round $D^2$-sampling process",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8414
    },
    {
      "source": "The popular $k$-means++ algorithm is simply a $k$-round $D^2$-sampling process",
      "target": "We have prepared an efficient implementation",
      "similarity": 0.8373
    },
    {
      "source": "The popular $k$-means++ algorithm is simply a $k$-round $D^2$-sampling process",
      "target": "factual retention QA pairs\u2014far below human success rates of 73.9% and 79.3%",
      "similarity": 0.8365
    },
    {
      "source": "The popular $k$-means++ algorithm is simply a $k$-round $D^2$-sampling process",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8363
    },
    {
      "source": "In this work",
      "target": "AcVpLS86RT",
      "similarity": 0.8791
    },
    {
      "source": "In this work",
      "target": "E4LAVLXAHW",
      "similarity": 0.8657
    },
    {
      "source": "In this work",
      "target": "In this task",
      "similarity": 0.8526
    },
    {
      "source": "In this work",
      "target": "Building on the SpiderBoost algorithm framework",
      "similarity": 0.8495
    },
    {
      "source": "In this work",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8492
    },
    {
      "source": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8432
    },
    {
      "source": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "target": "sgbI8Pxwie",
      "similarity": 0.8406
    },
    {
      "source": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "target": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "similarity": 0.8406
    },
    {
      "source": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "target": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "similarity": 0.8353
    },
    {
      "source": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "target": "Usklli4gMc",
      "similarity": 0.8341
    },
    {
      "source": "It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.",
      "target": "FrFQpAgnGE",
      "similarity": 0.8849
    },
    {
      "source": "It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.",
      "target": "nx9Z5Kva96",
      "similarity": 0.8589
    },
    {
      "source": "It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8553
    },
    {
      "source": "It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.",
      "target": "QC2qE1tcmd",
      "similarity": 0.8547
    },
    {
      "source": "It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.",
      "target": "yIlyHJdYV3",
      "similarity": 0.8525
    },
    {
      "source": "Further",
      "target": "a given query",
      "similarity": 0.8139
    },
    {
      "source": "Further",
      "target": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "similarity": 0.798
    },
    {
      "source": "Further",
      "target": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "similarity": 0.7965
    },
    {
      "source": "Further",
      "target": "compositional benchmarks",
      "similarity": 0.7922
    },
    {
      "source": "Further",
      "target": "We evaluated our method on **more than 160 scenes** from the Replica",
      "similarity": 0.7875
    },
    {
      "source": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "target": "iLUcsecZJp",
      "similarity": 0.8434
    },
    {
      "source": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "target": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "similarity": 0.8349
    },
    {
      "source": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "target": "effectiveness through experiments on various representative benchmarks. With an",
      "similarity": 0.8344
    },
    {
      "source": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "target": "Further",
      "similarity": 0.8341
    },
    {
      "source": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "target": "aVfDrl7xDV",
      "similarity": 0.8322
    },
    {
      "source": "Finally",
      "target": "show that the proposed strategy can enhance the performance of strong pruning",
      "similarity": 0.8383
    },
    {
      "source": "Finally",
      "target": "Moreover",
      "similarity": 0.793
    },
    {
      "source": "Finally",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.7925
    },
    {
      "source": "Finally",
      "target": "WwwJfkGq0G",
      "similarity": 0.7885
    },
    {
      "source": "Finally",
      "target": "yaQbTAD2JJ",
      "similarity": 0.7884
    },
    {
      "source": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.87
    },
    {
      "source": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "target": "The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs.",
      "similarity": 0.8372
    },
    {
      "source": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8292
    },
    {
      "source": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "target": "FSjIrOm1vz",
      "similarity": 0.8249
    },
    {
      "source": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.8233
    },
    {
      "source": "LvRQgsvd5V",
      "target": "Prediction (NWP) systems on HR-Extreme",
      "similarity": 0.7939
    },
    {
      "source": "LvRQgsvd5V",
      "target": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "similarity": 0.7888
    },
    {
      "source": "LvRQgsvd5V",
      "target": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "similarity": 0.7885
    },
    {
      "source": "LvRQgsvd5V",
      "target": "existing agent benchmarks neglect long-context video understanding",
      "similarity": 0.7846
    },
    {
      "source": "LvRQgsvd5V",
      "target": "ZadnlOHsHv",
      "similarity": 0.7831
    },
    {
      "source": "Traditionally",
      "target": "je3GZissZc",
      "similarity": 0.8634
    },
    {
      "source": "Traditionally",
      "target": "riieAeQBJm",
      "similarity": 0.8622
    },
    {
      "source": "Traditionally",
      "target": "hwSmPOAmhk",
      "similarity": 0.8599
    },
    {
      "source": "Traditionally",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8593
    },
    {
      "source": "Traditionally",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.857
    },
    {
      "source": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "target": "To address this challenge",
      "similarity": 0.8285
    },
    {
      "source": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8247
    },
    {
      "source": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "target": "MxbEiFRf39",
      "similarity": 0.8243
    },
    {
      "source": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "target": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "similarity": 0.8215
    },
    {
      "source": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "target": "For the diversity",
      "similarity": 0.8211
    },
    {
      "source": "In this work",
      "target": "eiqrnVaeIw",
      "similarity": 0.8722
    },
    {
      "source": "In this work",
      "target": "je3GZissZc",
      "similarity": 0.8609
    },
    {
      "source": "In this work",
      "target": "VpWki1v2P8",
      "similarity": 0.8547
    },
    {
      "source": "In this work",
      "target": "Reweighting (GSR)",
      "similarity": 0.8537
    },
    {
      "source": "In this work",
      "target": "However",
      "similarity": 0.8486
    },
    {
      "source": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "target": "VQwI055flA",
      "similarity": 0.8944
    },
    {
      "source": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8831
    },
    {
      "source": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "target": "bMC1t7eLRc",
      "similarity": 0.877
    },
    {
      "source": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "target": "Furthermore",
      "similarity": 0.8755
    },
    {
      "source": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "target": "FrFQpAgnGE",
      "similarity": 0.875
    },
    {
      "source": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "target": "L5godAOC2z",
      "similarity": 0.8679
    },
    {
      "source": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.8447
    },
    {
      "source": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "target": "SMK0f8JoKF",
      "similarity": 0.8325
    },
    {
      "source": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "target": "CLIP",
      "similarity": 0.831
    },
    {
      "source": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.8308
    },
    {
      "source": "Remarkably",
      "target": "a single GPU in a few hours",
      "similarity": 0.8416
    },
    {
      "source": "Remarkably",
      "target": "7bAjVh3CG3",
      "similarity": 0.8411
    },
    {
      "source": "Remarkably",
      "target": "QowsEic1sc",
      "similarity": 0.8386
    },
    {
      "source": "Remarkably",
      "target": "a dependency parser",
      "similarity": 0.8377
    },
    {
      "source": "Remarkably",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8324
    },
    {
      "source": "Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.\"",
      "target": "8pusxkLEQO",
      "similarity": 0.8247
    },
    {
      "source": "Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.\"",
      "target": "In experiments with GPT-4",
      "similarity": 0.8221
    },
    {
      "source": "Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.\"",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8205
    },
    {
      "source": "Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.\"",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8189
    },
    {
      "source": "Empirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks.\"",
      "target": "WttfQGwpES",
      "similarity": 0.815
    },
    {
      "source": "AUBvo4sxVL",
      "target": "frsg32u0rO",
      "similarity": 0.8483
    },
    {
      "source": "AUBvo4sxVL",
      "target": "This paper proposes",
      "similarity": 0.8417
    },
    {
      "source": "AUBvo4sxVL",
      "target": "Q150eWkQ4I",
      "similarity": 0.8219
    },
    {
      "source": "AUBvo4sxVL",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8213
    },
    {
      "source": "AUBvo4sxVL",
      "target": "function predictors on 3D scenes from the iGibson building dataset and showcase optimal planning with 4-joint robotic manipulators. Lastly",
      "similarity": 0.8192
    },
    {
      "source": "IDxZhXrpNf",
      "target": "non-private ANN algorithm.",
      "similarity": 0.8347
    },
    {
      "source": "IDxZhXrpNf",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8284
    },
    {
      "source": "IDxZhXrpNf",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.828
    },
    {
      "source": "IDxZhXrpNf",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8222
    },
    {
      "source": "IDxZhXrpNf",
      "target": "TvGPP8i18S",
      "similarity": 0.8205
    },
    {
      "source": "With regards to improving Shampoo's computational efficiency",
      "target": "a challenge",
      "similarity": 0.8931
    },
    {
      "source": "With regards to improving Shampoo's computational efficiency",
      "target": "Furthermore",
      "similarity": 0.8888
    },
    {
      "source": "With regards to improving Shampoo's computational efficiency",
      "target": "wHebuIb6IH",
      "similarity": 0.8878
    },
    {
      "source": "With regards to improving Shampoo's computational efficiency",
      "target": "3bcN6xlO6f",
      "similarity": 0.8868
    },
    {
      "source": "With regards to improving Shampoo's computational efficiency",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8793
    },
    {
      "source": "JAMxRSXLFz",
      "target": "254NJe9JEw",
      "similarity": 0.8895
    },
    {
      "source": "JAMxRSXLFz",
      "target": "Jszf4et48m",
      "similarity": 0.8721
    },
    {
      "source": "JAMxRSXLFz",
      "target": "To this end",
      "similarity": 0.8694
    },
    {
      "source": "JAMxRSXLFz",
      "target": "BlSIKSPhfz",
      "similarity": 0.8683
    },
    {
      "source": "JAMxRSXLFz",
      "target": "To this end",
      "similarity": 0.8664
    },
    {
      "source": "haJHr4UsQX",
      "target": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "similarity": 0.8359
    },
    {
      "source": "haJHr4UsQX",
      "target": "ed7zI29lRF",
      "similarity": 0.8281
    },
    {
      "source": "haJHr4UsQX",
      "target": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "similarity": 0.8179
    },
    {
      "source": "haJHr4UsQX",
      "target": "exhibit a randomly chosen pair of these skills. Here",
      "similarity": 0.814
    },
    {
      "source": "haJHr4UsQX",
      "target": "xiQNfYl33p",
      "similarity": 0.8105
    },
    {
      "source": "to fully understand the compositional properties of the human language",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8556
    },
    {
      "source": "to fully understand the compositional properties of the human language",
      "target": "OhauMUNW8T",
      "similarity": 0.8495
    },
    {
      "source": "to fully understand the compositional properties of the human language",
      "target": "Building on these insights",
      "similarity": 0.8464
    },
    {
      "source": "to fully understand the compositional properties of the human language",
      "target": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "similarity": 0.8419
    },
    {
      "source": "to fully understand the compositional properties of the human language",
      "target": "pDDODPtpx9",
      "similarity": 0.8389
    },
    {
      "source": "modeling an image caption as a \u201cbag of words\u201d. As a result",
      "target": "bwOndfohRK",
      "similarity": 0.8125
    },
    {
      "source": "modeling an image caption as a \u201cbag of words\u201d. As a result",
      "target": "spDUv05cEq",
      "similarity": 0.7874
    },
    {
      "source": "modeling an image caption as a \u201cbag of words\u201d. As a result",
      "target": "tkiZQlL04w",
      "similarity": 0.7813
    },
    {
      "source": "modeling an image caption as a \u201cbag of words\u201d. As a result",
      "target": "EDoD3DgivF",
      "similarity": 0.7809
    },
    {
      "source": "modeling an image caption as a \u201cbag of words\u201d. As a result",
      "target": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "similarity": 0.7755
    },
    {
      "source": "poorly on compositional tasks",
      "target": "zXCnIyX9MG",
      "similarity": 0.8119
    },
    {
      "source": "poorly on compositional tasks",
      "target": "However",
      "similarity": 0.8103
    },
    {
      "source": "poorly on compositional tasks",
      "target": "OFukl9Qg8P",
      "similarity": 0.779
    },
    {
      "source": "poorly on compositional tasks",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.7772
    },
    {
      "source": "poorly on compositional tasks",
      "target": "1Z6PSw7OL8",
      "similarity": 0.7757
    },
    {
      "source": "entities of a sentence (subject",
      "target": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "similarity": 0.8452
    },
    {
      "source": "entities of a sentence (subject",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8432
    },
    {
      "source": "entities of a sentence (subject",
      "target": "yitH9xAHQs",
      "similarity": 0.839
    },
    {
      "source": "entities of a sentence (subject",
      "target": "At the inference stage",
      "similarity": 0.8381
    },
    {
      "source": "entities of a sentence (subject",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8354
    },
    {
      "source": "in order to be solved. In this paper",
      "target": "AP0ndQloqR",
      "similarity": 0.871
    },
    {
      "source": "in order to be solved. In this paper",
      "target": "JSB171dSUU",
      "similarity": 0.8597
    },
    {
      "source": "in order to be solved. In this paper",
      "target": "dTkqaCKLPp",
      "similarity": 0.8597
    },
    {
      "source": "in order to be solved. In this paper",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.8576
    },
    {
      "source": "in order to be solved. In this paper",
      "target": "NWb128pSCb",
      "similarity": 0.8552
    },
    {
      "source": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "target": "has difficulty in capturing the relationship and the similarity structure of a",
      "similarity": 0.8712
    },
    {
      "source": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "target": "Essg9kb4yx",
      "similarity": 0.8666
    },
    {
      "source": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "target": "We further show that the density of long-distance referrals",
      "similarity": 0.8653
    },
    {
      "source": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8414
    },
    {
      "source": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8277
    },
    {
      "source": "a dependency parser",
      "target": "7bAjVh3CG3",
      "similarity": 0.839
    },
    {
      "source": "a dependency parser",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8349
    },
    {
      "source": "a dependency parser",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8324
    },
    {
      "source": "a dependency parser",
      "target": "vue9P1Ypk6",
      "similarity": 0.8285
    },
    {
      "source": "a dependency parser",
      "target": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "similarity": 0.8233
    },
    {
      "source": "encoder. Differently from standard autoregressive or parallel predictions",
      "target": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "similarity": 0.85
    },
    {
      "source": "encoder. Differently from standard autoregressive or parallel predictions",
      "target": "Jszf4et48m",
      "similarity": 0.842
    },
    {
      "source": "encoder. Differently from standard autoregressive or parallel predictions",
      "target": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "similarity": 0.8415
    },
    {
      "source": "encoder. Differently from standard autoregressive or parallel predictions",
      "target": "sound",
      "similarity": 0.8414
    },
    {
      "source": "encoder. Differently from standard autoregressive or parallel predictions",
      "target": "In this paper",
      "similarity": 0.8385
    },
    {
      "source": "generative process is partially-ordered following the CGM structure. This",
      "target": "254NJe9JEw",
      "similarity": 0.8478
    },
    {
      "source": "generative process is partially-ordered following the CGM structure. This",
      "target": "Second",
      "similarity": 0.8461
    },
    {
      "source": "generative process is partially-ordered following the CGM structure. This",
      "target": "Second",
      "similarity": 0.8456
    },
    {
      "source": "generative process is partially-ordered following the CGM structure. This",
      "target": "In contrast",
      "similarity": 0.8428
    },
    {
      "source": "generative process is partially-ordered following the CGM structure. This",
      "target": "hjROBHstZ3",
      "similarity": 0.8414
    },
    {
      "source": "structure encourages the decoder to learn only the main causal dependencies in",
      "target": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "similarity": 0.9037
    },
    {
      "source": "structure encourages the decoder to learn only the main causal dependencies in",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8671
    },
    {
      "source": "structure encourages the decoder to learn only the main causal dependencies in",
      "target": "However",
      "similarity": 0.8543
    },
    {
      "source": "structure encourages the decoder to learn only the main causal dependencies in",
      "target": "B2Fqu7Y2cd",
      "similarity": 0.8533
    },
    {
      "source": "structure encourages the decoder to learn only the main causal dependencies in",
      "target": "KAIqwkB3dT",
      "similarity": 0.8472
    },
    {
      "source": "a sentence discarding spurious correlations. Using extensive experiments on five",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8494
    },
    {
      "source": "a sentence discarding spurious correlations. Using extensive experiments on five",
      "target": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "similarity": 0.8437
    },
    {
      "source": "a sentence discarding spurious correlations. Using extensive experiments on five",
      "target": "that",
      "similarity": 0.8433
    },
    {
      "source": "a sentence discarding spurious correlations. Using extensive experiments on five",
      "target": "of top-k chunks",
      "similarity": 0.8333
    },
    {
      "source": "a sentence discarding spurious correlations. Using extensive experiments on five",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8325
    },
    {
      "source": "compositional benchmarks",
      "target": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "similarity": 0.879
    },
    {
      "source": "compositional benchmarks",
      "target": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "similarity": 0.8335
    },
    {
      "source": "compositional benchmarks",
      "target": "We evaluated our method on **more than 160 scenes** from the Replica",
      "similarity": 0.7982
    },
    {
      "source": "compositional benchmarks",
      "target": "by focusing on efficiently solving the underlying optimization problem using a general",
      "similarity": 0.7863
    },
    {
      "source": "compositional benchmarks",
      "target": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "similarity": 0.7857
    },
    {
      "source": "all the state-of-the-art compositional approaches by a large margin",
      "target": "x1An5a3U9I",
      "similarity": 0.7761
    },
    {
      "source": "all the state-of-the-art compositional approaches by a large margin",
      "target": "direct long-context and RAG solutions using the same state-of-the-art long-context",
      "similarity": 0.7678
    },
    {
      "source": "all the state-of-the-art compositional approaches by a large margin",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.7646
    },
    {
      "source": "all the state-of-the-art compositional approaches by a large margin",
      "target": "WoPovNkM5h",
      "similarity": 0.7575
    },
    {
      "source": "all the state-of-the-art compositional approaches by a large margin",
      "target": "PY56Wur7S0",
      "similarity": 0.7559
    },
    {
      "source": "over methods trained using much larger datasets.",
      "target": "To remedy this problem",
      "similarity": 0.8476
    },
    {
      "source": "over methods trained using much larger datasets.",
      "target": "Second",
      "similarity": 0.847
    },
    {
      "source": "over methods trained using much larger datasets.",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8357
    },
    {
      "source": "over methods trained using much larger datasets.",
      "target": "OiQttMHwce",
      "similarity": 0.835
    },
    {
      "source": "over methods trained using much larger datasets.",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8306
    },
    {
      "source": "Our model weights and code are publicly available.\"",
      "target": "QowsEic1sc",
      "similarity": 0.8275
    },
    {
      "source": "Our model weights and code are publicly available.\"",
      "target": "uQnvYP7yX9",
      "similarity": 0.8252
    },
    {
      "source": "Our model weights and code are publicly available.\"",
      "target": "All experimental resources",
      "similarity": 0.8231
    },
    {
      "source": "Our model weights and code are publicly available.\"",
      "target": "HrdVqFSn1e",
      "similarity": 0.822
    },
    {
      "source": "Our model weights and code are publicly available.\"",
      "target": "8DBTq09LgN",
      "similarity": 0.8191
    },
    {
      "source": "Rz0kozh3LE",
      "target": "It was numerically observed that the linear interpolation",
      "similarity": 0.8827
    },
    {
      "source": "Rz0kozh3LE",
      "target": "To address this limitation",
      "similarity": 0.8728
    },
    {
      "source": "Rz0kozh3LE",
      "target": "f7KxfUrRSb",
      "similarity": 0.8565
    },
    {
      "source": "Rz0kozh3LE",
      "target": "PIpGN5Ko3v",
      "similarity": 0.8448
    },
    {
      "source": "Rz0kozh3LE",
      "target": "work that captures both architectures. We introduce a modification in the skip",
      "similarity": 0.8429
    },
    {
      "source": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "target": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "similarity": 0.8476
    },
    {
      "source": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "target": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "similarity": 0.842
    },
    {
      "source": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.8165
    },
    {
      "source": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "target": "OQqNieeivq",
      "similarity": 0.8114
    },
    {
      "source": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "target": "Building on these insights",
      "similarity": 0.8053
    },
    {
      "source": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "target": "4v4RcAODj9",
      "similarity": 0.8358
    },
    {
      "source": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "target": "Our framework",
      "similarity": 0.832
    },
    {
      "source": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "target": "wLnls9LS3x",
      "similarity": 0.8284
    },
    {
      "source": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8188
    },
    {
      "source": "Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.",
      "target": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "similarity": 0.816
    },
    {
      "source": "However",
      "target": "lS2SGfWizd",
      "similarity": 0.8486
    },
    {
      "source": "However",
      "target": "using only a 4K context window",
      "similarity": 0.8365
    },
    {
      "source": "However",
      "target": "Fk3eod9aaD",
      "similarity": 0.8337
    },
    {
      "source": "However",
      "target": "mXHTifc1Fn",
      "similarity": 0.83
    },
    {
      "source": "However",
      "target": "Besides this primary purpose",
      "similarity": 0.821
    },
    {
      "source": "To address these shortcomings",
      "target": "However",
      "similarity": 0.8293
    },
    {
      "source": "To address these shortcomings",
      "target": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "similarity": 0.824
    },
    {
      "source": "To address these shortcomings",
      "target": "prompts. As such",
      "similarity": 0.8237
    },
    {
      "source": "To address these shortcomings",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8213
    },
    {
      "source": "To address these shortcomings",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8207
    },
    {
      "source": "Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.",
      "target": "CNL-P introduces precise grammar structures and strict semantic norms",
      "similarity": 0.8449
    },
    {
      "source": "Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.",
      "target": "oVKEAFjEqv",
      "similarity": 0.8182
    },
    {
      "source": "Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.",
      "target": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "similarity": 0.8056
    },
    {
      "source": "Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.",
      "target": "FhTAG591Ve",
      "similarity": 0.8004
    },
    {
      "source": "Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.",
      "target": "5z9GjHgerY",
      "similarity": 0.7921
    },
    {
      "source": "In a single-device scenario",
      "target": "hwSmPOAmhk",
      "similarity": 0.8639
    },
    {
      "source": "In a single-device scenario",
      "target": "Second",
      "similarity": 0.858
    },
    {
      "source": "In a single-device scenario",
      "target": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "similarity": 0.8517
    },
    {
      "source": "In a single-device scenario",
      "target": "The effectiveness of MoE models depends primarily on their routing mechanisms",
      "similarity": 0.8499
    },
    {
      "source": "In a single-device scenario",
      "target": "YFxfcQMLWX",
      "similarity": 0.8463
    },
    {
      "source": "In a client-server setting",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8464
    },
    {
      "source": "In a client-server setting",
      "target": "nIEjY4a2Lf",
      "similarity": 0.8376
    },
    {
      "source": "In a client-server setting",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.8302
    },
    {
      "source": "In a client-server setting",
      "target": "X6y5CC44HM",
      "similarity": 0.8278
    },
    {
      "source": "In a client-server setting",
      "target": "8pusxkLEQO",
      "similarity": 0.8234
    },
    {
      "source": "HMrcv7Q4Ub",
      "target": "oZkqkkvdND",
      "similarity": 0.8136
    },
    {
      "source": "HMrcv7Q4Ub",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.8103
    },
    {
      "source": "HMrcv7Q4Ub",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.8093
    },
    {
      "source": "HMrcv7Q4Ub",
      "target": "irrtPRFksw",
      "similarity": 0.8079
    },
    {
      "source": "HMrcv7Q4Ub",
      "target": "To address this",
      "similarity": 0.8076
    },
    {
      "source": "GMwRl2e9Y1",
      "target": "IjbXZdugdj",
      "similarity": 0.8511
    },
    {
      "source": "GMwRl2e9Y1",
      "target": "Lastly",
      "similarity": 0.8435
    },
    {
      "source": "GMwRl2e9Y1",
      "target": "analysis)",
      "similarity": 0.8408
    },
    {
      "source": "GMwRl2e9Y1",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8295
    },
    {
      "source": "GMwRl2e9Y1",
      "target": "SOTA LLMs",
      "similarity": 0.8227
    },
    {
      "source": "They operate by maintaining a set of vectors---often referred to as the codebook---and quantizing each encoder output to the nearest vector in the codebook.",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8418
    },
    {
      "source": "They operate by maintaining a set of vectors---often referred to as the codebook---and quantizing each encoder output to the nearest vector in the codebook.",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8382
    },
    {
      "source": "They operate by maintaining a set of vectors---often referred to as the codebook---and quantizing each encoder output to the nearest vector in the codebook.",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8282
    },
    {
      "source": "They operate by maintaining a set of vectors---often referred to as the codebook---and quantizing each encoder output to the nearest vector in the codebook.",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8274
    },
    {
      "source": "They operate by maintaining a set of vectors---often referred to as the codebook---and quantizing each encoder output to the nearest vector in the codebook.",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8261
    },
    {
      "source": "However",
      "target": "In the images pruning benchmark",
      "similarity": 0.8566
    },
    {
      "source": "However",
      "target": "nzjSvVZBIp",
      "similarity": 0.8321
    },
    {
      "source": "However",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8313
    },
    {
      "source": "However",
      "target": "WttfQGwpES",
      "similarity": 0.8312
    },
    {
      "source": "However",
      "target": "X-Ray",
      "similarity": 0.827
    },
    {
      "source": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "target": "JSB171dSUU",
      "similarity": 0.8901
    },
    {
      "source": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8809
    },
    {
      "source": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "target": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "similarity": 0.8674
    },
    {
      "source": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8613
    },
    {
      "source": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "target": "pDDODPtpx9",
      "similarity": 0.8611
    },
    {
      "source": "In this work",
      "target": "DzGe40glxs",
      "similarity": 0.9142
    },
    {
      "source": "In this work",
      "target": "m5qpn0KTMZ",
      "similarity": 0.8963
    },
    {
      "source": "In this work",
      "target": "In this work",
      "similarity": 0.8156
    },
    {
      "source": "In this work",
      "target": "GtvuNrk58a",
      "similarity": 0.8148
    },
    {
      "source": "In this work",
      "target": "oYSsbY3G4o",
      "similarity": 0.8117
    },
    {
      "source": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.8518
    },
    {
      "source": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "target": "il5yUQsrjC",
      "similarity": 0.8514
    },
    {
      "source": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8475
    },
    {
      "source": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "target": "In particular",
      "similarity": 0.8463
    },
    {
      "source": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "target": "RWJX5F5I9g",
      "similarity": 0.8411
    },
    {
      "source": "As a result",
      "target": "training data. Equipped with these findings",
      "similarity": 0.856
    },
    {
      "source": "As a result",
      "target": "IDJUscOjM3",
      "similarity": 0.8525
    },
    {
      "source": "As a result",
      "target": "For TP",
      "similarity": 0.851
    },
    {
      "source": "As a result",
      "target": "TljGdvzFq2",
      "similarity": 0.8503
    },
    {
      "source": "As a result",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8497
    },
    {
      "source": "Across 11 different VQ-VAE training paradigms",
      "target": "Finally",
      "similarity": 0.8369
    },
    {
      "source": "Across 11 different VQ-VAE training paradigms",
      "target": "implementation",
      "similarity": 0.8231
    },
    {
      "source": "Across 11 different VQ-VAE training paradigms",
      "target": "20qZK2T7fa",
      "similarity": 0.8201
    },
    {
      "source": "Across 11 different VQ-VAE training paradigms",
      "target": "assessing and advancing topological methods",
      "similarity": 0.8176
    },
    {
      "source": "Across 11 different VQ-VAE training paradigms",
      "target": "m8yby1JfbU",
      "similarity": 0.8175
    },
    {
      "source": "PZYr22zFyE",
      "target": "To overcome such limitations",
      "similarity": 0.844
    },
    {
      "source": "PZYr22zFyE",
      "target": "L0evcuybH5",
      "similarity": 0.8345
    },
    {
      "source": "PZYr22zFyE",
      "target": "Ax0i933gtp",
      "similarity": 0.8263
    },
    {
      "source": "PZYr22zFyE",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8242
    },
    {
      "source": "PZYr22zFyE",
      "target": "8vzMLo8LDN",
      "similarity": 0.8201
    },
    {
      "source": "TJo6aQb7mK",
      "target": "To address this",
      "similarity": 0.823
    },
    {
      "source": "TJo6aQb7mK",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8071
    },
    {
      "source": "TJo6aQb7mK",
      "target": "5YbuOTUFQ4",
      "similarity": 0.7975
    },
    {
      "source": "TJo6aQb7mK",
      "target": "mXHTifc1Fn",
      "similarity": 0.7936
    },
    {
      "source": "TJo6aQb7mK",
      "target": "97rOQDPmk2",
      "similarity": 0.7935
    },
    {
      "source": "IXyfbaGlps",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8395
    },
    {
      "source": "IXyfbaGlps",
      "target": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "similarity": 0.8241
    },
    {
      "source": "IXyfbaGlps",
      "target": "VGQugiuCQs",
      "similarity": 0.823
    },
    {
      "source": "IXyfbaGlps",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8219
    },
    {
      "source": "IXyfbaGlps",
      "target": "PwxYoMvmvy",
      "similarity": 0.8213
    },
    {
      "source": "yaqPf0KAlN",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8584
    },
    {
      "source": "yaqPf0KAlN",
      "target": "zpENPcQSj1",
      "similarity": 0.8348
    },
    {
      "source": "yaqPf0KAlN",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.8303
    },
    {
      "source": "yaqPf0KAlN",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.823
    },
    {
      "source": "yaqPf0KAlN",
      "target": "practice is to instead extrapolate from scaled down",
      "similarity": 0.8223
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.874
    },
    {
      "source": "However",
      "target": "MxbEiFRf39",
      "similarity": 0.8629
    },
    {
      "source": "However",
      "target": "Many neural combinatorial optimization (NCO) methods have been proposed to solve CO problems.",
      "similarity": 0.8438
    },
    {
      "source": "However",
      "target": "kRBQwlkFSP",
      "similarity": 0.836
    },
    {
      "source": "However",
      "target": "we demonstrate that our method achieves state-of-the-art decomposition",
      "similarity": 0.8293
    },
    {
      "source": "awvJBtB2op",
      "target": "4JK2XMGUc8",
      "similarity": 0.8307
    },
    {
      "source": "awvJBtB2op",
      "target": "Experimental results show that this new method improves the performance of the model in both short and long contexts.",
      "similarity": 0.83
    },
    {
      "source": "awvJBtB2op",
      "target": "Finally",
      "similarity": 0.8287
    },
    {
      "source": "awvJBtB2op",
      "target": "fully utilizes the contextual information among tasks",
      "similarity": 0.8272
    },
    {
      "source": "awvJBtB2op",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.827
    },
    {
      "source": "zY37C8d6bS",
      "target": "HqjRlT65WX",
      "similarity": 0.8706
    },
    {
      "source": "zY37C8d6bS",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8685
    },
    {
      "source": "zY37C8d6bS",
      "target": "However",
      "similarity": 0.8572
    },
    {
      "source": "zY37C8d6bS",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.854
    },
    {
      "source": "zY37C8d6bS",
      "target": "5xSRg3eYZz",
      "similarity": 0.8496
    },
    {
      "source": "ugyqNEOjoU",
      "target": "TYSQYx9vwd",
      "similarity": 0.8668
    },
    {
      "source": "ugyqNEOjoU",
      "target": "K4FAFNRpko",
      "similarity": 0.8637
    },
    {
      "source": "ugyqNEOjoU",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8627
    },
    {
      "source": "ugyqNEOjoU",
      "target": "zxO4WuVGns",
      "similarity": 0.8465
    },
    {
      "source": "ugyqNEOjoU",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8462
    },
    {
      "source": "iOMnn1hSBO",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8899
    },
    {
      "source": "iOMnn1hSBO",
      "target": "2mqb8bPHeb",
      "similarity": 0.8888
    },
    {
      "source": "iOMnn1hSBO",
      "target": "To this end",
      "similarity": 0.8847
    },
    {
      "source": "iOMnn1hSBO",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8725
    },
    {
      "source": "iOMnn1hSBO",
      "target": "AJpUZd8Clb",
      "similarity": 0.8692
    },
    {
      "source": "Wf2ndb8nhf",
      "target": "To this end",
      "similarity": 0.8454
    },
    {
      "source": "Wf2ndb8nhf",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8441
    },
    {
      "source": "Wf2ndb8nhf",
      "target": "ud8FtE1N4N",
      "similarity": 0.836
    },
    {
      "source": "Wf2ndb8nhf",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8256
    },
    {
      "source": "Wf2ndb8nhf",
      "target": "wNobG8bV5Q",
      "similarity": 0.8201
    },
    {
      "source": "DzGe40glxs",
      "target": "m5qpn0KTMZ",
      "similarity": 0.8451
    },
    {
      "source": "DzGe40glxs",
      "target": "oYSsbY3G4o",
      "similarity": 0.8433
    },
    {
      "source": "DzGe40glxs",
      "target": "GtvuNrk58a",
      "similarity": 0.8403
    },
    {
      "source": "DzGe40glxs",
      "target": "Based on this",
      "similarity": 0.8174
    },
    {
      "source": "DzGe40glxs",
      "target": "Finally",
      "similarity": 0.8136
    },
    {
      "source": "K2Tqn8R9pu",
      "target": "XAjfjizaKs",
      "similarity": 0.8095
    },
    {
      "source": "K2Tqn8R9pu",
      "target": "o2Igqm95SJ",
      "similarity": 0.7997
    },
    {
      "source": "K2Tqn8R9pu",
      "target": "WWXjMYZxfH",
      "similarity": 0.7983
    },
    {
      "source": "K2Tqn8R9pu",
      "target": "On the other hand",
      "similarity": 0.7919
    },
    {
      "source": "K2Tqn8R9pu",
      "target": "ogXkmugNZw",
      "similarity": 0.7766
    },
    {
      "source": "bhOysNJvWm",
      "target": "oP7arLOWix",
      "similarity": 0.8676
    },
    {
      "source": "bhOysNJvWm",
      "target": "To this end",
      "similarity": 0.8656
    },
    {
      "source": "bhOysNJvWm",
      "target": "Qja5s0K3VX",
      "similarity": 0.8643
    },
    {
      "source": "bhOysNJvWm",
      "target": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "similarity": 0.8587
    },
    {
      "source": "bhOysNJvWm",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8563
    },
    {
      "source": "generating time series of tabular data",
      "target": "comprehensive experiments",
      "similarity": 0.8335
    },
    {
      "source": "generating time series of tabular data",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8241
    },
    {
      "source": "generating time series of tabular data",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.824
    },
    {
      "source": "generating time series of tabular data",
      "target": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "similarity": 0.816
    },
    {
      "source": "generating time series of tabular data",
      "target": "First",
      "similarity": 0.8138
    },
    {
      "source": "remains a largely unexplored domain.",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8499
    },
    {
      "source": "remains a largely unexplored domain.",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8456
    },
    {
      "source": "remains a largely unexplored domain.",
      "target": "97rOQDPmk2",
      "similarity": 0.8422
    },
    {
      "source": "remains a largely unexplored domain.",
      "target": "gsShHPxkUW",
      "similarity": 0.8365
    },
    {
      "source": "remains a largely unexplored domain.",
      "target": "OiQttMHwce",
      "similarity": 0.8363
    },
    {
      "source": "This gap is probably due to the difficulty of jointly solving different problems",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.8608
    },
    {
      "source": "This gap is probably due to the difficulty of jointly solving different problems",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.814
    },
    {
      "source": "This gap is probably due to the difficulty of jointly solving different problems",
      "target": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "similarity": 0.7901
    },
    {
      "source": "This gap is probably due to the difficulty of jointly solving different problems",
      "target": "Aly68Y5Es0",
      "similarity": 0.7893
    },
    {
      "source": "This gap is probably due to the difficulty of jointly solving different problems",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.7889
    },
    {
      "source": "In this paper",
      "target": "K7xpl3LZQp",
      "similarity": 0.8402
    },
    {
      "source": "In this paper",
      "target": "relying on backward propagation",
      "similarity": 0.8282
    },
    {
      "source": "In this paper",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8274
    },
    {
      "source": "In this paper",
      "target": "d7pr2doXn3",
      "similarity": 0.8254
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8212
    },
    {
      "source": "Using extensive experiments on six datasets",
      "target": "dermining interpretability. To address these challenges",
      "similarity": 0.8518
    },
    {
      "source": "Using extensive experiments on six datasets",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.8346
    },
    {
      "source": "Using extensive experiments on six datasets",
      "target": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "similarity": 0.8263
    },
    {
      "source": "Using extensive experiments on six datasets",
      "target": "To enable structural learning with the language model",
      "similarity": 0.826
    },
    {
      "source": "Using extensive experiments on six datasets",
      "target": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "similarity": 0.8179
    },
    {
      "source": "BlSIKSPhfz",
      "target": "First",
      "similarity": 0.8628
    },
    {
      "source": "BlSIKSPhfz",
      "target": "Usklli4gMc",
      "similarity": 0.8542
    },
    {
      "source": "BlSIKSPhfz",
      "target": "pDDODPtpx9",
      "similarity": 0.8494
    },
    {
      "source": "BlSIKSPhfz",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8465
    },
    {
      "source": "BlSIKSPhfz",
      "target": "Reweighting (GSR)",
      "similarity": 0.8461
    },
    {
      "source": "ThRMTCgpvo",
      "target": "lvw3UgeVxS",
      "similarity": 0.873
    },
    {
      "source": "ThRMTCgpvo",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8669
    },
    {
      "source": "ThRMTCgpvo",
      "target": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "similarity": 0.8369
    },
    {
      "source": "ThRMTCgpvo",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8308
    },
    {
      "source": "ThRMTCgpvo",
      "target": "a single GPU in a few hours",
      "similarity": 0.8308
    },
    {
      "source": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8577
    },
    {
      "source": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8476
    },
    {
      "source": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8418
    },
    {
      "source": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "target": "S85PP4xjFD",
      "similarity": 0.8414
    },
    {
      "source": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "target": "uL1H29dM0c",
      "similarity": 0.8373
    },
    {
      "source": "For the task of story writing with known prefixes and suffixes",
      "target": "Most existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However",
      "similarity": 0.7868
    },
    {
      "source": "For the task of story writing with known prefixes and suffixes",
      "target": "and calibration of models",
      "similarity": 0.7698
    },
    {
      "source": "For the task of story writing with known prefixes and suffixes",
      "target": "FBhKUXK7od",
      "similarity": 0.7687
    },
    {
      "source": "For the task of story writing with known prefixes and suffixes",
      "target": "TtKN1TpvUu",
      "similarity": 0.768
    },
    {
      "source": "For the task of story writing with known prefixes and suffixes",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.7662
    },
    {
      "source": "hwSmPOAmhk",
      "target": "instructions",
      "similarity": 0.8645
    },
    {
      "source": "hwSmPOAmhk",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8604
    },
    {
      "source": "hwSmPOAmhk",
      "target": "eiqrnVaeIw",
      "similarity": 0.8558
    },
    {
      "source": "hwSmPOAmhk",
      "target": "Mjn53GtMxi",
      "similarity": 0.8546
    },
    {
      "source": "hwSmPOAmhk",
      "target": "je3GZissZc",
      "similarity": 0.8541
    },
    {
      "source": "G5DziesYxL",
      "target": "AcVpLS86RT",
      "similarity": 0.8686
    },
    {
      "source": "G5DziesYxL",
      "target": "Moreover",
      "similarity": 0.8686
    },
    {
      "source": "G5DziesYxL",
      "target": "instructions",
      "similarity": 0.8578
    },
    {
      "source": "G5DziesYxL",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.854
    },
    {
      "source": "G5DziesYxL",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8537
    },
    {
      "source": "4JK2XMGUc8",
      "target": "increased their demand. However",
      "similarity": 0.9241
    },
    {
      "source": "4JK2XMGUc8",
      "target": "0h6v4SpLCY",
      "similarity": 0.9223
    },
    {
      "source": "4JK2XMGUc8",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.9129
    },
    {
      "source": "4JK2XMGUc8",
      "target": "However",
      "similarity": 0.9116
    },
    {
      "source": "4JK2XMGUc8",
      "target": "mkNVPGpEPm",
      "similarity": 0.9002
    },
    {
      "source": "LM4PYXBId5",
      "target": "Nevertheless",
      "similarity": 0.8101
    },
    {
      "source": "LM4PYXBId5",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8051
    },
    {
      "source": "LM4PYXBId5",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.795
    },
    {
      "source": "LM4PYXBId5",
      "target": "mzL19kKE3r",
      "similarity": 0.7899
    },
    {
      "source": "LM4PYXBId5",
      "target": "aXwukBD6M6",
      "similarity": 0.788
    },
    {
      "source": "elTJBP7Fbv",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.856
    },
    {
      "source": "elTJBP7Fbv",
      "target": "$$",
      "similarity": 0.8395
    },
    {
      "source": "elTJBP7Fbv",
      "target": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "similarity": 0.8229
    },
    {
      "source": "elTJBP7Fbv",
      "target": "works remains elusive. Current interpretability work can extract features from",
      "similarity": 0.8216
    },
    {
      "source": "elTJBP7Fbv",
      "target": "mDKxlfraAn",
      "similarity": 0.8025
    },
    {
      "source": "B2Fqu7Y2cd",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8478
    },
    {
      "source": "B2Fqu7Y2cd",
      "target": "than existing search techniques",
      "similarity": 0.8464
    },
    {
      "source": "B2Fqu7Y2cd",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8464
    },
    {
      "source": "B2Fqu7Y2cd",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8382
    },
    {
      "source": "B2Fqu7Y2cd",
      "target": "KAIqwkB3dT",
      "similarity": 0.8371
    },
    {
      "source": "qykpnEWf2J",
      "target": "VmJdqhuTCh",
      "similarity": 0.8495
    },
    {
      "source": "qykpnEWf2J",
      "target": "This paper proposes",
      "similarity": 0.833
    },
    {
      "source": "qykpnEWf2J",
      "target": "Existing estimators often rely on non-differentiable combinatorial components. Here",
      "similarity": 0.8325
    },
    {
      "source": "qykpnEWf2J",
      "target": "NWb128pSCb",
      "similarity": 0.8291
    },
    {
      "source": "qykpnEWf2J",
      "target": "f3QR9TEERH",
      "similarity": 0.8282
    },
    {
      "source": "YwJkv2YqBq",
      "target": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "similarity": 0.8693
    },
    {
      "source": "YwJkv2YqBq",
      "target": "In the more general context",
      "similarity": 0.8617
    },
    {
      "source": "YwJkv2YqBq",
      "target": "cADpvQgnqg",
      "similarity": 0.8463
    },
    {
      "source": "YwJkv2YqBq",
      "target": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "similarity": 0.8358
    },
    {
      "source": "YwJkv2YqBq",
      "target": "However",
      "similarity": 0.8324
    },
    {
      "source": "kX8h23UG6v",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8452
    },
    {
      "source": "kX8h23UG6v",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8396
    },
    {
      "source": "kX8h23UG6v",
      "target": "gfI9v7AbFg",
      "similarity": 0.8363
    },
    {
      "source": "kX8h23UG6v",
      "target": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "similarity": 0.8362
    },
    {
      "source": "kX8h23UG6v",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8352
    },
    {
      "source": "QhxjQOMdDF",
      "target": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "similarity": 0.851
    },
    {
      "source": "QhxjQOMdDF",
      "target": "bmrYu2Ekdz",
      "similarity": 0.8449
    },
    {
      "source": "QhxjQOMdDF",
      "target": "pDDODPtpx9",
      "similarity": 0.8303
    },
    {
      "source": "QhxjQOMdDF",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8269
    },
    {
      "source": "QhxjQOMdDF",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.8263
    },
    {
      "source": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "target": "Yet",
      "similarity": 0.8511
    },
    {
      "source": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8145
    },
    {
      "source": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "target": "i7k2sXSW1b",
      "similarity": 0.7995
    },
    {
      "source": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "target": "OQqNieeivq",
      "similarity": 0.799
    },
    {
      "source": "By computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory",
      "target": "590yfqz1LE",
      "similarity": 0.7978
    },
    {
      "source": "Theoretically",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8629
    },
    {
      "source": "Theoretically",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8505
    },
    {
      "source": "Theoretically",
      "target": "CkKEuLmRnr",
      "similarity": 0.846
    },
    {
      "source": "Theoretically",
      "target": "TvGPP8i18S",
      "similarity": 0.8437
    },
    {
      "source": "Theoretically",
      "target": "F57HPKZ6KD",
      "similarity": 0.8385
    },
    {
      "source": "In particular",
      "target": "il5yUQsrjC",
      "similarity": 0.9197
    },
    {
      "source": "In particular",
      "target": "8eNLKk5by4",
      "similarity": 0.9038
    },
    {
      "source": "In particular",
      "target": "XdRIno98gG",
      "similarity": 0.8686
    },
    {
      "source": "In particular",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8624
    },
    {
      "source": "In particular",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8487
    },
    {
      "source": "uZgK0tcPqd",
      "target": "For instance",
      "similarity": 0.8691
    },
    {
      "source": "uZgK0tcPqd",
      "target": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "similarity": 0.8604
    },
    {
      "source": "uZgK0tcPqd",
      "target": "identically. Therefore",
      "similarity": 0.857
    },
    {
      "source": "uZgK0tcPqd",
      "target": "prompts of 128K length",
      "similarity": 0.8483
    },
    {
      "source": "uZgK0tcPqd",
      "target": "X6y5CC44HM",
      "similarity": 0.8463
    },
    {
      "source": "JYwVijuNA7",
      "target": "Qja5s0K3VX",
      "similarity": 0.8715
    },
    {
      "source": "JYwVijuNA7",
      "target": "size in stages. We show that this approach not only generalizes prior works like",
      "similarity": 0.8645
    },
    {
      "source": "JYwVijuNA7",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.864
    },
    {
      "source": "JYwVijuNA7",
      "target": "To this end",
      "similarity": 0.8629
    },
    {
      "source": "JYwVijuNA7",
      "target": "wUtXB43Chi",
      "similarity": 0.8613
    },
    {
      "source": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8753
    },
    {
      "source": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "target": "Qja5s0K3VX",
      "similarity": 0.8718
    },
    {
      "source": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "target": "Using this extension",
      "similarity": 0.8657
    },
    {
      "source": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "target": "FXw0okNcOb",
      "similarity": 0.8642
    },
    {
      "source": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "target": "JYwVijuNA7",
      "similarity": 0.8608
    },
    {
      "source": "kSISSDUYFh",
      "target": "Furthermore",
      "similarity": 0.8448
    },
    {
      "source": "kSISSDUYFh",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8435
    },
    {
      "source": "kSISSDUYFh",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8353
    },
    {
      "source": "kSISSDUYFh",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8332
    },
    {
      "source": "kSISSDUYFh",
      "target": "samples. However",
      "similarity": 0.8315
    },
    {
      "source": "NO6Tv6QcDs",
      "target": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "similarity": 0.7918
    },
    {
      "source": "NO6Tv6QcDs",
      "target": "75PhjtbBdr",
      "similarity": 0.7849
    },
    {
      "source": "NO6Tv6QcDs",
      "target": "X0epAjg0hd",
      "similarity": 0.7785
    },
    {
      "source": "NO6Tv6QcDs",
      "target": "To address these issues",
      "similarity": 0.7738
    },
    {
      "source": "NO6Tv6QcDs",
      "target": "On three standard circuit evaluation datasets (indirect object identification",
      "similarity": 0.7725
    },
    {
      "source": "QFgbJOYJSE",
      "target": "kx8i1yfkRX",
      "similarity": 0.7962
    },
    {
      "source": "QFgbJOYJSE",
      "target": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "similarity": 0.7941
    },
    {
      "source": "QFgbJOYJSE",
      "target": "X0epAjg0hd",
      "similarity": 0.7839
    },
    {
      "source": "QFgbJOYJSE",
      "target": "GkWA6NjePN",
      "similarity": 0.7836
    },
    {
      "source": "QFgbJOYJSE",
      "target": "9juyeCqL0u",
      "similarity": 0.7833
    },
    {
      "source": "xQVxo9dSID",
      "target": "ACSNlt77hq",
      "similarity": 0.8475
    },
    {
      "source": "xQVxo9dSID",
      "target": "cADpvQgnqg",
      "similarity": 0.8356
    },
    {
      "source": "xQVxo9dSID",
      "target": "vbmSSIhKAM",
      "similarity": 0.8263
    },
    {
      "source": "xQVxo9dSID",
      "target": "Furthermore",
      "similarity": 0.8249
    },
    {
      "source": "xQVxo9dSID",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8245
    },
    {
      "source": "mTCbq2QssD",
      "target": "KAIqwkB3dT",
      "similarity": 0.8848
    },
    {
      "source": "mTCbq2QssD",
      "target": "5xSRg3eYZz",
      "similarity": 0.8606
    },
    {
      "source": "mTCbq2QssD",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8587
    },
    {
      "source": "mTCbq2QssD",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8546
    },
    {
      "source": "mTCbq2QssD",
      "target": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "similarity": 0.8526
    },
    {
      "source": "GR0y0F3Ipd",
      "target": "PrefEval comprises 3",
      "similarity": 0.8012
    },
    {
      "source": "GR0y0F3Ipd",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.7978
    },
    {
      "source": "GR0y0F3Ipd",
      "target": "it hard to decide on a proper causal discovery strategy.",
      "similarity": 0.7893
    },
    {
      "source": "GR0y0F3Ipd",
      "target": "GkWA6NjePN",
      "similarity": 0.7874
    },
    {
      "source": "GR0y0F3Ipd",
      "target": "These results suggest a single fundamental subspace facilitates how the model chooses between context and prior knowledge.\"",
      "similarity": 0.7851
    },
    {
      "source": "However",
      "target": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "similarity": 0.796
    },
    {
      "source": "However",
      "target": "huuKoVQnB0",
      "similarity": 0.794
    },
    {
      "source": "However",
      "target": "CIs9x2ZRgh",
      "similarity": 0.7853
    },
    {
      "source": "However",
      "target": "pQsllTesiE",
      "similarity": 0.7843
    },
    {
      "source": "However",
      "target": "Speculative decoding (SD) leverages smaller models to efficiently propose future tokens",
      "similarity": 0.7824
    },
    {
      "source": "To address this",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.8509
    },
    {
      "source": "To address this",
      "target": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "similarity": 0.8279
    },
    {
      "source": "To address this",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8231
    },
    {
      "source": "To address this",
      "target": "ZadnlOHsHv",
      "similarity": 0.8096
    },
    {
      "source": "To address this",
      "target": "(e.g.",
      "similarity": 0.809
    },
    {
      "source": "MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator.",
      "target": "RZwtbg3qYD",
      "similarity": 0.8177
    },
    {
      "source": "MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator.",
      "target": "Real-world causal structures",
      "similarity": 0.8046
    },
    {
      "source": "MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator.",
      "target": "KeRwLLwZaw",
      "similarity": 0.7921
    },
    {
      "source": "MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator.",
      "target": "3ygfMPLv0P",
      "similarity": 0.7911
    },
    {
      "source": "MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator.",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.7814
    },
    {
      "source": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8471
    },
    {
      "source": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8419
    },
    {
      "source": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "target": "ReItdfwMcg",
      "similarity": 0.8401
    },
    {
      "source": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8307
    },
    {
      "source": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "target": "x33vSZUg0A",
      "similarity": 0.8256
    },
    {
      "source": "At the inference stage",
      "target": "In experiments with GPT-4",
      "similarity": 0.8801
    },
    {
      "source": "At the inference stage",
      "target": "Moreover",
      "similarity": 0.8503
    },
    {
      "source": "At the inference stage",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8451
    },
    {
      "source": "At the inference stage",
      "target": "We5z3UEnUY",
      "similarity": 0.8443
    },
    {
      "source": "At the inference stage",
      "target": "9XETcRsufZ",
      "similarity": 0.844
    },
    {
      "source": "Validated using our collected college-level circuit analysis problems",
      "target": "Fk3eod9aaD",
      "similarity": 0.8909
    },
    {
      "source": "Validated using our collected college-level circuit analysis problems",
      "target": "To overcome such limitations",
      "similarity": 0.838
    },
    {
      "source": "Validated using our collected college-level circuit analysis problems",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.8255
    },
    {
      "source": "Validated using our collected college-level circuit analysis problems",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8249
    },
    {
      "source": "Validated using our collected college-level circuit analysis problems",
      "target": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "similarity": 0.8199
    },
    {
      "source": "The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs.",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8313
    },
    {
      "source": "The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs.",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.8301
    },
    {
      "source": "The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs.",
      "target": "Besides this primary purpose",
      "similarity": 0.81
    },
    {
      "source": "The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs.",
      "target": "Q5Sawm0nqo",
      "similarity": 0.8077
    },
    {
      "source": "The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs.",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8056
    },
    {
      "source": "We will release our code",
      "target": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "similarity": 0.8237
    },
    {
      "source": "We will release our code",
      "target": "However",
      "similarity": 0.8237
    },
    {
      "source": "We will release our code",
      "target": "yj9lLwMjnE",
      "similarity": 0.8208
    },
    {
      "source": "We will release our code",
      "target": "z0hUsPhwUN",
      "similarity": 0.8083
    },
    {
      "source": "We will release our code",
      "target": "XBF63bHDZw",
      "similarity": 0.801
    },
    {
      "source": "FEZOLWexPb",
      "target": "ZadnlOHsHv",
      "similarity": 0.8746
    },
    {
      "source": "FEZOLWexPb",
      "target": "PDnEDS244P",
      "similarity": 0.8561
    },
    {
      "source": "FEZOLWexPb",
      "target": "Bpn8q40n1n",
      "similarity": 0.8477
    },
    {
      "source": "FEZOLWexPb",
      "target": "Based on this concept",
      "similarity": 0.8365
    },
    {
      "source": "FEZOLWexPb",
      "target": "2ea5TNVR0c",
      "similarity": 0.8359
    },
    {
      "source": "9kJperA2a4",
      "target": "jTEKTdI3K9",
      "similarity": 0.9095
    },
    {
      "source": "9kJperA2a4",
      "target": "v1rFkElnIn",
      "similarity": 0.8948
    },
    {
      "source": "9kJperA2a4",
      "target": "For example",
      "similarity": 0.8754
    },
    {
      "source": "9kJperA2a4",
      "target": "se4vjm7h4E",
      "similarity": 0.8663
    },
    {
      "source": "9kJperA2a4",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8652
    },
    {
      "source": "kwCHcaeHrf",
      "target": "riieAeQBJm",
      "similarity": 0.9219
    },
    {
      "source": "kwCHcaeHrf",
      "target": "BL4WBIfyrz",
      "similarity": 0.8996
    },
    {
      "source": "kwCHcaeHrf",
      "target": "dAeET8gxqg",
      "similarity": 0.887
    },
    {
      "source": "kwCHcaeHrf",
      "target": "Further",
      "similarity": 0.8799
    },
    {
      "source": "kwCHcaeHrf",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8778
    },
    {
      "source": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8937
    },
    {
      "source": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.8737
    },
    {
      "source": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "target": "However",
      "similarity": 0.8613
    },
    {
      "source": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "target": "To address this limitation",
      "similarity": 0.8608
    },
    {
      "source": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "target": "Yet",
      "similarity": 0.8606
    },
    {
      "source": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "target": "N0ETIi580T",
      "similarity": 0.8485
    },
    {
      "source": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8299
    },
    {
      "source": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "target": "Experimentally",
      "similarity": 0.8293
    },
    {
      "source": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8286
    },
    {
      "source": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "target": "aVfDrl7xDV",
      "similarity": 0.8226
    },
    {
      "source": "of the training distribution in the latent space of the classifier. Under mild assumptions",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8487
    },
    {
      "source": "of the training distribution in the latent space of the classifier. Under mild assumptions",
      "target": "5BRFddsAai",
      "similarity": 0.846
    },
    {
      "source": "of the training distribution in the latent space of the classifier. Under mild assumptions",
      "target": "iXCeQ2m6vT",
      "similarity": 0.8442
    },
    {
      "source": "of the training distribution in the latent space of the classifier. Under mild assumptions",
      "target": "bmbRCRiNDu",
      "similarity": 0.8419
    },
    {
      "source": "of the training distribution in the latent space of the classifier. Under mild assumptions",
      "target": "Qja5s0K3VX",
      "similarity": 0.8355
    },
    {
      "source": "and adversarial samples and rejecting them. Empirical validation of the approach",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.7969
    },
    {
      "source": "and adversarial samples and rejecting them. Empirical validation of the approach",
      "target": "aN57tSd5Us",
      "similarity": 0.7928
    },
    {
      "source": "and adversarial samples and rejecting them. Empirical validation of the approach",
      "target": "NGKQoaqLpo",
      "similarity": 0.7893
    },
    {
      "source": "and adversarial samples and rejecting them. Empirical validation of the approach",
      "target": "eLLBILFRsA",
      "similarity": 0.7858
    },
    {
      "source": "and adversarial samples and rejecting them. Empirical validation of the approach",
      "target": "nt8gBX58Kh",
      "similarity": 0.7857
    },
    {
      "source": "is conducted on various neural architectures (ResNet",
      "target": "FPBce2P1er",
      "similarity": 0.7924
    },
    {
      "source": "is conducted on various neural architectures (ResNet",
      "target": "L5godAOC2z",
      "similarity": 0.7793
    },
    {
      "source": "is conducted on various neural architectures (ResNet",
      "target": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "similarity": 0.7714
    },
    {
      "source": "is conducted on various neural architectures (ResNet",
      "target": "Moreover",
      "similarity": 0.7711
    },
    {
      "source": "is conducted on various neural architectures (ResNet",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.7709
    },
    {
      "source": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8386
    },
    {
      "source": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "target": "HN0CYZbAPw",
      "similarity": 0.8323
    },
    {
      "source": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "target": "In this paper",
      "similarity": 0.8295
    },
    {
      "source": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "target": "To this end",
      "similarity": 0.8278
    },
    {
      "source": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8275
    },
    {
      "source": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "target": "5z9GjHgerY",
      "similarity": 0.8315
    },
    {
      "source": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "target": "MBBRHDuiwM",
      "similarity": 0.8103
    },
    {
      "source": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "target": "SuH5SdOXpe",
      "similarity": 0.8077
    },
    {
      "source": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "target": "FhTAG591Ve",
      "similarity": 0.8036
    },
    {
      "source": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.7981
    },
    {
      "source": "Llh6CinTiy",
      "target": "FBhKUXK7od",
      "similarity": 0.8432
    },
    {
      "source": "Llh6CinTiy",
      "target": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "similarity": 0.8416
    },
    {
      "source": "Llh6CinTiy",
      "target": "The project website is available at:",
      "similarity": 0.8414
    },
    {
      "source": "Llh6CinTiy",
      "target": "eW4yh6HKz4",
      "similarity": 0.8157
    },
    {
      "source": "Llh6CinTiy",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.8032
    },
    {
      "source": "Our experiments on a variety of chaotic systems",
      "target": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "similarity": 0.8565
    },
    {
      "source": "Our experiments on a variety of chaotic systems",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8491
    },
    {
      "source": "Our experiments on a variety of chaotic systems",
      "target": "ERv8ptegFi",
      "similarity": 0.8451
    },
    {
      "source": "Our experiments on a variety of chaotic systems",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.845
    },
    {
      "source": "Our experiments on a variety of chaotic systems",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8419
    },
    {
      "source": "jCPak79Kev",
      "target": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "similarity": 0.8405
    },
    {
      "source": "jCPak79Kev",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8389
    },
    {
      "source": "jCPak79Kev",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8307
    },
    {
      "source": "jCPak79Kev",
      "target": "H9UnNgdq0g",
      "similarity": 0.8291
    },
    {
      "source": "jCPak79Kev",
      "target": "CvjXlsBLCX",
      "similarity": 0.827
    },
    {
      "source": "Excitingly",
      "target": "C45YqeBDUM",
      "similarity": 0.8466
    },
    {
      "source": "Excitingly",
      "target": "GhexuBLxbO",
      "similarity": 0.8313
    },
    {
      "source": "Excitingly",
      "target": "We identify two broad strategies to produce MI explanations: (i) \"\"where-then-what\"\"",
      "similarity": 0.8312
    },
    {
      "source": "Excitingly",
      "target": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "similarity": 0.8282
    },
    {
      "source": "Excitingly",
      "target": "(VideoWA)",
      "similarity": 0.816
    },
    {
      "source": "Yet",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8175
    },
    {
      "source": "Yet",
      "target": "OQqNieeivq",
      "similarity": 0.8135
    },
    {
      "source": "Yet",
      "target": "entities of a sentence (subject",
      "similarity": 0.8031
    },
    {
      "source": "Yet",
      "target": "In this paper",
      "similarity": 0.8028
    },
    {
      "source": "Yet",
      "target": "p60Y6o85Cj",
      "similarity": 0.802
    },
    {
      "source": "This paper proposes",
      "target": "Q150eWkQ4I",
      "similarity": 0.8664
    },
    {
      "source": "This paper proposes",
      "target": "named Pacmann",
      "similarity": 0.8643
    },
    {
      "source": "This paper proposes",
      "target": "NWb128pSCb",
      "similarity": 0.863
    },
    {
      "source": "This paper proposes",
      "target": "VmJdqhuTCh",
      "similarity": 0.8611
    },
    {
      "source": "This paper proposes",
      "target": "QOfswj7hij",
      "similarity": 0.8549
    },
    {
      "source": "AnalogGenie addresses two key gaps in the field: building a foundational comprehensive dataset of analog circuit topology and developing a scalable sequence-based graph representation universal to analog circuits.",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8379
    },
    {
      "source": "AnalogGenie addresses two key gaps in the field: building a foundational comprehensive dataset of analog circuit topology and developing a scalable sequence-based graph representation universal to analog circuits.",
      "target": "zcTLpIfj9u",
      "similarity": 0.834
    },
    {
      "source": "AnalogGenie addresses two key gaps in the field: building a foundational comprehensive dataset of analog circuit topology and developing a scalable sequence-based graph representation universal to analog circuits.",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8286
    },
    {
      "source": "AnalogGenie addresses two key gaps in the field: building a foundational comprehensive dataset of analog circuit topology and developing a scalable sequence-based graph representation universal to analog circuits.",
      "target": "254NJe9JEw",
      "similarity": 0.8263
    },
    {
      "source": "AnalogGenie addresses two key gaps in the field: building a foundational comprehensive dataset of analog circuit topology and developing a scalable sequence-based graph representation universal to analog circuits.",
      "target": "IuU0wcO0mo",
      "similarity": 0.8241
    },
    {
      "source": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8419
    },
    {
      "source": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "target": "zGzs5SIwT8",
      "similarity": 0.826
    },
    {
      "source": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "target": "i3T0wvQDKg",
      "similarity": 0.8176
    },
    {
      "source": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "target": "5oSUgTzs8Y",
      "similarity": 0.8143
    },
    {
      "source": "Experimental results show the remarkable generation performance of AnalogGenie in broadening the variety of analog ICs",
      "target": "To tackle this challenge",
      "similarity": 0.8084
    },
    {
      "source": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "target": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "similarity": 0.8617
    },
    {
      "source": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "target": "Vz0CWFMPUe",
      "similarity": 0.8602
    },
    {
      "source": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "target": "nx9Z5Kva96",
      "similarity": 0.8504
    },
    {
      "source": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8482
    },
    {
      "source": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "target": "We release models",
      "similarity": 0.8481
    },
    {
      "source": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "target": "In this work",
      "similarity": 0.8915
    },
    {
      "source": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "target": "ajSmXqgS24",
      "similarity": 0.8545
    },
    {
      "source": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "target": "GLWf2fq0bX",
      "similarity": 0.8495
    },
    {
      "source": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "target": "dmCGjPFVhF",
      "similarity": 0.8469
    },
    {
      "source": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "target": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "similarity": 0.8219
    },
    {
      "source": "6ldD8Y4gBQ",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8502
    },
    {
      "source": "6ldD8Y4gBQ",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8409
    },
    {
      "source": "6ldD8Y4gBQ",
      "target": "Finally",
      "similarity": 0.8385
    },
    {
      "source": "6ldD8Y4gBQ",
      "target": "U3PBITXNG6",
      "similarity": 0.8343
    },
    {
      "source": "6ldD8Y4gBQ",
      "target": "the entire observable history remained an open problem. In this work",
      "similarity": 0.8296
    },
    {
      "source": "Existing approaches",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8589
    },
    {
      "source": "Existing approaches",
      "target": "Specifically",
      "similarity": 0.8469
    },
    {
      "source": "Existing approaches",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.844
    },
    {
      "source": "Existing approaches",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8362
    },
    {
      "source": "Existing approaches",
      "target": "In this paper",
      "similarity": 0.8359
    },
    {
      "source": "However",
      "target": "x33vSZUg0A",
      "similarity": 0.8248
    },
    {
      "source": "However",
      "target": "evaluate how well fine details are learned",
      "similarity": 0.8033
    },
    {
      "source": "However",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8021
    },
    {
      "source": "However",
      "target": "DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees",
      "similarity": 0.8021
    },
    {
      "source": "However",
      "target": "Neb17mimVH",
      "similarity": 0.8012
    },
    {
      "source": "Most importantly",
      "target": "S85PP4xjFD",
      "similarity": 0.8195
    },
    {
      "source": "Most importantly",
      "target": "as representations of instances. In this work",
      "similarity": 0.8164
    },
    {
      "source": "Most importantly",
      "target": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "similarity": 0.8148
    },
    {
      "source": "Most importantly",
      "target": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "similarity": 0.8147
    },
    {
      "source": "Most importantly",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8041
    },
    {
      "source": "This paper introduces *data taggants*",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8484
    },
    {
      "source": "This paper introduces *data taggants*",
      "target": "In this task",
      "similarity": 0.838
    },
    {
      "source": "This paper introduces *data taggants*",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8344
    },
    {
      "source": "This paper introduces *data taggants*",
      "target": "In brief",
      "similarity": 0.8342
    },
    {
      "source": "This paper introduces *data taggants*",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8261
    },
    {
      "source": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "target": "kmgrlG9TR0",
      "similarity": 0.8787
    },
    {
      "source": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8548
    },
    {
      "source": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "target": "EyaH1wzmao",
      "similarity": 0.8492
    },
    {
      "source": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "target": "cRnCcuLvyr",
      "similarity": 0.8483
    },
    {
      "source": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "target": "In this work",
      "similarity": 0.8447
    },
    {
      "source": "The keys are built as to allow for statistical certificates with black-box access only to the model.\\",
      "target": "VoayJihXra",
      "similarity": 0.8562
    },
    {
      "source": "The keys are built as to allow for statistical certificates with black-box access only to the model.\\",
      "target": "Second",
      "similarity": 0.8491
    },
    {
      "source": "The keys are built as to allow for statistical certificates with black-box access only to the model.\\",
      "target": "K7xpl3LZQp",
      "similarity": 0.8461
    },
    {
      "source": "The keys are built as to allow for statistical certificates with black-box access only to the model.\\",
      "target": "Second",
      "similarity": 0.8441
    },
    {
      "source": "The keys are built as to allow for statistical certificates with black-box access only to the model.\\",
      "target": "finetuned on 4K-length sequences",
      "similarity": 0.844
    },
    {
      "source": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "target": "As expected",
      "similarity": 0.8709
    },
    {
      "source": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "target": "Second",
      "similarity": 0.85
    },
    {
      "source": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8489
    },
    {
      "source": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8469
    },
    {
      "source": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8441
    },
    {
      "source": "Our findings demonstrate that data taggants can reliably detect  models trained on the protected dataset with high confidence",
      "target": "9EqQC2ct4H",
      "similarity": 0.8645
    },
    {
      "source": "Our findings demonstrate that data taggants can reliably detect  models trained on the protected dataset with high confidence",
      "target": "uqe5HkjbT9",
      "similarity": 0.8476
    },
    {
      "source": "Our findings demonstrate that data taggants can reliably detect  models trained on the protected dataset with high confidence",
      "target": "Jszf4et48m",
      "similarity": 0.8452
    },
    {
      "source": "Our findings demonstrate that data taggants can reliably detect  models trained on the protected dataset with high confidence",
      "target": "UvTo3tVBk2",
      "similarity": 0.8442
    },
    {
      "source": "Our findings demonstrate that data taggants can reliably detect  models trained on the protected dataset with high confidence",
      "target": "To enable TTA for regression",
      "similarity": 0.8422
    },
    {
      "source": "We demonstrate the stealthiness and robustness of our method",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.8943
    },
    {
      "source": "We demonstrate the stealthiness and robustness of our method",
      "target": "2pNLknCTvG",
      "similarity": 0.8866
    },
    {
      "source": "We demonstrate the stealthiness and robustness of our method",
      "target": "Yet",
      "similarity": 0.8768
    },
    {
      "source": "We demonstrate the stealthiness and robustness of our method",
      "target": "To this end",
      "similarity": 0.8751
    },
    {
      "source": "We demonstrate the stealthiness and robustness of our method",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8721
    },
    {
      "source": "% shows to be stealthy and robust",
      "target": "kGvXIlIVLM",
      "similarity": 0.8209
    },
    {
      "source": "% shows to be stealthy and robust",
      "target": "uqWM9hBDAE",
      "similarity": 0.8176
    },
    {
      "source": "% shows to be stealthy and robust",
      "target": "FSjIrOm1vz",
      "similarity": 0.8112
    },
    {
      "source": "% shows to be stealthy and robust",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.8109
    },
    {
      "source": "% shows to be stealthy and robust",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8082
    },
    {
      "source": "against various defense mechanisms.\"",
      "target": "While our convergence rate estimates recover existing results for minimizing",
      "similarity": 0.8212
    },
    {
      "source": "against various defense mechanisms.\"",
      "target": "To fill this gap",
      "similarity": 0.815
    },
    {
      "source": "against various defense mechanisms.\"",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8048
    },
    {
      "source": "against various defense mechanisms.\"",
      "target": "fine-tuning of a shallow fully-connected network following the representation.",
      "similarity": 0.8011
    },
    {
      "source": "against various defense mechanisms.\"",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.7979
    },
    {
      "source": "vf5aUZT0Fz",
      "target": "nzjSvVZBIp",
      "similarity": 0.7933
    },
    {
      "source": "vf5aUZT0Fz",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.7806
    },
    {
      "source": "vf5aUZT0Fz",
      "target": "over methods trained using much larger datasets.",
      "similarity": 0.7688
    },
    {
      "source": "vf5aUZT0Fz",
      "target": "g0rnZeBguq",
      "similarity": 0.7682
    },
    {
      "source": "vf5aUZT0Fz",
      "target": "AWg2tkbydO",
      "similarity": 0.7659
    },
    {
      "source": "Q2bJ2qgcP1",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8404
    },
    {
      "source": "Q2bJ2qgcP1",
      "target": "However",
      "similarity": 0.8384
    },
    {
      "source": "Q2bJ2qgcP1",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8331
    },
    {
      "source": "Q2bJ2qgcP1",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8271
    },
    {
      "source": "Q2bJ2qgcP1",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.825
    },
    {
      "source": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "target": "rTQNGQxm4K",
      "similarity": 0.8756
    },
    {
      "source": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "target": "HqjRlT65WX",
      "similarity": 0.8645
    },
    {
      "source": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8632
    },
    {
      "source": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "target": "First",
      "similarity": 0.8602
    },
    {
      "source": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "target": "OuLgaHEmzi",
      "similarity": 0.859
    },
    {
      "source": "Our findings stem from a novel application of \\textit{observational sampling}",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8161
    },
    {
      "source": "Our findings stem from a novel application of \\textit{observational sampling}",
      "target": "a3PmRgAB5T",
      "similarity": 0.8114
    },
    {
      "source": "Our findings stem from a novel application of \\textit{observational sampling}",
      "target": "To address this issue",
      "similarity": 0.8074
    },
    {
      "source": "Our findings stem from a novel application of \\textit{observational sampling}",
      "target": "gFvRRCnQvX",
      "similarity": 0.8042
    },
    {
      "source": "Our findings stem from a novel application of \\textit{observational sampling}",
      "target": "increased their demand. However",
      "similarity": 0.8009
    },
    {
      "source": "IIsTO4P3Ag",
      "target": "DpLFmc09pC",
      "similarity": 0.7853
    },
    {
      "source": "IIsTO4P3Ag",
      "target": "HyjIEf90Tn",
      "similarity": 0.7831
    },
    {
      "source": "IIsTO4P3Ag",
      "target": "9chRqsPOGL",
      "similarity": 0.7829
    },
    {
      "source": "IIsTO4P3Ag",
      "target": "Fu0aggezN9",
      "similarity": 0.7767
    },
    {
      "source": "IIsTO4P3Ag",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.7757
    },
    {
      "source": "FBhKUXK7od",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8745
    },
    {
      "source": "FBhKUXK7od",
      "target": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "similarity": 0.8586
    },
    {
      "source": "FBhKUXK7od",
      "target": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "similarity": 0.8568
    },
    {
      "source": "FBhKUXK7od",
      "target": "gkUyYcY1W9",
      "similarity": 0.8486
    },
    {
      "source": "FBhKUXK7od",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8472
    },
    {
      "source": "rdv6yeMFpn",
      "target": "by the scarcity of datasets for benchmarking these architectures. To address this gap",
      "similarity": 0.8122
    },
    {
      "source": "rdv6yeMFpn",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8111
    },
    {
      "source": "rdv6yeMFpn",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8101
    },
    {
      "source": "rdv6yeMFpn",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8044
    },
    {
      "source": "rdv6yeMFpn",
      "target": "2c7pfOqu9k",
      "similarity": 0.8042
    },
    {
      "source": "HN8V0flwJF",
      "target": "However",
      "similarity": 0.8884
    },
    {
      "source": "HN8V0flwJF",
      "target": "riieAeQBJm",
      "similarity": 0.8872
    },
    {
      "source": "HN8V0flwJF",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8859
    },
    {
      "source": "HN8V0flwJF",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8805
    },
    {
      "source": "HN8V0flwJF",
      "target": "To this end",
      "similarity": 0.8716
    },
    {
      "source": "mnna9LUg7P",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8641
    },
    {
      "source": "mnna9LUg7P",
      "target": "rCX9l4OTCT",
      "similarity": 0.8634
    },
    {
      "source": "mnna9LUg7P",
      "target": "TYSQYx9vwd",
      "similarity": 0.8569
    },
    {
      "source": "mnna9LUg7P",
      "target": "ULorFBST6X",
      "similarity": 0.8547
    },
    {
      "source": "mnna9LUg7P",
      "target": "tijmpS9Vy2",
      "similarity": 0.8544
    },
    {
      "source": "L238BAx0wP",
      "target": "eLLBILFRsA",
      "similarity": 0.8939
    },
    {
      "source": "L238BAx0wP",
      "target": "cfGpIcOIa5",
      "similarity": 0.8544
    },
    {
      "source": "L238BAx0wP",
      "target": "JMPOqoe4tl",
      "similarity": 0.8412
    },
    {
      "source": "L238BAx0wP",
      "target": "Third",
      "similarity": 0.835
    },
    {
      "source": "L238BAx0wP",
      "target": "3ogIALgghF",
      "similarity": 0.8286
    },
    {
      "source": "tFV5GrWOGm",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8357
    },
    {
      "source": "tFV5GrWOGm",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8304
    },
    {
      "source": "tFV5GrWOGm",
      "target": "uNomADvF3s",
      "similarity": 0.8172
    },
    {
      "source": "tFV5GrWOGm",
      "target": "GFgn2LprFR",
      "similarity": 0.8038
    },
    {
      "source": "tFV5GrWOGm",
      "target": "a dependency parser",
      "similarity": 0.7967
    },
    {
      "source": "uqe5HkjbT9",
      "target": "Moreover",
      "similarity": 0.885
    },
    {
      "source": "uqe5HkjbT9",
      "target": "ods",
      "similarity": 0.8839
    },
    {
      "source": "uqe5HkjbT9",
      "target": "5oSUgTzs8Y",
      "similarity": 0.8771
    },
    {
      "source": "uqe5HkjbT9",
      "target": "Metrics for probability measures",
      "similarity": 0.8681
    },
    {
      "source": "uqe5HkjbT9",
      "target": "underscore the necessity for future research to focus on improving the accuracy of",
      "similarity": 0.8673
    },
    {
      "source": "2vHIHrJAcI",
      "target": "world perspective. To address this",
      "similarity": 0.9169
    },
    {
      "source": "2vHIHrJAcI",
      "target": "NfCEVihkdC",
      "similarity": 0.914
    },
    {
      "source": "2vHIHrJAcI",
      "target": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "similarity": 0.8672
    },
    {
      "source": "2vHIHrJAcI",
      "target": "In this work",
      "similarity": 0.8269
    },
    {
      "source": "2vHIHrJAcI",
      "target": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "similarity": 0.8224
    },
    {
      "source": "in model performance as the query vocabulary set expands",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.909
    },
    {
      "source": "in model performance as the query vocabulary set expands",
      "target": "a challenge",
      "similarity": 0.8845
    },
    {
      "source": "in model performance as the query vocabulary set expands",
      "target": "TDy5Ih78b4",
      "similarity": 0.8699
    },
    {
      "source": "in model performance as the query vocabulary set expands",
      "target": "With regards to improving Shampoo's computational efficiency",
      "similarity": 0.8672
    },
    {
      "source": "in model performance as the query vocabulary set expands",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8662
    },
    {
      "source": "includes semantically similar and ambiguous vocabularies",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8681
    },
    {
      "source": "includes semantically similar and ambiguous vocabularies",
      "target": "However",
      "similarity": 0.8671
    },
    {
      "source": "includes semantically similar and ambiguous vocabularies",
      "target": "TDy5Ih78b4",
      "similarity": 0.8528
    },
    {
      "source": "includes semantically similar and ambiguous vocabularies",
      "target": "dgR6i4TSng",
      "similarity": 0.8463
    },
    {
      "source": "includes semantically similar and ambiguous vocabularies",
      "target": "yUC8pU508S",
      "similarity": 0.8457
    },
    {
      "source": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "target": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "similarity": 0.8289
    },
    {
      "source": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "target": "In this work",
      "similarity": 0.8277
    },
    {
      "source": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "target": "For example",
      "similarity": 0.823
    },
    {
      "source": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "target": "From this perspective",
      "similarity": 0.8117
    },
    {
      "source": "\u2018couch\u2019. The previous OVS evaluation protocol",
      "target": "md9qolJwLl",
      "similarity": 0.8082
    },
    {
      "source": "such ambiguity",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8336
    },
    {
      "source": "such ambiguity",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8318
    },
    {
      "source": "such ambiguity",
      "target": "uREg3OHjLL",
      "similarity": 0.8309
    },
    {
      "source": "such ambiguity",
      "target": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "similarity": 0.8269
    },
    {
      "source": "such ambiguity",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.823
    },
    {
      "source": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.8331
    },
    {
      "source": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "target": "large-scale",
      "similarity": 0.8226
    },
    {
      "source": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "target": "Moreover",
      "similarity": 0.8153
    },
    {
      "source": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8137
    },
    {
      "source": "pairs is simply treated as incorrect on a pixel-wise basis. This contradicts the open",
      "target": "However",
      "similarity": 0.8125
    },
    {
      "source": "nature of OVS",
      "target": "more effective and reliable evaluation framework for OVS models compared to the",
      "similarity": 0.9023
    },
    {
      "source": "nature of OVS",
      "target": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "similarity": 0.8502
    },
    {
      "source": "nature of OVS",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8193
    },
    {
      "source": "nature of OVS",
      "target": "mkuB677eMM",
      "similarity": 0.8138
    },
    {
      "source": "nature of OVS",
      "target": "mXHTifc1Fn",
      "similarity": 0.8119
    },
    {
      "source": "world perspective. To address this",
      "target": "NfCEVihkdC",
      "similarity": 0.9005
    },
    {
      "source": "world perspective. To address this",
      "target": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "similarity": 0.8911
    },
    {
      "source": "world perspective. To address this",
      "target": "From this perspective",
      "similarity": 0.8141
    },
    {
      "source": "world perspective. To address this",
      "target": "vjel3nWP2a",
      "similarity": 0.8125
    },
    {
      "source": "world perspective. To address this",
      "target": "In parallel",
      "similarity": 0.8122
    },
    {
      "source": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "target": "6ouZaBzeNO",
      "similarity": 0.8785
    },
    {
      "source": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8333
    },
    {
      "source": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "target": "l0ZzTvPfTw",
      "similarity": 0.8152
    },
    {
      "source": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "target": "connection component",
      "similarity": 0.8094
    },
    {
      "source": "and propose a mask-wise evaluation protocol that is based on matched and mis-",
      "target": "KeRwLLwZaw",
      "similarity": 0.8075
    },
    {
      "source": "matched mask pairs between prediction and annotation respectively. Extensive",
      "target": "Vz0CWFMPUe",
      "similarity": 0.9098
    },
    {
      "source": "matched mask pairs between prediction and annotation respectively. Extensive",
      "target": "nx9Z5Kva96",
      "similarity": 0.8831
    },
    {
      "source": "matched mask pairs between prediction and annotation respectively. Extensive",
      "target": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "similarity": 0.8648
    },
    {
      "source": "matched mask pairs between prediction and annotation respectively. Extensive",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8627
    },
    {
      "source": "matched mask pairs between prediction and annotation respectively. Extensive",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8569
    },
    {
      "source": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "target": "To remedy this problem",
      "similarity": 0.8711
    },
    {
      "source": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "target": "mnna9LUg7P",
      "similarity": 0.8461
    },
    {
      "source": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8434
    },
    {
      "source": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "target": "These tasks are built from geometry problems",
      "similarity": 0.84
    },
    {
      "source": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8398
    },
    {
      "source": "more effective and reliable evaluation framework for OVS models compared to the",
      "target": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "similarity": 0.8206
    },
    {
      "source": "more effective and reliable evaluation framework for OVS models compared to the",
      "target": "FPfCUJTsCn",
      "similarity": 0.8037
    },
    {
      "source": "more effective and reliable evaluation framework for OVS models compared to the",
      "target": "M5t0WvjfCg",
      "similarity": 0.8002
    },
    {
      "source": "more effective and reliable evaluation framework for OVS models compared to the",
      "target": "IDxZhXrpNf",
      "similarity": 0.7983
    },
    {
      "source": "more effective and reliable evaluation framework for OVS models compared to the",
      "target": "mkuB677eMM",
      "similarity": 0.7913
    },
    {
      "source": "previous pixel-wise approach on the perspective of open-world. Moreover",
      "target": "5AtlfHYCPa",
      "similarity": 0.8268
    },
    {
      "source": "previous pixel-wise approach on the perspective of open-world. Moreover",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8135
    },
    {
      "source": "previous pixel-wise approach on the perspective of open-world. Moreover",
      "target": "First",
      "similarity": 0.8091
    },
    {
      "source": "previous pixel-wise approach on the perspective of open-world. Moreover",
      "target": "Igm9bbkzHC",
      "similarity": 0.8086
    },
    {
      "source": "previous pixel-wise approach on the perspective of open-world. Moreover",
      "target": "RWJX5F5I9g",
      "similarity": 0.8062
    },
    {
      "source": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "target": "NTHMw8S1Ow",
      "similarity": 0.8276
    },
    {
      "source": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "target": "than existing search techniques",
      "similarity": 0.8226
    },
    {
      "source": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "target": "B2Fqu7Y2cd",
      "similarity": 0.8217
    },
    {
      "source": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "target": "HqjRlT65WX",
      "similarity": 0.8191
    },
    {
      "source": "sis of mismatched mask pairs reveals that a large amount of ambiguous categories",
      "target": "iLUcsecZJp",
      "similarity": 0.8174
    },
    {
      "source": "exist in commonly used OVS datasets. Interestingly",
      "target": "Due to these fairness constraints",
      "similarity": 0.8118
    },
    {
      "source": "exist in commonly used OVS datasets. Interestingly",
      "target": "comprehensive experiments",
      "similarity": 0.8106
    },
    {
      "source": "exist in commonly used OVS datasets. Interestingly",
      "target": "However",
      "similarity": 0.8051
    },
    {
      "source": "exist in commonly used OVS datasets. Interestingly",
      "target": "tasks in ways different than what text or static imagery can provide. However",
      "similarity": 0.8047
    },
    {
      "source": "exist in commonly used OVS datasets. Interestingly",
      "target": "rnJxelIZrq",
      "similarity": 0.8035
    },
    {
      "source": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "target": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "similarity": 0.8412
    },
    {
      "source": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "target": "To address these challenges",
      "similarity": 0.8387
    },
    {
      "source": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8369
    },
    {
      "source": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "target": "enhance reliability. This study investigates the efficacy of such approaches",
      "similarity": 0.8327
    },
    {
      "source": "ambiguities during both training and inference enhances capabilities of OVS mod-",
      "target": "rwqShzb9li",
      "similarity": 0.8319
    },
    {
      "source": "els. These findings and the new evaluation protocol encourage further exploration",
      "target": "l6QnSQizmN",
      "similarity": 0.851
    },
    {
      "source": "els. These findings and the new evaluation protocol encourage further exploration",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8458
    },
    {
      "source": "els. These findings and the new evaluation protocol encourage further exploration",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8443
    },
    {
      "source": "els. These findings and the new evaluation protocol encourage further exploration",
      "target": "In this paper",
      "similarity": 0.8355
    },
    {
      "source": "els. These findings and the new evaluation protocol encourage further exploration",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8322
    },
    {
      "source": "of the open nature of OVS",
      "target": "ZadnlOHsHv",
      "similarity": 0.79
    },
    {
      "source": "of the open nature of OVS",
      "target": "To remedy this problem",
      "similarity": 0.7819
    },
    {
      "source": "of the open nature of OVS",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.7811
    },
    {
      "source": "of the open nature of OVS",
      "target": "YOc5t8PHf2",
      "similarity": 0.7791
    },
    {
      "source": "of the open nature of OVS",
      "target": "PgXpOOqtyd",
      "similarity": 0.7763
    },
    {
      "source": "CI5Cj0vktS",
      "target": "SG1R2H3fa1",
      "similarity": 0.8318
    },
    {
      "source": "CI5Cj0vktS",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8228
    },
    {
      "source": "CI5Cj0vktS",
      "target": "Ax3uliEBVR",
      "similarity": 0.8159
    },
    {
      "source": "CI5Cj0vktS",
      "target": "Inspired by MuZero",
      "similarity": 0.8149
    },
    {
      "source": "CI5Cj0vktS",
      "target": "Therefore",
      "similarity": 0.8115
    },
    {
      "source": "zxO4WuVGns",
      "target": "In addition",
      "similarity": 0.8693
    },
    {
      "source": "zxO4WuVGns",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8624
    },
    {
      "source": "zxO4WuVGns",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8551
    },
    {
      "source": "zxO4WuVGns",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8539
    },
    {
      "source": "zxO4WuVGns",
      "target": "TYSQYx9vwd",
      "similarity": 0.8527
    },
    {
      "source": "RyWypcIMiE",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.877
    },
    {
      "source": "RyWypcIMiE",
      "target": "Tn5B6Udq3E",
      "similarity": 0.845
    },
    {
      "source": "RyWypcIMiE",
      "target": "J9FgrqOOni",
      "similarity": 0.8442
    },
    {
      "source": "RyWypcIMiE",
      "target": "Mjn53GtMxi",
      "similarity": 0.8388
    },
    {
      "source": "RyWypcIMiE",
      "target": "0fJfVOSUra",
      "similarity": 0.8329
    },
    {
      "source": "i3T0wvQDKg",
      "target": "1qGkuxI9UX",
      "similarity": 0.848
    },
    {
      "source": "i3T0wvQDKg",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8327
    },
    {
      "source": "i3T0wvQDKg",
      "target": "Yet",
      "similarity": 0.8302
    },
    {
      "source": "i3T0wvQDKg",
      "target": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "similarity": 0.8239
    },
    {
      "source": "i3T0wvQDKg",
      "target": "OhauMUNW8T",
      "similarity": 0.8179
    },
    {
      "source": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "target": "access to labeled test samples",
      "similarity": 0.866
    },
    {
      "source": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "target": "than existing search techniques",
      "similarity": 0.8541
    },
    {
      "source": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "target": "6F6qwdycgJ",
      "similarity": 0.8503
    },
    {
      "source": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8476
    },
    {
      "source": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "target": "However",
      "similarity": 0.8467
    },
    {
      "source": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "target": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "similarity": 0.846
    },
    {
      "source": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8438
    },
    {
      "source": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "target": "prompts. As such",
      "similarity": 0.8361
    },
    {
      "source": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "target": "FFE.\"",
      "similarity": 0.8331
    },
    {
      "source": "One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases",
      "target": "Ke2BEL4csm",
      "similarity": 0.8294
    },
    {
      "source": "We provide real data examples demonstrating validity",
      "target": "KzSGJy1PIf",
      "similarity": 0.8657
    },
    {
      "source": "We provide real data examples demonstrating validity",
      "target": "(including gradient-based",
      "similarity": 0.8579
    },
    {
      "source": "We provide real data examples demonstrating validity",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8576
    },
    {
      "source": "We provide real data examples demonstrating validity",
      "target": "frozen nonlinear manifolds",
      "similarity": 0.8553
    },
    {
      "source": "We provide real data examples demonstrating validity",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8496
    },
    {
      "source": "nzOD1we8Z4",
      "target": "6yENDA7J4G",
      "similarity": 0.8338
    },
    {
      "source": "nzOD1we8Z4",
      "target": "nYjAzwor9R",
      "similarity": 0.8269
    },
    {
      "source": "nzOD1we8Z4",
      "target": "fXJCqdUSVG",
      "similarity": 0.8197
    },
    {
      "source": "nzOD1we8Z4",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8191
    },
    {
      "source": "nzOD1we8Z4",
      "target": "First",
      "similarity": 0.8171
    },
    {
      "source": "SVRRQ8goQo",
      "target": "The framework automates the generation of query-response pairs using predefined rules",
      "similarity": 0.8183
    },
    {
      "source": "SVRRQ8goQo",
      "target": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "similarity": 0.8108
    },
    {
      "source": "SVRRQ8goQo",
      "target": "VoayJihXra",
      "similarity": 0.8046
    },
    {
      "source": "SVRRQ8goQo",
      "target": "To bridge this gap",
      "similarity": 0.8035
    },
    {
      "source": "SVRRQ8goQo",
      "target": "vaJ4FObpXN",
      "similarity": 0.8
    },
    {
      "source": "Based on this concept",
      "target": "PDnEDS244P",
      "similarity": 0.9303
    },
    {
      "source": "Based on this concept",
      "target": "2ea5TNVR0c",
      "similarity": 0.9088
    },
    {
      "source": "Based on this concept",
      "target": "bilities",
      "similarity": 0.8835
    },
    {
      "source": "Based on this concept",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8816
    },
    {
      "source": "Based on this concept",
      "target": "ZadnlOHsHv",
      "similarity": 0.8509
    },
    {
      "source": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "target": "To tackle this challenge",
      "similarity": 0.8772
    },
    {
      "source": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8741
    },
    {
      "source": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.874
    },
    {
      "source": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "target": "as representations of instances. In this work",
      "similarity": 0.8662
    },
    {
      "source": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "target": "qZEdmyqCHF",
      "similarity": 0.8648
    },
    {
      "source": "We perform detailed analyses",
      "target": "Ax0i933gtp",
      "similarity": 0.8875
    },
    {
      "source": "We perform detailed analyses",
      "target": "GpUv1FvZi1",
      "similarity": 0.8783
    },
    {
      "source": "We perform detailed analyses",
      "target": "pPQPQ7Yd58",
      "similarity": 0.8713
    },
    {
      "source": "We perform detailed analyses",
      "target": "TDy5Ih78b4",
      "similarity": 0.8685
    },
    {
      "source": "We perform detailed analyses",
      "target": "We evaluate performance across three integrated tasks",
      "similarity": 0.8652
    },
    {
      "source": "We evaluate performance across three integrated tasks",
      "target": "GpUv1FvZi1",
      "similarity": 0.8916
    },
    {
      "source": "We evaluate performance across three integrated tasks",
      "target": "TDy5Ih78b4",
      "similarity": 0.8552
    },
    {
      "source": "We evaluate performance across three integrated tasks",
      "target": "However",
      "similarity": 0.8549
    },
    {
      "source": "We evaluate performance across three integrated tasks",
      "target": "3cvwO5DBZn",
      "similarity": 0.8467
    },
    {
      "source": "We evaluate performance across three integrated tasks",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8462
    },
    {
      "source": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "target": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "similarity": 0.8862
    },
    {
      "source": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "target": "also struggle",
      "similarity": 0.8785
    },
    {
      "source": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "target": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "similarity": 0.8543
    },
    {
      "source": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "target": "solution. For $p = 1$",
      "similarity": 0.8476
    },
    {
      "source": "KOR-Bench aims to enhance reasoning evaluation and support further research in this area.\"",
      "target": "jj7b3p5kLY",
      "similarity": 0.8458
    },
    {
      "source": "mkDam1xIzW",
      "target": "RAyRXQjsFl",
      "similarity": 0.8835
    },
    {
      "source": "mkDam1xIzW",
      "target": "4GT9uTsAJE",
      "similarity": 0.8832
    },
    {
      "source": "mkDam1xIzW",
      "target": "fNMKqyvuZT",
      "similarity": 0.8829
    },
    {
      "source": "mkDam1xIzW",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8796
    },
    {
      "source": "mkDam1xIzW",
      "target": "{Subsequently}",
      "similarity": 0.878
    },
    {
      "source": "dkrEoT68by",
      "target": "uMEsKEiB7J",
      "similarity": 0.8261
    },
    {
      "source": "dkrEoT68by",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8119
    },
    {
      "source": "dkrEoT68by",
      "target": "zl3pfz4VCV",
      "similarity": 0.8105
    },
    {
      "source": "dkrEoT68by",
      "target": "Second",
      "similarity": 0.8078
    },
    {
      "source": "dkrEoT68by",
      "target": "MxbEiFRf39",
      "similarity": 0.8072
    },
    {
      "source": "Departing from this practice",
      "target": "MxbEiFRf39",
      "similarity": 0.8349
    },
    {
      "source": "Departing from this practice",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8304
    },
    {
      "source": "Departing from this practice",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8288
    },
    {
      "source": "Departing from this practice",
      "target": "Specifically",
      "similarity": 0.8159
    },
    {
      "source": "Departing from this practice",
      "target": "Second",
      "similarity": 0.8129
    },
    {
      "source": "OlRjxSuSwl",
      "target": "evaluate how well fine details are learned",
      "similarity": 0.83
    },
    {
      "source": "OlRjxSuSwl",
      "target": "To this end",
      "similarity": 0.822
    },
    {
      "source": "OlRjxSuSwl",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.8211
    },
    {
      "source": "OlRjxSuSwl",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8195
    },
    {
      "source": "OlRjxSuSwl",
      "target": "iOMnn1hSBO",
      "similarity": 0.8142
    },
    {
      "source": "L5godAOC2z",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.853
    },
    {
      "source": "L5godAOC2z",
      "target": "VIUisLx8lQ",
      "similarity": 0.8349
    },
    {
      "source": "L5godAOC2z",
      "target": "CLIP",
      "similarity": 0.8213
    },
    {
      "source": "L5godAOC2z",
      "target": "As the size of the model and data grows",
      "similarity": 0.819
    },
    {
      "source": "L5godAOC2z",
      "target": "cC3LxGZasH",
      "similarity": 0.8184
    },
    {
      "source": "rvvSSmGIFS",
      "target": "At the inference stage",
      "similarity": 0.8408
    },
    {
      "source": "rvvSSmGIFS",
      "target": "yR47RmND1m",
      "similarity": 0.8289
    },
    {
      "source": "rvvSSmGIFS",
      "target": "vqbd2OQnGp",
      "similarity": 0.8232
    },
    {
      "source": "rvvSSmGIFS",
      "target": "MJNywBdSDy",
      "similarity": 0.8128
    },
    {
      "source": "rvvSSmGIFS",
      "target": "standard training and",
      "similarity": 0.8125
    },
    {
      "source": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "target": "ih3BJmIZbC",
      "similarity": 0.866
    },
    {
      "source": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "target": "wkbx7BRAsM",
      "similarity": 0.8306
    },
    {
      "source": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "target": "GTcEe5fayC",
      "similarity": 0.8281
    },
    {
      "source": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "target": "2zmO1GVT0Y",
      "similarity": 0.8267
    },
    {
      "source": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "target": "YcUV5apdlq",
      "similarity": 0.8204
    },
    {
      "source": "bnINPG5A32",
      "target": "D2hhkU5O48",
      "similarity": 0.8345
    },
    {
      "source": "bnINPG5A32",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8343
    },
    {
      "source": "bnINPG5A32",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8287
    },
    {
      "source": "bnINPG5A32",
      "target": "In this paper",
      "similarity": 0.8175
    },
    {
      "source": "bnINPG5A32",
      "target": "Ev4iw23gdI",
      "similarity": 0.8101
    },
    {
      "source": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "target": "However",
      "similarity": 0.872
    },
    {
      "source": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "target": "HqjRlT65WX",
      "similarity": 0.8645
    },
    {
      "source": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "target": "S1Bv3068Xt",
      "similarity": 0.8594
    },
    {
      "source": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8522
    },
    {
      "source": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8513
    },
    {
      "source": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "target": "1F8xTfv6ah",
      "similarity": 0.883
    },
    {
      "source": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "target": "P6IVIoGRRg",
      "similarity": 0.8697
    },
    {
      "source": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "target": "xnF2U0ro7b",
      "similarity": 0.8513
    },
    {
      "source": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "target": "Aye5wL6TCn",
      "similarity": 0.8447
    },
    {
      "source": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "target": "In this work",
      "similarity": 0.8421
    },
    {
      "source": "The resulting drift not only overcomes the difficulties above",
      "target": "Yet",
      "similarity": 0.8515
    },
    {
      "source": "The resulting drift not only overcomes the difficulties above",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8488
    },
    {
      "source": "The resulting drift not only overcomes the difficulties above",
      "target": "JSB171dSUU",
      "similarity": 0.8481
    },
    {
      "source": "The resulting drift not only overcomes the difficulties above",
      "target": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "similarity": 0.8477
    },
    {
      "source": "The resulting drift not only overcomes the difficulties above",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8421
    },
    {
      "source": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "target": "First",
      "similarity": 0.8724
    },
    {
      "source": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "target": "In brief",
      "similarity": 0.8659
    },
    {
      "source": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8653
    },
    {
      "source": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "target": "However",
      "similarity": 0.8562
    },
    {
      "source": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8558
    },
    {
      "source": "With theoretical justification and empirical evidence",
      "target": "space",
      "similarity": 0.8326
    },
    {
      "source": "With theoretical justification and empirical evidence",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8202
    },
    {
      "source": "With theoretical justification and empirical evidence",
      "target": "goBaGHLAdP",
      "similarity": 0.8151
    },
    {
      "source": "With theoretical justification and empirical evidence",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.8142
    },
    {
      "source": "With theoretical justification and empirical evidence",
      "target": "imT03YXlG2",
      "similarity": 0.8126
    },
    {
      "source": "Further",
      "target": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "similarity": 0.8364
    },
    {
      "source": "Further",
      "target": "distribution shifts show our framework produces concept-based interpretations",
      "similarity": 0.8305
    },
    {
      "source": "Further",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8216
    },
    {
      "source": "Further",
      "target": "5xSRg3eYZz",
      "similarity": 0.8194
    },
    {
      "source": "Further",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.816
    },
    {
      "source": "SIuD7CySb4",
      "target": "FBhKUXK7od",
      "similarity": 0.8297
    },
    {
      "source": "SIuD7CySb4",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8289
    },
    {
      "source": "SIuD7CySb4",
      "target": "j8WHjM9aMm",
      "similarity": 0.8218
    },
    {
      "source": "SIuD7CySb4",
      "target": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "similarity": 0.8032
    },
    {
      "source": "SIuD7CySb4",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.802
    },
    {
      "source": "gY08Ou8EL7",
      "target": "UVnD9Ze6mF",
      "similarity": 0.8982
    },
    {
      "source": "gY08Ou8EL7",
      "target": "We release models",
      "similarity": 0.8655
    },
    {
      "source": "gY08Ou8EL7",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8558
    },
    {
      "source": "gY08Ou8EL7",
      "target": "To this end",
      "similarity": 0.8501
    },
    {
      "source": "gY08Ou8EL7",
      "target": "2mqb8bPHeb",
      "similarity": 0.8424
    },
    {
      "source": "Second",
      "target": "Building on these insights",
      "similarity": 0.8178
    },
    {
      "source": "Second",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.802
    },
    {
      "source": "Second",
      "target": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "similarity": 0.8018
    },
    {
      "source": "Second",
      "target": "8rbkePAapb",
      "similarity": 0.8014
    },
    {
      "source": "Second",
      "target": "zXCnIyX9MG",
      "similarity": 0.8011
    },
    {
      "source": "To address both challenges we augment the recently proposed",
      "target": "faceswaps",
      "similarity": 0.8843
    },
    {
      "source": "To address both challenges we augment the recently proposed",
      "target": "to address these failure modes",
      "similarity": 0.8785
    },
    {
      "source": "To address both challenges we augment the recently proposed",
      "target": "For TP",
      "similarity": 0.8779
    },
    {
      "source": "To address both challenges we augment the recently proposed",
      "target": "90DC0IvlSs",
      "similarity": 0.8739
    },
    {
      "source": "To address both challenges we augment the recently proposed",
      "target": "EQgEMAD4kv",
      "similarity": 0.8731
    },
    {
      "source": "dual shape representation",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8282
    },
    {
      "source": "dual shape representation",
      "target": "iVxxgZlXh6",
      "similarity": 0.8271
    },
    {
      "source": "dual shape representation",
      "target": "attribution and dataset selection.\"",
      "similarity": 0.8236
    },
    {
      "source": "dual shape representation",
      "target": "Unlike prior constructions that run encrypted search on the server side",
      "similarity": 0.817
    },
    {
      "source": "dual shape representation",
      "target": "In this paper",
      "similarity": 0.8077
    },
    {
      "source": "To improve reconstruction",
      "target": "In this work",
      "similarity": 0.8333
    },
    {
      "source": "To improve reconstruction",
      "target": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "similarity": 0.8229
    },
    {
      "source": "To improve reconstruction",
      "target": "Despite its simplicity",
      "similarity": 0.8223
    },
    {
      "source": "To improve reconstruction",
      "target": "7liN6uHAQZ",
      "similarity": 0.8198
    },
    {
      "source": "To improve reconstruction",
      "target": "connection component",
      "similarity": 0.8149
    },
    {
      "source": "To achieve computationally efficient yet high-resolution rendering",
      "target": "4O0v4s3IzY",
      "similarity": 0.8697
    },
    {
      "source": "To achieve computationally efficient yet high-resolution rendering",
      "target": "Moreover",
      "similarity": 0.8684
    },
    {
      "source": "To achieve computationally efficient yet high-resolution rendering",
      "target": "Finally",
      "similarity": 0.8637
    },
    {
      "source": "To achieve computationally efficient yet high-resolution rendering",
      "target": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "similarity": 0.8573
    },
    {
      "source": "To achieve computationally efficient yet high-resolution rendering",
      "target": "is often a non-linear function",
      "similarity": 0.8539
    },
    {
      "source": "We evaluate the proposed approach on the challenging THuman2.0",
      "target": "6NNA0MxhCH",
      "similarity": 0.8209
    },
    {
      "source": "We evaluate the proposed approach on the challenging THuman2.0",
      "target": "We provide new insights into the structure of this function class and develop",
      "similarity": 0.8191
    },
    {
      "source": "We evaluate the proposed approach on the challenging THuman2.0",
      "target": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "similarity": 0.8187
    },
    {
      "source": "We evaluate the proposed approach on the challenging THuman2.0",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.817
    },
    {
      "source": "We evaluate the proposed approach on the challenging THuman2.0",
      "target": "rTCJ29pkuA",
      "similarity": 0.8155
    },
    {
      "source": "00SnKBGTsz",
      "target": "KeRwLLwZaw",
      "similarity": 0.8121
    },
    {
      "source": "00SnKBGTsz",
      "target": "7liN6uHAQZ",
      "similarity": 0.812
    },
    {
      "source": "00SnKBGTsz",
      "target": "Real-world causal structures",
      "similarity": 0.8081
    },
    {
      "source": "00SnKBGTsz",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8007
    },
    {
      "source": "00SnKBGTsz",
      "target": "FPBce2P1er",
      "similarity": 0.7983
    },
    {
      "source": "MxbEiFRf39",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8651
    },
    {
      "source": "MxbEiFRf39",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8597
    },
    {
      "source": "MxbEiFRf39",
      "target": "Second",
      "similarity": 0.8579
    },
    {
      "source": "MxbEiFRf39",
      "target": "This success is driven by using our two data augmentation techniques and a multi-candidate inference strategy.",
      "similarity": 0.8573
    },
    {
      "source": "MxbEiFRf39",
      "target": "Specifically",
      "similarity": 0.8565
    },
    {
      "source": "Code",
      "target": "uNomADvF3s",
      "similarity": 0.8351
    },
    {
      "source": "Code",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8271
    },
    {
      "source": "Code",
      "target": "kxnoqaisCT",
      "similarity": 0.818
    },
    {
      "source": "Code",
      "target": "OFukl9Qg8P",
      "similarity": 0.8175
    },
    {
      "source": "Code",
      "target": "Building on these insights",
      "similarity": 0.8174
    },
    {
      "source": "rK0YJwL69S",
      "target": "LLM response) of potential edges",
      "similarity": 0.8181
    },
    {
      "source": "rK0YJwL69S",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8147
    },
    {
      "source": "rK0YJwL69S",
      "target": "Following these principles",
      "similarity": 0.8116
    },
    {
      "source": "rK0YJwL69S",
      "target": "iXbUquaWbl",
      "similarity": 0.8092
    },
    {
      "source": "rK0YJwL69S",
      "target": "https://sites.google.com/view/rnd-dagger\"",
      "similarity": 0.8084
    },
    {
      "source": "hXm0Wu2U9K",
      "target": "suz4utPr9Y",
      "similarity": 0.8688
    },
    {
      "source": "hXm0Wu2U9K",
      "target": "Pacmann carefully offloads limited computation and storage to the client",
      "similarity": 0.8662
    },
    {
      "source": "hXm0Wu2U9K",
      "target": "EEgYUccwsV",
      "similarity": 0.8652
    },
    {
      "source": "hXm0Wu2U9K",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8643
    },
    {
      "source": "hXm0Wu2U9K",
      "target": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "similarity": 0.8564
    },
    {
      "source": "In this paper",
      "target": "which requires only a parametrization of the velocity field $v_t$",
      "similarity": 0.8741
    },
    {
      "source": "In this paper",
      "target": "To this end",
      "similarity": 0.8685
    },
    {
      "source": "In this paper",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8581
    },
    {
      "source": "In this paper",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8571
    },
    {
      "source": "In this paper",
      "target": "2kGKsyhtvh",
      "similarity": 0.8558
    },
    {
      "source": "uNomADvF3s",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8512
    },
    {
      "source": "uNomADvF3s",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8391
    },
    {
      "source": "uNomADvF3s",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8331
    },
    {
      "source": "uNomADvF3s",
      "target": "In this paper",
      "similarity": 0.8211
    },
    {
      "source": "uNomADvF3s",
      "target": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "similarity": 0.8198
    },
    {
      "source": "TUvg5uwdeG",
      "target": "previous results.\"",
      "similarity": 0.8686
    },
    {
      "source": "TUvg5uwdeG",
      "target": "6GATHdOi1x",
      "similarity": 0.8678
    },
    {
      "source": "TUvg5uwdeG",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8616
    },
    {
      "source": "TUvg5uwdeG",
      "target": "Neb17mimVH",
      "similarity": 0.8612
    },
    {
      "source": "TUvg5uwdeG",
      "target": "tDIL7UXmSS",
      "similarity": 0.861
    },
    {
      "source": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "target": "Yk87CwhBDx",
      "similarity": 0.8511
    },
    {
      "source": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "target": "NHhjczmJjo",
      "similarity": 0.8508
    },
    {
      "source": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "target": "is often a non-linear function",
      "similarity": 0.8463
    },
    {
      "source": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "target": "4O0v4s3IzY",
      "similarity": 0.8414
    },
    {
      "source": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "target": "As a case study",
      "similarity": 0.8383
    },
    {
      "source": "First",
      "target": "P4XmKjXTrM",
      "similarity": 0.8524
    },
    {
      "source": "First",
      "target": "84WmbzikPP",
      "similarity": 0.8419
    },
    {
      "source": "First",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8397
    },
    {
      "source": "First",
      "target": "To remedy this problem",
      "similarity": 0.8368
    },
    {
      "source": "First",
      "target": "yFGR36PLDJ",
      "similarity": 0.8362
    },
    {
      "source": "Second",
      "target": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "similarity": 0.8594
    },
    {
      "source": "Second",
      "target": "than existing search techniques",
      "similarity": 0.8472
    },
    {
      "source": "Second",
      "target": "HE6pJoNnFp",
      "similarity": 0.8416
    },
    {
      "source": "Second",
      "target": "rTQNGQxm4K",
      "similarity": 0.8369
    },
    {
      "source": "Second",
      "target": "skGSOcrIj7",
      "similarity": 0.8309
    },
    {
      "source": "It was numerically observed that the linear interpolation",
      "target": "work that captures both architectures. We introduce a modification in the skip",
      "similarity": 0.846
    },
    {
      "source": "It was numerically observed that the linear interpolation",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8414
    },
    {
      "source": "It was numerically observed that the linear interpolation",
      "target": "Lastly",
      "similarity": 0.8322
    },
    {
      "source": "It was numerically observed that the linear interpolation",
      "target": "f7KxfUrRSb",
      "similarity": 0.8303
    },
    {
      "source": "It was numerically observed that the linear interpolation",
      "target": "4YzVF9isgD",
      "similarity": 0.8273
    },
    {
      "source": "which requires only a parametrization of the velocity field $v_t$",
      "target": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "similarity": 0.8816
    },
    {
      "source": "which requires only a parametrization of the velocity field $v_t$",
      "target": "To this end",
      "similarity": 0.8799
    },
    {
      "source": "which requires only a parametrization of the velocity field $v_t$",
      "target": "FXw0okNcOb",
      "similarity": 0.8762
    },
    {
      "source": "which requires only a parametrization of the velocity field $v_t$",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8658
    },
    {
      "source": "which requires only a parametrization of the velocity field $v_t$",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.865
    },
    {
      "source": "suffers from  a \"\"teleportation-of-mass\"\" issue.",
      "target": "WebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts",
      "similarity": 0.7824
    },
    {
      "source": "suffers from  a \"\"teleportation-of-mass\"\" issue.",
      "target": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "similarity": 0.7503
    },
    {
      "source": "Using tools from the Wasserstein geometry",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8272
    },
    {
      "source": "Using tools from the Wasserstein geometry",
      "target": "1CIUkpoata",
      "similarity": 0.826
    },
    {
      "source": "Using tools from the Wasserstein geometry",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.8214
    },
    {
      "source": "Using tools from the Wasserstein geometry",
      "target": "xQCXInDq0m",
      "similarity": 0.821
    },
    {
      "source": "Using tools from the Wasserstein geometry",
      "target": "41uZB8bDFh",
      "similarity": 0.8207
    },
    {
      "source": "we give an analytical example",
      "target": "74vnDs1R97",
      "similarity": 0.883
    },
    {
      "source": "we give an analytical example",
      "target": "pZiyCaVuti",
      "similarity": 0.8829
    },
    {
      "source": "we give an analytical example",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8829
    },
    {
      "source": "we give an analytical example",
      "target": "i7jAYFYDcM",
      "similarity": 0.8616
    },
    {
      "source": "we give an analytical example",
      "target": "To explore real-time segmentation",
      "similarity": 0.8599
    },
    {
      "source": "where we can precisely measure the explosion of the velocity field.",
      "target": "KvaDHPhhir",
      "similarity": 0.8646
    },
    {
      "source": "where we can precisely measure the explosion of the velocity field.",
      "target": "We further analyze the key effects of these neurons on the image classification task",
      "similarity": 0.8076
    },
    {
      "source": "where we can precisely measure the explosion of the velocity field.",
      "target": "MMwaQEVsAg",
      "similarity": 0.8032
    },
    {
      "source": "where we can precisely measure the explosion of the velocity field.",
      "target": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "similarity": 0.8013
    },
    {
      "source": "where we can precisely measure the explosion of the velocity field.",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.7961
    },
    {
      "source": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8586
    },
    {
      "source": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8525
    },
    {
      "source": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "target": "This corresponds to",
      "similarity": 0.8428
    },
    {
      "source": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "target": "Along our analysis",
      "similarity": 0.8402
    },
    {
      "source": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "target": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "similarity": 0.8376
    },
    {
      "source": "parametrize both $f_t$ and $v_t$",
      "target": "We provide new insights into the structure of this function class and develop",
      "similarity": 0.8212
    },
    {
      "source": "parametrize both $f_t$ and $v_t$",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8166
    },
    {
      "source": "parametrize both $f_t$ and $v_t$",
      "target": "mobile devices.\"",
      "similarity": 0.8107
    },
    {
      "source": "parametrize both $f_t$ and $v_t$",
      "target": "To address this",
      "similarity": 0.8093
    },
    {
      "source": "parametrize both $f_t$ and $v_t$",
      "target": "dEg5SdGaiq",
      "similarity": 0.8085
    },
    {
      "source": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "target": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "similarity": 0.8537
    },
    {
      "source": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "target": "K4FAFNRpko",
      "similarity": 0.8531
    },
    {
      "source": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "target": "fXb9BbuyAD",
      "similarity": 0.8525
    },
    {
      "source": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "target": "frozen nonlinear manifolds",
      "similarity": 0.8451
    },
    {
      "source": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "target": "mnna9LUg7P",
      "similarity": 0.8382
    },
    {
      "source": "This corresponds to",
      "target": "gsShHPxkUW",
      "similarity": 0.8776
    },
    {
      "source": "This corresponds to",
      "target": "EW6bNEqalF",
      "similarity": 0.8659
    },
    {
      "source": "This corresponds to",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8646
    },
    {
      "source": "This corresponds to",
      "target": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "similarity": 0.8609
    },
    {
      "source": "This corresponds to",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.852
    },
    {
      "source": "the Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics.",
      "target": "Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.\"",
      "similarity": 0.7753
    },
    {
      "source": "the Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics.",
      "target": "mNVR9jJYqK",
      "similarity": 0.7735
    },
    {
      "source": "the Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics.",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.7687
    },
    {
      "source": "the Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics.",
      "target": "LM4PYXBId5",
      "similarity": 0.7641
    },
    {
      "source": "the Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics.",
      "target": "Our experimental evaluations on four distinct datasets",
      "similarity": 0.7614
    },
    {
      "source": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "target": "6qUUgw9bAZ",
      "similarity": 0.8039
    },
    {
      "source": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "target": "In offline evaluations",
      "similarity": 0.7974
    },
    {
      "source": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "target": "Given a dataset comprising several groups",
      "similarity": 0.7874
    },
    {
      "source": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "target": "However",
      "similarity": 0.7819
    },
    {
      "source": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "target": "which",
      "similarity": 0.777
    },
    {
      "source": "hPWWXpCaJ7",
      "target": "layers",
      "similarity": 0.8466
    },
    {
      "source": "hPWWXpCaJ7",
      "target": "In this paper",
      "similarity": 0.846
    },
    {
      "source": "hPWWXpCaJ7",
      "target": "D2hhkU5O48",
      "similarity": 0.8442
    },
    {
      "source": "hPWWXpCaJ7",
      "target": "fundamentally different from FFEs",
      "similarity": 0.832
    },
    {
      "source": "hPWWXpCaJ7",
      "target": "Ev4iw23gdI",
      "similarity": 0.8271
    },
    {
      "source": "4l3AH8Bhmt",
      "target": "Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.",
      "similarity": 0.7906
    },
    {
      "source": "4l3AH8Bhmt",
      "target": "8RCmNLeeXx",
      "similarity": 0.7777
    },
    {
      "source": "4l3AH8Bhmt",
      "target": "hwnObmOTrV",
      "similarity": 0.7771
    },
    {
      "source": "4l3AH8Bhmt",
      "target": "Vanilla SFT (i.e.",
      "similarity": 0.7675
    },
    {
      "source": "4l3AH8Bhmt",
      "target": "YslOW2SO6S",
      "similarity": 0.7643
    },
    {
      "source": "Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8318
    },
    {
      "source": "Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge",
      "target": "Oeb0I3JcVc",
      "similarity": 0.8146
    },
    {
      "source": "Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge",
      "target": "ptjrpEGrGg",
      "similarity": 0.8069
    },
    {
      "source": "Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge",
      "target": "SG1R2H3fa1",
      "similarity": 0.8067
    },
    {
      "source": "Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge",
      "target": "However",
      "similarity": 0.8003
    },
    {
      "source": "To mitigate such Attention Drift issue",
      "target": "In particular",
      "similarity": 0.8223
    },
    {
      "source": "To mitigate such Attention Drift issue",
      "target": "Code",
      "similarity": 0.8125
    },
    {
      "source": "To mitigate such Attention Drift issue",
      "target": "OuLgaHEmzi",
      "similarity": 0.8121
    },
    {
      "source": "To mitigate such Attention Drift issue",
      "target": "We then leverage a popular data compression technique",
      "similarity": 0.811
    },
    {
      "source": "To mitigate such Attention Drift issue",
      "target": "aliasing if pushed too far",
      "similarity": 0.8068
    },
    {
      "source": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "target": "X0epAjg0hd",
      "similarity": 0.8633
    },
    {
      "source": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "target": "7bAjVh3CG3",
      "similarity": 0.8343
    },
    {
      "source": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "target": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "similarity": 0.8216
    },
    {
      "source": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "target": "3RSLW9YSgk",
      "similarity": 0.8212
    },
    {
      "source": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "target": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "similarity": 0.821
    },
    {
      "source": "pCj2sLNoJq",
      "target": "BL4WBIfyrz",
      "similarity": 0.8741
    },
    {
      "source": "pCj2sLNoJq",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8695
    },
    {
      "source": "pCj2sLNoJq",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8649
    },
    {
      "source": "pCj2sLNoJq",
      "target": "riieAeQBJm",
      "similarity": 0.8592
    },
    {
      "source": "pCj2sLNoJq",
      "target": "HN8V0flwJF",
      "similarity": 0.8489
    },
    {
      "source": "d9aWa875kj",
      "target": "txD9llAYn9",
      "similarity": 0.8488
    },
    {
      "source": "d9aWa875kj",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8448
    },
    {
      "source": "d9aWa875kj",
      "target": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "similarity": 0.8389
    },
    {
      "source": "d9aWa875kj",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8317
    },
    {
      "source": "d9aWa875kj",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8295
    },
    {
      "source": "5RUM1aIdok",
      "target": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "similarity": 0.8175
    },
    {
      "source": "5RUM1aIdok",
      "target": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "similarity": 0.7988
    },
    {
      "source": "5RUM1aIdok",
      "target": "gWgaypDBs8",
      "similarity": 0.7925
    },
    {
      "source": "5RUM1aIdok",
      "target": "Tz8Li6G2xU",
      "similarity": 0.7786
    },
    {
      "source": "5RUM1aIdok",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.7706
    },
    {
      "source": "cwuSAR7EKd",
      "target": "rWQDzq3O5c",
      "similarity": 0.9018
    },
    {
      "source": "cwuSAR7EKd",
      "target": "We also identify how inference scaling in tree search would impact model performance.",
      "similarity": 0.8673
    },
    {
      "source": "cwuSAR7EKd",
      "target": "Moreover",
      "similarity": 0.8297
    },
    {
      "source": "cwuSAR7EKd",
      "target": "lS2SGfWizd",
      "similarity": 0.8287
    },
    {
      "source": "cwuSAR7EKd",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.8176
    },
    {
      "source": "1ExfUpmIW4",
      "target": "GhexuBLxbO",
      "similarity": 0.8336
    },
    {
      "source": "1ExfUpmIW4",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.832
    },
    {
      "source": "1ExfUpmIW4",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8127
    },
    {
      "source": "1ExfUpmIW4",
      "target": "We design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.",
      "similarity": 0.8104
    },
    {
      "source": "1ExfUpmIW4",
      "target": "5btFIv2PNb",
      "similarity": 0.8095
    },
    {
      "source": "Zk9guOl9NS",
      "target": "wide dissemination",
      "similarity": 0.8653
    },
    {
      "source": "Zk9guOl9NS",
      "target": "named Pacmann",
      "similarity": 0.8475
    },
    {
      "source": "Zk9guOl9NS",
      "target": "hjROBHstZ3",
      "similarity": 0.8463
    },
    {
      "source": "Zk9guOl9NS",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8434
    },
    {
      "source": "Zk9guOl9NS",
      "target": "To develop SoundCTM",
      "similarity": 0.8432
    },
    {
      "source": "kmgrlG9TR0",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8559
    },
    {
      "source": "kmgrlG9TR0",
      "target": "For that purpose",
      "similarity": 0.8555
    },
    {
      "source": "kmgrlG9TR0",
      "target": "dOAkHmsjRX",
      "similarity": 0.8441
    },
    {
      "source": "kmgrlG9TR0",
      "target": "BI2int5SAC",
      "similarity": 0.8393
    },
    {
      "source": "kmgrlG9TR0",
      "target": "EyaH1wzmao",
      "similarity": 0.8388
    },
    {
      "source": "We demonstrate a positive correlation between our benchmark and the downstream alignment task performance. Based on our benchmark",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.7978
    },
    {
      "source": "We demonstrate a positive correlation between our benchmark and the downstream alignment task performance. Based on our benchmark",
      "target": "introduce a novel inductive graph framework",
      "similarity": 0.7961
    },
    {
      "source": "We demonstrate a positive correlation between our benchmark and the downstream alignment task performance. Based on our benchmark",
      "target": "Prior research has shown that any polynomial-time algorithm under the statistical query (SQ) framework requires $\\Omega(d^{s^\\star/2}\\lor d)$ samples",
      "similarity": 0.786
    },
    {
      "source": "We demonstrate a positive correlation between our benchmark and the downstream alignment task performance. Based on our benchmark",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.7818
    },
    {
      "source": "We demonstrate a positive correlation between our benchmark and the downstream alignment task performance. Based on our benchmark",
      "target": "cfKZ5VrhXt",
      "similarity": 0.781
    },
    {
      "source": "44hcrfzydU",
      "target": "Mjn53GtMxi",
      "similarity": 0.8599
    },
    {
      "source": "44hcrfzydU",
      "target": "AcVpLS86RT",
      "similarity": 0.8587
    },
    {
      "source": "44hcrfzydU",
      "target": "Due to the high costs of setting up and running experiments",
      "similarity": 0.8541
    },
    {
      "source": "44hcrfzydU",
      "target": "In this task",
      "similarity": 0.8503
    },
    {
      "source": "44hcrfzydU",
      "target": "However",
      "similarity": 0.8427
    },
    {
      "source": "AmEgWDhmTr",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8373
    },
    {
      "source": "AmEgWDhmTr",
      "target": "5xSRg3eYZz",
      "similarity": 0.8329
    },
    {
      "source": "AmEgWDhmTr",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8289
    },
    {
      "source": "AmEgWDhmTr",
      "target": "vl7kf0YHwj",
      "similarity": 0.828
    },
    {
      "source": "AmEgWDhmTr",
      "target": "YvKJGYL4j7",
      "similarity": 0.8269
    },
    {
      "source": "fjEZ2LPceZ",
      "target": "constraints and dynamics",
      "similarity": 0.8519
    },
    {
      "source": "fjEZ2LPceZ",
      "target": "rTCJ29pkuA",
      "similarity": 0.8224
    },
    {
      "source": "fjEZ2LPceZ",
      "target": "This paper proposes",
      "similarity": 0.8221
    },
    {
      "source": "fjEZ2LPceZ",
      "target": "Q150eWkQ4I",
      "similarity": 0.8147
    },
    {
      "source": "fjEZ2LPceZ",
      "target": "6NNA0MxhCH",
      "similarity": 0.8118
    },
    {
      "source": "254NJe9JEw",
      "target": "nCrJD7qPJN",
      "similarity": 0.8804
    },
    {
      "source": "254NJe9JEw",
      "target": "To this end",
      "similarity": 0.8763
    },
    {
      "source": "254NJe9JEw",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8731
    },
    {
      "source": "254NJe9JEw",
      "target": "On the other hand",
      "similarity": 0.8726
    },
    {
      "source": "254NJe9JEw",
      "target": "3E8YNv1HjU",
      "similarity": 0.8722
    },
    {
      "source": "NWb128pSCb",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.8631
    },
    {
      "source": "NWb128pSCb",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.859
    },
    {
      "source": "NWb128pSCb",
      "target": "wide dissemination",
      "similarity": 0.8589
    },
    {
      "source": "NWb128pSCb",
      "target": "5M0ic2RxQZ",
      "similarity": 0.8576
    },
    {
      "source": "NWb128pSCb",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8456
    },
    {
      "source": "However",
      "target": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "similarity": 0.8637
    },
    {
      "source": "However",
      "target": "cation",
      "similarity": 0.8328
    },
    {
      "source": "However",
      "target": "Bl3e8HV9xW",
      "similarity": 0.8254
    },
    {
      "source": "However",
      "target": "layers",
      "similarity": 0.8212
    },
    {
      "source": "However",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8152
    },
    {
      "source": "To address these deficiencies",
      "target": "TrVYEZtSQH",
      "similarity": 0.7899
    },
    {
      "source": "To address these deficiencies",
      "target": "In this paper",
      "similarity": 0.7806
    },
    {
      "source": "To address these deficiencies",
      "target": "space for $p > 1$",
      "similarity": 0.7735
    },
    {
      "source": "To address these deficiencies",
      "target": "However",
      "similarity": 0.7686
    },
    {
      "source": "To address these deficiencies",
      "target": "huuKoVQnB0",
      "similarity": 0.7617
    },
    {
      "source": "Semantic variations are achieved through two types of linguistic permutations",
      "target": "Usklli4gMc",
      "similarity": 0.8501
    },
    {
      "source": "Semantic variations are achieved through two types of linguistic permutations",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8413
    },
    {
      "source": "Semantic variations are achieved through two types of linguistic permutations",
      "target": "sIE2rI3ZPs",
      "similarity": 0.8391
    },
    {
      "source": "Semantic variations are achieved through two types of linguistic permutations",
      "target": "Jszf4et48m",
      "similarity": 0.8355
    },
    {
      "source": "Semantic variations are achieved through two types of linguistic permutations",
      "target": "extreme weather forecasts to enhance their practical utility\"",
      "similarity": 0.835
    },
    {
      "source": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "target": "Building on these insights",
      "similarity": 0.8859
    },
    {
      "source": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "target": "pQsllTesiE",
      "similarity": 0.7905
    },
    {
      "source": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "target": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "similarity": 0.7886
    },
    {
      "source": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "target": "Fs9EabmQrJ",
      "similarity": 0.7879
    },
    {
      "source": "Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.7861
    },
    {
      "source": "We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations",
      "target": "To tackle these challenges",
      "similarity": 0.8887
    },
    {
      "source": "We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.8715
    },
    {
      "source": "We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations",
      "target": "In contrast",
      "similarity": 0.8555
    },
    {
      "source": "We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations",
      "target": "Second",
      "similarity": 0.8486
    },
    {
      "source": "We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations",
      "target": "nCrJD7qPJN",
      "similarity": 0.845
    },
    {
      "source": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "target": "{Subsequently}",
      "similarity": 0.8921
    },
    {
      "source": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8874
    },
    {
      "source": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8805
    },
    {
      "source": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "target": "fNMKqyvuZT",
      "similarity": 0.8785
    },
    {
      "source": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "target": "Lut5t3qElA",
      "similarity": 0.8782
    },
    {
      "source": "eU39PDsZtT",
      "target": "Thus",
      "similarity": 0.883
    },
    {
      "source": "eU39PDsZtT",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.8547
    },
    {
      "source": "eU39PDsZtT",
      "target": "introduce a novel inductive graph framework",
      "similarity": 0.839
    },
    {
      "source": "eU39PDsZtT",
      "target": "constraints and dynamics",
      "similarity": 0.8222
    },
    {
      "source": "eU39PDsZtT",
      "target": "In this paper",
      "similarity": 0.8141
    },
    {
      "source": "present significant challenges in efficiently selecting the appropriate LLM for",
      "target": "JytL2MrlLT",
      "similarity": 0.8886
    },
    {
      "source": "present significant challenges in efficiently selecting the appropriate LLM for",
      "target": "V4K9h1qNxE",
      "similarity": 0.8715
    },
    {
      "source": "present significant challenges in efficiently selecting the appropriate LLM for",
      "target": "1CIUkpoata",
      "similarity": 0.8687
    },
    {
      "source": "present significant challenges in efficiently selecting the appropriate LLM for",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8655
    },
    {
      "source": "present significant challenges in efficiently selecting the appropriate LLM for",
      "target": "wgRQ2WAORJ",
      "similarity": 0.857
    },
    {
      "source": "a given query",
      "target": "by focusing on efficiently solving the underlying optimization problem using a general",
      "similarity": 0.7847
    },
    {
      "source": "a given query",
      "target": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "similarity": 0.7673
    },
    {
      "source": "a given query",
      "target": "ZadnlOHsHv",
      "similarity": 0.7658
    },
    {
      "source": "a given query",
      "target": "Prediction (NWP) systems on HR-Extreme",
      "similarity": 0.7656
    },
    {
      "source": "a given query",
      "target": "LvRQgsvd5V",
      "similarity": 0.7647
    },
    {
      "source": "computational cost. Current LLM selection methods often struggle to generalize",
      "target": "HN8V0flwJF",
      "similarity": 0.8661
    },
    {
      "source": "computational cost. Current LLM selection methods often struggle to generalize",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8474
    },
    {
      "source": "computational cost. Current LLM selection methods often struggle to generalize",
      "target": "Glm7Kj47nN",
      "similarity": 0.8401
    },
    {
      "source": "computational cost. Current LLM selection methods often struggle to generalize",
      "target": "JvkuZZ04O7",
      "similarity": 0.8366
    },
    {
      "source": "computational cost. Current LLM selection methods often struggle to generalize",
      "target": "However",
      "similarity": 0.8256
    },
    {
      "source": "across new LLMs and different tasks because of their limited ability to leverage",
      "target": "sahQq2sH5x",
      "similarity": 0.8682
    },
    {
      "source": "across new LLMs and different tasks because of their limited ability to leverage",
      "target": "relying on backward propagation",
      "similarity": 0.8633
    },
    {
      "source": "across new LLMs and different tasks because of their limited ability to leverage",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8605
    },
    {
      "source": "across new LLMs and different tasks because of their limited ability to leverage",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.859
    },
    {
      "source": "across new LLMs and different tasks because of their limited ability to leverage",
      "target": "To address this limitation",
      "similarity": 0.8567
    },
    {
      "source": "contextual interactions among tasks",
      "target": "03OkC0LKDD",
      "similarity": 0.8648
    },
    {
      "source": "contextual interactions among tasks",
      "target": "U834XHJuqk",
      "similarity": 0.853
    },
    {
      "source": "contextual interactions among tasks",
      "target": "GeUK3zGreN",
      "similarity": 0.8392
    },
    {
      "source": "contextual interactions among tasks",
      "target": "A1HhtITVEi",
      "similarity": 0.8273
    },
    {
      "source": "contextual interactions among tasks",
      "target": "9qpdDiDQ2H",
      "similarity": 0.8267
    },
    {
      "source": "dence on a transductive learning framework. To address these shortcomings",
      "target": "fine-tuning of a shallow fully-connected network following the representation.",
      "similarity": 0.808
    },
    {
      "source": "dence on a transductive learning framework. To address these shortcomings",
      "target": "While our convergence rate estimates recover existing results for minimizing",
      "similarity": 0.8075
    },
    {
      "source": "dence on a transductive learning framework. To address these shortcomings",
      "target": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "similarity": 0.8073
    },
    {
      "source": "dence on a transductive learning framework. To address these shortcomings",
      "target": "AoIKgHu9Si",
      "similarity": 0.8028
    },
    {
      "source": "dence on a transductive learning framework. To address these shortcomings",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8013
    },
    {
      "source": "introduce a novel inductive graph framework",
      "target": "constraints and dynamics",
      "similarity": 0.8776
    },
    {
      "source": "introduce a novel inductive graph framework",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.853
    },
    {
      "source": "introduce a novel inductive graph framework",
      "target": "Thus",
      "similarity": 0.8494
    },
    {
      "source": "introduce a novel inductive graph framework",
      "target": "rTCJ29pkuA",
      "similarity": 0.8381
    },
    {
      "source": "introduce a novel inductive graph framework",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8187
    },
    {
      "source": "fully utilizes the contextual information among tasks",
      "target": "FxNNiUgtfa",
      "similarity": 0.8121
    },
    {
      "source": "fully utilizes the contextual information among tasks",
      "target": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "similarity": 0.8072
    },
    {
      "source": "fully utilizes the contextual information among tasks",
      "target": "$$",
      "similarity": 0.7965
    },
    {
      "source": "fully utilizes the contextual information among tasks",
      "target": "8vzMLo8LDN",
      "similarity": 0.7963
    },
    {
      "source": "fully utilizes the contextual information among tasks",
      "target": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "similarity": 0.7945
    },
    {
      "source": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "target": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "similarity": 0.8366
    },
    {
      "source": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8251
    },
    {
      "source": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "target": "QsA3YzNUxA",
      "similarity": 0.8222
    },
    {
      "source": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "target": "paradigms show promise",
      "similarity": 0.8216
    },
    {
      "source": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.8208
    },
    {
      "source": "graph comprising task",
      "target": "hovDbX4Gh6",
      "similarity": 0.8508
    },
    {
      "source": "graph comprising task",
      "target": "In this paper",
      "similarity": 0.8504
    },
    {
      "source": "graph comprising task",
      "target": "MyVC4X5B2X",
      "similarity": 0.8469
    },
    {
      "source": "graph comprising task",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8442
    },
    {
      "source": "graph comprising task",
      "target": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "similarity": 0.8387
    },
    {
      "source": "edges",
      "target": "qZEdmyqCHF",
      "similarity": 0.8613
    },
    {
      "source": "edges",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8513
    },
    {
      "source": "edges",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8499
    },
    {
      "source": "edges",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8478
    },
    {
      "source": "edges",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8397
    },
    {
      "source": "requirements and the LLM\u2019s capabilities. Through an innovative edge prediction",
      "target": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "similarity": 0.8239
    },
    {
      "source": "requirements and the LLM\u2019s capabilities. Through an innovative edge prediction",
      "target": "xzSUdw6s76",
      "similarity": 0.8041
    },
    {
      "source": "requirements and the LLM\u2019s capabilities. Through an innovative edge prediction",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8003
    },
    {
      "source": "requirements and the LLM\u2019s capabilities. Through an innovative edge prediction",
      "target": "We evaluate nearly 40 reward models on RM-Bench.",
      "similarity": 0.8
    },
    {
      "source": "requirements and the LLM\u2019s capabilities. Through an innovative edge prediction",
      "target": "pHOH8FVrTp",
      "similarity": 0.7967
    },
    {
      "source": "mechanism",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8545
    },
    {
      "source": "mechanism",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8349
    },
    {
      "source": "mechanism",
      "target": "8TBGdH3t6a",
      "similarity": 0.8322
    },
    {
      "source": "mechanism",
      "target": "G328D1xt4W",
      "similarity": 0.8289
    },
    {
      "source": "mechanism",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8287
    },
    {
      "source": "LLM response) of potential edges",
      "target": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "similarity": 0.8101
    },
    {
      "source": "LLM response) of potential edges",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.795
    },
    {
      "source": "LLM response) of potential edges",
      "target": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "similarity": 0.7883
    },
    {
      "source": "LLM response) of potential edges",
      "target": "Prior methods improve accuracy using external semantic supervision",
      "similarity": 0.787
    },
    {
      "source": "LLM response) of potential edges",
      "target": "KW8yzAOIZr",
      "similarity": 0.7829
    },
    {
      "source": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "target": "Our experimental results demonstrate that with enhanced disentanglement capa-",
      "similarity": 0.8063
    },
    {
      "source": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "target": "vaJ4FObpXN",
      "similarity": 0.8033
    },
    {
      "source": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "target": "S85PP4xjFD",
      "similarity": 0.7981
    },
    {
      "source": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "target": "mnna9LUg7P",
      "similarity": 0.7952
    },
    {
      "source": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "target": "To tackle this challenge",
      "similarity": 0.7948
    },
    {
      "source": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8129
    },
    {
      "source": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8104
    },
    {
      "source": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "target": "Furthermore",
      "similarity": 0.8102
    },
    {
      "source": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "target": "odvSjn416y",
      "similarity": 0.7892
    },
    {
      "source": "Comprehensive experiments across three distinct effect-cost weight scenarios have",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.7891
    },
    {
      "source": "shown that GraphRouter substantially surpasses existing routers",
      "target": "To this end",
      "similarity": 0.8733
    },
    {
      "source": "shown that GraphRouter substantially surpasses existing routers",
      "target": "Moreover",
      "similarity": 0.8713
    },
    {
      "source": "shown that GraphRouter substantially surpasses existing routers",
      "target": "IuU0wcO0mo",
      "similarity": 0.8627
    },
    {
      "source": "shown that GraphRouter substantially surpasses existing routers",
      "target": "74vnDs1R97",
      "similarity": 0.8587
    },
    {
      "source": "shown that GraphRouter substantially surpasses existing routers",
      "target": "previous results.\"",
      "similarity": 0.858
    },
    {
      "source": "minimum performance improvement of 12.3%. In addition",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8767
    },
    {
      "source": "minimum performance improvement of 12.3%. In addition",
      "target": "xiQNfYl33p",
      "similarity": 0.8666
    },
    {
      "source": "minimum performance improvement of 12.3%. In addition",
      "target": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "similarity": 0.8608
    },
    {
      "source": "minimum performance improvement of 12.3%. In addition",
      "target": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "similarity": 0.8607
    },
    {
      "source": "minimum performance improvement of 12.3%. In addition",
      "target": "5M0ic2RxQZ",
      "similarity": 0.8601
    },
    {
      "source": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "target": "a challenge",
      "similarity": 0.8988
    },
    {
      "source": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "target": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "similarity": 0.8669
    },
    {
      "source": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8623
    },
    {
      "source": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.861
    },
    {
      "source": "generalization across new LLMs settings and supports diverse tasks with at least a",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8597
    },
    {
      "source": "9.5% boost in effect and a significant reduction in computational demands. This",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8545
    },
    {
      "source": "9.5% boost in effect and a significant reduction in computational demands. This",
      "target": "aTYexOYlLb",
      "similarity": 0.8543
    },
    {
      "source": "9.5% boost in effect and a significant reduction in computational demands. This",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8532
    },
    {
      "source": "9.5% boost in effect and a significant reduction in computational demands. This",
      "target": "n2NidsYDop",
      "similarity": 0.8516
    },
    {
      "source": "9.5% boost in effect and a significant reduction in computational demands. This",
      "target": "INqLJwqUmc",
      "similarity": 0.8394
    },
    {
      "source": "work endeavors to apply a graph-based approach for the contextual and adaptive",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8022
    },
    {
      "source": "work endeavors to apply a graph-based approach for the contextual and adaptive",
      "target": "Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets",
      "similarity": 0.7984
    },
    {
      "source": "work endeavors to apply a graph-based approach for the contextual and adaptive",
      "target": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "similarity": 0.7927
    },
    {
      "source": "work endeavors to apply a graph-based approach for the contextual and adaptive",
      "target": "e8qXTxMgPg",
      "similarity": 0.7865
    },
    {
      "source": "work endeavors to apply a graph-based approach for the contextual and adaptive",
      "target": "FBhKUXK7od",
      "similarity": 0.7842
    },
    {
      "source": "selection of LLMs",
      "target": "wmV4cIbgl6",
      "similarity": 0.862
    },
    {
      "source": "selection of LLMs",
      "target": "additional structural constraints",
      "similarity": 0.839
    },
    {
      "source": "selection of LLMs",
      "target": "aTYexOYlLb",
      "similarity": 0.8383
    },
    {
      "source": "selection of LLMs",
      "target": "GySIAKEwtZ",
      "similarity": 0.8325
    },
    {
      "source": "selection of LLMs",
      "target": "AoIKgHu9Si",
      "similarity": 0.8315
    },
    {
      "source": "8sfc8MwG5v",
      "target": "x$",
      "similarity": 0.8526
    },
    {
      "source": "8sfc8MwG5v",
      "target": "that",
      "similarity": 0.8256
    },
    {
      "source": "8sfc8MwG5v",
      "target": "It contains three fundamental sub-tasks: interactive segmentation",
      "similarity": 0.8229
    },
    {
      "source": "8sfc8MwG5v",
      "target": "MBBRHDuiwM",
      "similarity": 0.8218
    },
    {
      "source": "8sfc8MwG5v",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8211
    },
    {
      "source": "learning. The rich",
      "target": "In this setting",
      "similarity": 0.8421
    },
    {
      "source": "learning. The rich",
      "target": "U3PBITXNG6",
      "similarity": 0.8285
    },
    {
      "source": "learning. The rich",
      "target": "TUvg5uwdeG",
      "similarity": 0.8233
    },
    {
      "source": "learning. The rich",
      "target": "improving model efficacy",
      "similarity": 0.8225
    },
    {
      "source": "learning. The rich",
      "target": "Neb17mimVH",
      "similarity": 0.8153
    },
    {
      "source": "scale FMs are leveraged for multiple downstream tasks",
      "target": "4O0v4s3IzY",
      "similarity": 0.8592
    },
    {
      "source": "scale FMs are leveraged for multiple downstream tasks",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8529
    },
    {
      "source": "scale FMs are leveraged for multiple downstream tasks",
      "target": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "similarity": 0.8473
    },
    {
      "source": "scale FMs are leveraged for multiple downstream tasks",
      "target": "EyaH1wzmao",
      "similarity": 0.8447
    },
    {
      "source": "scale FMs are leveraged for multiple downstream tasks",
      "target": "dOAkHmsjRX",
      "similarity": 0.8434
    },
    {
      "source": "fine-tuning of a shallow fully-connected network following the representation.",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8665
    },
    {
      "source": "fine-tuning of a shallow fully-connected network following the representation.",
      "target": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "similarity": 0.8485
    },
    {
      "source": "fine-tuning of a shallow fully-connected network following the representation.",
      "target": "Additionally",
      "similarity": 0.8184
    },
    {
      "source": "fine-tuning of a shallow fully-connected network following the representation.",
      "target": "AoIKgHu9Si",
      "similarity": 0.8179
    },
    {
      "source": "fine-tuning of a shallow fully-connected network following the representation.",
      "target": "bsFWJ0Kget",
      "similarity": 0.8159
    },
    {
      "source": "However",
      "target": "HqjRlT65WX",
      "similarity": 0.8562
    },
    {
      "source": "However",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8541
    },
    {
      "source": "However",
      "target": "KAIqwkB3dT",
      "similarity": 0.8493
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8391
    },
    {
      "source": "However",
      "target": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "similarity": 0.8386
    },
    {
      "source": "a challenge",
      "target": "TDy5Ih78b4",
      "similarity": 0.8881
    },
    {
      "source": "a challenge",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.88
    },
    {
      "source": "a challenge",
      "target": "cZWCjan02B",
      "similarity": 0.8735
    },
    {
      "source": "a challenge",
      "target": "However",
      "similarity": 0.8729
    },
    {
      "source": "a challenge",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8706
    },
    {
      "source": "In this paper",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.8125
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8113
    },
    {
      "source": "In this paper",
      "target": "CNL-P introduces precise grammar structures and strict semantic norms",
      "similarity": 0.8084
    },
    {
      "source": "In this paper",
      "target": "Moreover",
      "similarity": 0.8058
    },
    {
      "source": "In this paper",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8054
    },
    {
      "source": "for transforming complex",
      "target": "We validate our approach in two tasks",
      "similarity": 0.7979
    },
    {
      "source": "for transforming complex",
      "target": "As its pre-training capabilities are related to perplexity (PPL)",
      "similarity": 0.7899
    },
    {
      "source": "for transforming complex",
      "target": "Specifically",
      "similarity": 0.7856
    },
    {
      "source": "for transforming complex",
      "target": "We show that the safety constraint is satisfied in high probability and that the regret for $\\mathtt{C\\text{-}SquareCB}$ is sub-linear in horizon $T$",
      "similarity": 0.7814
    },
    {
      "source": "for transforming complex",
      "target": "mzL19kKE3r",
      "similarity": 0.7801
    },
    {
      "source": "decision-making pipelines using high-level concept vectors. Specifically",
      "target": "In our experiments",
      "similarity": 0.874
    },
    {
      "source": "decision-making pipelines using high-level concept vectors. Specifically",
      "target": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "similarity": 0.8718
    },
    {
      "source": "decision-making pipelines using high-level concept vectors. Specifically",
      "target": "oP7arLOWix",
      "similarity": 0.8717
    },
    {
      "source": "decision-making pipelines using high-level concept vectors. Specifically",
      "target": "6GATHdOi1x",
      "similarity": 0.8707
    },
    {
      "source": "decision-making pipelines using high-level concept vectors. Specifically",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8672
    },
    {
      "source": "on the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d",
      "target": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "similarity": 0.824
    },
    {
      "source": "on the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8179
    },
    {
      "source": "on the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8132
    },
    {
      "source": "on the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d",
      "target": "Crucially",
      "similarity": 0.811
    },
    {
      "source": "on the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d",
      "target": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "similarity": 0.8027
    },
    {
      "source": "where the distribution of inputs often shifts from the original training distribution.",
      "target": "vRvVVb0NAz",
      "similarity": 0.8497
    },
    {
      "source": "where the distribution of inputs often shifts from the original training distribution.",
      "target": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "similarity": 0.8288
    },
    {
      "source": "where the distribution of inputs often shifts from the original training distribution.",
      "target": "Oazgf8A24z",
      "similarity": 0.81
    },
    {
      "source": "where the distribution of inputs often shifts from the original training distribution.",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8061
    },
    {
      "source": "where the distribution of inputs often shifts from the original training distribution.",
      "target": "AmEgWDhmTr",
      "similarity": 0.7965
    },
    {
      "source": "We first identify the potential failure modes of such pipelines under different types",
      "target": "To overcome this limitation",
      "similarity": 0.8597
    },
    {
      "source": "We first identify the potential failure modes of such pipelines under different types",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8551
    },
    {
      "source": "We first identify the potential failure modes of such pipelines under different types",
      "target": "se4vjm7h4E",
      "similarity": 0.843
    },
    {
      "source": "We first identify the potential failure modes of such pipelines under different types",
      "target": "IQxBDLmVpT",
      "similarity": 0.8366
    },
    {
      "source": "We first identify the potential failure modes of such pipelines under different types",
      "target": "5AtlfHYCPa",
      "similarity": 0.8321
    },
    {
      "source": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "target": "introduce MANTRA",
      "similarity": 0.8905
    },
    {
      "source": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "target": "that BNDL can achieve effective disentangled learning. In addition",
      "similarity": 0.8497
    },
    {
      "source": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8467
    },
    {
      "source": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8394
    },
    {
      "source": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "target": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "similarity": 0.8311
    },
    {
      "source": "to address these failure modes",
      "target": "90DC0IvlSs",
      "similarity": 0.8944
    },
    {
      "source": "to address these failure modes",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8879
    },
    {
      "source": "to address these failure modes",
      "target": "EQgEMAD4kv",
      "similarity": 0.8793
    },
    {
      "source": "to address these failure modes",
      "target": "fWRBheSJth",
      "similarity": 0.8753
    },
    {
      "source": "to address these failure modes",
      "target": "(1) make no assumptions on the data",
      "similarity": 0.8749
    },
    {
      "source": "and the prediction layer based solely on unlabeled data from the target domain",
      "target": "N4rYbQowE3",
      "similarity": 0.8132
    },
    {
      "source": "and the prediction layer based solely on unlabeled data from the target domain",
      "target": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "similarity": 0.8068
    },
    {
      "source": "and the prediction layer based solely on unlabeled data from the target domain",
      "target": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "similarity": 0.8003
    },
    {
      "source": "and the prediction layer based solely on unlabeled data from the target domain",
      "target": "B2Fqu7Y2cd",
      "similarity": 0.8002
    },
    {
      "source": "and the prediction layer based solely on unlabeled data from the target domain",
      "target": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "similarity": 0.7969
    },
    {
      "source": "without access to the source dataset. Empirical evaluations with various real-world",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.8546
    },
    {
      "source": "without access to the source dataset. Empirical evaluations with various real-world",
      "target": "odvSjn416y",
      "similarity": 0.8334
    },
    {
      "source": "without access to the source dataset. Empirical evaluations with various real-world",
      "target": "an upper bound of excess risk on downstream classification tasks of representations",
      "similarity": 0.8166
    },
    {
      "source": "without access to the source dataset. Empirical evaluations with various real-world",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8131
    },
    {
      "source": "without access to the source dataset. Empirical evaluations with various real-world",
      "target": "YcUV5apdlq",
      "similarity": 0.8114
    },
    {
      "source": "distribution shifts show our framework produces concept-based interpretations",
      "target": "Recently",
      "similarity": 0.8627
    },
    {
      "source": "distribution shifts show our framework produces concept-based interpretations",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8298
    },
    {
      "source": "distribution shifts show our framework produces concept-based interpretations",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8271
    },
    {
      "source": "distribution shifts show our framework produces concept-based interpretations",
      "target": "eHehzSDUFp",
      "similarity": 0.8253
    },
    {
      "source": "distribution shifts show our framework produces concept-based interpretations",
      "target": "iLUcsecZJp",
      "similarity": 0.8215
    },
    {
      "source": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "target": "To explore this",
      "similarity": 0.8336
    },
    {
      "source": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8286
    },
    {
      "source": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8263
    },
    {
      "source": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8202
    },
    {
      "source": "better aligned with the test data and boosts post-deployment accuracy by up to",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8198
    },
    {
      "source": "28%",
      "target": "strategies",
      "similarity": 0.8607
    },
    {
      "source": "28%",
      "target": "A1HhtITVEi",
      "similarity": 0.8206
    },
    {
      "source": "28%",
      "target": "TlAdgeoDTo",
      "similarity": 0.8202
    },
    {
      "source": "28%",
      "target": "8TBGdH3t6a",
      "similarity": 0.8027
    },
    {
      "source": "28%",
      "target": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "similarity": 0.8005
    },
    {
      "source": "EW6bNEqalF",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8754
    },
    {
      "source": "EW6bNEqalF",
      "target": "However",
      "similarity": 0.8541
    },
    {
      "source": "EW6bNEqalF",
      "target": "These problems are elaborately selected to cover all challenging language biases",
      "similarity": 0.8434
    },
    {
      "source": "EW6bNEqalF",
      "target": "K4FAFNRpko",
      "similarity": 0.8412
    },
    {
      "source": "EW6bNEqalF",
      "target": "Ax0i933gtp",
      "similarity": 0.8406
    },
    {
      "source": "the introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric",
      "target": "The inherent complexity and performance shortcomings of modern systems motivate a new concept; doing document retrieval by directly embedding the images of the document pages. We release $\\textit{ColPali}$",
      "similarity": 0.7692
    },
    {
      "source": "the introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric",
      "target": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "similarity": 0.7619
    },
    {
      "source": "the introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric",
      "target": "This phenomenon occurs in most state-of-the-art Large Language Models (LLMs)",
      "similarity": 0.7596
    },
    {
      "source": "the introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric",
      "target": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "similarity": 0.7571
    },
    {
      "source": "the introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric",
      "target": "Real-world causal structures",
      "similarity": 0.7561
    },
    {
      "source": "MJNywBdSDy",
      "target": "At the inference stage",
      "similarity": 0.8402
    },
    {
      "source": "MJNywBdSDy",
      "target": "Building on these insights",
      "similarity": 0.8233
    },
    {
      "source": "MJNywBdSDy",
      "target": "vqbd2OQnGp",
      "similarity": 0.8188
    },
    {
      "source": "MJNywBdSDy",
      "target": "entities of a sentence (subject",
      "similarity": 0.8179
    },
    {
      "source": "MJNywBdSDy",
      "target": "nzjSvVZBIp",
      "similarity": 0.8135
    },
    {
      "source": "7xCSK9BLPy",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.836
    },
    {
      "source": "7xCSK9BLPy",
      "target": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "similarity": 0.8292
    },
    {
      "source": "7xCSK9BLPy",
      "target": "a hypergraph",
      "similarity": 0.8185
    },
    {
      "source": "7xCSK9BLPy",
      "target": "UIFAJZ22ZF",
      "similarity": 0.8125
    },
    {
      "source": "7xCSK9BLPy",
      "target": "unlimited streaming.\"",
      "similarity": 0.8053
    },
    {
      "source": "ZjOXuAfS6l",
      "target": "JbRM5QKRDd",
      "similarity": 0.9067
    },
    {
      "source": "ZjOXuAfS6l",
      "target": "are effective at curbing memorization",
      "similarity": 0.8387
    },
    {
      "source": "ZjOXuAfS6l",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.836
    },
    {
      "source": "ZjOXuAfS6l",
      "target": "1NprT9Kz0d",
      "similarity": 0.8305
    },
    {
      "source": "ZjOXuAfS6l",
      "target": "With extensive ablation studies",
      "similarity": 0.8227
    },
    {
      "source": "zCxGCdzreM",
      "target": "PJNhZoCjLh",
      "similarity": 0.826
    },
    {
      "source": "zCxGCdzreM",
      "target": "AcVpLS86RT",
      "similarity": 0.8063
    },
    {
      "source": "zCxGCdzreM",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8047
    },
    {
      "source": "zCxGCdzreM",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.802
    },
    {
      "source": "zCxGCdzreM",
      "target": "Mjn53GtMxi",
      "similarity": 0.8005
    },
    {
      "source": "In this work",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8366
    },
    {
      "source": "In this work",
      "target": "memorization",
      "similarity": 0.8125
    },
    {
      "source": "In this work",
      "target": "FAfxvdv1Dy",
      "similarity": 0.7911
    },
    {
      "source": "In this work",
      "target": "7liN6uHAQZ",
      "similarity": 0.7863
    },
    {
      "source": "In this work",
      "target": "Real-world causal structures",
      "similarity": 0.7813
    },
    {
      "source": "To this end",
      "target": "training data. Equipped with these findings",
      "similarity": 0.9094
    },
    {
      "source": "To this end",
      "target": "90DC0IvlSs",
      "similarity": 0.8966
    },
    {
      "source": "To this end",
      "target": "Using this extension",
      "similarity": 0.8847
    },
    {
      "source": "To this end",
      "target": "models. However",
      "similarity": 0.8839
    },
    {
      "source": "To this end",
      "target": "For TP",
      "similarity": 0.8831
    },
    {
      "source": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.9045
    },
    {
      "source": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "target": "However",
      "similarity": 0.8839
    },
    {
      "source": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "target": "c61unr33XA",
      "similarity": 0.8506
    },
    {
      "source": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "target": "fNMKqyvuZT",
      "similarity": 0.849
    },
    {
      "source": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8411
    },
    {
      "source": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "target": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "similarity": 0.8652
    },
    {
      "source": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8325
    },
    {
      "source": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8257
    },
    {
      "source": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.822
    },
    {
      "source": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "target": "GbgCRJedQ7",
      "similarity": 0.8211
    },
    {
      "source": "We believe this demonstrates the feasibility of large scale",
      "target": "VVixJ9QavY",
      "similarity": 0.829
    },
    {
      "source": "We believe this demonstrates the feasibility of large scale",
      "target": "cADpvQgnqg",
      "similarity": 0.8273
    },
    {
      "source": "We believe this demonstrates the feasibility of large scale",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8271
    },
    {
      "source": "We believe this demonstrates the feasibility of large scale",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8243
    },
    {
      "source": "We believe this demonstrates the feasibility of large scale",
      "target": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "similarity": 0.8231
    },
    {
      "source": "4YpMrGfldX",
      "target": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "similarity": 0.8732
    },
    {
      "source": "4YpMrGfldX",
      "target": "2QdsjiNXgj",
      "similarity": 0.8421
    },
    {
      "source": "4YpMrGfldX",
      "target": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "similarity": 0.8377
    },
    {
      "source": "4YpMrGfldX",
      "target": "Such models faced convergence issues due to vanishing gradient",
      "similarity": 0.8314
    },
    {
      "source": "4YpMrGfldX",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8254
    },
    {
      "source": "ajxAJ8GUX4",
      "target": "xJXq6FkqEw",
      "similarity": 0.8805
    },
    {
      "source": "ajxAJ8GUX4",
      "target": "ymt4crbbXh",
      "similarity": 0.8763
    },
    {
      "source": "ajxAJ8GUX4",
      "target": "ssRdQimeUI",
      "similarity": 0.8667
    },
    {
      "source": "ajxAJ8GUX4",
      "target": "j1tSLYKwg8",
      "similarity": 0.866
    },
    {
      "source": "ajxAJ8GUX4",
      "target": "of the NTK",
      "similarity": 0.8655
    },
    {
      "source": "lLkgj7FEtZ",
      "target": "dEg5SdGaiq",
      "similarity": 0.8002
    },
    {
      "source": "lLkgj7FEtZ",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.798
    },
    {
      "source": "lLkgj7FEtZ",
      "target": "than prior private ANN schemes",
      "similarity": 0.798
    },
    {
      "source": "lLkgj7FEtZ",
      "target": "However",
      "similarity": 0.7976
    },
    {
      "source": "lLkgj7FEtZ",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.7948
    },
    {
      "source": "9XETcRsufZ",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8169
    },
    {
      "source": "9XETcRsufZ",
      "target": "In experiments with GPT-4",
      "similarity": 0.8153
    },
    {
      "source": "9XETcRsufZ",
      "target": "Moreover",
      "similarity": 0.8106
    },
    {
      "source": "9XETcRsufZ",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8071
    },
    {
      "source": "9XETcRsufZ",
      "target": "This study highlights a major",
      "similarity": 0.8055
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8688
    },
    {
      "source": "However",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8672
    },
    {
      "source": "However",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8601
    },
    {
      "source": "However",
      "target": "riieAeQBJm",
      "similarity": 0.858
    },
    {
      "source": "However",
      "target": "IuU0wcO0mo",
      "similarity": 0.856
    },
    {
      "source": "In this paper",
      "target": "As a case study",
      "similarity": 0.8514
    },
    {
      "source": "In this paper",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8514
    },
    {
      "source": "In this paper",
      "target": "In this paper",
      "similarity": 0.8469
    },
    {
      "source": "In this paper",
      "target": "Yk87CwhBDx",
      "similarity": 0.8467
    },
    {
      "source": "In this paper",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.8457
    },
    {
      "source": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "target": "AJpUZd8Clb",
      "similarity": 0.8561
    },
    {
      "source": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "target": "Finally",
      "similarity": 0.853
    },
    {
      "source": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "target": "254NJe9JEw",
      "similarity": 0.8523
    },
    {
      "source": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "target": "Mjn53GtMxi",
      "similarity": 0.8503
    },
    {
      "source": "we show that as we increase the number of experts (while fixing the number of active parameters)",
      "target": "instructions",
      "similarity": 0.8487
    },
    {
      "source": "We begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph  problems that cannot be solved by any number of experts of a certain width; however",
      "target": "For scenarios with constant label distribution",
      "similarity": 0.8468
    },
    {
      "source": "We begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph  problems that cannot be solved by any number of experts of a certain width; however",
      "target": "of our approaches.",
      "similarity": 0.8315
    },
    {
      "source": "We begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph  problems that cannot be solved by any number of experts of a certain width; however",
      "target": "kRBQwlkFSP",
      "similarity": 0.8217
    },
    {
      "source": "We begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph  problems that cannot be solved by any number of experts of a certain width; however",
      "target": "JytL2MrlLT",
      "similarity": 0.8192
    },
    {
      "source": "We begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph  problems that cannot be solved by any number of experts of a certain width; however",
      "target": "MxbEiFRf39",
      "similarity": 0.817
    },
    {
      "source": "On the other hand",
      "target": "In this work",
      "similarity": 0.8432
    },
    {
      "source": "On the other hand",
      "target": "Finally",
      "similarity": 0.843
    },
    {
      "source": "On the other hand",
      "target": "E48QvQppIN",
      "similarity": 0.8412
    },
    {
      "source": "On the other hand",
      "target": "3E8YNv1HjU",
      "similarity": 0.8407
    },
    {
      "source": "On the other hand",
      "target": "AJpUZd8Clb",
      "similarity": 0.8405
    },
    {
      "source": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "target": "XdRIno98gG",
      "similarity": 0.8564
    },
    {
      "source": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "target": "myYzr50xBh",
      "similarity": 0.8536
    },
    {
      "source": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "target": "model weights",
      "similarity": 0.8531
    },
    {
      "source": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "target": "il5yUQsrjC",
      "similarity": 0.8491
    },
    {
      "source": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "target": "8eNLKk5by4",
      "similarity": 0.8486
    },
    {
      "source": "Lastly",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.863
    },
    {
      "source": "Lastly",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8579
    },
    {
      "source": "Lastly",
      "target": "In brief",
      "similarity": 0.8511
    },
    {
      "source": "Lastly",
      "target": "XmProj9cPs",
      "similarity": 0.8423
    },
    {
      "source": "Lastly",
      "target": "In this task",
      "similarity": 0.8413
    },
    {
      "source": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "target": "dropping",
      "similarity": 0.9147
    },
    {
      "source": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "target": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "similarity": 0.8373
    },
    {
      "source": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "target": "In this paper",
      "similarity": 0.833
    },
    {
      "source": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "target": "IuU0wcO0mo",
      "similarity": 0.8281
    },
    {
      "source": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8268
    },
    {
      "source": "EpnZEzYDUT",
      "target": "ROpY0qRUXL",
      "similarity": 0.8665
    },
    {
      "source": "EpnZEzYDUT",
      "target": "bBoetBIN2R",
      "similarity": 0.8642
    },
    {
      "source": "EpnZEzYDUT",
      "target": "from computationally inexpensive prefix distributions.\"",
      "similarity": 0.8533
    },
    {
      "source": "EpnZEzYDUT",
      "target": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "similarity": 0.8374
    },
    {
      "source": "EpnZEzYDUT",
      "target": "Vz0CWFMPUe",
      "similarity": 0.8369
    },
    {
      "source": "0BujOfTqab",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8243
    },
    {
      "source": "0BujOfTqab",
      "target": "In empirical evaluation on synthetic and real-world environments",
      "similarity": 0.8114
    },
    {
      "source": "0BujOfTqab",
      "target": "m73tETvFkX",
      "similarity": 0.8023
    },
    {
      "source": "0BujOfTqab",
      "target": "As its pre-training capabilities are related to perplexity (PPL)",
      "similarity": 0.799
    },
    {
      "source": "0BujOfTqab",
      "target": "rnJxelIZrq",
      "similarity": 0.7954
    },
    {
      "source": "HqLHY4TzGj",
      "target": "In this paper",
      "similarity": 0.8242
    },
    {
      "source": "HqLHY4TzGj",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8105
    },
    {
      "source": "HqLHY4TzGj",
      "target": "In experiments with GPT-4",
      "similarity": 0.8009
    },
    {
      "source": "HqLHY4TzGj",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.7932
    },
    {
      "source": "HqLHY4TzGj",
      "target": "8DBTq09LgN",
      "similarity": 0.7916
    },
    {
      "source": "WNvvwK0tut",
      "target": "On the other hand",
      "similarity": 0.8284
    },
    {
      "source": "WNvvwK0tut",
      "target": "ZNnmcddaB3",
      "similarity": 0.8205
    },
    {
      "source": "WNvvwK0tut",
      "target": "However",
      "similarity": 0.8124
    },
    {
      "source": "WNvvwK0tut",
      "target": "This study highlights a major",
      "similarity": 0.8085
    },
    {
      "source": "WNvvwK0tut",
      "target": "To address this gap",
      "similarity": 0.8008
    },
    {
      "source": "In text generation",
      "target": "fsDZwS49uY",
      "similarity": 0.8404
    },
    {
      "source": "In text generation",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8175
    },
    {
      "source": "In text generation",
      "target": "To address this",
      "similarity": 0.8046
    },
    {
      "source": "In text generation",
      "target": "aVfDrl7xDV",
      "similarity": 0.8018
    },
    {
      "source": "In text generation",
      "target": "To overcome this",
      "similarity": 0.8014
    },
    {
      "source": "Moreover",
      "target": "Second",
      "similarity": 0.8279
    },
    {
      "source": "Moreover",
      "target": "JAMxRSXLFz",
      "similarity": 0.8258
    },
    {
      "source": "Moreover",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8251
    },
    {
      "source": "Moreover",
      "target": "In response",
      "similarity": 0.8248
    },
    {
      "source": "Moreover",
      "target": "Second",
      "similarity": 0.8224
    },
    {
      "source": "KRnsX5Em3W",
      "target": "While our convergence rate estimates recover existing results for minimizing",
      "similarity": 0.8149
    },
    {
      "source": "KRnsX5Em3W",
      "target": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "similarity": 0.8099
    },
    {
      "source": "KRnsX5Em3W",
      "target": "VGURexnlUL",
      "similarity": 0.8022
    },
    {
      "source": "KRnsX5Em3W",
      "target": "LSp4KBhAom",
      "similarity": 0.7984
    },
    {
      "source": "KRnsX5Em3W",
      "target": "fine-tuning of a shallow fully-connected network following the representation.",
      "similarity": 0.795
    },
    {
      "source": "KzSGJy1PIf",
      "target": "(including gradient-based",
      "similarity": 0.8575
    },
    {
      "source": "KzSGJy1PIf",
      "target": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "similarity": 0.8508
    },
    {
      "source": "KzSGJy1PIf",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8485
    },
    {
      "source": "KzSGJy1PIf",
      "target": "To address these issues",
      "similarity": 0.8441
    },
    {
      "source": "KzSGJy1PIf",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.839
    },
    {
      "source": "lydPkW4lfz",
      "target": "depth-wise",
      "similarity": 0.8832
    },
    {
      "source": "lydPkW4lfz",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8745
    },
    {
      "source": "lydPkW4lfz",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8486
    },
    {
      "source": "lydPkW4lfz",
      "target": "high-resolution extreme weather cases derived from the High-Resolution Rapid",
      "similarity": 0.8463
    },
    {
      "source": "lydPkW4lfz",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8374
    },
    {
      "source": "hNjCVVm0EQ",
      "target": "CvGqMD5OtX",
      "similarity": 0.8415
    },
    {
      "source": "hNjCVVm0EQ",
      "target": "tnB94WQGrn",
      "similarity": 0.8133
    },
    {
      "source": "hNjCVVm0EQ",
      "target": "component of real-world software development.\"",
      "similarity": 0.8123
    },
    {
      "source": "hNjCVVm0EQ",
      "target": "KeRwLLwZaw",
      "similarity": 0.8115
    },
    {
      "source": "hNjCVVm0EQ",
      "target": "In this paper",
      "similarity": 0.7935
    },
    {
      "source": "In this paper",
      "target": "(including gradient-based",
      "similarity": 0.8126
    },
    {
      "source": "In this paper",
      "target": "Fk3eod9aaD",
      "similarity": 0.794
    },
    {
      "source": "In this paper",
      "target": "mDKxlfraAn",
      "similarity": 0.7924
    },
    {
      "source": "In this paper",
      "target": "Notably",
      "similarity": 0.7923
    },
    {
      "source": "In this paper",
      "target": "Fortunately",
      "similarity": 0.7831
    },
    {
      "source": "V5ns6uvRZ9",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8673
    },
    {
      "source": "V5ns6uvRZ9",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.8445
    },
    {
      "source": "V5ns6uvRZ9",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8441
    },
    {
      "source": "V5ns6uvRZ9",
      "target": "jxMAPMqNr5",
      "similarity": 0.8427
    },
    {
      "source": "V5ns6uvRZ9",
      "target": "4YzVF9isgD",
      "similarity": 0.8293
    },
    {
      "source": "Brute-force techniques quickly break down even on small datasets. Existing approaches which go beyond brute force either can only find candidate small subsets to remove (but cannot certify their non-existence) [BGM20",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8231
    },
    {
      "source": "Brute-force techniques quickly break down even on small datasets. Existing approaches which go beyond brute force either can only find candidate small subsets to remove (but cannot certify their non-existence) [BGM20",
      "target": "mnna9LUg7P",
      "similarity": 0.8128
    },
    {
      "source": "Brute-force techniques quickly break down even on small datasets. Existing approaches which go beyond brute force either can only find candidate small subsets to remove (but cannot certify their non-existence) [BGM20",
      "target": "Finally",
      "similarity": 0.8122
    },
    {
      "source": "Brute-force techniques quickly break down even on small datasets. Existing approaches which go beyond brute force either can only find candidate small subsets to remove (but cannot certify their non-existence) [BGM20",
      "target": "aN57tSd5Us",
      "similarity": 0.8097
    },
    {
      "source": "Brute-force techniques quickly break down even on small datasets. Existing approaches which go beyond brute force either can only find candidate small subsets to remove (but cannot certify their non-existence) [BGM20",
      "target": "mechanism",
      "similarity": 0.8085
    },
    {
      "source": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "target": "To address this",
      "similarity": 0.832
    },
    {
      "source": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "target": "spDUv05cEq",
      "similarity": 0.8024
    },
    {
      "source": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "target": "FEZOLWexPb",
      "similarity": 0.7955
    },
    {
      "source": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "target": "HZgZrtIreg",
      "similarity": 0.7945
    },
    {
      "source": "We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.7945
    },
    {
      "source": "4X9RpKH4Ls",
      "target": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "similarity": 0.8227
    },
    {
      "source": "4X9RpKH4Ls",
      "target": "gcouwCx7dG",
      "similarity": 0.8196
    },
    {
      "source": "4X9RpKH4Ls",
      "target": "bBoetBIN2R",
      "similarity": 0.8106
    },
    {
      "source": "4X9RpKH4Ls",
      "target": "In particular",
      "similarity": 0.7956
    },
    {
      "source": "4X9RpKH4Ls",
      "target": "Vz0CWFMPUe",
      "similarity": 0.794
    },
    {
      "source": "dAeET8gxqg",
      "target": "riieAeQBJm",
      "similarity": 0.9121
    },
    {
      "source": "dAeET8gxqg",
      "target": "Further",
      "similarity": 0.8813
    },
    {
      "source": "dAeET8gxqg",
      "target": "We found that long distance referrals",
      "similarity": 0.8791
    },
    {
      "source": "dAeET8gxqg",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8774
    },
    {
      "source": "dAeET8gxqg",
      "target": "BL4WBIfyrz",
      "similarity": 0.8724
    },
    {
      "source": "79ZkWgY2FI",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8604
    },
    {
      "source": "79ZkWgY2FI",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8472
    },
    {
      "source": "79ZkWgY2FI",
      "target": "Ke2BEL4csm",
      "similarity": 0.8424
    },
    {
      "source": "79ZkWgY2FI",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8421
    },
    {
      "source": "79ZkWgY2FI",
      "target": "prompts. As such",
      "similarity": 0.8414
    },
    {
      "source": "large-scale settings",
      "target": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "similarity": 0.8245
    },
    {
      "source": "large-scale settings",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8174
    },
    {
      "source": "large-scale settings",
      "target": "D1Y2XFgsPI",
      "similarity": 0.816
    },
    {
      "source": "large-scale settings",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.8107
    },
    {
      "source": "large-scale settings",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8089
    },
    {
      "source": "data affects predictions is often difficult due to model training costs. Current",
      "target": "S85PP4xjFD",
      "similarity": 0.839
    },
    {
      "source": "data affects predictions is often difficult due to model training costs. Current",
      "target": "OjAU0LLDbe",
      "similarity": 0.8371
    },
    {
      "source": "data affects predictions is often difficult due to model training costs. Current",
      "target": "YwzxpZW3p7",
      "similarity": 0.8145
    },
    {
      "source": "data affects predictions is often difficult due to model training costs. Current",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8142
    },
    {
      "source": "data affects predictions is often difficult due to model training costs. Current",
      "target": "(e.g.",
      "similarity": 0.8098
    },
    {
      "source": "practice is to instead extrapolate from scaled down",
      "target": "XmProj9cPs",
      "similarity": 0.8546
    },
    {
      "source": "practice is to instead extrapolate from scaled down",
      "target": "zpENPcQSj1",
      "similarity": 0.8523
    },
    {
      "source": "practice is to instead extrapolate from scaled down",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.842
    },
    {
      "source": "practice is to instead extrapolate from scaled down",
      "target": "yp95goUAT1",
      "similarity": 0.836
    },
    {
      "source": "practice is to instead extrapolate from scaled down",
      "target": "To overcome those challenges",
      "similarity": 0.8327
    },
    {
      "source": "models. However",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8931
    },
    {
      "source": "models. However",
      "target": "In this paper",
      "similarity": 0.8746
    },
    {
      "source": "models. However",
      "target": "3E8YNv1HjU",
      "similarity": 0.8724
    },
    {
      "source": "models. However",
      "target": "pDDODPtpx9",
      "similarity": 0.8637
    },
    {
      "source": "models. However",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8611
    },
    {
      "source": "identically. Therefore",
      "target": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "similarity": 0.8451
    },
    {
      "source": "identically. Therefore",
      "target": "VnLhUogHYE",
      "similarity": 0.8317
    },
    {
      "source": "identically. Therefore",
      "target": "population shifts. In particular",
      "similarity": 0.8293
    },
    {
      "source": "identically. Therefore",
      "target": "The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance",
      "similarity": 0.8281
    },
    {
      "source": "identically. Therefore",
      "target": "AcVpLS86RT",
      "similarity": 0.8274
    },
    {
      "source": "models raises the question: how does training data distribution influence model",
      "target": "HqjRlT65WX",
      "similarity": 0.866
    },
    {
      "source": "models raises the question: how does training data distribution influence model",
      "target": "vRvVVb0NAz",
      "similarity": 0.8559
    },
    {
      "source": "models raises the question: how does training data distribution influence model",
      "target": "PwxYoMvmvy",
      "similarity": 0.8354
    },
    {
      "source": "models raises the question: how does training data distribution influence model",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8352
    },
    {
      "source": "models raises the question: how does training data distribution influence model",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8337
    },
    {
      "source": "behavior across compute scale? We find that small- and large-scale language",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8317
    },
    {
      "source": "behavior across compute scale? We find that small- and large-scale language",
      "target": "b57IG6N20B",
      "similarity": 0.8285
    },
    {
      "source": "behavior across compute scale? We find that small- and large-scale language",
      "target": "rTQNGQxm4K",
      "similarity": 0.8261
    },
    {
      "source": "behavior across compute scale? We find that small- and large-scale language",
      "target": "vl7kf0YHwj",
      "similarity": 0.8259
    },
    {
      "source": "behavior across compute scale? We find that small- and large-scale language",
      "target": "INqLJwqUmc",
      "similarity": 0.822
    },
    {
      "source": "model predictions (generally) *do* highly correlate across choice of",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8008
    },
    {
      "source": "model predictions (generally) *do* highly correlate across choice of",
      "target": "Inspired by these findings",
      "similarity": 0.7998
    },
    {
      "source": "model predictions (generally) *do* highly correlate across choice of",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.7935
    },
    {
      "source": "model predictions (generally) *do* highly correlate across choice of",
      "target": "S4dItvpvAv",
      "similarity": 0.7918
    },
    {
      "source": "model predictions (generally) *do* highly correlate across choice of",
      "target": "x83w6yGIWb",
      "similarity": 0.7913
    },
    {
      "source": "training data. Equipped with these findings",
      "target": "Using this extension",
      "similarity": 0.8788
    },
    {
      "source": "training data. Equipped with these findings",
      "target": "90DC0IvlSs",
      "similarity": 0.872
    },
    {
      "source": "training data. Equipped with these findings",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8713
    },
    {
      "source": "training data. Equipped with these findings",
      "target": "nCrJD7qPJN",
      "similarity": 0.8687
    },
    {
      "source": "training data. Equipped with these findings",
      "target": "tDIL7UXmSS",
      "similarity": 0.8665
    },
    {
      "source": "affects effectiveness in two downstream proxy model applications: data",
      "target": "4xWQS2z77v",
      "similarity": 0.8927
    },
    {
      "source": "affects effectiveness in two downstream proxy model applications: data",
      "target": "zCZnEXF3bN",
      "similarity": 0.8687
    },
    {
      "source": "affects effectiveness in two downstream proxy model applications: data",
      "target": "p4cLtzk4oe",
      "similarity": 0.8571
    },
    {
      "source": "affects effectiveness in two downstream proxy model applications: data",
      "target": "Based on the observations",
      "similarity": 0.8553
    },
    {
      "source": "affects effectiveness in two downstream proxy model applications: data",
      "target": "HaX48yksVL",
      "similarity": 0.8551
    },
    {
      "source": "attribution and dataset selection.\"",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8395
    },
    {
      "source": "attribution and dataset selection.\"",
      "target": "aXwukBD6M6",
      "similarity": 0.8376
    },
    {
      "source": "attribution and dataset selection.\"",
      "target": "iVxxgZlXh6",
      "similarity": 0.8347
    },
    {
      "source": "attribution and dataset selection.\"",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8336
    },
    {
      "source": "attribution and dataset selection.\"",
      "target": "fifXzmzeGy",
      "similarity": 0.8325
    },
    {
      "source": "LSp4KBhAom",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8572
    },
    {
      "source": "LSp4KBhAom",
      "target": "To achieve this",
      "similarity": 0.8356
    },
    {
      "source": "LSp4KBhAom",
      "target": "n2NidsYDop",
      "similarity": 0.834
    },
    {
      "source": "LSp4KBhAom",
      "target": "INqLJwqUmc",
      "similarity": 0.8276
    },
    {
      "source": "LSp4KBhAom",
      "target": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "similarity": 0.8254
    },
    {
      "source": "However",
      "target": "assessing and advancing topological methods",
      "similarity": 0.8514
    },
    {
      "source": "However",
      "target": "gsShHPxkUW",
      "similarity": 0.8456
    },
    {
      "source": "However",
      "target": "OjAU0LLDbe",
      "similarity": 0.8434
    },
    {
      "source": "However",
      "target": "20qZK2T7fa",
      "similarity": 0.8426
    },
    {
      "source": "However",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8405
    },
    {
      "source": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "target": "In light of this",
      "similarity": 0.8938
    },
    {
      "source": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "target": "gFvRRCnQvX",
      "similarity": 0.8909
    },
    {
      "source": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "target": "cC3LxGZasH",
      "similarity": 0.8664
    },
    {
      "source": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "target": "L0evcuybH5",
      "similarity": 0.8618
    },
    {
      "source": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8598
    },
    {
      "source": "such as limited view overlap or low lighting.",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8653
    },
    {
      "source": "such as limited view overlap or low lighting.",
      "target": "KlN00vQEY2",
      "similarity": 0.8531
    },
    {
      "source": "such as limited view overlap or low lighting.",
      "target": "This paper introduces WebRL",
      "similarity": 0.8528
    },
    {
      "source": "such as limited view overlap or low lighting.",
      "target": "Second",
      "similarity": 0.8492
    },
    {
      "source": "such as limited view overlap or low lighting.",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8419
    },
    {
      "source": "To address this",
      "target": "6F6qwdycgJ",
      "similarity": 0.8895
    },
    {
      "source": "To address this",
      "target": "AJpUZd8Clb",
      "similarity": 0.8752
    },
    {
      "source": "To address this",
      "target": "To this end",
      "similarity": 0.8745
    },
    {
      "source": "To address this",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8723
    },
    {
      "source": "To address this",
      "target": "cmfyMV45XO",
      "similarity": 0.8661
    },
    {
      "source": "Taking sparse RGB images as input",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8421
    },
    {
      "source": "Taking sparse RGB images as input",
      "target": "FPQzXME9NK",
      "similarity": 0.8326
    },
    {
      "source": "Taking sparse RGB images as input",
      "target": "To bridge this gap",
      "similarity": 0.8271
    },
    {
      "source": "Taking sparse RGB images as input",
      "target": "P4XmKjXTrM",
      "similarity": 0.8134
    },
    {
      "source": "Taking sparse RGB images as input",
      "target": "Moreover",
      "similarity": 0.812
    },
    {
      "source": "In particular",
      "target": "1F8xTfv6ah",
      "similarity": 0.8482
    },
    {
      "source": "In particular",
      "target": "d16mJDyQN6",
      "similarity": 0.8348
    },
    {
      "source": "In particular",
      "target": "While existing T2S distillation models address this limitation through $1$-step generation",
      "similarity": 0.831
    },
    {
      "source": "In particular",
      "target": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "similarity": 0.8248
    },
    {
      "source": "In particular",
      "target": "We conducted a comprehensive regret analysis of our proposed framework",
      "similarity": 0.8131
    },
    {
      "source": "automatically re-weighting the confidence to better reflect point estimation accuracy.",
      "target": "The framework automates the generation of query-response pairs using predefined rules",
      "similarity": 0.8096
    },
    {
      "source": "automatically re-weighting the confidence to better reflect point estimation accuracy.",
      "target": "JBXO05r4AV",
      "similarity": 0.8075
    },
    {
      "source": "automatically re-weighting the confidence to better reflect point estimation accuracy.",
      "target": "7bAjVh3CG3",
      "similarity": 0.8045
    },
    {
      "source": "automatically re-weighting the confidence to better reflect point estimation accuracy.",
      "target": "2kGKsyhtvh",
      "similarity": 0.8034
    },
    {
      "source": "automatically re-weighting the confidence to better reflect point estimation accuracy.",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.803
    },
    {
      "source": "We use the calibrated confidence to generate high-quality pseudo labels for the calibrating views and fine-tune the models using low-rank adaptation (LoRA) on the pseudo-labeled data.",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8015
    },
    {
      "source": "We use the calibrated confidence to generate high-quality pseudo labels for the calibrating views and fine-tune the models using low-rank adaptation (LoRA) on the pseudo-labeled data.",
      "target": "CI5Cj0vktS",
      "similarity": 0.7967
    },
    {
      "source": "We use the calibrated confidence to generate high-quality pseudo labels for the calibrating views and fine-tune the models using low-rank adaptation (LoRA) on the pseudo-labeled data.",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.7956
    },
    {
      "source": "We use the calibrated confidence to generate high-quality pseudo labels for the calibrating views and fine-tune the models using low-rank adaptation (LoRA) on the pseudo-labeled data.",
      "target": "WKW5TG8ItY",
      "similarity": 0.7941
    },
    {
      "source": "We use the calibrated confidence to generate high-quality pseudo labels for the calibrating views and fine-tune the models using low-rank adaptation (LoRA) on the pseudo-labeled data.",
      "target": "mPdmDYIQ7f",
      "similarity": 0.7938
    },
    {
      "source": "Our method does not require any external priors or manual labels. It completes the self-calibration process on a **single standard GPU within just 5 minutes**.",
      "target": "jj7b3p5kLY",
      "similarity": 0.864
    },
    {
      "source": "Our method does not require any external priors or manual labels. It completes the self-calibration process on a **single standard GPU within just 5 minutes**.",
      "target": "tu3qwNjrtw",
      "similarity": 0.8526
    },
    {
      "source": "Our method does not require any external priors or manual labels. It completes the self-calibration process on a **single standard GPU within just 5 minutes**.",
      "target": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "similarity": 0.8472
    },
    {
      "source": "Our method does not require any external priors or manual labels. It completes the self-calibration process on a **single standard GPU within just 5 minutes**.",
      "target": "fAAaT826Vv",
      "similarity": 0.8466
    },
    {
      "source": "Our method does not require any external priors or manual labels. It completes the self-calibration process on a **single standard GPU within just 5 minutes**.",
      "target": "We propose the use of principal persistence measures",
      "similarity": 0.8428
    },
    {
      "source": "Each low-rank adapter requires only **18MB** of storage.",
      "target": "2kGKsyhtvh",
      "similarity": 0.8379
    },
    {
      "source": "Each low-rank adapter requires only **18MB** of storage.",
      "target": "IZDiRbVSVN",
      "similarity": 0.8294
    },
    {
      "source": "Each low-rank adapter requires only **18MB** of storage.",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8269
    },
    {
      "source": "Each low-rank adapter requires only **18MB** of storage.",
      "target": "To this end",
      "similarity": 0.8267
    },
    {
      "source": "Each low-rank adapter requires only **18MB** of storage.",
      "target": "yu1vqQqKkx",
      "similarity": 0.8256
    },
    {
      "source": "We evaluated our method on **more than 160 scenes** from the Replica",
      "target": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "similarity": 0.8397
    },
    {
      "source": "We evaluated our method on **more than 160 scenes** from the Replica",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8387
    },
    {
      "source": "We evaluated our method on **more than 160 scenes** from the Replica",
      "target": "several settings",
      "similarity": 0.8093
    },
    {
      "source": "We evaluated our method on **more than 160 scenes** from the Replica",
      "target": "GQ1Tc3vHbt",
      "similarity": 0.8081
    },
    {
      "source": "We evaluated our method on **more than 160 scenes** from the Replica",
      "target": "7liN6uHAQZ",
      "similarity": 0.808
    },
    {
      "source": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8806
    },
    {
      "source": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "target": "pRCOZllZdT",
      "similarity": 0.8715
    },
    {
      "source": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8615
    },
    {
      "source": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "target": "Refresh (HRRR) data",
      "similarity": 0.8599
    },
    {
      "source": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "target": "bcTjW5kS4W",
      "similarity": 0.8561
    },
    {
      "source": "For more details",
      "target": "To address this gap",
      "similarity": 0.8159
    },
    {
      "source": "For more details",
      "target": "outcomes. To explore the factors that impact evaluation reliability",
      "similarity": 0.7958
    },
    {
      "source": "For more details",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.7867
    },
    {
      "source": "For more details",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.7699
    },
    {
      "source": "For more details",
      "target": "uxDFlPGRLX",
      "similarity": 0.7658
    },
    {
      "source": "BkwCrIsTbR",
      "target": "eLLBILFRsA",
      "similarity": 0.8463
    },
    {
      "source": "BkwCrIsTbR",
      "target": "je3GZissZc",
      "similarity": 0.8436
    },
    {
      "source": "BkwCrIsTbR",
      "target": "7El7K1DoyX",
      "similarity": 0.8351
    },
    {
      "source": "BkwCrIsTbR",
      "target": "IuU0wcO0mo",
      "similarity": 0.828
    },
    {
      "source": "BkwCrIsTbR",
      "target": "GkWA6NjePN",
      "similarity": 0.8205
    },
    {
      "source": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "target": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "similarity": 0.8496
    },
    {
      "source": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8449
    },
    {
      "source": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "target": "introduce MANTRA",
      "similarity": 0.8359
    },
    {
      "source": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "target": "g0rnZeBguq",
      "similarity": 0.8325
    },
    {
      "source": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8298
    },
    {
      "source": "uSz2K30RRd",
      "target": "tj5xJInWty",
      "similarity": 0.8728
    },
    {
      "source": "uSz2K30RRd",
      "target": "wSkvf2WyYz",
      "similarity": 0.8723
    },
    {
      "source": "uSz2K30RRd",
      "target": "4GT9uTsAJE",
      "similarity": 0.8553
    },
    {
      "source": "uSz2K30RRd",
      "target": "In this paper",
      "similarity": 0.8553
    },
    {
      "source": "uSz2K30RRd",
      "target": "Motivated by this observation",
      "similarity": 0.8532
    },
    {
      "source": "point in the latent representation space for each input. However",
      "target": "n2NidsYDop",
      "similarity": 0.8845
    },
    {
      "source": "point in the latent representation space for each input. However",
      "target": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "similarity": 0.8555
    },
    {
      "source": "point in the latent representation space for each input. However",
      "target": "KAIqwkB3dT",
      "similarity": 0.8453
    },
    {
      "source": "point in the latent representation space for each input. However",
      "target": "bsFWJ0Kget",
      "similarity": 0.8397
    },
    {
      "source": "point in the latent representation space for each input. However",
      "target": "iLUcsecZJp",
      "similarity": 0.8383
    },
    {
      "source": "has difficulty in capturing the relationship and the similarity structure of a",
      "target": "jTEKTdI3K9",
      "similarity": 0.8795
    },
    {
      "source": "has difficulty in capturing the relationship and the similarity structure of a",
      "target": "wWnsoLhHwt",
      "similarity": 0.8595
    },
    {
      "source": "has difficulty in capturing the relationship and the similarity structure of a",
      "target": "For example",
      "similarity": 0.8583
    },
    {
      "source": "has difficulty in capturing the relationship and the similarity structure of a",
      "target": "v1rFkElnIn",
      "similarity": 0.8581
    },
    {
      "source": "has difficulty in capturing the relationship and the similarity structure of a",
      "target": "9kJperA2a4",
      "similarity": 0.8569
    },
    {
      "source": "huge amount of instances in the real world. For richer classes of the similarity",
      "target": "dEg5SdGaiq",
      "similarity": 0.8235
    },
    {
      "source": "huge amount of instances in the real world. For richer classes of the similarity",
      "target": "Moreover",
      "similarity": 0.8156
    },
    {
      "source": "huge amount of instances in the real world. For richer classes of the similarity",
      "target": "Extensive experiments on MuJoCo",
      "similarity": 0.81
    },
    {
      "source": "huge amount of instances in the real world. For richer classes of the similarity",
      "target": "CkUHtnyhpY",
      "similarity": 0.8006
    },
    {
      "source": "huge amount of instances in the real world. For richer classes of the similarity",
      "target": "wWnsoLhHwt",
      "similarity": 0.8001
    },
    {
      "source": "propose the use of weighted point sets",
      "target": "named Pacmann",
      "similarity": 0.8884
    },
    {
      "source": "propose the use of weighted point sets",
      "target": "FiyS0ecSm0",
      "similarity": 0.8727
    },
    {
      "source": "propose the use of weighted point sets",
      "target": "VmJdqhuTCh",
      "similarity": 0.8649
    },
    {
      "source": "propose the use of weighted point sets",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.853
    },
    {
      "source": "propose the use of weighted point sets",
      "target": "dw9VUsSHGB",
      "similarity": 0.8529
    },
    {
      "source": "as representations of instances. In this work",
      "target": "To tackle this challenge",
      "similarity": 0.8726
    },
    {
      "source": "as representations of instances. In this work",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8652
    },
    {
      "source": "as representations of instances. In this work",
      "target": "yIlyHJdYV3",
      "similarity": 0.8631
    },
    {
      "source": "as representations of instances. In this work",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8624
    },
    {
      "source": "as representations of instances. In this work",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.8573
    },
    {
      "source": "of our proposed method through a new understanding of the contrastive loss of",
      "target": "nzjSvVZBIp",
      "similarity": 0.8625
    },
    {
      "source": "of our proposed method through a new understanding of the contrastive loss of",
      "target": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "similarity": 0.8472
    },
    {
      "source": "of our proposed method through a new understanding of the contrastive loss of",
      "target": "zDC3iCBxJb",
      "similarity": 0.8245
    },
    {
      "source": "of our proposed method through a new understanding of the contrastive loss of",
      "target": "In this paper",
      "similarity": 0.8244
    },
    {
      "source": "of our proposed method through a new understanding of the contrastive loss of",
      "target": "comprehensive experiments",
      "similarity": 0.8105
    },
    {
      "source": "CLIP",
      "target": "gWgaypDBs8",
      "similarity": 0.868
    },
    {
      "source": "CLIP",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8465
    },
    {
      "source": "CLIP",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.823
    },
    {
      "source": "CLIP",
      "target": "Finally",
      "similarity": 0.8219
    },
    {
      "source": "CLIP",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8192
    },
    {
      "source": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "target": "Additionally",
      "similarity": 0.8553
    },
    {
      "source": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "target": "semTHoVGsJ",
      "similarity": 0.8547
    },
    {
      "source": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8542
    },
    {
      "source": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8426
    },
    {
      "source": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "target": "Despite its simplicity",
      "similarity": 0.8391
    },
    {
      "source": "an upper bound of excess risk on downstream classification tasks of representations",
      "target": "GfXMTAJaxZ",
      "similarity": 0.8634
    },
    {
      "source": "an upper bound of excess risk on downstream classification tasks of representations",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.8508
    },
    {
      "source": "an upper bound of excess risk on downstream classification tasks of representations",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8418
    },
    {
      "source": "an upper bound of excess risk on downstream classification tasks of representations",
      "target": "wkbx7BRAsM",
      "similarity": 0.8394
    },
    {
      "source": "an upper bound of excess risk on downstream classification tasks of representations",
      "target": "nrvoWOWcyg",
      "similarity": 0.8348
    },
    {
      "source": "that achieve the optimal similarity. In addition",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8189
    },
    {
      "source": "that achieve the optimal similarity. In addition",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8182
    },
    {
      "source": "that achieve the optimal similarity. In addition",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.811
    },
    {
      "source": "that achieve the optimal similarity. In addition",
      "target": "x33vSZUg0A",
      "similarity": 0.8096
    },
    {
      "source": "that achieve the optimal similarity. In addition",
      "target": "To address this",
      "similarity": 0.8044
    },
    {
      "source": "similarity based on weighted point sets consistently achieves the optimal similarity.",
      "target": "yZ7sn9pyqb",
      "similarity": 0.8521
    },
    {
      "source": "similarity based on weighted point sets consistently achieves the optimal similarity.",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8204
    },
    {
      "source": "similarity based on weighted point sets consistently achieves the optimal similarity.",
      "target": "b57IG6N20B",
      "similarity": 0.8043
    },
    {
      "source": "similarity based on weighted point sets consistently achieves the optimal similarity.",
      "target": "data affects predictions is often difficult due to model training costs. Current",
      "similarity": 0.8041
    },
    {
      "source": "similarity based on weighted point sets consistently achieves the optimal similarity.",
      "target": "Sf4ep9Udjf",
      "similarity": 0.8002
    },
    {
      "source": "To verify the effectiveness of our proposed method",
      "target": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "similarity": 0.8416
    },
    {
      "source": "To verify the effectiveness of our proposed method",
      "target": "uZgK0tcPqd",
      "similarity": 0.8147
    },
    {
      "source": "To verify the effectiveness of our proposed method",
      "target": "Iyrtb9EJBp",
      "similarity": 0.8071
    },
    {
      "source": "To verify the effectiveness of our proposed method",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8056
    },
    {
      "source": "To verify the effectiveness of our proposed method",
      "target": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "similarity": 0.8026
    },
    {
      "source": "text-image representation models and classification tasks on common benchmarks.\"",
      "target": "DpLFmc09pC",
      "similarity": 0.8222
    },
    {
      "source": "text-image representation models and classification tasks on common benchmarks.\"",
      "target": "27SSnLl85x",
      "similarity": 0.8057
    },
    {
      "source": "text-image representation models and classification tasks on common benchmarks.\"",
      "target": "INqLJwqUmc",
      "similarity": 0.8047
    },
    {
      "source": "text-image representation models and classification tasks on common benchmarks.\"",
      "target": "In this paper",
      "similarity": 0.8045
    },
    {
      "source": "text-image representation models and classification tasks on common benchmarks.\"",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.8023
    },
    {
      "source": "C8jXEugWkq",
      "target": "vVxeFSR4fU",
      "similarity": 0.8236
    },
    {
      "source": "C8jXEugWkq",
      "target": "In this work",
      "similarity": 0.8168
    },
    {
      "source": "C8jXEugWkq",
      "target": "gLa96FlWwn",
      "similarity": 0.8136
    },
    {
      "source": "C8jXEugWkq",
      "target": "To address this",
      "similarity": 0.813
    },
    {
      "source": "C8jXEugWkq",
      "target": "number of parameters required for fine-tuning these models. These compression",
      "similarity": 0.81
    },
    {
      "source": "This work introduces EqNIO",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.83
    },
    {
      "source": "This work introduces EqNIO",
      "target": "n2NidsYDop",
      "similarity": 0.8242
    },
    {
      "source": "This work introduces EqNIO",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.8193
    },
    {
      "source": "This work introduces EqNIO",
      "target": "a hypergraph",
      "similarity": 0.8184
    },
    {
      "source": "This work introduces EqNIO",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.818
    },
    {
      "source": "X6y5CC44HM",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8489
    },
    {
      "source": "X6y5CC44HM",
      "target": "To address these challenges",
      "similarity": 0.8367
    },
    {
      "source": "X6y5CC44HM",
      "target": "prompts of 128K length",
      "similarity": 0.8344
    },
    {
      "source": "X6y5CC44HM",
      "target": "For instance",
      "similarity": 0.8317
    },
    {
      "source": "X6y5CC44HM",
      "target": "Despite its simplicity",
      "similarity": 0.8277
    },
    {
      "source": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "target": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "similarity": 0.8255
    },
    {
      "source": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "target": "By leveraging online data collection",
      "similarity": 0.8156
    },
    {
      "source": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "target": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "similarity": 0.8117
    },
    {
      "source": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "target": "standard training and",
      "similarity": 0.8095
    },
    {
      "source": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "target": "AoIKgHu9Si",
      "similarity": 0.8052
    },
    {
      "source": "especially in topological deep learning (TDL)",
      "target": "e0X9l4kecx",
      "similarity": 0.8261
    },
    {
      "source": "especially in topological deep learning (TDL)",
      "target": "ajSmXqgS24",
      "similarity": 0.8175
    },
    {
      "source": "especially in topological deep learning (TDL)",
      "target": "By leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state",
      "similarity": 0.8115
    },
    {
      "source": "especially in topological deep learning (TDL)",
      "target": "U42TkrEDzb",
      "similarity": 0.8048
    },
    {
      "source": "especially in topological deep learning (TDL)",
      "target": "dmCGjPFVhF",
      "similarity": 0.8008
    },
    {
      "source": "by the scarcity of datasets for benchmarking these architectures. To address this gap",
      "target": "Our trained agent exhibits strong physical reasoning capabilities in 2D space",
      "similarity": 0.8183
    },
    {
      "source": "by the scarcity of datasets for benchmarking these architectures. To address this gap",
      "target": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "similarity": 0.8139
    },
    {
      "source": "by the scarcity of datasets for benchmarking these architectures. To address this gap",
      "target": "iLUcsecZJp",
      "similarity": 0.8119
    },
    {
      "source": "by the scarcity of datasets for benchmarking these architectures. To address this gap",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8101
    },
    {
      "source": "by the scarcity of datasets for benchmarking these architectures. To address this gap",
      "target": "2c7pfOqu9k",
      "similarity": 0.8098
    },
    {
      "source": "introduce MANTRA",
      "target": "xJXq6FkqEw",
      "similarity": 0.8517
    },
    {
      "source": "introduce MANTRA",
      "target": "prompts of 128K length",
      "similarity": 0.8502
    },
    {
      "source": "introduce MANTRA",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8444
    },
    {
      "source": "introduce MANTRA",
      "target": "To address these challenges",
      "similarity": 0.8433
    },
    {
      "source": "introduce MANTRA",
      "target": "For instance",
      "similarity": 0.8413
    },
    {
      "source": "benchmarking higher-order models",
      "target": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "similarity": 0.8289
    },
    {
      "source": "benchmarking higher-order models",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.8273
    },
    {
      "source": "benchmarking higher-order models",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.8088
    },
    {
      "source": "benchmarking higher-order models",
      "target": "To address this",
      "similarity": 0.8008
    },
    {
      "source": "benchmarking higher-order models",
      "target": "XBF63bHDZw",
      "similarity": 0.7982
    },
    {
      "source": "of surfaces and three-dimensional manifolds",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8801
    },
    {
      "source": "of surfaces and three-dimensional manifolds",
      "target": "BL4WBIfyrz",
      "similarity": 0.8747
    },
    {
      "source": "of surfaces and three-dimensional manifolds",
      "target": "riieAeQBJm",
      "similarity": 0.8697
    },
    {
      "source": "of surfaces and three-dimensional manifolds",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8667
    },
    {
      "source": "of surfaces and three-dimensional manifolds",
      "target": "We found that long distance referrals",
      "similarity": 0.8561
    },
    {
      "source": "several graph- and simplicial complex-based models on three topological classification",
      "target": "sVNfWhtaJC",
      "similarity": 0.8605
    },
    {
      "source": "several graph- and simplicial complex-based models on three topological classification",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8407
    },
    {
      "source": "several graph- and simplicial complex-based models on three topological classification",
      "target": "1xzqz73hvL",
      "similarity": 0.8357
    },
    {
      "source": "several graph- and simplicial complex-based models on three topological classification",
      "target": "fL4qWkSmtM",
      "similarity": 0.832
    },
    {
      "source": "several graph- and simplicial complex-based models on three topological classification",
      "target": "Inspired by these findings",
      "similarity": 0.826
    },
    {
      "source": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.7962
    },
    {
      "source": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "target": "CjXaMI2kUH",
      "similarity": 0.7865
    },
    {
      "source": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "target": "aSy2nYwiZ2",
      "similarity": 0.7793
    },
    {
      "source": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "target": "In each case",
      "similarity": 0.7767
    },
    {
      "source": "tasks. We demonstrate that while simplicial complex-based neural networks generally",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.7764
    },
    {
      "source": "outperform their graph-based counterparts in capturing simple topological invariants",
      "target": "relying on backward propagation",
      "similarity": 0.8298
    },
    {
      "source": "outperform their graph-based counterparts in capturing simple topological invariants",
      "target": "Using this approach",
      "similarity": 0.8284
    },
    {
      "source": "outperform their graph-based counterparts in capturing simple topological invariants",
      "target": "However",
      "similarity": 0.8279
    },
    {
      "source": "outperform their graph-based counterparts in capturing simple topological invariants",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8245
    },
    {
      "source": "outperform their graph-based counterparts in capturing simple topological invariants",
      "target": "r1KcapkzCt",
      "similarity": 0.8225
    },
    {
      "source": "also struggle",
      "target": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "similarity": 0.8535
    },
    {
      "source": "also struggle",
      "target": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "similarity": 0.8519
    },
    {
      "source": "also struggle",
      "target": "FtjLUHyZAO",
      "similarity": 0.8468
    },
    {
      "source": "also struggle",
      "target": "L0evcuybH5",
      "similarity": 0.8334
    },
    {
      "source": "also struggle",
      "target": "ohJxgRLlLt",
      "similarity": 0.8269
    },
    {
      "source": "assessing and advancing topological methods",
      "target": "20qZK2T7fa",
      "similarity": 0.8743
    },
    {
      "source": "assessing and advancing topological methods",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8571
    },
    {
      "source": "assessing and advancing topological methods",
      "target": "Finally",
      "similarity": 0.853
    },
    {
      "source": "assessing and advancing topological methods",
      "target": "To remedy this problem",
      "similarity": 0.8487
    },
    {
      "source": "assessing and advancing topological methods",
      "target": "overhead in parameters and inference time. In this paper",
      "similarity": 0.8469
    },
    {
      "source": "higher-order models.\"",
      "target": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "similarity": 0.8366
    },
    {
      "source": "higher-order models.\"",
      "target": "VOoJEQlLW5",
      "similarity": 0.8129
    },
    {
      "source": "higher-order models.\"",
      "target": "ScVnYBaSEw",
      "similarity": 0.7987
    },
    {
      "source": "higher-order models.\"",
      "target": "AZR4R3lw7y",
      "similarity": 0.7963
    },
    {
      "source": "higher-order models.\"",
      "target": "Next",
      "similarity": 0.7935
    },
    {
      "source": "wgRQ2WAORJ",
      "target": "Furthermore",
      "similarity": 0.8829
    },
    {
      "source": "wgRQ2WAORJ",
      "target": "41uZB8bDFh",
      "similarity": 0.8807
    },
    {
      "source": "wgRQ2WAORJ",
      "target": "1CIUkpoata",
      "similarity": 0.8772
    },
    {
      "source": "wgRQ2WAORJ",
      "target": "Moreover",
      "similarity": 0.8765
    },
    {
      "source": "wgRQ2WAORJ",
      "target": "fs2Z2z3GRx",
      "similarity": 0.8753
    },
    {
      "source": "CL3U0GxFRD",
      "target": "m8yby1JfbU",
      "similarity": 0.8454
    },
    {
      "source": "CL3U0GxFRD",
      "target": "Pnk7vMbznK",
      "similarity": 0.8217
    },
    {
      "source": "CL3U0GxFRD",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8212
    },
    {
      "source": "CL3U0GxFRD",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.8167
    },
    {
      "source": "CL3U0GxFRD",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.812
    },
    {
      "source": "code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).\"",
      "target": "q87GUkdQBm",
      "similarity": 0.8947
    },
    {
      "source": "code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).\"",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8377
    },
    {
      "source": "code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).\"",
      "target": "CtM5xjRSfm",
      "similarity": 0.8115
    },
    {
      "source": "code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).\"",
      "target": "d8hYXbxX71",
      "similarity": 0.7979
    },
    {
      "source": "code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).\"",
      "target": "gWgaypDBs8",
      "similarity": 0.7935
    },
    {
      "source": "aMBSY2ebPw",
      "target": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "similarity": 0.9006
    },
    {
      "source": "aMBSY2ebPw",
      "target": "4FWAwZtd2n",
      "similarity": 0.8482
    },
    {
      "source": "aMBSY2ebPw",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8467
    },
    {
      "source": "aMBSY2ebPw",
      "target": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "similarity": 0.8465
    },
    {
      "source": "aMBSY2ebPw",
      "target": "YzxMu1asQi",
      "similarity": 0.8453
    },
    {
      "source": "a3g2l4yEys",
      "target": "yitH9xAHQs",
      "similarity": 0.8296
    },
    {
      "source": "a3g2l4yEys",
      "target": "5xSRg3eYZz",
      "similarity": 0.7878
    },
    {
      "source": "a3g2l4yEys",
      "target": "GPT-4",
      "similarity": 0.7763
    },
    {
      "source": "a3g2l4yEys",
      "target": "S1Bv3068Xt",
      "similarity": 0.7757
    },
    {
      "source": "a3g2l4yEys",
      "target": "rTQNGQxm4K",
      "similarity": 0.7744
    },
    {
      "source": "This paper introduces PANGEA",
      "target": "vbmSSIhKAM",
      "similarity": 0.8678
    },
    {
      "source": "This paper introduces PANGEA",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8587
    },
    {
      "source": "This paper introduces PANGEA",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8565
    },
    {
      "source": "This paper introduces PANGEA",
      "target": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "similarity": 0.8526
    },
    {
      "source": "This paper introduces PANGEA",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8472
    },
    {
      "source": "To rigorously assess models' capabilities",
      "target": "All experimental resources",
      "similarity": 0.7767
    },
    {
      "source": "To rigorously assess models' capabilities",
      "target": "To overcome those challenges",
      "similarity": 0.776
    },
    {
      "source": "To rigorously assess models' capabilities",
      "target": "VQwI055flA",
      "similarity": 0.7759
    },
    {
      "source": "To rigorously assess models' capabilities",
      "target": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "similarity": 0.7758
    },
    {
      "source": "To rigorously assess models' capabilities",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.7745
    },
    {
      "source": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8336
    },
    {
      "source": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "target": "j1tSLYKwg8",
      "similarity": 0.8305
    },
    {
      "source": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "target": "For instance",
      "similarity": 0.8296
    },
    {
      "source": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "target": "xJXq6FkqEw",
      "similarity": 0.8287
    },
    {
      "source": "Results show that PANGEA significantly outperforms existing open-source models in multilingual settings and diverse cultural contexts. Ablation studies further reveal the importance of English data proportions",
      "target": "In this paper",
      "similarity": 0.8284
    },
    {
      "source": "0LSAmFCc4p",
      "target": "pB1XSj2y4X",
      "similarity": 0.841
    },
    {
      "source": "0LSAmFCc4p",
      "target": "To address these limitations",
      "similarity": 0.8348
    },
    {
      "source": "0LSAmFCc4p",
      "target": "HSi4VetQLj",
      "similarity": 0.8297
    },
    {
      "source": "0LSAmFCc4p",
      "target": "7IzeL0kflu",
      "similarity": 0.8246
    },
    {
      "source": "0LSAmFCc4p",
      "target": "of natural language. However",
      "similarity": 0.8217
    },
    {
      "source": "zfeso8ceqr",
      "target": "However",
      "similarity": 0.8369
    },
    {
      "source": "zfeso8ceqr",
      "target": "TDy5Ih78b4",
      "similarity": 0.836
    },
    {
      "source": "zfeso8ceqr",
      "target": "1R5BcYS8EC",
      "similarity": 0.835
    },
    {
      "source": "zfeso8ceqr",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8345
    },
    {
      "source": "zfeso8ceqr",
      "target": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "similarity": 0.8264
    },
    {
      "source": "5M0ic2RxQZ",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.8677
    },
    {
      "source": "5M0ic2RxQZ",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8482
    },
    {
      "source": "5M0ic2RxQZ",
      "target": "For production-level generation",
      "similarity": 0.8474
    },
    {
      "source": "5M0ic2RxQZ",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8419
    },
    {
      "source": "5M0ic2RxQZ",
      "target": "wide dissemination",
      "similarity": 0.8406
    },
    {
      "source": "cCl10IU836",
      "target": "tRNKe2Vgqt",
      "similarity": 0.8418
    },
    {
      "source": "cCl10IU836",
      "target": "Q5Sawm0nqo",
      "similarity": 0.7766
    },
    {
      "source": "cCl10IU836",
      "target": "ajSmXqgS24",
      "similarity": 0.7627
    },
    {
      "source": "cCl10IU836",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.7602
    },
    {
      "source": "cCl10IU836",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.76
    },
    {
      "source": "q3EbOXb4y1",
      "target": "vRvVVb0NAz",
      "similarity": 0.853
    },
    {
      "source": "q3EbOXb4y1",
      "target": "To overcome this",
      "similarity": 0.8382
    },
    {
      "source": "q3EbOXb4y1",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8303
    },
    {
      "source": "q3EbOXb4y1",
      "target": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "similarity": 0.812
    },
    {
      "source": "q3EbOXb4y1",
      "target": "fsDZwS49uY",
      "similarity": 0.7841
    },
    {
      "source": "X1U74IwuxG",
      "target": "254NJe9JEw",
      "similarity": 0.8592
    },
    {
      "source": "X1U74IwuxG",
      "target": "JAMxRSXLFz",
      "similarity": 0.8592
    },
    {
      "source": "X1U74IwuxG",
      "target": "instructions",
      "similarity": 0.8584
    },
    {
      "source": "X1U74IwuxG",
      "target": "These findings highlight the significant room for improvement in current reward models.\"",
      "similarity": 0.8539
    },
    {
      "source": "X1U74IwuxG",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8523
    },
    {
      "source": "hovDbX4Gh6",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8736
    },
    {
      "source": "hovDbX4Gh6",
      "target": "In this paper",
      "similarity": 0.8725
    },
    {
      "source": "hovDbX4Gh6",
      "target": "riieAeQBJm",
      "similarity": 0.8628
    },
    {
      "source": "hovDbX4Gh6",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8617
    },
    {
      "source": "hovDbX4Gh6",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8489
    },
    {
      "source": "This construction process is fundamental to applying graph-based models",
      "target": "9qS3HzSDNv",
      "similarity": 0.8981
    },
    {
      "source": "This construction process is fundamental to applying graph-based models",
      "target": "In contrast",
      "similarity": 0.8773
    },
    {
      "source": "This construction process is fundamental to applying graph-based models",
      "target": "relying on backward propagation",
      "similarity": 0.8661
    },
    {
      "source": "This construction process is fundamental to applying graph-based models",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.8626
    },
    {
      "source": "This construction process is fundamental to applying graph-based models",
      "target": "d7pr2doXn3",
      "similarity": 0.8563
    },
    {
      "source": "Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods",
      "target": "8TBGdH3t6a",
      "similarity": 0.8183
    },
    {
      "source": "Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods",
      "target": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "similarity": 0.8127
    },
    {
      "source": "Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods",
      "target": "SuH5SdOXpe",
      "similarity": 0.8003
    },
    {
      "source": "Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods",
      "target": "8egnwady4b",
      "similarity": 0.8001
    },
    {
      "source": "Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.7997
    },
    {
      "source": "To tackle these challenges",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.9105
    },
    {
      "source": "To tackle these challenges",
      "target": "3) We train the model through compression-based auto-regression",
      "similarity": 0.8546
    },
    {
      "source": "To tackle these challenges",
      "target": "(1) make no assumptions on the data",
      "similarity": 0.8528
    },
    {
      "source": "To tackle these challenges",
      "target": "yu1vqQqKkx",
      "similarity": 0.8497
    },
    {
      "source": "To tackle these challenges",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8476
    },
    {
      "source": "First",
      "target": "Traditional fine-tuning methods require substantial data",
      "similarity": 0.8577
    },
    {
      "source": "First",
      "target": "In order to support an empirically grounded inductive approach to research",
      "similarity": 0.8456
    },
    {
      "source": "First",
      "target": "However",
      "similarity": 0.8277
    },
    {
      "source": "First",
      "target": "q5EZ7gKcnW",
      "similarity": 0.8171
    },
    {
      "source": "First",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.8166
    },
    {
      "source": "Second",
      "target": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "similarity": 0.8745
    },
    {
      "source": "Second",
      "target": "In contrast",
      "similarity": 0.8554
    },
    {
      "source": "Second",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8526
    },
    {
      "source": "Second",
      "target": "xiQNfYl33p",
      "similarity": 0.8502
    },
    {
      "source": "Second",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8496
    },
    {
      "source": "The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8667
    },
    {
      "source": "The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance",
      "target": "With extensive ablation studies",
      "similarity": 0.85
    },
    {
      "source": "The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance",
      "target": "hoYFLRNbhc",
      "similarity": 0.845
    },
    {
      "source": "The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance",
      "target": "5AtlfHYCPa",
      "similarity": 0.8439
    },
    {
      "source": "The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance",
      "target": "prompts of 128K length",
      "similarity": 0.837
    },
    {
      "source": "Ge7okBGZYi",
      "target": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "similarity": 0.82
    },
    {
      "source": "Ge7okBGZYi",
      "target": "MscdsFVZrN",
      "similarity": 0.8022
    },
    {
      "source": "Ge7okBGZYi",
      "target": "8y5Uf6oEiB",
      "similarity": 0.7966
    },
    {
      "source": "Ge7okBGZYi",
      "target": "Theory (SPADE) approach relies on a Generalized Extreme Value (GEV) model",
      "similarity": 0.7939
    },
    {
      "source": "Ge7okBGZYi",
      "target": "P9VdRQOyqu",
      "similarity": 0.7932
    },
    {
      "source": "computer graphics and scientific computing; however",
      "target": "powerful expressiveness",
      "similarity": 0.8651
    },
    {
      "source": "computer graphics and scientific computing; however",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.8384
    },
    {
      "source": "computer graphics and scientific computing; however",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.83
    },
    {
      "source": "computer graphics and scientific computing; however",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8247
    },
    {
      "source": "computer graphics and scientific computing; however",
      "target": "l6QnSQizmN",
      "similarity": 0.8246
    },
    {
      "source": "implementation",
      "target": "20qZK2T7fa",
      "similarity": 0.8683
    },
    {
      "source": "implementation",
      "target": "In this work",
      "similarity": 0.866
    },
    {
      "source": "implementation",
      "target": "1yJP5TVWih",
      "similarity": 0.8435
    },
    {
      "source": "implementation",
      "target": "K4FAFNRpko",
      "similarity": 0.8431
    },
    {
      "source": "implementation",
      "target": "Finally",
      "similarity": 0.8429
    },
    {
      "source": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "target": "Mjn53GtMxi",
      "similarity": 0.8417
    },
    {
      "source": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "target": "Usklli4gMc",
      "similarity": 0.8366
    },
    {
      "source": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "target": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "similarity": 0.834
    },
    {
      "source": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "target": "See https://4d-diffusion.github.io for video samples.\"",
      "similarity": 0.8315
    },
    {
      "source": "a comprehensive analysis comparing the two most common techniques for mitigating",
      "target": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "similarity": 0.8313
    },
    {
      "source": "this spectral bias: Fourier feature encodings (FFE) and multigrid parametric",
      "target": "4iFSBgxvIO",
      "similarity": 0.8202
    },
    {
      "source": "this spectral bias: Fourier feature encodings (FFE) and multigrid parametric",
      "target": "tj5xJInWty",
      "similarity": 0.8151
    },
    {
      "source": "this spectral bias: Fourier feature encodings (FFE) and multigrid parametric",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8011
    },
    {
      "source": "this spectral bias: Fourier feature encodings (FFE) and multigrid parametric",
      "target": "In this paper",
      "similarity": 0.7999
    },
    {
      "source": "this spectral bias: Fourier feature encodings (FFE) and multigrid parametric",
      "target": "goBaGHLAdP",
      "similarity": 0.7952
    },
    {
      "source": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8524
    },
    {
      "source": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "target": "In this task",
      "similarity": 0.8443
    },
    {
      "source": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8437
    },
    {
      "source": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "target": "Due to the high costs of setting up and running experiments",
      "similarity": 0.8421
    },
    {
      "source": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8383
    },
    {
      "source": "MPEs often outperform them and learn representations with higher resolution and",
      "target": "In this paper",
      "similarity": 0.8483
    },
    {
      "source": "MPEs often outperform them and learn representations with higher resolution and",
      "target": "vVxeFSR4fU",
      "similarity": 0.8283
    },
    {
      "source": "MPEs often outperform them and learn representations with higher resolution and",
      "target": "In this work",
      "similarity": 0.8261
    },
    {
      "source": "MPEs often outperform them and learn representations with higher resolution and",
      "target": "GkWA6NjePN",
      "similarity": 0.8252
    },
    {
      "source": "MPEs often outperform them and learn representations with higher resolution and",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8227
    },
    {
      "source": "finer detail. FFE's roots in the Fourier transform",
      "target": "Discoveries of such relations",
      "similarity": 0.8141
    },
    {
      "source": "finer detail. FFE's roots in the Fourier transform",
      "target": "pOO9cqLq7Q",
      "similarity": 0.804
    },
    {
      "source": "finer detail. FFE's roots in the Fourier transform",
      "target": "X6y5CC44HM",
      "similarity": 0.8007
    },
    {
      "source": "finer detail. FFE's roots in the Fourier transform",
      "target": "First",
      "similarity": 0.7938
    },
    {
      "source": "finer detail. FFE's roots in the Fourier transform",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.7926
    },
    {
      "source": "aliasing if pushed too far",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8283
    },
    {
      "source": "aliasing if pushed too far",
      "target": "kxnoqaisCT",
      "similarity": 0.8281
    },
    {
      "source": "aliasing if pushed too far",
      "target": "In this paper",
      "similarity": 0.8251
    },
    {
      "source": "aliasing if pushed too far",
      "target": "However",
      "similarity": 0.8235
    },
    {
      "source": "aliasing if pushed too far",
      "target": "7bAjVh3CG3",
      "similarity": 0.8165
    },
    {
      "source": "no such limitation. To understand the difference in performance",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8398
    },
    {
      "source": "no such limitation. To understand the difference in performance",
      "target": "eiqrnVaeIw",
      "similarity": 0.8259
    },
    {
      "source": "no such limitation. To understand the difference in performance",
      "target": "6GATHdOi1x",
      "similarity": 0.8146
    },
    {
      "source": "no such limitation. To understand the difference in performance",
      "target": "YslOW2SO6S",
      "similarity": 0.8122
    },
    {
      "source": "no such limitation. To understand the difference in performance",
      "target": "VpWki1v2P8",
      "similarity": 0.8111
    },
    {
      "source": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "target": "In particular",
      "similarity": 0.8693
    },
    {
      "source": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8511
    },
    {
      "source": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "target": "9KiE3t6CsL",
      "similarity": 0.8481
    },
    {
      "source": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8473
    },
    {
      "source": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "target": "qZEdmyqCHF",
      "similarity": 0.8439
    },
    {
      "source": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8429
    },
    {
      "source": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "target": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "similarity": 0.8405
    },
    {
      "source": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "target": "lOi6FtIwR8",
      "similarity": 0.8368
    },
    {
      "source": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "target": "ff2V3UR9sC",
      "similarity": 0.8356
    },
    {
      "source": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "target": "In this work",
      "similarity": 0.8346
    },
    {
      "source": "of the NTK",
      "target": "ymt4crbbXh",
      "similarity": 0.9266
    },
    {
      "source": "of the NTK",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8829
    },
    {
      "source": "of the NTK",
      "target": "xJXq6FkqEw",
      "similarity": 0.8719
    },
    {
      "source": "of the NTK",
      "target": "j1tSLYKwg8",
      "similarity": 0.8685
    },
    {
      "source": "of the NTK",
      "target": "In this paper",
      "similarity": 0.8621
    },
    {
      "source": "structure of their grid and not their learnable embedding. This mechanism is",
      "target": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "similarity": 0.849
    },
    {
      "source": "structure of their grid and not their learnable embedding. This mechanism is",
      "target": "connection component",
      "similarity": 0.8466
    },
    {
      "source": "structure of their grid and not their learnable embedding. This mechanism is",
      "target": "In parallel",
      "similarity": 0.8168
    },
    {
      "source": "structure of their grid and not their learnable embedding. This mechanism is",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8154
    },
    {
      "source": "structure of their grid and not their learnable embedding. This mechanism is",
      "target": "In contrast",
      "similarity": 0.81
    },
    {
      "source": "fundamentally different from FFEs",
      "target": "Ev4iw23gdI",
      "similarity": 0.8519
    },
    {
      "source": "fundamentally different from FFEs",
      "target": "D2hhkU5O48",
      "similarity": 0.8449
    },
    {
      "source": "fundamentally different from FFEs",
      "target": "In this paper",
      "similarity": 0.8345
    },
    {
      "source": "fundamentally different from FFEs",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8281
    },
    {
      "source": "fundamentally different from FFEs",
      "target": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "similarity": 0.8199
    },
    {
      "source": "improve performance. Results are empirically validated on a 2D image regression",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.8426
    },
    {
      "source": "improve performance. Results are empirically validated on a 2D image regression",
      "target": "qFZnAC4GHR",
      "similarity": 0.8381
    },
    {
      "source": "improve performance. Results are empirically validated on a 2D image regression",
      "target": "The best-performing model",
      "similarity": 0.8288
    },
    {
      "source": "improve performance. Results are empirically validated on a 2D image regression",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8259
    },
    {
      "source": "improve performance. Results are empirically validated on a 2D image regression",
      "target": "also study the necessity of this condition via ablation studies and analytical exam-",
      "similarity": 0.8259
    },
    {
      "source": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "target": "vRvVVb0NAz",
      "similarity": 0.8843
    },
    {
      "source": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8424
    },
    {
      "source": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "target": "8y5Uf6oEiB",
      "similarity": 0.8333
    },
    {
      "source": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "target": "MscdsFVZrN",
      "similarity": 0.8277
    },
    {
      "source": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8271
    },
    {
      "source": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "target": "By leveraging online data collection",
      "similarity": 0.8789
    },
    {
      "source": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "target": "QogcGNXJVw",
      "similarity": 0.8559
    },
    {
      "source": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "target": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "similarity": 0.8397
    },
    {
      "source": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "target": "N4rYbQowE3",
      "similarity": 0.8286
    },
    {
      "source": "surface regression on objects from the Stanford graphics dataset. Using peak",
      "target": "standard training and",
      "similarity": 0.8259
    },
    {
      "source": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "target": "ZadnlOHsHv",
      "similarity": 0.8248
    },
    {
      "source": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "target": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "similarity": 0.8161
    },
    {
      "source": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.815
    },
    {
      "source": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "target": "In a client-server setting",
      "similarity": 0.8142
    },
    {
      "source": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "target": "In $\\texttt{ProAdvPrompter}$",
      "similarity": 0.8037
    },
    {
      "source": "evaluate how well fine details are learned",
      "target": "iOMnn1hSBO",
      "similarity": 0.8528
    },
    {
      "source": "evaluate how well fine details are learned",
      "target": "x33vSZUg0A",
      "similarity": 0.842
    },
    {
      "source": "evaluate how well fine details are learned",
      "target": "To this end",
      "similarity": 0.837
    },
    {
      "source": "evaluate how well fine details are learned",
      "target": "previous results.\"",
      "similarity": 0.8318
    },
    {
      "source": "evaluate how well fine details are learned",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8296
    },
    {
      "source": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "target": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "similarity": 0.8425
    },
    {
      "source": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "target": "kbjJ9ZOakb",
      "similarity": 0.8271
    },
    {
      "source": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "target": "XsgHl54yO7",
      "similarity": 0.8241
    },
    {
      "source": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "target": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "similarity": 0.8181
    },
    {
      "source": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "target": "Next",
      "similarity": 0.8109
    },
    {
      "source": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.888
    },
    {
      "source": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8527
    },
    {
      "source": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "target": "To overcome these challenges",
      "similarity": 0.846
    },
    {
      "source": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "target": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "similarity": 0.8427
    },
    {
      "source": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "target": "FrFQpAgnGE",
      "similarity": 0.8387
    },
    {
      "source": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "target": "hPWWXpCaJ7",
      "similarity": 0.82
    },
    {
      "source": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "target": "In this paper",
      "similarity": 0.8114
    },
    {
      "source": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "target": "On an average of 6 diverse tasks",
      "similarity": 0.8114
    },
    {
      "source": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "target": "D2hhkU5O48",
      "similarity": 0.8105
    },
    {
      "source": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "target": "SMK0f8JoKF",
      "similarity": 0.8068
    },
    {
      "source": "FFE.\"",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8612
    },
    {
      "source": "FFE.\"",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8421
    },
    {
      "source": "FFE.\"",
      "target": "prompts. As such",
      "similarity": 0.8417
    },
    {
      "source": "FFE.\"",
      "target": "79ZkWgY2FI",
      "similarity": 0.8393
    },
    {
      "source": "FFE.\"",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8318
    },
    {
      "source": "il5yUQsrjC",
      "target": "8eNLKk5by4",
      "similarity": 0.9007
    },
    {
      "source": "il5yUQsrjC",
      "target": "XdRIno98gG",
      "similarity": 0.8772
    },
    {
      "source": "il5yUQsrjC",
      "target": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "similarity": 0.8627
    },
    {
      "source": "il5yUQsrjC",
      "target": "sIE2rI3ZPs",
      "similarity": 0.862
    },
    {
      "source": "il5yUQsrjC",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.859
    },
    {
      "source": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "target": "increased their demand. However",
      "similarity": 0.9206
    },
    {
      "source": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "target": "0h6v4SpLCY",
      "similarity": 0.8915
    },
    {
      "source": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "target": "4JK2XMGUc8",
      "similarity": 0.8887
    },
    {
      "source": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.887
    },
    {
      "source": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "target": "However",
      "similarity": 0.8853
    },
    {
      "source": "gJG4IPwg6l",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8053
    },
    {
      "source": "gJG4IPwg6l",
      "target": "In parallel",
      "similarity": 0.7962
    },
    {
      "source": "gJG4IPwg6l",
      "target": "structure of their grid and not their learnable embedding. This mechanism is",
      "similarity": 0.7955
    },
    {
      "source": "gJG4IPwg6l",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.7918
    },
    {
      "source": "gJG4IPwg6l",
      "target": "In this work",
      "similarity": 0.7915
    },
    {
      "source": "UmdotAAVDe",
      "target": "Finally",
      "similarity": 0.8547
    },
    {
      "source": "UmdotAAVDe",
      "target": "i7jAYFYDcM",
      "similarity": 0.8378
    },
    {
      "source": "UmdotAAVDe",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8373
    },
    {
      "source": "UmdotAAVDe",
      "target": "work that captures both architectures. We introduce a modification in the skip",
      "similarity": 0.8301
    },
    {
      "source": "UmdotAAVDe",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.828
    },
    {
      "source": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "target": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "similarity": 0.8142
    },
    {
      "source": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "target": "However",
      "similarity": 0.8125
    },
    {
      "source": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "target": "RQz7szbVDs",
      "similarity": 0.8121
    },
    {
      "source": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "target": "gFvRRCnQvX",
      "similarity": 0.8106
    },
    {
      "source": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "target": "FCMpUOZkxi",
      "similarity": 0.8043
    },
    {
      "source": "cRnCcuLvyr",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8494
    },
    {
      "source": "cRnCcuLvyr",
      "target": "EyaH1wzmao",
      "similarity": 0.8482
    },
    {
      "source": "cRnCcuLvyr",
      "target": "across new LLMs and different tasks because of their limited ability to leverage",
      "similarity": 0.8411
    },
    {
      "source": "cRnCcuLvyr",
      "target": "relying on backward propagation",
      "similarity": 0.8384
    },
    {
      "source": "cRnCcuLvyr",
      "target": "In this work",
      "similarity": 0.8372
    },
    {
      "source": "yORSk4Ycsa",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8578
    },
    {
      "source": "yORSk4Ycsa",
      "target": "YcUV5apdlq",
      "similarity": 0.8519
    },
    {
      "source": "yORSk4Ycsa",
      "target": "wide dissemination",
      "similarity": 0.8516
    },
    {
      "source": "yORSk4Ycsa",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8503
    },
    {
      "source": "yORSk4Ycsa",
      "target": "h8yg0hT96f",
      "similarity": 0.8483
    },
    {
      "source": "ThhQyIruEs",
      "target": "ogXkmugNZw",
      "similarity": 0.835
    },
    {
      "source": "ThhQyIruEs",
      "target": "On the AlpacaEval benchmark",
      "similarity": 0.8148
    },
    {
      "source": "ThhQyIruEs",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.8092
    },
    {
      "source": "ThhQyIruEs",
      "target": "uHLgDEgiS5",
      "similarity": 0.8082
    },
    {
      "source": "ThhQyIruEs",
      "target": "On the other hand",
      "similarity": 0.8078
    },
    {
      "source": "YslOW2SO6S",
      "target": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "similarity": 0.8896
    },
    {
      "source": "YslOW2SO6S",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8609
    },
    {
      "source": "YslOW2SO6S",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.85
    },
    {
      "source": "YslOW2SO6S",
      "target": "Following this new setting",
      "similarity": 0.8403
    },
    {
      "source": "YslOW2SO6S",
      "target": "Reweighting (GSR)",
      "similarity": 0.8264
    },
    {
      "source": "CtM5xjRSfm",
      "target": "q87GUkdQBm",
      "similarity": 0.8365
    },
    {
      "source": "CtM5xjRSfm",
      "target": "Moreover",
      "similarity": 0.8162
    },
    {
      "source": "CtM5xjRSfm",
      "target": "ZNnmcddaB3",
      "similarity": 0.8115
    },
    {
      "source": "CtM5xjRSfm",
      "target": "Finally",
      "similarity": 0.8096
    },
    {
      "source": "CtM5xjRSfm",
      "target": "TjP1d8PP8l",
      "similarity": 0.8075
    },
    {
      "source": "3IFRygQKGL",
      "target": "In this paper",
      "similarity": 0.8145
    },
    {
      "source": "3IFRygQKGL",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8106
    },
    {
      "source": "3IFRygQKGL",
      "target": "Our code",
      "similarity": 0.8038
    },
    {
      "source": "3IFRygQKGL",
      "target": "yR47RmND1m",
      "similarity": 0.8004
    },
    {
      "source": "3IFRygQKGL",
      "target": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "similarity": 0.795
    },
    {
      "source": "Inspired by MuZero",
      "target": "Ax3uliEBVR",
      "similarity": 0.8477
    },
    {
      "source": "Inspired by MuZero",
      "target": "4v4RcAODj9",
      "similarity": 0.8248
    },
    {
      "source": "Inspired by MuZero",
      "target": "mkDam1xIzW",
      "similarity": 0.8206
    },
    {
      "source": "Inspired by MuZero",
      "target": "4GT9uTsAJE",
      "similarity": 0.8157
    },
    {
      "source": "Inspired by MuZero",
      "target": "N4NhVN30ph",
      "similarity": 0.8104
    },
    {
      "source": "aSy2nYwiZ2",
      "target": "In each case",
      "similarity": 0.8225
    },
    {
      "source": "aSy2nYwiZ2",
      "target": "DTqx3iqjkz",
      "similarity": 0.8212
    },
    {
      "source": "aSy2nYwiZ2",
      "target": "UyU8ETswPg",
      "similarity": 0.821
    },
    {
      "source": "aSy2nYwiZ2",
      "target": "zXCnIyX9MG",
      "similarity": 0.8208
    },
    {
      "source": "aSy2nYwiZ2",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8207
    },
    {
      "source": "ispjankYab",
      "target": "latent variables",
      "similarity": 0.8383
    },
    {
      "source": "ispjankYab",
      "target": "nrvoWOWcyg",
      "similarity": 0.8368
    },
    {
      "source": "ispjankYab",
      "target": "cADpvQgnqg",
      "similarity": 0.8357
    },
    {
      "source": "ispjankYab",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8355
    },
    {
      "source": "ispjankYab",
      "target": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "similarity": 0.8343
    },
    {
      "source": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8604
    },
    {
      "source": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "target": "DPzQ5n3mNm",
      "similarity": 0.8487
    },
    {
      "source": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.848
    },
    {
      "source": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "target": "E2PFv7ad3p",
      "similarity": 0.836
    },
    {
      "source": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "target": "MxbEiFRf39",
      "similarity": 0.8291
    },
    {
      "source": "To tackle this challenge",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.894
    },
    {
      "source": "To tackle this challenge",
      "target": "fAAaT826Vv",
      "similarity": 0.8733
    },
    {
      "source": "To tackle this challenge",
      "target": "Despite theoretically sound",
      "similarity": 0.8625
    },
    {
      "source": "To tackle this challenge",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8598
    },
    {
      "source": "To tackle this challenge",
      "target": "tu3qwNjrtw",
      "similarity": 0.8584
    },
    {
      "source": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "target": "Further",
      "similarity": 0.8652
    },
    {
      "source": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8584
    },
    {
      "source": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8556
    },
    {
      "source": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "target": "of natural language. However",
      "similarity": 0.8536
    },
    {
      "source": "Our approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.",
      "target": "BL4WBIfyrz",
      "similarity": 0.8522
    },
    {
      "source": "In empirical evaluation on synthetic and real-world environments",
      "target": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "similarity": 0.8205
    },
    {
      "source": "In empirical evaluation on synthetic and real-world environments",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8151
    },
    {
      "source": "In empirical evaluation on synthetic and real-world environments",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.8131
    },
    {
      "source": "In empirical evaluation on synthetic and real-world environments",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8096
    },
    {
      "source": "In empirical evaluation on synthetic and real-world environments",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8055
    },
    {
      "source": "We also observe that the abstracted high-order actions are potentially interpretable",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.9052
    },
    {
      "source": "We also observe that the abstracted high-order actions are potentially interpretable",
      "target": "However",
      "similarity": 0.8986
    },
    {
      "source": "We also observe that the abstracted high-order actions are potentially interpretable",
      "target": "wHebuIb6IH",
      "similarity": 0.8847
    },
    {
      "source": "We also observe that the abstracted high-order actions are potentially interpretable",
      "target": "t9lS1lX9FQ",
      "similarity": 0.881
    },
    {
      "source": "We also observe that the abstracted high-order actions are potentially interpretable",
      "target": "Furthermore",
      "similarity": 0.8807
    },
    {
      "source": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "target": "rTQNGQxm4K",
      "similarity": 0.8776
    },
    {
      "source": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "target": "5xSRg3eYZz",
      "similarity": 0.8578
    },
    {
      "source": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "target": "In particular",
      "similarity": 0.8567
    },
    {
      "source": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "target": "OuLgaHEmzi",
      "similarity": 0.8544
    },
    {
      "source": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "target": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "similarity": 0.8529
    },
    {
      "source": "BmG88rONaU",
      "target": "4GT9uTsAJE",
      "similarity": 0.8356
    },
    {
      "source": "BmG88rONaU",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8228
    },
    {
      "source": "BmG88rONaU",
      "target": "{Subsequently}",
      "similarity": 0.8189
    },
    {
      "source": "BmG88rONaU",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8186
    },
    {
      "source": "BmG88rONaU",
      "target": "4FIjRodbW6",
      "similarity": 0.8118
    },
    {
      "source": "However",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8981
    },
    {
      "source": "However",
      "target": "NvDRvtrGLo",
      "similarity": 0.8968
    },
    {
      "source": "However",
      "target": "INow59Vurm",
      "similarity": 0.8944
    },
    {
      "source": "However",
      "target": "avSocG0oFA",
      "similarity": 0.8833
    },
    {
      "source": "However",
      "target": "3Z2flzXzBY",
      "similarity": 0.8727
    },
    {
      "source": "Specifically",
      "target": "gsShHPxkUW",
      "similarity": 0.8508
    },
    {
      "source": "Specifically",
      "target": "EW6bNEqalF",
      "similarity": 0.837
    },
    {
      "source": "Specifically",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8325
    },
    {
      "source": "Specifically",
      "target": "2fojNANZSv",
      "similarity": 0.8283
    },
    {
      "source": "Specifically",
      "target": "This corresponds to",
      "similarity": 0.823
    },
    {
      "source": "In this paper",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8784
    },
    {
      "source": "In this paper",
      "target": "xiQNfYl33p",
      "similarity": 0.8545
    },
    {
      "source": "In this paper",
      "target": "KW8yzAOIZr",
      "similarity": 0.8477
    },
    {
      "source": "In this paper",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8451
    },
    {
      "source": "In this paper",
      "target": "hjROBHstZ3",
      "similarity": 0.8407
    },
    {
      "source": "Based on the observations",
      "target": "p4cLtzk4oe",
      "similarity": 0.8836
    },
    {
      "source": "Based on the observations",
      "target": "zCZnEXF3bN",
      "similarity": 0.8621
    },
    {
      "source": "Based on the observations",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8579
    },
    {
      "source": "Based on the observations",
      "target": "AJpUZd8Clb",
      "similarity": 0.8555
    },
    {
      "source": "Based on the observations",
      "target": "iOMnn1hSBO",
      "similarity": 0.8551
    },
    {
      "source": "In brief",
      "target": "To this end",
      "similarity": 0.8648
    },
    {
      "source": "In brief",
      "target": "In this task",
      "similarity": 0.8601
    },
    {
      "source": "In brief",
      "target": "However",
      "similarity": 0.8559
    },
    {
      "source": "In brief",
      "target": "AJpUZd8Clb",
      "similarity": 0.8529
    },
    {
      "source": "In brief",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8521
    },
    {
      "source": "Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift.",
      "target": "5xwx1Myosu",
      "similarity": 0.8511
    },
    {
      "source": "Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift.",
      "target": "What mechanisms underlie this ability for compositional generalization?",
      "similarity": 0.8314
    },
    {
      "source": "Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift.",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8163
    },
    {
      "source": "Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift.",
      "target": "nYjAzwor9R",
      "similarity": 0.8124
    },
    {
      "source": "Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift.",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8116
    },
    {
      "source": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "target": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "similarity": 0.8641
    },
    {
      "source": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8497
    },
    {
      "source": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "target": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "similarity": 0.8417
    },
    {
      "source": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "target": "In this paper",
      "similarity": 0.8415
    },
    {
      "source": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "target": "jj7b3p5kLY",
      "similarity": 0.8324
    },
    {
      "source": "TDy5Ih78b4",
      "target": "However",
      "similarity": 0.9137
    },
    {
      "source": "TDy5Ih78b4",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.9043
    },
    {
      "source": "TDy5Ih78b4",
      "target": "cZWCjan02B",
      "similarity": 0.8993
    },
    {
      "source": "TDy5Ih78b4",
      "target": "t9lS1lX9FQ",
      "similarity": 0.8858
    },
    {
      "source": "TDy5Ih78b4",
      "target": "prefix distributions",
      "similarity": 0.8835
    },
    {
      "source": "UyU8ETswPg",
      "target": "wCOJpXm0Me",
      "similarity": 0.8537
    },
    {
      "source": "UyU8ETswPg",
      "target": "PgXpOOqtyd",
      "similarity": 0.8361
    },
    {
      "source": "UyU8ETswPg",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.8303
    },
    {
      "source": "UyU8ETswPg",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8178
    },
    {
      "source": "UyU8ETswPg",
      "target": "Iht4NNVqk0",
      "similarity": 0.8156
    },
    {
      "source": "h6ktwCPYxE",
      "target": "aKJr5NnN8U",
      "similarity": 0.8092
    },
    {
      "source": "h6ktwCPYxE",
      "target": "This insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair",
      "similarity": 0.807
    },
    {
      "source": "h6ktwCPYxE",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8018
    },
    {
      "source": "h6ktwCPYxE",
      "target": "In this paper",
      "similarity": 0.8006
    },
    {
      "source": "h6ktwCPYxE",
      "target": "whaO3482bs",
      "similarity": 0.8001
    },
    {
      "source": "kN25ggeq1J",
      "target": "In this paper",
      "similarity": 0.8449
    },
    {
      "source": "kN25ggeq1J",
      "target": "6VhDQP7WGX",
      "similarity": 0.8396
    },
    {
      "source": "kN25ggeq1J",
      "target": "pHOH8FVrTp",
      "similarity": 0.8105
    },
    {
      "source": "kN25ggeq1J",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8105
    },
    {
      "source": "kN25ggeq1J",
      "target": "j9VVzueEbG",
      "similarity": 0.8074
    },
    {
      "source": "We summarize three meta-benchmarks based on established forms of logical reasoning",
      "target": "Our codes are available at \\url{https://github.com/lswhim/PreferDiff}.\"",
      "similarity": 0.8384
    },
    {
      "source": "We summarize three meta-benchmarks based on established forms of logical reasoning",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8242
    },
    {
      "source": "We summarize three meta-benchmarks based on established forms of logical reasoning",
      "target": "edges",
      "similarity": 0.823
    },
    {
      "source": "We summarize three meta-benchmarks based on established forms of logical reasoning",
      "target": "bRa4JLPzii",
      "similarity": 0.8225
    },
    {
      "source": "We summarize three meta-benchmarks based on established forms of logical reasoning",
      "target": "otW0TJOUYF",
      "similarity": 0.8222
    },
    {
      "source": "eaTqsptDPL",
      "target": "1qq1QJKM5q",
      "similarity": 0.8547
    },
    {
      "source": "eaTqsptDPL",
      "target": "kbeX97jExm",
      "similarity": 0.851
    },
    {
      "source": "eaTqsptDPL",
      "target": "1qGkuxI9UX",
      "similarity": 0.8463
    },
    {
      "source": "eaTqsptDPL",
      "target": "respectively. On skill retention tasks",
      "similarity": 0.8459
    },
    {
      "source": "eaTqsptDPL",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8432
    },
    {
      "source": "Recently",
      "target": "To address this",
      "similarity": 0.8496
    },
    {
      "source": "Recently",
      "target": "Antib6Uovh",
      "similarity": 0.8413
    },
    {
      "source": "Recently",
      "target": "HqjRlT65WX",
      "similarity": 0.8382
    },
    {
      "source": "Recently",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8323
    },
    {
      "source": "Recently",
      "target": "To enable TTA for regression",
      "similarity": 0.8155
    },
    {
      "source": "Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks.",
      "target": "Pujt3ADZgI",
      "similarity": 0.8439
    },
    {
      "source": "Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks.",
      "target": "AcVpLS86RT",
      "similarity": 0.8382
    },
    {
      "source": "Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks.",
      "target": "rpwGUtTeA5",
      "similarity": 0.8302
    },
    {
      "source": "Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks.",
      "target": "findings reveal that incorporating collective judgments from such a mixed pool",
      "similarity": 0.829
    },
    {
      "source": "Such merging methodology faces a central challenge: interference between model parameters fine-tuned on different tasks.",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8273
    },
    {
      "source": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.9102
    },
    {
      "source": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.9062
    },
    {
      "source": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "target": "pRCOZllZdT",
      "similarity": 0.9032
    },
    {
      "source": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "target": "JSB171dSUU",
      "similarity": 0.9029
    },
    {
      "source": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "target": "jTEKTdI3K9",
      "similarity": 0.8949
    },
    {
      "source": "To improve the performance of a merged model",
      "target": "aKkDY1Wca0",
      "similarity": 0.8515
    },
    {
      "source": "To improve the performance of a merged model",
      "target": "It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding.",
      "similarity": 0.8514
    },
    {
      "source": "To improve the performance of a merged model",
      "target": "ff2V3UR9sC",
      "similarity": 0.8312
    },
    {
      "source": "To improve the performance of a merged model",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8281
    },
    {
      "source": "To improve the performance of a merged model",
      "target": "NKotdPUc3L",
      "similarity": 0.8277
    },
    {
      "source": "In this work",
      "target": "BA1eG7vCNb",
      "similarity": 0.8575
    },
    {
      "source": "In this work",
      "target": "E2PFv7ad3p",
      "similarity": 0.8499
    },
    {
      "source": "In this work",
      "target": "Among these",
      "similarity": 0.8385
    },
    {
      "source": "In this work",
      "target": "show that the proposed strategy can enhance the performance of strong pruning",
      "similarity": 0.8379
    },
    {
      "source": "In this work",
      "target": "We conduct a detailed analysis of early stopping in our algorithm",
      "similarity": 0.8365
    },
    {
      "source": "In the course of this process",
      "target": "vjel3nWP2a",
      "similarity": 0.8038
    },
    {
      "source": "In the course of this process",
      "target": "O6znYvxC1U",
      "similarity": 0.798
    },
    {
      "source": "In the course of this process",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.7948
    },
    {
      "source": "In the course of this process",
      "target": "NfCEVihkdC",
      "similarity": 0.7908
    },
    {
      "source": "In the course of this process",
      "target": "However",
      "similarity": 0.7879
    },
    {
      "source": "Drawing upon our observation",
      "target": "dTkqaCKLPp",
      "similarity": 0.8245
    },
    {
      "source": "Drawing upon our observation",
      "target": "To validate OvercookedV2",
      "similarity": 0.8189
    },
    {
      "source": "Drawing upon our observation",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8082
    },
    {
      "source": "Drawing upon our observation",
      "target": "Building on these insights",
      "similarity": 0.8077
    },
    {
      "source": "Drawing upon our observation",
      "target": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "similarity": 0.802
    },
    {
      "source": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "target": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "similarity": 0.8808
    },
    {
      "source": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "target": "2QdsjiNXgj",
      "similarity": 0.851
    },
    {
      "source": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "target": "In response",
      "similarity": 0.8507
    },
    {
      "source": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8485
    },
    {
      "source": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "target": "254NJe9JEw",
      "similarity": 0.8484
    },
    {
      "source": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "target": "ogXkmugNZw",
      "similarity": 0.8162
    },
    {
      "source": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "target": "mYgoNEsUDi",
      "similarity": 0.7919
    },
    {
      "source": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "target": "world perspective. To address this",
      "similarity": 0.7891
    },
    {
      "source": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "target": "gLa96FlWwn",
      "similarity": 0.7877
    },
    {
      "source": "Our code is available at https://github.com/baiklab/SAFT-Merge.\"",
      "target": "For example",
      "similarity": 0.7872
    },
    {
      "source": "je3GZissZc",
      "target": "jqmptcSNVG",
      "similarity": 0.8791
    },
    {
      "source": "je3GZissZc",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8691
    },
    {
      "source": "je3GZissZc",
      "target": "instructions",
      "similarity": 0.8618
    },
    {
      "source": "je3GZissZc",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8612
    },
    {
      "source": "je3GZissZc",
      "target": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "similarity": 0.86
    },
    {
      "source": "sLKDbuyq99",
      "target": "For the diversity",
      "similarity": 0.856
    },
    {
      "source": "sLKDbuyq99",
      "target": "gfI9v7AbFg",
      "similarity": 0.8427
    },
    {
      "source": "sLKDbuyq99",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8422
    },
    {
      "source": "sLKDbuyq99",
      "target": "Specifically",
      "similarity": 0.8409
    },
    {
      "source": "sLKDbuyq99",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8393
    },
    {
      "source": "BkftcwIVmR",
      "target": "uhaLuZcCjH",
      "similarity": 0.8574
    },
    {
      "source": "BkftcwIVmR",
      "target": "the state-of-the-art private ANN search schemes",
      "similarity": 0.8541
    },
    {
      "source": "BkftcwIVmR",
      "target": "tn2mjzjSyR",
      "similarity": 0.846
    },
    {
      "source": "BkftcwIVmR",
      "target": "s9zoyICZ4k",
      "similarity": 0.8385
    },
    {
      "source": "BkftcwIVmR",
      "target": "To address these challenges",
      "similarity": 0.8359
    },
    {
      "source": "JbRM5QKRDd",
      "target": "Second",
      "similarity": 0.8699
    },
    {
      "source": "JbRM5QKRDd",
      "target": "Instruct",
      "similarity": 0.8638
    },
    {
      "source": "JbRM5QKRDd",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8588
    },
    {
      "source": "JbRM5QKRDd",
      "target": "This paper introduces WebRL",
      "similarity": 0.8465
    },
    {
      "source": "JbRM5QKRDd",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8417
    },
    {
      "source": "qnlG3zPQUy",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8407
    },
    {
      "source": "qnlG3zPQUy",
      "target": "0fJfVOSUra",
      "similarity": 0.8215
    },
    {
      "source": "qnlG3zPQUy",
      "target": "ed7zI29lRF",
      "similarity": 0.8213
    },
    {
      "source": "qnlG3zPQUy",
      "target": "uuriavczkL",
      "similarity": 0.8203
    },
    {
      "source": "qnlG3zPQUy",
      "target": "tePFpDgyqg",
      "similarity": 0.8201
    },
    {
      "source": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "target": "nYPuSzGE3X",
      "similarity": 0.8508
    },
    {
      "source": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "target": "nfKfAzkiez",
      "similarity": 0.8274
    },
    {
      "source": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "target": "1F8xTfv6ah",
      "similarity": 0.8271
    },
    {
      "source": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "target": "P6IVIoGRRg",
      "similarity": 0.8265
    },
    {
      "source": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "target": "98d7DLMGdt",
      "similarity": 0.8217
    },
    {
      "source": "faceswaps",
      "target": "1qgZXeMTTU",
      "similarity": 0.8799
    },
    {
      "source": "faceswaps",
      "target": "relying on backward propagation",
      "similarity": 0.8703
    },
    {
      "source": "faceswaps",
      "target": "254NJe9JEw",
      "similarity": 0.8681
    },
    {
      "source": "faceswaps",
      "target": "For TP",
      "similarity": 0.8657
    },
    {
      "source": "faceswaps",
      "target": "BI2int5SAC",
      "similarity": 0.865
    },
    {
      "source": "ftGnpZrW7P",
      "target": "To develop SoundCTM",
      "similarity": 0.8383
    },
    {
      "source": "ftGnpZrW7P",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8222
    },
    {
      "source": "ftGnpZrW7P",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8185
    },
    {
      "source": "ftGnpZrW7P",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8163
    },
    {
      "source": "ftGnpZrW7P",
      "target": "Our study uncovers many hidden mechanisms by which language models solve mathematical questions",
      "similarity": 0.8154
    },
    {
      "source": "XQlccqJpCC",
      "target": "1yJP5TVWih",
      "similarity": 0.8476
    },
    {
      "source": "XQlccqJpCC",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8381
    },
    {
      "source": "XQlccqJpCC",
      "target": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "similarity": 0.8321
    },
    {
      "source": "XQlccqJpCC",
      "target": "uHLgDEgiS5",
      "similarity": 0.8255
    },
    {
      "source": "XQlccqJpCC",
      "target": "dTPz4rEDok",
      "similarity": 0.8203
    },
    {
      "source": "However",
      "target": "This reformulation enables DiffILO to simultaneously solve ILPs and train the model via straightforward gradient descent",
      "similarity": 0.8726
    },
    {
      "source": "However",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8684
    },
    {
      "source": "However",
      "target": "instructions",
      "similarity": 0.8662
    },
    {
      "source": "However",
      "target": "IDJUscOjM3",
      "similarity": 0.858
    },
    {
      "source": "However",
      "target": "K7xpl3LZQp",
      "similarity": 0.8566
    },
    {
      "source": "In order to support an empirically grounded inductive approach to research",
      "target": "Traditional fine-tuning methods require substantial data",
      "similarity": 0.8689
    },
    {
      "source": "In order to support an empirically grounded inductive approach to research",
      "target": "However",
      "similarity": 0.8201
    },
    {
      "source": "In order to support an empirically grounded inductive approach to research",
      "target": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "similarity": 0.8173
    },
    {
      "source": "In order to support an empirically grounded inductive approach to research",
      "target": "q5EZ7gKcnW",
      "similarity": 0.8085
    },
    {
      "source": "In order to support an empirically grounded inductive approach to research",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.7913
    },
    {
      "source": "wkbx7BRAsM",
      "target": "GfXMTAJaxZ",
      "similarity": 0.8783
    },
    {
      "source": "wkbx7BRAsM",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.851
    },
    {
      "source": "wkbx7BRAsM",
      "target": "60GeEoG5kD",
      "similarity": 0.8422
    },
    {
      "source": "wkbx7BRAsM",
      "target": "GTcEe5fayC",
      "similarity": 0.8416
    },
    {
      "source": "wkbx7BRAsM",
      "target": "nrvoWOWcyg",
      "similarity": 0.8367
    },
    {
      "source": "5AtlfHYCPa",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8941
    },
    {
      "source": "5AtlfHYCPa",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.884
    },
    {
      "source": "5AtlfHYCPa",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8739
    },
    {
      "source": "5AtlfHYCPa",
      "target": "jTEKTdI3K9",
      "similarity": 0.8662
    },
    {
      "source": "5AtlfHYCPa",
      "target": "pRCOZllZdT",
      "similarity": 0.8646
    },
    {
      "source": "significant advancements in the field",
      "target": "v1rFkElnIn",
      "similarity": 0.831
    },
    {
      "source": "significant advancements in the field",
      "target": "wWnsoLhHwt",
      "similarity": 0.8146
    },
    {
      "source": "significant advancements in the field",
      "target": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "similarity": 0.8137
    },
    {
      "source": "significant advancements in the field",
      "target": "Due to these fairness constraints",
      "similarity": 0.8117
    },
    {
      "source": "significant advancements in the field",
      "target": "CkUHtnyhpY",
      "similarity": 0.8115
    },
    {
      "source": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "target": "However",
      "similarity": 0.9132
    },
    {
      "source": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "target": "cZWCjan02B",
      "similarity": 0.9061
    },
    {
      "source": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "target": "t9lS1lX9FQ",
      "similarity": 0.897
    },
    {
      "source": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "target": "prefix distributions",
      "similarity": 0.882
    },
    {
      "source": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "target": "pre-training data",
      "similarity": 0.8776
    },
    {
      "source": "these successes",
      "target": "Finally",
      "similarity": 0.8378
    },
    {
      "source": "these successes",
      "target": "KlN00vQEY2",
      "similarity": 0.8284
    },
    {
      "source": "these successes",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8272
    },
    {
      "source": "these successes",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8257
    },
    {
      "source": "these successes",
      "target": "However",
      "similarity": 0.8236
    },
    {
      "source": "of extreme weather events",
      "target": "component of real-world software development.\"",
      "similarity": 0.8394
    },
    {
      "source": "of extreme weather events",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8394
    },
    {
      "source": "of extreme weather events",
      "target": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "similarity": 0.8254
    },
    {
      "source": "of extreme weather events",
      "target": "CvGqMD5OtX",
      "similarity": 0.8117
    },
    {
      "source": "of extreme weather events",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8108
    },
    {
      "source": "such events remains limited. Given the critical importance of accurately forecasting",
      "target": "To address this",
      "similarity": 0.8281
    },
    {
      "source": "such events remains limited. Given the critical importance of accurately forecasting",
      "target": "named Pacmann",
      "similarity": 0.8235
    },
    {
      "source": "such events remains limited. Given the critical importance of accurately forecasting",
      "target": "NTHMw8S1Ow",
      "similarity": 0.8219
    },
    {
      "source": "such events remains limited. Given the critical importance of accurately forecasting",
      "target": "This paper proposes",
      "similarity": 0.818
    },
    {
      "source": "such events remains limited. Given the critical importance of accurately forecasting",
      "target": "nIEjY4a2Lf",
      "similarity": 0.8176
    },
    {
      "source": "extreme weather",
      "target": "However",
      "similarity": 0.7941
    },
    {
      "source": "extreme weather",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.7923
    },
    {
      "source": "extreme weather",
      "target": "In experiments with GPT-4",
      "similarity": 0.7858
    },
    {
      "source": "extreme weather",
      "target": "We5z3UEnUY",
      "similarity": 0.7853
    },
    {
      "source": "extreme weather",
      "target": "FEpAUnS7f7",
      "similarity": 0.7819
    },
    {
      "source": "high-resolution extreme weather cases derived from the High-Resolution Rapid",
      "target": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "similarity": 0.8164
    },
    {
      "source": "high-resolution extreme weather cases derived from the High-Resolution Rapid",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8139
    },
    {
      "source": "high-resolution extreme weather cases derived from the High-Resolution Rapid",
      "target": "nrvoWOWcyg",
      "similarity": 0.8106
    },
    {
      "source": "high-resolution extreme weather cases derived from the High-Resolution Rapid",
      "target": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "similarity": 0.8089
    },
    {
      "source": "high-resolution extreme weather cases derived from the High-Resolution Rapid",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8063
    },
    {
      "source": "Refresh (HRRR) data",
      "target": "bcTjW5kS4W",
      "similarity": 0.9317
    },
    {
      "source": "Refresh (HRRR) data",
      "target": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "similarity": 0.9011
    },
    {
      "source": "Refresh (HRRR) data",
      "target": "4A9IdSa1ul",
      "similarity": 0.8606
    },
    {
      "source": "Refresh (HRRR) data",
      "target": "To overcome this limitation",
      "similarity": 0.8551
    },
    {
      "source": "Refresh (HRRR) data",
      "target": "https://github.com/OceannTwT/Tool-Planner.\"",
      "similarity": 0.85
    },
    {
      "source": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "target": "1Z6PSw7OL8",
      "similarity": 0.8341
    },
    {
      "source": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "target": "P4XmKjXTrM",
      "similarity": 0.8256
    },
    {
      "source": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.8241
    },
    {
      "source": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8213
    },
    {
      "source": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "target": "JTji0Jfh5a",
      "similarity": 0.815
    },
    {
      "source": "Prediction (NWP) systems on HR-Extreme",
      "target": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "similarity": 0.8016
    },
    {
      "source": "Prediction (NWP) systems on HR-Extreme",
      "target": "To address this",
      "similarity": 0.788
    },
    {
      "source": "Prediction (NWP) systems on HR-Extreme",
      "target": "hPWWXpCaJ7",
      "similarity": 0.7808
    },
    {
      "source": "Prediction (NWP) systems on HR-Extreme",
      "target": "XsgHl54yO7",
      "similarity": 0.778
    },
    {
      "source": "Prediction (NWP) systems on HR-Extreme",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.7755
    },
    {
      "source": "deep learning model called HR-Heim which has superior performance on both",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8082
    },
    {
      "source": "deep learning model called HR-Heim which has superior performance on both",
      "target": "B8akWa62Da",
      "similarity": 0.8079
    },
    {
      "source": "deep learning model called HR-Heim which has superior performance on both",
      "target": "NCrFA7dq8T",
      "similarity": 0.8073
    },
    {
      "source": "deep learning model called HR-Heim which has superior performance on both",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.803
    },
    {
      "source": "deep learning model called HR-Heim which has superior performance on both",
      "target": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "similarity": 0.8022
    },
    {
      "source": "general loss and HR-Extreme compared to others. Our results reveal that the",
      "target": "It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.",
      "similarity": 0.853
    },
    {
      "source": "general loss and HR-Extreme compared to others. Our results reveal that the",
      "target": "mFY0tPDWK8",
      "similarity": 0.8372
    },
    {
      "source": "general loss and HR-Extreme compared to others. Our results reveal that the",
      "target": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "similarity": 0.8275
    },
    {
      "source": "general loss and HR-Extreme compared to others. Our results reveal that the",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8183
    },
    {
      "source": "general loss and HR-Extreme compared to others. Our results reveal that the",
      "target": "GTcEe5fayC",
      "similarity": 0.818
    },
    {
      "source": "errors of extreme weather cases are significantly larger than overall forecast error",
      "target": "This paper introduces WebRL",
      "similarity": 0.886
    },
    {
      "source": "errors of extreme weather cases are significantly larger than overall forecast error",
      "target": "DPzQ5n3mNm",
      "similarity": 0.8642
    },
    {
      "source": "errors of extreme weather cases are significantly larger than overall forecast error",
      "target": "U42TkrEDzb",
      "similarity": 0.852
    },
    {
      "source": "errors of extreme weather cases are significantly larger than overall forecast error",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8509
    },
    {
      "source": "errors of extreme weather cases are significantly larger than overall forecast error",
      "target": "the costliness of the labels",
      "similarity": 0.8509
    },
    {
      "source": "highlighting them as an crucial source of loss in weather prediction. These findings",
      "target": "bmrYu2Ekdz",
      "similarity": 0.8202
    },
    {
      "source": "highlighting them as an crucial source of loss in weather prediction. These findings",
      "target": "powerful expressiveness",
      "similarity": 0.8089
    },
    {
      "source": "highlighting them as an crucial source of loss in weather prediction. These findings",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8042
    },
    {
      "source": "highlighting them as an crucial source of loss in weather prediction. These findings",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.7974
    },
    {
      "source": "highlighting them as an crucial source of loss in weather prediction. These findings",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.7904
    },
    {
      "source": "underscore the necessity for future research to focus on improving the accuracy of",
      "target": "Metrics for probability measures",
      "similarity": 0.8716
    },
    {
      "source": "underscore the necessity for future research to focus on improving the accuracy of",
      "target": "ods",
      "similarity": 0.8472
    },
    {
      "source": "underscore the necessity for future research to focus on improving the accuracy of",
      "target": "this simple method is computationally fast",
      "similarity": 0.8392
    },
    {
      "source": "underscore the necessity for future research to focus on improving the accuracy of",
      "target": "6bKEWevgSd",
      "similarity": 0.836
    },
    {
      "source": "underscore the necessity for future research to focus on improving the accuracy of",
      "target": "However",
      "similarity": 0.8354
    },
    {
      "source": "extreme weather forecasts to enhance their practical utility\"",
      "target": "riieAeQBJm",
      "similarity": 0.8664
    },
    {
      "source": "extreme weather forecasts to enhance their practical utility\"",
      "target": "IuU0wcO0mo",
      "similarity": 0.8569
    },
    {
      "source": "extreme weather forecasts to enhance their practical utility\"",
      "target": "3E8YNv1HjU",
      "similarity": 0.8523
    },
    {
      "source": "extreme weather forecasts to enhance their practical utility\"",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8523
    },
    {
      "source": "extreme weather forecasts to enhance their practical utility\"",
      "target": "dOAkHmsjRX",
      "similarity": 0.8519
    },
    {
      "source": "5ck9PIrTpH",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.7641
    },
    {
      "source": "5ck9PIrTpH",
      "target": "rpouyo09V0",
      "similarity": 0.7612
    },
    {
      "source": "5ck9PIrTpH",
      "target": "tn2mjzjSyR",
      "similarity": 0.759
    },
    {
      "source": "5ck9PIrTpH",
      "target": "Discoveries of such relations",
      "similarity": 0.7581
    },
    {
      "source": "5ck9PIrTpH",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.7575
    },
    {
      "source": "xnF2U0ro7b",
      "target": "Additionally",
      "similarity": 0.8762
    },
    {
      "source": "xnF2U0ro7b",
      "target": "qIbbBSzH6n",
      "similarity": 0.8755
    },
    {
      "source": "xnF2U0ro7b",
      "target": "1F8xTfv6ah",
      "similarity": 0.8575
    },
    {
      "source": "xnF2U0ro7b",
      "target": "VVixJ9QavY",
      "similarity": 0.8523
    },
    {
      "source": "xnF2U0ro7b",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8473
    },
    {
      "source": "3Fgylj4uqL",
      "target": "In contrast",
      "similarity": 0.8322
    },
    {
      "source": "3Fgylj4uqL",
      "target": "r1KcapkzCt",
      "similarity": 0.8314
    },
    {
      "source": "3Fgylj4uqL",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8283
    },
    {
      "source": "3Fgylj4uqL",
      "target": "pCj2sLNoJq",
      "similarity": 0.828
    },
    {
      "source": "3Fgylj4uqL",
      "target": "However",
      "similarity": 0.8233
    },
    {
      "source": "RAyRXQjsFl",
      "target": "{Subsequently}",
      "similarity": 0.8809
    },
    {
      "source": "RAyRXQjsFl",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8746
    },
    {
      "source": "RAyRXQjsFl",
      "target": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "similarity": 0.8719
    },
    {
      "source": "RAyRXQjsFl",
      "target": "4GT9uTsAJE",
      "similarity": 0.8708
    },
    {
      "source": "RAyRXQjsFl",
      "target": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "similarity": 0.8706
    },
    {
      "source": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8504
    },
    {
      "source": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "target": "KAIqwkB3dT",
      "similarity": 0.8502
    },
    {
      "source": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8497
    },
    {
      "source": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "target": "r5IXBlTCGc",
      "similarity": 0.847
    },
    {
      "source": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "target": "eHehzSDUFp",
      "similarity": 0.8467
    },
    {
      "source": "5BRFddsAai",
      "target": "NHhjczmJjo",
      "similarity": 0.8496
    },
    {
      "source": "5BRFddsAai",
      "target": "xvhV3LvYTc",
      "similarity": 0.846
    },
    {
      "source": "5BRFddsAai",
      "target": "To this end",
      "similarity": 0.8437
    },
    {
      "source": "5BRFddsAai",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8424
    },
    {
      "source": "5BRFddsAai",
      "target": "Finally",
      "similarity": 0.841
    },
    {
      "source": "0h6v4SpLCY",
      "target": "increased their demand. However",
      "similarity": 0.9325
    },
    {
      "source": "0h6v4SpLCY",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.928
    },
    {
      "source": "0h6v4SpLCY",
      "target": "However",
      "similarity": 0.9216
    },
    {
      "source": "0h6v4SpLCY",
      "target": "mkNVPGpEPm",
      "similarity": 0.9018
    },
    {
      "source": "0h6v4SpLCY",
      "target": "sULAwlAWc1",
      "similarity": 0.8971
    },
    {
      "source": "CLE09ESvul",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8638
    },
    {
      "source": "CLE09ESvul",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8535
    },
    {
      "source": "CLE09ESvul",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8396
    },
    {
      "source": "CLE09ESvul",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8365
    },
    {
      "source": "CLE09ESvul",
      "target": "t9lS1lX9FQ",
      "similarity": 0.8353
    },
    {
      "source": "mkNVPGpEPm",
      "target": "increased their demand. However",
      "similarity": 0.9015
    },
    {
      "source": "mkNVPGpEPm",
      "target": "However",
      "similarity": 0.8944
    },
    {
      "source": "mkNVPGpEPm",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8851
    },
    {
      "source": "mkNVPGpEPm",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8789
    },
    {
      "source": "mkNVPGpEPm",
      "target": "sULAwlAWc1",
      "similarity": 0.877
    },
    {
      "source": "jlzNb1iWs3",
      "target": "WOt1owGfuN",
      "similarity": 0.8414
    },
    {
      "source": "jlzNb1iWs3",
      "target": "KlN00vQEY2",
      "similarity": 0.8362
    },
    {
      "source": "jlzNb1iWs3",
      "target": "traditional energy-based models",
      "similarity": 0.8351
    },
    {
      "source": "jlzNb1iWs3",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8311
    },
    {
      "source": "jlzNb1iWs3",
      "target": "Aye5wL6TCn",
      "similarity": 0.8269
    },
    {
      "source": "TOiageVNru",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8308
    },
    {
      "source": "TOiageVNru",
      "target": "uClUUJk05H",
      "similarity": 0.8222
    },
    {
      "source": "TOiageVNru",
      "target": "L238BAx0wP",
      "similarity": 0.8041
    },
    {
      "source": "TOiageVNru",
      "target": "Third",
      "similarity": 0.8022
    },
    {
      "source": "TOiageVNru",
      "target": "JV8zULNh24",
      "similarity": 0.8009
    },
    {
      "source": "FjZcwQJX8D",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8444
    },
    {
      "source": "FjZcwQJX8D",
      "target": "hrqNOxpItr",
      "similarity": 0.8254
    },
    {
      "source": "FjZcwQJX8D",
      "target": "PUnD86UEK5",
      "similarity": 0.8189
    },
    {
      "source": "FjZcwQJX8D",
      "target": "To overcome those challenges",
      "similarity": 0.8152
    },
    {
      "source": "FjZcwQJX8D",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8147
    },
    {
      "source": "Metrics for probability measures",
      "target": "ods",
      "similarity": 0.8749
    },
    {
      "source": "Metrics for probability measures",
      "target": "5oSUgTzs8Y",
      "similarity": 0.8702
    },
    {
      "source": "Metrics for probability measures",
      "target": "Moreover",
      "similarity": 0.8652
    },
    {
      "source": "Metrics for probability measures",
      "target": "To overcome these challenges",
      "similarity": 0.8617
    },
    {
      "source": "Metrics for probability measures",
      "target": "2QdsjiNXgj",
      "similarity": 0.8595
    },
    {
      "source": "However",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.9068
    },
    {
      "source": "However",
      "target": "c61unr33XA",
      "similarity": 0.8749
    },
    {
      "source": "However",
      "target": "fNMKqyvuZT",
      "similarity": 0.865
    },
    {
      "source": "However",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8573
    },
    {
      "source": "However",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8521
    },
    {
      "source": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8834
    },
    {
      "source": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8765
    },
    {
      "source": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.866
    },
    {
      "source": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "target": "E2PFv7ad3p",
      "similarity": 0.8502
    },
    {
      "source": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8443
    },
    {
      "source": "However",
      "target": "NHhjczmJjo",
      "similarity": 0.8421
    },
    {
      "source": "However",
      "target": "4YzVF9isgD",
      "similarity": 0.8345
    },
    {
      "source": "However",
      "target": "E48QvQppIN",
      "similarity": 0.8336
    },
    {
      "source": "However",
      "target": "Finally",
      "similarity": 0.8306
    },
    {
      "source": "However",
      "target": "FviefuxmeW",
      "similarity": 0.8306
    },
    {
      "source": "We propose the use of principal persistence measures",
      "target": "fAAaT826Vv",
      "similarity": 0.8785
    },
    {
      "source": "We propose the use of principal persistence measures",
      "target": "We perform detailed analyses",
      "similarity": 0.8618
    },
    {
      "source": "We propose the use of principal persistence measures",
      "target": "Moreover on large datasets with up to 100 million vectors",
      "similarity": 0.8398
    },
    {
      "source": "We propose the use of principal persistence measures",
      "target": "To tackle this challenge",
      "similarity": 0.8384
    },
    {
      "source": "We propose the use of principal persistence measures",
      "target": "GpUv1FvZi1",
      "similarity": 0.8317
    },
    {
      "source": "We provide a parallelized GPU implementation of this regularizer",
      "target": "fuoM5YDBX4",
      "similarity": 0.8575
    },
    {
      "source": "We provide a parallelized GPU implementation of this regularizer",
      "target": "KW8yzAOIZr",
      "similarity": 0.8401
    },
    {
      "source": "We provide a parallelized GPU implementation of this regularizer",
      "target": "This paper proposes",
      "similarity": 0.8377
    },
    {
      "source": "We provide a parallelized GPU implementation of this regularizer",
      "target": "Zk9guOl9NS",
      "similarity": 0.8328
    },
    {
      "source": "We provide a parallelized GPU implementation of this regularizer",
      "target": "VmJdqhuTCh",
      "similarity": 0.8247
    },
    {
      "source": "Furthermore",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8614
    },
    {
      "source": "Furthermore",
      "target": "that minimizes symmetric InfoNCE is the pointwise mutual information",
      "similarity": 0.8249
    },
    {
      "source": "Furthermore",
      "target": "suggesting that larger models can handle more complex reasoning tasks before over-relying on",
      "similarity": 0.8213
    },
    {
      "source": "Furthermore",
      "target": "is often a non-linear function",
      "similarity": 0.8191
    },
    {
      "source": "Furthermore",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8172
    },
    {
      "source": "OQqNieeivq",
      "target": "In this paper",
      "similarity": 0.8742
    },
    {
      "source": "OQqNieeivq",
      "target": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "similarity": 0.8274
    },
    {
      "source": "OQqNieeivq",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8271
    },
    {
      "source": "OQqNieeivq",
      "target": "O6znYvxC1U",
      "similarity": 0.8211
    },
    {
      "source": "OQqNieeivq",
      "target": "owP2mymrTD",
      "similarity": 0.8143
    },
    {
      "source": "B5iOSxM2I0",
      "target": "WCRQFlji2q",
      "similarity": 0.8718
    },
    {
      "source": "B5iOSxM2I0",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.861
    },
    {
      "source": "B5iOSxM2I0",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.8558
    },
    {
      "source": "B5iOSxM2I0",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8549
    },
    {
      "source": "B5iOSxM2I0",
      "target": "To this end",
      "similarity": 0.8538
    },
    {
      "source": "P9VdRQOyqu",
      "target": "Specifically",
      "similarity": 0.8418
    },
    {
      "source": "P9VdRQOyqu",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8397
    },
    {
      "source": "P9VdRQOyqu",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8185
    },
    {
      "source": "P9VdRQOyqu",
      "target": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "similarity": 0.8107
    },
    {
      "source": "P9VdRQOyqu",
      "target": "cPD2hU35x3",
      "similarity": 0.81
    },
    {
      "source": "fZK6AQXlUU",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.827
    },
    {
      "source": "fZK6AQXlUU",
      "target": "kRBQwlkFSP",
      "similarity": 0.8265
    },
    {
      "source": "fZK6AQXlUU",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.826
    },
    {
      "source": "fZK6AQXlUU",
      "target": "However",
      "similarity": 0.8251
    },
    {
      "source": "fZK6AQXlUU",
      "target": "MxbEiFRf39",
      "similarity": 0.8209
    },
    {
      "source": "Qj1KwBZaEI",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8448
    },
    {
      "source": "Qj1KwBZaEI",
      "target": "Finally",
      "similarity": 0.8409
    },
    {
      "source": "Qj1KwBZaEI",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.835
    },
    {
      "source": "Qj1KwBZaEI",
      "target": "In addition",
      "similarity": 0.8288
    },
    {
      "source": "Qj1KwBZaEI",
      "target": "Our code and additional resources are available at https://structuredllm.com.\"",
      "similarity": 0.8267
    },
    {
      "source": "0T49QbSOho",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8366
    },
    {
      "source": "0T49QbSOho",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8292
    },
    {
      "source": "0T49QbSOho",
      "target": "Oeb0I3JcVc",
      "similarity": 0.8152
    },
    {
      "source": "0T49QbSOho",
      "target": "6Ai8SuDsh3",
      "similarity": 0.8133
    },
    {
      "source": "0T49QbSOho",
      "target": "imT03YXlG2",
      "similarity": 0.8133
    },
    {
      "source": "odvSjn416y",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.8298
    },
    {
      "source": "odvSjn416y",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8197
    },
    {
      "source": "odvSjn416y",
      "target": "To address this",
      "similarity": 0.805
    },
    {
      "source": "odvSjn416y",
      "target": "CS2JWaziYr",
      "similarity": 0.8024
    },
    {
      "source": "odvSjn416y",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.7952
    },
    {
      "source": "5IWJBStfU7",
      "target": "{Subsequently}",
      "similarity": 0.8794
    },
    {
      "source": "5IWJBStfU7",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8789
    },
    {
      "source": "5IWJBStfU7",
      "target": "nDTvP6tBMd",
      "similarity": 0.8742
    },
    {
      "source": "5IWJBStfU7",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8702
    },
    {
      "source": "5IWJBStfU7",
      "target": "fNMKqyvuZT",
      "similarity": 0.8663
    },
    {
      "source": "We identify two broad strategies to produce MI explanations: (i) \"\"where-then-what\"\"",
      "target": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "similarity": 0.8736
    },
    {
      "source": "We identify two broad strategies to produce MI explanations: (i) \"\"where-then-what\"\"",
      "target": "vQhn4wrQ6j",
      "similarity": 0.8361
    },
    {
      "source": "We identify two broad strategies to produce MI explanations: (i) \"\"where-then-what\"\"",
      "target": "Tkkrm3pA35",
      "similarity": 0.83
    },
    {
      "source": "We identify two broad strategies to produce MI explanations: (i) \"\"where-then-what\"\"",
      "target": "GeUK3zGreN",
      "similarity": 0.8225
    },
    {
      "source": "We identify two broad strategies to produce MI explanations: (i) \"\"where-then-what\"\"",
      "target": "C45YqeBDUM",
      "similarity": 0.8135
    },
    {
      "source": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8625
    },
    {
      "source": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "target": "Second",
      "similarity": 0.8507
    },
    {
      "source": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "target": "This paper introduces WebRL",
      "similarity": 0.8456
    },
    {
      "source": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8391
    },
    {
      "source": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.837
    },
    {
      "source": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "target": "aTYexOYlLb",
      "similarity": 0.8464
    },
    {
      "source": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "target": "wmV4cIbgl6",
      "similarity": 0.8321
    },
    {
      "source": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "target": "AoIKgHu9Si",
      "similarity": 0.832
    },
    {
      "source": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "target": "a hypergraph",
      "similarity": 0.8284
    },
    {
      "source": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "target": "However",
      "similarity": 0.8247
    },
    {
      "source": "s3IBHTTDYl",
      "target": "Along our analysis",
      "similarity": 0.7895
    },
    {
      "source": "s3IBHTTDYl",
      "target": "In this paper",
      "similarity": 0.7726
    },
    {
      "source": "s3IBHTTDYl",
      "target": "states while still maintaining the ability to precisely recall recent memories with the",
      "similarity": 0.772
    },
    {
      "source": "s3IBHTTDYl",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.7676
    },
    {
      "source": "s3IBHTTDYl",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.7674
    },
    {
      "source": "2oKkQTyfz7",
      "target": "rakhNY32vw",
      "similarity": 0.8725
    },
    {
      "source": "2oKkQTyfz7",
      "target": "ZSdubdbOoi",
      "similarity": 0.854
    },
    {
      "source": "2oKkQTyfz7",
      "target": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "similarity": 0.8505
    },
    {
      "source": "2oKkQTyfz7",
      "target": "4R71pdPBZp",
      "similarity": 0.8332
    },
    {
      "source": "2oKkQTyfz7",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8059
    },
    {
      "source": "hrqNOxpItr",
      "target": "pRCOZllZdT",
      "similarity": 0.8271
    },
    {
      "source": "hrqNOxpItr",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8172
    },
    {
      "source": "hrqNOxpItr",
      "target": "6VhDQP7WGX",
      "similarity": 0.8144
    },
    {
      "source": "hrqNOxpItr",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8125
    },
    {
      "source": "hrqNOxpItr",
      "target": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "similarity": 0.8082
    },
    {
      "source": "then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.847
    },
    {
      "source": "then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks",
      "target": "sIE2rI3ZPs",
      "similarity": 0.8394
    },
    {
      "source": "then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks",
      "target": "instructions",
      "similarity": 0.8393
    },
    {
      "source": "then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks",
      "target": "Usklli4gMc",
      "similarity": 0.8389
    },
    {
      "source": "then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks",
      "target": "IuU0wcO0mo",
      "similarity": 0.8374
    },
    {
      "source": "Together",
      "target": "yFGR36PLDJ",
      "similarity": 0.9144
    },
    {
      "source": "Together",
      "target": "jj7b3p5kLY",
      "similarity": 0.843
    },
    {
      "source": "Together",
      "target": "learning has exhibited impressive capacities across various healthcare domains",
      "similarity": 0.8392
    },
    {
      "source": "Together",
      "target": "gsShHPxkUW",
      "similarity": 0.8368
    },
    {
      "source": "Together",
      "target": "OiQttMHwce",
      "similarity": 0.8367
    },
    {
      "source": "cPozlf9OaF",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8588
    },
    {
      "source": "cPozlf9OaF",
      "target": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "similarity": 0.8131
    },
    {
      "source": "cPozlf9OaF",
      "target": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "similarity": 0.8082
    },
    {
      "source": "cPozlf9OaF",
      "target": "Usklli4gMc",
      "similarity": 0.8039
    },
    {
      "source": "cPozlf9OaF",
      "target": "PUnD86UEK5",
      "similarity": 0.802
    },
    {
      "source": "Oazgf8A24z",
      "target": "vRvVVb0NAz",
      "similarity": 0.8203
    },
    {
      "source": "Oazgf8A24z",
      "target": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "similarity": 0.8197
    },
    {
      "source": "Oazgf8A24z",
      "target": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "similarity": 0.8159
    },
    {
      "source": "Oazgf8A24z",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8113
    },
    {
      "source": "Oazgf8A24z",
      "target": "HqjRlT65WX",
      "similarity": 0.807
    },
    {
      "source": "BA1eG7vCNb",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.816
    },
    {
      "source": "BA1eG7vCNb",
      "target": "kX8h23UG6v",
      "similarity": 0.8091
    },
    {
      "source": "BA1eG7vCNb",
      "target": "introduce",
      "similarity": 0.8086
    },
    {
      "source": "BA1eG7vCNb",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8068
    },
    {
      "source": "BA1eG7vCNb",
      "target": "x1An5a3U9I",
      "similarity": 0.8044
    },
    {
      "source": "It relaxes the equal mass constraint",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8603
    },
    {
      "source": "It relaxes the equal mass constraint",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.8569
    },
    {
      "source": "It relaxes the equal mass constraint",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.847
    },
    {
      "source": "It relaxes the equal mass constraint",
      "target": "samples. However",
      "similarity": 0.844
    },
    {
      "source": "It relaxes the equal mass constraint",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8437
    },
    {
      "source": "In contrast",
      "target": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "similarity": 0.887
    },
    {
      "source": "In contrast",
      "target": "In this work",
      "similarity": 0.8167
    },
    {
      "source": "In contrast",
      "target": "CIs9x2ZRgh",
      "similarity": 0.805
    },
    {
      "source": "In contrast",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.7904
    },
    {
      "source": "In contrast",
      "target": "However",
      "similarity": 0.7847
    },
    {
      "source": "fsX9nFwMNj",
      "target": "bmbRCRiNDu",
      "similarity": 0.8412
    },
    {
      "source": "fsX9nFwMNj",
      "target": "To this end",
      "similarity": 0.8348
    },
    {
      "source": "fsX9nFwMNj",
      "target": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "similarity": 0.833
    },
    {
      "source": "fsX9nFwMNj",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8312
    },
    {
      "source": "fsX9nFwMNj",
      "target": "First",
      "similarity": 0.8303
    },
    {
      "source": "To address this",
      "target": "Meanwhile",
      "similarity": 0.8625
    },
    {
      "source": "To address this",
      "target": "tDIL7UXmSS",
      "similarity": 0.8608
    },
    {
      "source": "To address this",
      "target": "(2) The redundancy in natural language introduces noise",
      "similarity": 0.8439
    },
    {
      "source": "To address this",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8404
    },
    {
      "source": "To address this",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8393
    },
    {
      "source": "Our proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8669
    },
    {
      "source": "Our proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data",
      "target": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "similarity": 0.8628
    },
    {
      "source": "Our proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8546
    },
    {
      "source": "Our proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data",
      "target": "than prior private ANN schemes",
      "similarity": 0.8438
    },
    {
      "source": "Our proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8257
    },
    {
      "source": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "target": "aXwukBD6M6",
      "similarity": 0.8925
    },
    {
      "source": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "target": "Pnk7vMbznK",
      "similarity": 0.8583
    },
    {
      "source": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8494
    },
    {
      "source": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "target": "DzbUL4AJPP",
      "similarity": 0.8439
    },
    {
      "source": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8411
    },
    {
      "source": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "target": "2zmO1GVT0Y",
      "similarity": 0.8165
    },
    {
      "source": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "target": "6qUUgw9bAZ",
      "similarity": 0.8154
    },
    {
      "source": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "target": "IwPXYk6BV9",
      "similarity": 0.8093
    },
    {
      "source": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "target": "jJXZvPe5z0",
      "similarity": 0.7966
    },
    {
      "source": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "target": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "similarity": 0.7939
    },
    {
      "source": "In addition",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8103
    },
    {
      "source": "In addition",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8
    },
    {
      "source": "In addition",
      "target": "Igm9bbkzHC",
      "similarity": 0.799
    },
    {
      "source": "In addition",
      "target": "However",
      "similarity": 0.7941
    },
    {
      "source": "In addition",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.7865
    },
    {
      "source": "We will release all the source code",
      "target": "However",
      "similarity": 0.8107
    },
    {
      "source": "We will release all the source code",
      "target": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "similarity": 0.8039
    },
    {
      "source": "We will release all the source code",
      "target": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "similarity": 0.7948
    },
    {
      "source": "We will release all the source code",
      "target": "LLaMA-3-8B-based SFT model",
      "similarity": 0.7848
    },
    {
      "source": "We will release all the source code",
      "target": "Yet",
      "similarity": 0.7834
    },
    {
      "source": "UvTo3tVBk2",
      "target": "9EqQC2ct4H",
      "similarity": 0.8383
    },
    {
      "source": "UvTo3tVBk2",
      "target": "bsFWJ0Kget",
      "similarity": 0.8288
    },
    {
      "source": "UvTo3tVBk2",
      "target": "aWXnKanInf",
      "similarity": 0.8201
    },
    {
      "source": "UvTo3tVBk2",
      "target": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "similarity": 0.8187
    },
    {
      "source": "UvTo3tVBk2",
      "target": "ac93gRzxxV",
      "similarity": 0.8079
    },
    {
      "source": "mXHTifc1Fn",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.86
    },
    {
      "source": "mXHTifc1Fn",
      "target": "TYSQYx9vwd",
      "similarity": 0.8566
    },
    {
      "source": "mXHTifc1Fn",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8457
    },
    {
      "source": "mXHTifc1Fn",
      "target": "K4FAFNRpko",
      "similarity": 0.8434
    },
    {
      "source": "mXHTifc1Fn",
      "target": "rCX9l4OTCT",
      "similarity": 0.8428
    },
    {
      "source": "sULAwlAWc1",
      "target": "In doing so",
      "similarity": 0.9035
    },
    {
      "source": "sULAwlAWc1",
      "target": "increased their demand. However",
      "similarity": 0.8983
    },
    {
      "source": "sULAwlAWc1",
      "target": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "similarity": 0.8897
    },
    {
      "source": "sULAwlAWc1",
      "target": "However",
      "similarity": 0.8865
    },
    {
      "source": "sULAwlAWc1",
      "target": "in reinforcement learning (RL)",
      "similarity": 0.8808
    },
    {
      "source": "kYwTmlq6Vn",
      "target": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "similarity": 0.7825
    },
    {
      "source": "kYwTmlq6Vn",
      "target": "Furthermore",
      "similarity": 0.7802
    },
    {
      "source": "kYwTmlq6Vn",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.7782
    },
    {
      "source": "kYwTmlq6Vn",
      "target": "MnJzJ2gvuf",
      "similarity": 0.7725
    },
    {
      "source": "kYwTmlq6Vn",
      "target": "RQz7szbVDs",
      "similarity": 0.7724
    },
    {
      "source": "DPzQ5n3mNm",
      "target": "This paper introduces WebRL",
      "similarity": 0.897
    },
    {
      "source": "DPzQ5n3mNm",
      "target": "1CIUkpoata",
      "similarity": 0.8607
    },
    {
      "source": "DPzQ5n3mNm",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8509
    },
    {
      "source": "DPzQ5n3mNm",
      "target": "JytL2MrlLT",
      "similarity": 0.8459
    },
    {
      "source": "DPzQ5n3mNm",
      "target": "1NprT9Kz0d",
      "similarity": 0.843
    },
    {
      "source": "5V0f8igznO",
      "target": "Through extensive experiments",
      "similarity": 0.7934
    },
    {
      "source": "5V0f8igznO",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.7908
    },
    {
      "source": "5V0f8igznO",
      "target": "Finally",
      "similarity": 0.7874
    },
    {
      "source": "5V0f8igznO",
      "target": "In $\\texttt{ProAdvPrompter}$",
      "similarity": 0.7865
    },
    {
      "source": "5V0f8igznO",
      "target": "and calibration of models",
      "similarity": 0.7844
    },
    {
      "source": "To bridge this gap in understanding",
      "target": "To enrich long documents",
      "similarity": 0.86
    },
    {
      "source": "To bridge this gap in understanding",
      "target": "K3KrOsR6y9",
      "similarity": 0.8566
    },
    {
      "source": "To bridge this gap in understanding",
      "target": "mOpNrrV2zH",
      "similarity": 0.8223
    },
    {
      "source": "To bridge this gap in understanding",
      "target": "20qZK2T7fa",
      "similarity": 0.8179
    },
    {
      "source": "To bridge this gap in understanding",
      "target": "ykuc5q381b",
      "similarity": 0.8129
    },
    {
      "source": "Additionally",
      "target": "UwcZEoNP19",
      "similarity": 0.8102
    },
    {
      "source": "Additionally",
      "target": "UL2",
      "similarity": 0.8091
    },
    {
      "source": "Additionally",
      "target": "dh78yRFVK9",
      "similarity": 0.809
    },
    {
      "source": "Additionally",
      "target": "ANBuEJesgx",
      "similarity": 0.8087
    },
    {
      "source": "Additionally",
      "target": "Aided Design (CAD) scripting code",
      "similarity": 0.808
    },
    {
      "source": "Building on these insights",
      "target": "pQsllTesiE",
      "similarity": 0.7833
    },
    {
      "source": "Building on these insights",
      "target": "md9qolJwLl",
      "similarity": 0.7696
    },
    {
      "source": "Building on these insights",
      "target": "Fs9EabmQrJ",
      "similarity": 0.7631
    },
    {
      "source": "Building on these insights",
      "target": "compositional benchmarks",
      "similarity": 0.7624
    },
    {
      "source": "Building on these insights",
      "target": "We find that naively applying LLMs to proof optimization falls short",
      "similarity": 0.7616
    },
    {
      "source": "CvGqMD5OtX",
      "target": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "similarity": 0.8385
    },
    {
      "source": "CvGqMD5OtX",
      "target": "ZSdubdbOoi",
      "similarity": 0.8282
    },
    {
      "source": "CvGqMD5OtX",
      "target": "wxPnuFp8fZ",
      "similarity": 0.8269
    },
    {
      "source": "CvGqMD5OtX",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8253
    },
    {
      "source": "CvGqMD5OtX",
      "target": "7VkHffT5X2",
      "similarity": 0.8241
    },
    {
      "source": "te2IdORabL",
      "target": "TYSQYx9vwd",
      "similarity": 0.8557
    },
    {
      "source": "te2IdORabL",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8462
    },
    {
      "source": "te2IdORabL",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.8275
    },
    {
      "source": "te2IdORabL",
      "target": "FPfCUJTsCn",
      "similarity": 0.8259
    },
    {
      "source": "te2IdORabL",
      "target": "frozen nonlinear manifolds",
      "similarity": 0.8238
    },
    {
      "source": "K5yeB4dTtS",
      "target": "By contrast",
      "similarity": 0.8325
    },
    {
      "source": "K5yeB4dTtS",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8305
    },
    {
      "source": "K5yeB4dTtS",
      "target": "VoI4d6uhdr",
      "similarity": 0.8271
    },
    {
      "source": "K5yeB4dTtS",
      "target": "cADpvQgnqg",
      "similarity": 0.8216
    },
    {
      "source": "K5yeB4dTtS",
      "target": "CahIEKCu5Q",
      "similarity": 0.8201
    },
    {
      "source": "KD5nJUgeW4",
      "target": "However",
      "similarity": 0.8635
    },
    {
      "source": "KD5nJUgeW4",
      "target": "Es4RPNDtmq",
      "similarity": 0.8554
    },
    {
      "source": "KD5nJUgeW4",
      "target": "In this paper",
      "similarity": 0.8553
    },
    {
      "source": "KD5nJUgeW4",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8549
    },
    {
      "source": "KD5nJUgeW4",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.854
    },
    {
      "source": "b57IG6N20B",
      "target": "vl7kf0YHwj",
      "similarity": 0.8483
    },
    {
      "source": "b57IG6N20B",
      "target": "vRvVVb0NAz",
      "similarity": 0.8305
    },
    {
      "source": "b57IG6N20B",
      "target": "HqjRlT65WX",
      "similarity": 0.8289
    },
    {
      "source": "b57IG6N20B",
      "target": "rTQNGQxm4K",
      "similarity": 0.8258
    },
    {
      "source": "b57IG6N20B",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8246
    },
    {
      "source": "6GATHdOi1x",
      "target": "However",
      "similarity": 0.8892
    },
    {
      "source": "6GATHdOi1x",
      "target": "bmbRCRiNDu",
      "similarity": 0.8705
    },
    {
      "source": "6GATHdOi1x",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8661
    },
    {
      "source": "6GATHdOi1x",
      "target": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "similarity": 0.8659
    },
    {
      "source": "6GATHdOi1x",
      "target": "1R5BcYS8EC",
      "similarity": 0.8631
    },
    {
      "source": "Our codes are available at \\url{https://github.com/lswhim/PreferDiff}.\"",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.843
    },
    {
      "source": "Our codes are available at \\url{https://github.com/lswhim/PreferDiff}.\"",
      "target": "Along with SketikZ",
      "similarity": 0.8419
    },
    {
      "source": "Our codes are available at \\url{https://github.com/lswhim/PreferDiff}.\"",
      "target": "To overcome these challenges",
      "similarity": 0.8375
    },
    {
      "source": "Our codes are available at \\url{https://github.com/lswhim/PreferDiff}.\"",
      "target": "bMC1t7eLRc",
      "similarity": 0.8374
    },
    {
      "source": "Our codes are available at \\url{https://github.com/lswhim/PreferDiff}.\"",
      "target": "G328D1xt4W",
      "similarity": 0.8357
    },
    {
      "source": "HpUs2EXjOl",
      "target": "U3PBITXNG6",
      "similarity": 0.8703
    },
    {
      "source": "HpUs2EXjOl",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8667
    },
    {
      "source": "HpUs2EXjOl",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8587
    },
    {
      "source": "HpUs2EXjOl",
      "target": "Finally",
      "similarity": 0.8517
    },
    {
      "source": "HpUs2EXjOl",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8483
    },
    {
      "source": "However",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8376
    },
    {
      "source": "However",
      "target": "uy4EavBEwl",
      "similarity": 0.8243
    },
    {
      "source": "However",
      "target": "THqWPzL00e",
      "similarity": 0.8028
    },
    {
      "source": "However",
      "target": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "similarity": 0.8012
    },
    {
      "source": "However",
      "target": "selection of LLMs",
      "similarity": 0.8005
    },
    {
      "source": "In this paper",
      "target": "D2hhkU5O48",
      "similarity": 0.8375
    },
    {
      "source": "In this paper",
      "target": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "similarity": 0.8238
    },
    {
      "source": "In this paper",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8221
    },
    {
      "source": "In this paper",
      "target": "VnLhUogHYE",
      "similarity": 0.8112
    },
    {
      "source": "In this paper",
      "target": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "similarity": 0.8104
    },
    {
      "source": "Our findings reveal that SAEs developed to improve the MSE-$\\mathrm{L}_0$ Pareto frontier may confuse interpretability",
      "target": "than prior private ANN schemes",
      "similarity": 0.8155
    },
    {
      "source": "Our findings reveal that SAEs developed to improve the MSE-$\\mathrm{L}_0$ Pareto frontier may confuse interpretability",
      "target": "lBB3eSn6fY",
      "similarity": 0.8135
    },
    {
      "source": "Our findings reveal that SAEs developed to improve the MSE-$\\mathrm{L}_0$ Pareto frontier may confuse interpretability",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8011
    },
    {
      "source": "Our findings reveal that SAEs developed to improve the MSE-$\\mathrm{L}_0$ Pareto frontier may confuse interpretability",
      "target": "To enable TTA for regression",
      "similarity": 0.7954
    },
    {
      "source": "Our findings reveal that SAEs developed to improve the MSE-$\\mathrm{L}_0$ Pareto frontier may confuse interpretability",
      "target": "Specifically",
      "similarity": 0.7898
    },
    {
      "source": "The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word.",
      "target": "x1An5a3U9I",
      "similarity": 0.8253
    },
    {
      "source": "The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word.",
      "target": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "similarity": 0.8237
    },
    {
      "source": "The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word.",
      "target": "To remedy this problem",
      "similarity": 0.8226
    },
    {
      "source": "The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word.",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8174
    },
    {
      "source": "The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word.",
      "target": "jj7b3p5kLY",
      "similarity": 0.8157
    },
    {
      "source": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "target": "EEgYUccwsV",
      "similarity": 0.8758
    },
    {
      "source": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "target": "suz4utPr9Y",
      "similarity": 0.8652
    },
    {
      "source": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "target": "Pacmann carefully offloads limited computation and storage to the client",
      "similarity": 0.8524
    },
    {
      "source": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "target": "wPMRwmytZe",
      "similarity": 0.8517
    },
    {
      "source": "Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.\"",
      "target": "Besides this primary purpose",
      "similarity": 0.8446
    },
    {
      "source": "dRz3cizftU",
      "target": "KlN00vQEY2",
      "similarity": 0.8572
    },
    {
      "source": "dRz3cizftU",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8469
    },
    {
      "source": "dRz3cizftU",
      "target": "Aye5wL6TCn",
      "similarity": 0.8364
    },
    {
      "source": "dRz3cizftU",
      "target": "ISqx8giekS",
      "similarity": 0.8297
    },
    {
      "source": "dRz3cizftU",
      "target": "E2PFv7ad3p",
      "similarity": 0.8264
    },
    {
      "source": "https://github.com/OceannTwT/Tool-Planner.\"",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.875
    },
    {
      "source": "https://github.com/OceannTwT/Tool-Planner.\"",
      "target": "J9FgrqOOni",
      "similarity": 0.8609
    },
    {
      "source": "https://github.com/OceannTwT/Tool-Planner.\"",
      "target": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "similarity": 0.8507
    },
    {
      "source": "https://github.com/OceannTwT/Tool-Planner.\"",
      "target": "T2d0geb6y0",
      "similarity": 0.8466
    },
    {
      "source": "https://github.com/OceannTwT/Tool-Planner.\"",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8456
    },
    {
      "source": "2QdsjiNXgj",
      "target": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "similarity": 0.885
    },
    {
      "source": "2QdsjiNXgj",
      "target": "5oSUgTzs8Y",
      "similarity": 0.8802
    },
    {
      "source": "2QdsjiNXgj",
      "target": "ods",
      "similarity": 0.8589
    },
    {
      "source": "2QdsjiNXgj",
      "target": "Moreover",
      "similarity": 0.8575
    },
    {
      "source": "2QdsjiNXgj",
      "target": "uqe5HkjbT9",
      "similarity": 0.853
    },
    {
      "source": "FoF5RaA3ug",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8351
    },
    {
      "source": "FoF5RaA3ug",
      "target": "IDJUscOjM3",
      "similarity": 0.8298
    },
    {
      "source": "FoF5RaA3ug",
      "target": "For TP",
      "similarity": 0.8268
    },
    {
      "source": "FoF5RaA3ug",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8264
    },
    {
      "source": "FoF5RaA3ug",
      "target": "Pujt3ADZgI",
      "similarity": 0.8241
    },
    {
      "source": "In this paper",
      "target": "First",
      "similarity": 0.8488
    },
    {
      "source": "In this paper",
      "target": "S1Bv3068Xt",
      "similarity": 0.8418
    },
    {
      "source": "In this paper",
      "target": "HqjRlT65WX",
      "similarity": 0.84
    },
    {
      "source": "In this paper",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8384
    },
    {
      "source": "In this paper",
      "target": "rTQNGQxm4K",
      "similarity": 0.8356
    },
    {
      "source": "We first conduct a comprehensive comparison of various loss functions for soft label utilization in dataset distillation",
      "target": "sion",
      "similarity": 0.8948
    },
    {
      "source": "We first conduct a comprehensive comparison of various loss functions for soft label utilization in dataset distillation",
      "target": "EyaH1wzmao",
      "similarity": 0.8592
    },
    {
      "source": "We first conduct a comprehensive comparison of various loss functions for soft label utilization in dataset distillation",
      "target": "Using this extension",
      "similarity": 0.8429
    },
    {
      "source": "We first conduct a comprehensive comparison of various loss functions for soft label utilization in dataset distillation",
      "target": "as nodes that meet two criteria: 1) Anomaly: root cause nodes should take on",
      "similarity": 0.8395
    },
    {
      "source": "We first conduct a comprehensive comparison of various loss functions for soft label utilization in dataset distillation",
      "target": "dOAkHmsjRX",
      "similarity": 0.8388
    },
    {
      "source": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "target": "we can maximize the ELBO for normal data and minimize it for labeled sensitive data",
      "similarity": 0.8255
    },
    {
      "source": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8197
    },
    {
      "source": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "target": "2mqb8bPHeb",
      "similarity": 0.8195
    },
    {
      "source": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "target": "9KiE3t6CsL",
      "similarity": 0.8192
    },
    {
      "source": "This finding highlights the necessity of a universal loss function for training models on synthetic datasets.",
      "target": "hoYFLRNbhc",
      "similarity": 0.8191
    },
    {
      "source": "Building on these insights",
      "target": "CjXaMI2kUH",
      "similarity": 0.8366
    },
    {
      "source": "Building on these insights",
      "target": "Iht4NNVqk0",
      "similarity": 0.8349
    },
    {
      "source": "Building on these insights",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8301
    },
    {
      "source": "Building on these insights",
      "target": "1Z6PSw7OL8",
      "similarity": 0.8246
    },
    {
      "source": "Building on these insights",
      "target": "PgXpOOqtyd",
      "similarity": 0.8241
    },
    {
      "source": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "target": "FXw0okNcOb",
      "similarity": 0.8875
    },
    {
      "source": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "target": "testbed for the future development of long-context video agents.\"",
      "similarity": 0.8726
    },
    {
      "source": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.868
    },
    {
      "source": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "target": "Jszf4et48m",
      "similarity": 0.8646
    },
    {
      "source": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "target": "kbeX97jExm",
      "similarity": 0.8621
    },
    {
      "source": "Importantly",
      "target": "N0ETIi580T",
      "similarity": 0.8276
    },
    {
      "source": "Importantly",
      "target": "iVMcYxTiVM",
      "similarity": 0.8186
    },
    {
      "source": "Importantly",
      "target": "4GT9uTsAJE",
      "similarity": 0.8183
    },
    {
      "source": "Importantly",
      "target": "ACSNlt77hq",
      "similarity": 0.8142
    },
    {
      "source": "Importantly",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8074
    },
    {
      "source": "For instance",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.8751
    },
    {
      "source": "For instance",
      "target": "pHe4P1IVnb",
      "similarity": 0.8584
    },
    {
      "source": "For instance",
      "target": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "similarity": 0.853
    },
    {
      "source": "For instance",
      "target": "9qpdDiDQ2H",
      "similarity": 0.853
    },
    {
      "source": "For instance",
      "target": "Towards doing so",
      "similarity": 0.8514
    },
    {
      "source": "Fk3eod9aaD",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8583
    },
    {
      "source": "Fk3eod9aaD",
      "target": "$$",
      "similarity": 0.8522
    },
    {
      "source": "Fk3eod9aaD",
      "target": "It is especially difficult to generate videos with coherent narratives based on text.",
      "similarity": 0.8504
    },
    {
      "source": "Fk3eod9aaD",
      "target": "We provide theoretical justifications for our new objective",
      "similarity": 0.84
    },
    {
      "source": "Fk3eod9aaD",
      "target": "To overcome such limitations",
      "similarity": 0.8363
    },
    {
      "source": "rnJxelIZrq",
      "target": "JWtrk7mprJ",
      "similarity": 0.8428
    },
    {
      "source": "rnJxelIZrq",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8351
    },
    {
      "source": "rnJxelIZrq",
      "target": "Nevertheless",
      "similarity": 0.8205
    },
    {
      "source": "rnJxelIZrq",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8177
    },
    {
      "source": "rnJxelIZrq",
      "target": "high-quality labels is often required to obtain noticeable improvements. Given",
      "similarity": 0.8166
    },
    {
      "source": "In our approach",
      "target": "To this end",
      "similarity": 0.8281
    },
    {
      "source": "In our approach",
      "target": "ud8FtE1N4N",
      "similarity": 0.8211
    },
    {
      "source": "In our approach",
      "target": "Wf2ndb8nhf",
      "similarity": 0.8107
    },
    {
      "source": "In our approach",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8083
    },
    {
      "source": "In our approach",
      "target": "B8akWa62Da",
      "similarity": 0.8072
    },
    {
      "source": "d2UrCGtntF",
      "target": "PY56Wur7S0",
      "similarity": 0.8306
    },
    {
      "source": "d2UrCGtntF",
      "target": "xI71dsS3o4",
      "similarity": 0.8215
    },
    {
      "source": "d2UrCGtntF",
      "target": "gVnJFY8nCM",
      "similarity": 0.8148
    },
    {
      "source": "d2UrCGtntF",
      "target": "We are the first to identify these challenges in online VFL",
      "similarity": 0.8121
    },
    {
      "source": "d2UrCGtntF",
      "target": "In this paper",
      "similarity": 0.811
    },
    {
      "source": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "target": "In this work",
      "similarity": 0.8631
    },
    {
      "source": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "target": "additional structural constraints",
      "similarity": 0.8495
    },
    {
      "source": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "target": "AAXBfJNHDt",
      "similarity": 0.8382
    },
    {
      "source": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8381
    },
    {
      "source": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.838
    },
    {
      "source": "image fidelity and pose alignment",
      "target": "Aided Design (CAD) scripting code",
      "similarity": 0.8028
    },
    {
      "source": "image fidelity and pose alignment",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.7889
    },
    {
      "source": "image fidelity and pose alignment",
      "target": "Second",
      "similarity": 0.7788
    },
    {
      "source": "image fidelity and pose alignment",
      "target": "To ensure this progress",
      "similarity": 0.7765
    },
    {
      "source": "image fidelity and pose alignment",
      "target": "dh78yRFVK9",
      "similarity": 0.7752
    },
    {
      "source": "See https://4d-diffusion.github.io for video samples.\"",
      "target": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "similarity": 0.8644
    },
    {
      "source": "See https://4d-diffusion.github.io for video samples.\"",
      "target": "Building on these insights",
      "similarity": 0.862
    },
    {
      "source": "See https://4d-diffusion.github.io for video samples.\"",
      "target": "nNiWRRj6r9",
      "similarity": 0.837
    },
    {
      "source": "See https://4d-diffusion.github.io for video samples.\"",
      "target": "Exploration can also be directed using intrinsic rewards",
      "similarity": 0.8291
    },
    {
      "source": "See https://4d-diffusion.github.io for video samples.\"",
      "target": "First",
      "similarity": 0.8273
    },
    {
      "source": "Glm7Kj47nN",
      "target": "HN8V0flwJF",
      "similarity": 0.8302
    },
    {
      "source": "Glm7Kj47nN",
      "target": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "similarity": 0.827
    },
    {
      "source": "Glm7Kj47nN",
      "target": "BpyHIrpUOL",
      "similarity": 0.8266
    },
    {
      "source": "Glm7Kj47nN",
      "target": "oeP6OL7ouB",
      "similarity": 0.8221
    },
    {
      "source": "Glm7Kj47nN",
      "target": "IuU0wcO0mo",
      "similarity": 0.8183
    },
    {
      "source": "eiqrnVaeIw",
      "target": "instructions",
      "similarity": 0.8774
    },
    {
      "source": "eiqrnVaeIw",
      "target": "VpWki1v2P8",
      "similarity": 0.877
    },
    {
      "source": "eiqrnVaeIw",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8738
    },
    {
      "source": "eiqrnVaeIw",
      "target": "To this end",
      "similarity": 0.8723
    },
    {
      "source": "eiqrnVaeIw",
      "target": "254NJe9JEw",
      "similarity": 0.8672
    },
    {
      "source": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "target": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "similarity": 0.8632
    },
    {
      "source": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "target": "tu3qwNjrtw",
      "similarity": 0.8477
    },
    {
      "source": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "target": "fAAaT826Vv",
      "similarity": 0.8443
    },
    {
      "source": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "target": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "similarity": 0.8395
    },
    {
      "source": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "target": "h8yg0hT96f",
      "similarity": 0.8384
    },
    {
      "source": "Our work evaluates for the first time whether language models can also be \\emph{compromised during pre-training}",
      "target": "In this paper",
      "similarity": 0.8383
    },
    {
      "source": "Our work evaluates for the first time whether language models can also be \\emph{compromised during pre-training}",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8325
    },
    {
      "source": "Our work evaluates for the first time whether language models can also be \\emph{compromised during pre-training}",
      "target": "mkDam1xIzW",
      "similarity": 0.8313
    },
    {
      "source": "Our work evaluates for the first time whether language models can also be \\emph{compromised during pre-training}",
      "target": "bc2H72hGxB",
      "similarity": 0.8258
    },
    {
      "source": "Our work evaluates for the first time whether language models can also be \\emph{compromised during pre-training}",
      "target": "T7bmHkwzS6",
      "similarity": 0.8245
    },
    {
      "source": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "target": "Finally",
      "similarity": 0.8514
    },
    {
      "source": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "target": "To address these limitations",
      "similarity": 0.838
    },
    {
      "source": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "target": "To address these challenges",
      "similarity": 0.8376
    },
    {
      "source": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "target": "A1HhtITVEi",
      "similarity": 0.8361
    },
    {
      "source": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "target": "of natural language. However",
      "similarity": 0.8326
    },
    {
      "source": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "target": "RWJX5F5I9g",
      "similarity": 0.8471
    },
    {
      "source": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "target": "wNobG8bV5Q",
      "similarity": 0.847
    },
    {
      "source": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "target": "approximation",
      "similarity": 0.8411
    },
    {
      "source": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "target": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "similarity": 0.838
    },
    {
      "source": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.8298
    },
    {
      "source": "mUMvr33FTu",
      "target": "Our code and additional resources are available at https://structuredllm.com.\"",
      "similarity": 0.8275
    },
    {
      "source": "mUMvr33FTu",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8214
    },
    {
      "source": "mUMvr33FTu",
      "target": "by learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.",
      "similarity": 0.8168
    },
    {
      "source": "mUMvr33FTu",
      "target": "Finally",
      "similarity": 0.8152
    },
    {
      "source": "mUMvr33FTu",
      "target": "In addition",
      "similarity": 0.812
    },
    {
      "source": "vcX0k4rGTt",
      "target": "analysis)",
      "similarity": 0.8574
    },
    {
      "source": "vcX0k4rGTt",
      "target": "SOTA LLMs",
      "similarity": 0.8475
    },
    {
      "source": "vcX0k4rGTt",
      "target": "In this task",
      "similarity": 0.8444
    },
    {
      "source": "vcX0k4rGTt",
      "target": "HN8V0flwJF",
      "similarity": 0.8416
    },
    {
      "source": "vcX0k4rGTt",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8403
    },
    {
      "source": "5Y9NT6lW21",
      "target": "Reweighting (GSR)",
      "similarity": 0.8537
    },
    {
      "source": "5Y9NT6lW21",
      "target": "To overcome those challenges",
      "similarity": 0.8435
    },
    {
      "source": "5Y9NT6lW21",
      "target": "R4q3cY3kQf",
      "similarity": 0.8424
    },
    {
      "source": "5Y9NT6lW21",
      "target": "YzxMu1asQi",
      "similarity": 0.8403
    },
    {
      "source": "5Y9NT6lW21",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8369
    },
    {
      "source": "8eNLKk5by4",
      "target": "XdRIno98gG",
      "similarity": 0.8563
    },
    {
      "source": "8eNLKk5by4",
      "target": "7El7K1DoyX",
      "similarity": 0.8526
    },
    {
      "source": "8eNLKk5by4",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8515
    },
    {
      "source": "8eNLKk5by4",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8501
    },
    {
      "source": "8eNLKk5by4",
      "target": "model weights",
      "similarity": 0.846
    },
    {
      "source": "OuLgaHEmzi",
      "target": "rTQNGQxm4K",
      "similarity": 0.8672
    },
    {
      "source": "OuLgaHEmzi",
      "target": "HqjRlT65WX",
      "similarity": 0.8654
    },
    {
      "source": "OuLgaHEmzi",
      "target": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "similarity": 0.8622
    },
    {
      "source": "OuLgaHEmzi",
      "target": "5xSRg3eYZz",
      "similarity": 0.8526
    },
    {
      "source": "OuLgaHEmzi",
      "target": "YvKJGYL4j7",
      "similarity": 0.8514
    },
    {
      "source": "qNp86ByQlN",
      "target": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "similarity": 0.8369
    },
    {
      "source": "qNp86ByQlN",
      "target": "ZjOXuAfS6l",
      "similarity": 0.8078
    },
    {
      "source": "qNp86ByQlN",
      "target": "O6znYvxC1U",
      "similarity": 0.8063
    },
    {
      "source": "qNp86ByQlN",
      "target": "The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.\"",
      "similarity": 0.7997
    },
    {
      "source": "qNp86ByQlN",
      "target": "r9oqHOdoHf",
      "similarity": 0.7988
    },
    {
      "source": "J6e4hurEKd",
      "target": "In this paper",
      "similarity": 0.8653
    },
    {
      "source": "J6e4hurEKd",
      "target": "We found that long distance referrals",
      "similarity": 0.8571
    },
    {
      "source": "J6e4hurEKd",
      "target": "R4q3cY3kQf",
      "similarity": 0.8569
    },
    {
      "source": "J6e4hurEKd",
      "target": "l6QnSQizmN",
      "similarity": 0.8535
    },
    {
      "source": "J6e4hurEKd",
      "target": "To overcome these limitations",
      "similarity": 0.8492
    },
    {
      "source": "AD5yx2xq8R",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.86
    },
    {
      "source": "AD5yx2xq8R",
      "target": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "similarity": 0.8521
    },
    {
      "source": "AD5yx2xq8R",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.8475
    },
    {
      "source": "AD5yx2xq8R",
      "target": "3) We train the model through compression-based auto-regression",
      "similarity": 0.843
    },
    {
      "source": "AD5yx2xq8R",
      "target": "Furthermore",
      "similarity": 0.8429
    },
    {
      "source": "yFGR36PLDJ",
      "target": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "similarity": 0.8391
    },
    {
      "source": "yFGR36PLDJ",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8366
    },
    {
      "source": "yFGR36PLDJ",
      "target": "computational cost. Current LLM selection methods often struggle to generalize",
      "similarity": 0.8179
    },
    {
      "source": "yFGR36PLDJ",
      "target": "XdRIno98gG",
      "similarity": 0.8157
    },
    {
      "source": "yFGR36PLDJ",
      "target": "OiQttMHwce",
      "similarity": 0.8151
    },
    {
      "source": "qFZnAC4GHR",
      "target": "also study the necessity of this condition via ablation studies and analytical exam-",
      "similarity": 0.8646
    },
    {
      "source": "qFZnAC4GHR",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.8535
    },
    {
      "source": "qFZnAC4GHR",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8482
    },
    {
      "source": "qFZnAC4GHR",
      "target": "0e2pcSxQJS",
      "similarity": 0.8455
    },
    {
      "source": "qFZnAC4GHR",
      "target": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "similarity": 0.8415
    },
    {
      "source": "To tackle this problem",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8473
    },
    {
      "source": "To tackle this problem",
      "target": "NWb128pSCb",
      "similarity": 0.844
    },
    {
      "source": "To tackle this problem",
      "target": "This paper proposes",
      "similarity": 0.8364
    },
    {
      "source": "To tackle this problem",
      "target": "AP0ndQloqR",
      "similarity": 0.8329
    },
    {
      "source": "To tackle this problem",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8325
    },
    {
      "source": "Finally",
      "target": "Further",
      "similarity": 0.8266
    },
    {
      "source": "Finally",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8235
    },
    {
      "source": "Finally",
      "target": "GySIAKEwtZ",
      "similarity": 0.8177
    },
    {
      "source": "Finally",
      "target": "We propose RAMEN",
      "similarity": 0.8149
    },
    {
      "source": "Finally",
      "target": "AoIKgHu9Si",
      "similarity": 0.8135
    },
    {
      "source": "N4NhVN30ph",
      "target": "solutions",
      "similarity": 0.8388
    },
    {
      "source": "N4NhVN30ph",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8288
    },
    {
      "source": "N4NhVN30ph",
      "target": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "similarity": 0.8243
    },
    {
      "source": "N4NhVN30ph",
      "target": "wLnls9LS3x",
      "similarity": 0.8203
    },
    {
      "source": "N4NhVN30ph",
      "target": "SG1R2H3fa1",
      "similarity": 0.8189
    },
    {
      "source": "NHMuM84tRT",
      "target": "FCBbh0HCrF",
      "similarity": 0.8567
    },
    {
      "source": "NHMuM84tRT",
      "target": "Our codebase",
      "similarity": 0.8289
    },
    {
      "source": "NHMuM84tRT",
      "target": "GhexuBLxbO",
      "similarity": 0.8256
    },
    {
      "source": "NHMuM84tRT",
      "target": "Furthermore",
      "similarity": 0.8228
    },
    {
      "source": "NHMuM84tRT",
      "target": "By contrasting the predictions of these two models",
      "similarity": 0.8206
    },
    {
      "source": "uREg3OHjLL",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8465
    },
    {
      "source": "uREg3OHjLL",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8245
    },
    {
      "source": "uREg3OHjLL",
      "target": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "similarity": 0.8192
    },
    {
      "source": "uREg3OHjLL",
      "target": "riTiq3i21b",
      "similarity": 0.8168
    },
    {
      "source": "uREg3OHjLL",
      "target": "amDkNPVWcn",
      "similarity": 0.8143
    },
    {
      "source": "A conjecture by Hertrich",
      "target": "LLMs. Interestingly",
      "similarity": 0.8642
    },
    {
      "source": "A conjecture by Hertrich",
      "target": "254NJe9JEw",
      "similarity": 0.8463
    },
    {
      "source": "A conjecture by Hertrich",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8442
    },
    {
      "source": "A conjecture by Hertrich",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.844
    },
    {
      "source": "A conjecture by Hertrich",
      "target": "We propose RAMEN",
      "similarity": 0.8431
    },
    {
      "source": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "target": "FrFQpAgnGE",
      "similarity": 0.9018
    },
    {
      "source": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8987
    },
    {
      "source": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8813
    },
    {
      "source": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "target": "qZEdmyqCHF",
      "similarity": 0.8731
    },
    {
      "source": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "target": "To this end",
      "similarity": 0.8708
    },
    {
      "source": "We follow up on this line of research and show that",
      "target": "a length of $d$.",
      "similarity": 0.8475
    },
    {
      "source": "We follow up on this line of research and show that",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.8346
    },
    {
      "source": "We follow up on this line of research and show that",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8142
    },
    {
      "source": "We follow up on this line of research and show that",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8134
    },
    {
      "source": "We follow up on this line of research and show that",
      "target": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "similarity": 0.8129
    },
    {
      "source": "Moreover",
      "target": "As a highlight",
      "similarity": 0.8756
    },
    {
      "source": "Moreover",
      "target": "mOpNrrV2zH",
      "similarity": 0.869
    },
    {
      "source": "Moreover",
      "target": "97rOQDPmk2",
      "similarity": 0.8596
    },
    {
      "source": "Moreover",
      "target": "To enrich long documents",
      "similarity": 0.8483
    },
    {
      "source": "Moreover",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8458
    },
    {
      "source": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "target": "We evaluate LEAP on multiple decision-making benchmarks",
      "similarity": 0.8795
    },
    {
      "source": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.8731
    },
    {
      "source": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8517
    },
    {
      "source": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "target": "ujpAYpFDEA",
      "similarity": 0.8499
    },
    {
      "source": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "target": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "similarity": 0.8396
    },
    {
      "source": "U42TkrEDzb",
      "target": "TDy5Ih78b4",
      "similarity": 0.8555
    },
    {
      "source": "U42TkrEDzb",
      "target": "dgR6i4TSng",
      "similarity": 0.8546
    },
    {
      "source": "U42TkrEDzb",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8541
    },
    {
      "source": "U42TkrEDzb",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8541
    },
    {
      "source": "U42TkrEDzb",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8539
    },
    {
      "source": "H0qIWXXLUR",
      "target": "zxO4WuVGns",
      "similarity": 0.8483
    },
    {
      "source": "H0qIWXXLUR",
      "target": "In addition",
      "similarity": 0.8455
    },
    {
      "source": "H0qIWXXLUR",
      "target": "tu3qwNjrtw",
      "similarity": 0.8435
    },
    {
      "source": "H0qIWXXLUR",
      "target": "rCX9l4OTCT",
      "similarity": 0.8402
    },
    {
      "source": "H0qIWXXLUR",
      "target": "Thus",
      "similarity": 0.84
    },
    {
      "source": "DL9txImSzm",
      "target": "YFxfcQMLWX",
      "similarity": 0.8765
    },
    {
      "source": "DL9txImSzm",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8616
    },
    {
      "source": "DL9txImSzm",
      "target": "Using this approach",
      "similarity": 0.8475
    },
    {
      "source": "DL9txImSzm",
      "target": "E4LAVLXAHW",
      "similarity": 0.8438
    },
    {
      "source": "DL9txImSzm",
      "target": "1qq1QJKM5q",
      "similarity": 0.8418
    },
    {
      "source": "iDcWYtYUwX",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8866
    },
    {
      "source": "iDcWYtYUwX",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.8466
    },
    {
      "source": "iDcWYtYUwX",
      "target": "cADpvQgnqg",
      "similarity": 0.841
    },
    {
      "source": "iDcWYtYUwX",
      "target": "EMMnAd3apQ",
      "similarity": 0.8392
    },
    {
      "source": "iDcWYtYUwX",
      "target": "Furthermore",
      "similarity": 0.8356
    },
    {
      "source": "YwzxpZW3p7",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8402
    },
    {
      "source": "YwzxpZW3p7",
      "target": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "similarity": 0.8338
    },
    {
      "source": "YwzxpZW3p7",
      "target": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "similarity": 0.8263
    },
    {
      "source": "YwzxpZW3p7",
      "target": "(1) When the representation dimension is regarded as the time axis",
      "similarity": 0.8232
    },
    {
      "source": "YwzxpZW3p7",
      "target": "pRCOZllZdT",
      "similarity": 0.8188
    },
    {
      "source": "Xj66fkrlTk",
      "target": "ods",
      "similarity": 0.8684
    },
    {
      "source": "Xj66fkrlTk",
      "target": "uqe5HkjbT9",
      "similarity": 0.8593
    },
    {
      "source": "Xj66fkrlTk",
      "target": "In this paper",
      "similarity": 0.8398
    },
    {
      "source": "Xj66fkrlTk",
      "target": "5oSUgTzs8Y",
      "similarity": 0.8393
    },
    {
      "source": "Xj66fkrlTk",
      "target": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "similarity": 0.8351
    },
    {
      "source": "IssPhpUsKt",
      "target": "Specifically",
      "similarity": 0.8866
    },
    {
      "source": "IssPhpUsKt",
      "target": "Fortunately",
      "similarity": 0.8078
    },
    {
      "source": "IssPhpUsKt",
      "target": "UeVx6L59fg",
      "similarity": 0.7927
    },
    {
      "source": "IssPhpUsKt",
      "target": "MRAG-Bench consists of 16",
      "similarity": 0.7826
    },
    {
      "source": "IssPhpUsKt",
      "target": "Second",
      "similarity": 0.7821
    },
    {
      "source": "HSi4VetQLj",
      "target": "of natural language. However",
      "similarity": 0.8619
    },
    {
      "source": "HSi4VetQLj",
      "target": "AnL6BuWzxa",
      "similarity": 0.8602
    },
    {
      "source": "HSi4VetQLj",
      "target": "To address these limitations",
      "similarity": 0.8304
    },
    {
      "source": "HSi4VetQLj",
      "target": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "similarity": 0.824
    },
    {
      "source": "HSi4VetQLj",
      "target": "jJXZvPe5z0",
      "similarity": 0.8206
    },
    {
      "source": "CbfsKHiWEn",
      "target": "Pacmann shows better scalability",
      "similarity": 0.853
    },
    {
      "source": "CbfsKHiWEn",
      "target": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "similarity": 0.8113
    },
    {
      "source": "CbfsKHiWEn",
      "target": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "similarity": 0.784
    },
    {
      "source": "CbfsKHiWEn",
      "target": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "similarity": 0.7824
    },
    {
      "source": "CbfsKHiWEn",
      "target": "roNSXZpUDN",
      "similarity": 0.7822
    },
    {
      "source": "97rOQDPmk2",
      "target": "Additionally",
      "similarity": 0.8595
    },
    {
      "source": "97rOQDPmk2",
      "target": "of top-k chunks",
      "similarity": 0.8554
    },
    {
      "source": "97rOQDPmk2",
      "target": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "similarity": 0.8534
    },
    {
      "source": "97rOQDPmk2",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8511
    },
    {
      "source": "97rOQDPmk2",
      "target": "mYgoNEsUDi",
      "similarity": 0.8506
    },
    {
      "source": "However",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8746
    },
    {
      "source": "However",
      "target": "cKlzKs3Nnb",
      "similarity": 0.867
    },
    {
      "source": "However",
      "target": "reaching 90\\% quality of a state-of-the-art",
      "similarity": 0.8648
    },
    {
      "source": "However",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8629
    },
    {
      "source": "However",
      "target": "5IWJBStfU7",
      "similarity": 0.8624
    },
    {
      "source": "Fortunately",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8338
    },
    {
      "source": "Fortunately",
      "target": "60GeEoG5kD",
      "similarity": 0.8178
    },
    {
      "source": "Fortunately",
      "target": "To meet real-time requirements and balance multi-task learning",
      "similarity": 0.8141
    },
    {
      "source": "Fortunately",
      "target": "solutions",
      "similarity": 0.8116
    },
    {
      "source": "Fortunately",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8114
    },
    {
      "source": "Despite its simplicity",
      "target": "6H4jRWKFc3",
      "similarity": 0.824
    },
    {
      "source": "Despite its simplicity",
      "target": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "similarity": 0.8239
    },
    {
      "source": "Despite its simplicity",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8234
    },
    {
      "source": "Despite its simplicity",
      "target": "In this work",
      "similarity": 0.8223
    },
    {
      "source": "Despite its simplicity",
      "target": "connection component",
      "similarity": 0.8158
    },
    {
      "source": "In this work",
      "target": "20qZK2T7fa",
      "similarity": 0.8663
    },
    {
      "source": "In this work",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8585
    },
    {
      "source": "In this work",
      "target": "OiQttMHwce",
      "similarity": 0.8437
    },
    {
      "source": "In this work",
      "target": "yORSk4Ycsa",
      "similarity": 0.8436
    },
    {
      "source": "In this work",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.836
    },
    {
      "source": "a linearly separable noisy dataset.",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.7971
    },
    {
      "source": "a linearly separable noisy dataset.",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.7834
    },
    {
      "source": "a linearly separable noisy dataset.",
      "target": "Ij9ilPh36h",
      "similarity": 0.7744
    },
    {
      "source": "a linearly separable noisy dataset.",
      "target": "IDxZhXrpNf",
      "similarity": 0.7653
    },
    {
      "source": "a linearly separable noisy dataset.",
      "target": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "similarity": 0.7627
    },
    {
      "source": "We identify four stages in the training dynamics",
      "target": "TDy5Ih78b4",
      "similarity": 0.8821
    },
    {
      "source": "We identify four stages in the training dynamics",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8729
    },
    {
      "source": "We identify four stages in the training dynamics",
      "target": "pre-training data",
      "similarity": 0.8728
    },
    {
      "source": "We identify four stages in the training dynamics",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8719
    },
    {
      "source": "We identify four stages in the training dynamics",
      "target": "However",
      "similarity": 0.8716
    },
    {
      "source": "Based on the training dynamics",
      "target": "These datasets are typically massive",
      "similarity": 0.8573
    },
    {
      "source": "Based on the training dynamics",
      "target": "In parallel",
      "similarity": 0.8216
    },
    {
      "source": "Based on the training dynamics",
      "target": "However",
      "similarity": 0.814
    },
    {
      "source": "Based on the training dynamics",
      "target": "vue9P1Ypk6",
      "similarity": 0.811
    },
    {
      "source": "Based on the training dynamics",
      "target": "O6znYvxC1U",
      "similarity": 0.8073
    },
    {
      "source": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.8059
    },
    {
      "source": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "target": "Finally",
      "similarity": 0.8029
    },
    {
      "source": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "target": "However",
      "similarity": 0.7995
    },
    {
      "source": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "target": "ZadnlOHsHv",
      "similarity": 0.7977
    },
    {
      "source": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "target": "aN57tSd5Us",
      "similarity": 0.7945
    },
    {
      "source": "Additionally",
      "target": "semTHoVGsJ",
      "similarity": 0.8599
    },
    {
      "source": "Additionally",
      "target": "To tackle this challenge",
      "similarity": 0.8501
    },
    {
      "source": "Additionally",
      "target": "population shifts. In particular",
      "similarity": 0.8451
    },
    {
      "source": "Additionally",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8396
    },
    {
      "source": "Additionally",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8348
    },
    {
      "source": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "target": "bcTjW5kS4W",
      "similarity": 0.9245
    },
    {
      "source": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "target": "4A9IdSa1ul",
      "similarity": 0.8538
    },
    {
      "source": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "target": "LNL7zKvm7e",
      "similarity": 0.8524
    },
    {
      "source": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "target": "In this paper",
      "similarity": 0.846
    },
    {
      "source": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "target": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "similarity": 0.8436
    },
    {
      "source": "Finally",
      "target": "AoIKgHu9Si",
      "similarity": 0.8261
    },
    {
      "source": "Finally",
      "target": "ogXkmugNZw",
      "similarity": 0.8254
    },
    {
      "source": "Finally",
      "target": "vVxeFSR4fU",
      "similarity": 0.8225
    },
    {
      "source": "Finally",
      "target": "Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.",
      "similarity": 0.8201
    },
    {
      "source": "Finally",
      "target": "Following these principles",
      "similarity": 0.8087
    },
    {
      "source": "V4K9h1qNxE",
      "target": "Furthermore",
      "similarity": 0.8867
    },
    {
      "source": "V4K9h1qNxE",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8707
    },
    {
      "source": "V4K9h1qNxE",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8693
    },
    {
      "source": "V4K9h1qNxE",
      "target": "1CIUkpoata",
      "similarity": 0.8605
    },
    {
      "source": "V4K9h1qNxE",
      "target": "wgRQ2WAORJ",
      "similarity": 0.859
    },
    {
      "source": "What mechanisms underlie this ability for compositional generalization?",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8265
    },
    {
      "source": "What mechanisms underlie this ability for compositional generalization?",
      "target": "ptjrpEGrGg",
      "similarity": 0.8184
    },
    {
      "source": "What mechanisms underlie this ability for compositional generalization?",
      "target": "5xwx1Myosu",
      "similarity": 0.8131
    },
    {
      "source": "What mechanisms underlie this ability for compositional generalization?",
      "target": "mobile devices.\"",
      "similarity": 0.8105
    },
    {
      "source": "What mechanisms underlie this ability for compositional generalization?",
      "target": "KlV5CkNQkl",
      "similarity": 0.8079
    },
    {
      "source": "By reformulating multi-head attention as a hypernetwork",
      "target": "8pusxkLEQO",
      "similarity": 0.9355
    },
    {
      "source": "By reformulating multi-head attention as a hypernetwork",
      "target": "Moreover",
      "similarity": 0.914
    },
    {
      "source": "By reformulating multi-head attention as a hypernetwork",
      "target": "nIEjY4a2Lf",
      "similarity": 0.8972
    },
    {
      "source": "By reformulating multi-head attention as a hypernetwork",
      "target": "ja4rpheN2n",
      "similarity": 0.8439
    },
    {
      "source": "By reformulating multi-head attention as a hypernetwork",
      "target": "In experiments with GPT-4",
      "similarity": 0.8384
    },
    {
      "source": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "target": "rCX9l4OTCT",
      "similarity": 0.8857
    },
    {
      "source": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8623
    },
    {
      "source": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "target": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "similarity": 0.8585
    },
    {
      "source": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "target": "To remedy this problem",
      "similarity": 0.8579
    },
    {
      "source": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "target": "xjKz6IxgCX",
      "similarity": 0.8504
    },
    {
      "source": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "target": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "similarity": 0.8458
    },
    {
      "source": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "target": "X0epAjg0hd",
      "similarity": 0.8312
    },
    {
      "source": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "target": "We evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e.",
      "similarity": 0.8288
    },
    {
      "source": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "target": "In this work",
      "similarity": 0.8287
    },
    {
      "source": "To further examine the hypothesis that the intrinsic hypernetwork of multi-head attention supports compositional generalization",
      "target": "relying on backward propagation",
      "similarity": 0.8279
    },
    {
      "source": "We find that this modification improves compositional generalization on abstract reasoning tasks.",
      "target": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "similarity": 0.8207
    },
    {
      "source": "We find that this modification improves compositional generalization on abstract reasoning tasks.",
      "target": "Other methods have focused on the low-budget regime",
      "similarity": 0.8177
    },
    {
      "source": "We find that this modification improves compositional generalization on abstract reasoning tasks.",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.815
    },
    {
      "source": "We find that this modification improves compositional generalization on abstract reasoning tasks.",
      "target": "owP2mymrTD",
      "similarity": 0.8144
    },
    {
      "source": "We find that this modification improves compositional generalization on abstract reasoning tasks.",
      "target": "2OMyAFjiJJ",
      "similarity": 0.809
    },
    {
      "source": "In particular",
      "target": "ofuLWn8DFZ",
      "similarity": 0.852
    },
    {
      "source": "In particular",
      "target": "Furthermore",
      "similarity": 0.8512
    },
    {
      "source": "In particular",
      "target": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "similarity": 0.8405
    },
    {
      "source": "In particular",
      "target": "OuLgaHEmzi",
      "similarity": 0.8401
    },
    {
      "source": "In particular",
      "target": "HqjRlT65WX",
      "similarity": 0.8227
    },
    {
      "source": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "target": "To this end",
      "similarity": 0.8808
    },
    {
      "source": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8712
    },
    {
      "source": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8679
    },
    {
      "source": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "target": "AJpUZd8Clb",
      "similarity": 0.8669
    },
    {
      "source": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "target": "Qja5s0K3VX",
      "similarity": 0.8621
    },
    {
      "source": "8rbkePAapb",
      "target": "methods improve exploration and enhance efficiency. Extensive experiments",
      "similarity": 0.8236
    },
    {
      "source": "8rbkePAapb",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8132
    },
    {
      "source": "8rbkePAapb",
      "target": "which",
      "similarity": 0.8124
    },
    {
      "source": "8rbkePAapb",
      "target": "eUEMjwh5wK",
      "similarity": 0.8116
    },
    {
      "source": "8rbkePAapb",
      "target": "implementation",
      "similarity": 0.8086
    },
    {
      "source": "9chRqsPOGL",
      "target": "GySIAKEwtZ",
      "similarity": 0.8508
    },
    {
      "source": "9chRqsPOGL",
      "target": "wmV4cIbgl6",
      "similarity": 0.8454
    },
    {
      "source": "9chRqsPOGL",
      "target": "We propose RAMEN",
      "similarity": 0.8349
    },
    {
      "source": "9chRqsPOGL",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8314
    },
    {
      "source": "9chRqsPOGL",
      "target": "DpLFmc09pC",
      "similarity": 0.8283
    },
    {
      "source": "Such an ability is well-suited for and often optimized by preference learning.",
      "target": "pDDODPtpx9",
      "similarity": 0.863
    },
    {
      "source": "Such an ability is well-suited for and often optimized by preference learning.",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8619
    },
    {
      "source": "Such an ability is well-suited for and often optimized by preference learning.",
      "target": "First",
      "similarity": 0.8592
    },
    {
      "source": "Such an ability is well-suited for and often optimized by preference learning.",
      "target": "AcVpLS86RT",
      "similarity": 0.8586
    },
    {
      "source": "Such an ability is well-suited for and often optimized by preference learning.",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8585
    },
    {
      "source": "However",
      "target": "dbuFJg7eaw",
      "similarity": 0.7914
    },
    {
      "source": "However",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.7906
    },
    {
      "source": "However",
      "target": "gkUyYcY1W9",
      "similarity": 0.7884
    },
    {
      "source": "However",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.7875
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.7866
    },
    {
      "source": "Such practice can introduce content variations irrelevant to whether the instruction is precisely followed (e.g.",
      "target": "k2uUeLCrQq",
      "similarity": 0.8365
    },
    {
      "source": "Such practice can introduce content variations irrelevant to whether the instruction is precisely followed (e.g.",
      "target": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "similarity": 0.818
    },
    {
      "source": "Such practice can introduce content variations irrelevant to whether the instruction is precisely followed (e.g.",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.816
    },
    {
      "source": "Such practice can introduce content variations irrelevant to whether the instruction is precisely followed (e.g.",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.8152
    },
    {
      "source": "Such practice can introduce content variations irrelevant to whether the instruction is precisely followed (e.g.",
      "target": "introduce a novel inductive graph framework",
      "similarity": 0.8058
    },
    {
      "source": "In light of this",
      "target": "gFvRRCnQvX",
      "similarity": 0.9081
    },
    {
      "source": "In light of this",
      "target": "cC3LxGZasH",
      "similarity": 0.8805
    },
    {
      "source": "In light of this",
      "target": "To address this issue",
      "similarity": 0.869
    },
    {
      "source": "In light of this",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8638
    },
    {
      "source": "In light of this",
      "target": "in reinforcement learning (RL)",
      "similarity": 0.8448
    },
    {
      "source": "By playing against itself",
      "target": "71XtUhazG0",
      "similarity": 0.8379
    },
    {
      "source": "By playing against itself",
      "target": "GySIAKEwtZ",
      "similarity": 0.833
    },
    {
      "source": "By playing against itself",
      "target": "In this paper",
      "similarity": 0.8326
    },
    {
      "source": "By playing against itself",
      "target": "additional structural constraints",
      "similarity": 0.8323
    },
    {
      "source": "By playing against itself",
      "target": "In this work",
      "similarity": 0.8314
    },
    {
      "source": "Our experiments show that a LLaMA3-8B model",
      "target": "Based on this",
      "similarity": 0.8006
    },
    {
      "source": "Our experiments show that a LLaMA3-8B model",
      "target": "sb1HgVDLjN",
      "similarity": 0.7973
    },
    {
      "source": "Our experiments show that a LLaMA3-8B model",
      "target": "vue9P1Ypk6",
      "similarity": 0.7961
    },
    {
      "source": "Our experiments show that a LLaMA3-8B model",
      "target": "Against grandmaster-level (2500 Elo) opponents",
      "similarity": 0.7869
    },
    {
      "source": "Our experiments show that a LLaMA3-8B model",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.7853
    },
    {
      "source": "Furthermore",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.9156
    },
    {
      "source": "Furthermore",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8987
    },
    {
      "source": "Furthermore",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8953
    },
    {
      "source": "Furthermore",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8843
    },
    {
      "source": "Furthermore",
      "target": "2mqb8bPHeb",
      "similarity": 0.8819
    },
    {
      "source": "We also identify how inference scaling in tree search would impact model performance.",
      "target": "rWQDzq3O5c",
      "similarity": 0.8737
    },
    {
      "source": "We also identify how inference scaling in tree search would impact model performance.",
      "target": "However",
      "similarity": 0.8309
    },
    {
      "source": "We also identify how inference scaling in tree search would impact model performance.",
      "target": "lS2SGfWizd",
      "similarity": 0.8097
    },
    {
      "source": "We also identify how inference scaling in tree search would impact model performance.",
      "target": "reaching 90\\% quality of a state-of-the-art",
      "similarity": 0.8072
    },
    {
      "source": "We also identify how inference scaling in tree search would impact model performance.",
      "target": "Fk3eod9aaD",
      "similarity": 0.799
    },
    {
      "source": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8549
    },
    {
      "source": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "target": "To tackle this problem",
      "similarity": 0.8345
    },
    {
      "source": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "target": "tu3qwNjrtw",
      "similarity": 0.8332
    },
    {
      "source": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "target": "SUc1UOWndp",
      "similarity": 0.8328
    },
    {
      "source": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "target": "hgwGi81ndj",
      "similarity": 0.8323
    },
    {
      "source": "Ev4iw23gdI",
      "target": "D2hhkU5O48",
      "similarity": 0.8441
    },
    {
      "source": "Ev4iw23gdI",
      "target": "SMK0f8JoKF",
      "similarity": 0.8305
    },
    {
      "source": "Ev4iw23gdI",
      "target": "wgDB1QuxIA",
      "similarity": 0.8284
    },
    {
      "source": "Ev4iw23gdI",
      "target": "2p03KljxE9",
      "similarity": 0.827
    },
    {
      "source": "Ev4iw23gdI",
      "target": "w8LMtFY97b",
      "similarity": 0.8125
    },
    {
      "source": "rySLejeB1k",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8442
    },
    {
      "source": "rySLejeB1k",
      "target": "To this end",
      "similarity": 0.8433
    },
    {
      "source": "rySLejeB1k",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8394
    },
    {
      "source": "rySLejeB1k",
      "target": "Se6MgCtRhz",
      "similarity": 0.8362
    },
    {
      "source": "rySLejeB1k",
      "target": "NHhjczmJjo",
      "similarity": 0.8359
    },
    {
      "source": "txZVQRc2ab",
      "target": "To make this efficient",
      "similarity": 0.8425
    },
    {
      "source": "txZVQRc2ab",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8218
    },
    {
      "source": "txZVQRc2ab",
      "target": "vaJ4FObpXN",
      "similarity": 0.8203
    },
    {
      "source": "txZVQRc2ab",
      "target": "group-unlabeled data",
      "similarity": 0.8176
    },
    {
      "source": "txZVQRc2ab",
      "target": "PxlfzEePC0",
      "similarity": 0.8168
    },
    {
      "source": "To overcome such limitations",
      "target": "In this paper",
      "similarity": 0.8952
    },
    {
      "source": "To overcome such limitations",
      "target": "jj7b3p5kLY",
      "similarity": 0.8646
    },
    {
      "source": "To overcome such limitations",
      "target": "L0evcuybH5",
      "similarity": 0.8554
    },
    {
      "source": "To overcome such limitations",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8526
    },
    {
      "source": "To overcome such limitations",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8519
    },
    {
      "source": "9tKC0YM8sX",
      "target": "eIgGesYKLG",
      "similarity": 0.7817
    },
    {
      "source": "9tKC0YM8sX",
      "target": "with compression rates of 25-30%. The compression process can be completed on",
      "similarity": 0.7759
    },
    {
      "source": "9tKC0YM8sX",
      "target": "However",
      "similarity": 0.7754
    },
    {
      "source": "9tKC0YM8sX",
      "target": "To address this",
      "similarity": 0.7725
    },
    {
      "source": "9tKC0YM8sX",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.7666
    },
    {
      "source": "uqWM9hBDAE",
      "target": "kGvXIlIVLM",
      "similarity": 0.8421
    },
    {
      "source": "uqWM9hBDAE",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8236
    },
    {
      "source": "uqWM9hBDAE",
      "target": "RWJX5F5I9g",
      "similarity": 0.8224
    },
    {
      "source": "uqWM9hBDAE",
      "target": "8eNLKk5by4",
      "similarity": 0.817
    },
    {
      "source": "uqWM9hBDAE",
      "target": "1Z3C49JQVf",
      "similarity": 0.8157
    },
    {
      "source": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "target": "aXwukBD6M6",
      "similarity": 0.8616
    },
    {
      "source": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8438
    },
    {
      "source": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8395
    },
    {
      "source": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "target": "Nevertheless",
      "similarity": 0.8387
    },
    {
      "source": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8373
    },
    {
      "source": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "target": "Qja5s0K3VX",
      "similarity": 0.8724
    },
    {
      "source": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "target": "oP7arLOWix",
      "similarity": 0.8695
    },
    {
      "source": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "target": "To this end",
      "similarity": 0.8564
    },
    {
      "source": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "target": "previous results.\"",
      "similarity": 0.855
    },
    {
      "source": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8532
    },
    {
      "source": "In our experiments",
      "target": "Qja5s0K3VX",
      "similarity": 0.878
    },
    {
      "source": "In our experiments",
      "target": "To this end",
      "similarity": 0.8672
    },
    {
      "source": "In our experiments",
      "target": "oP7arLOWix",
      "similarity": 0.8636
    },
    {
      "source": "In our experiments",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.862
    },
    {
      "source": "In our experiments",
      "target": "bilities",
      "similarity": 0.8569
    },
    {
      "source": "6ouZaBzeNO",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8401
    },
    {
      "source": "6ouZaBzeNO",
      "target": "connection component",
      "similarity": 0.8252
    },
    {
      "source": "6ouZaBzeNO",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8228
    },
    {
      "source": "6ouZaBzeNO",
      "target": "In parallel",
      "similarity": 0.8209
    },
    {
      "source": "6ouZaBzeNO",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.819
    },
    {
      "source": "In this paper",
      "target": "mb2ryuZ3wz",
      "similarity": 0.8525
    },
    {
      "source": "In this paper",
      "target": "In this work",
      "similarity": 0.8429
    },
    {
      "source": "In this paper",
      "target": "target node would not have been anomalous. Prior methods of assessing the fix",
      "similarity": 0.8245
    },
    {
      "source": "In this paper",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8223
    },
    {
      "source": "In this paper",
      "target": "BksqWM8737",
      "similarity": 0.8207
    },
    {
      "source": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "target": "vue9P1Ypk6",
      "similarity": 0.8512
    },
    {
      "source": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "target": "ogXkmugNZw",
      "similarity": 0.8455
    },
    {
      "source": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8308
    },
    {
      "source": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "target": "To address this",
      "similarity": 0.8227
    },
    {
      "source": "equations and to select challenging instances via rejection sampling. Using this methodology",
      "target": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "similarity": 0.8217
    },
    {
      "source": "nt8gBX58Kh",
      "target": "In this work",
      "similarity": 0.8272
    },
    {
      "source": "nt8gBX58Kh",
      "target": "Along our analysis",
      "similarity": 0.8211
    },
    {
      "source": "nt8gBX58Kh",
      "target": "x1An5a3U9I",
      "similarity": 0.816
    },
    {
      "source": "nt8gBX58Kh",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.8035
    },
    {
      "source": "nt8gBX58Kh",
      "target": "P9VdRQOyqu",
      "similarity": 0.8016
    },
    {
      "source": "JSB171dSUU",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.903
    },
    {
      "source": "JSB171dSUU",
      "target": "while ensuring safety during learning.\"",
      "similarity": 0.9003
    },
    {
      "source": "JSB171dSUU",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8943
    },
    {
      "source": "JSB171dSUU",
      "target": "jTEKTdI3K9",
      "similarity": 0.886
    },
    {
      "source": "JSB171dSUU",
      "target": "- In discrete image-based control (e.g.",
      "similarity": 0.886
    },
    {
      "source": "eWocmTQn7H",
      "target": "bmbRCRiNDu",
      "similarity": 0.8671
    },
    {
      "source": "eWocmTQn7H",
      "target": "respectively. On skill retention tasks",
      "similarity": 0.8569
    },
    {
      "source": "eWocmTQn7H",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.848
    },
    {
      "source": "eWocmTQn7H",
      "target": "bilities",
      "similarity": 0.8476
    },
    {
      "source": "eWocmTQn7H",
      "target": "Y7slJZPGCy",
      "similarity": 0.8471
    },
    {
      "source": "TUC0ZT2zIQ",
      "target": "relying on backward propagation",
      "similarity": 0.8578
    },
    {
      "source": "TUC0ZT2zIQ",
      "target": "d7pr2doXn3",
      "similarity": 0.8567
    },
    {
      "source": "TUC0ZT2zIQ",
      "target": "VoayJihXra",
      "similarity": 0.8555
    },
    {
      "source": "TUC0ZT2zIQ",
      "target": "9qS3HzSDNv",
      "similarity": 0.8534
    },
    {
      "source": "TUC0ZT2zIQ",
      "target": "In contrast",
      "similarity": 0.8417
    },
    {
      "source": "This reformulation allows us to model the joint distribution over original strings and their counterfactuals resulting from the same instantiation of the sampling noise. We develop an algorithm based on hindsight Gumbel sampling that allows us to infer the latent noise variables and generate counterfactuals of observed strings. Our experiments demonstrate that the approach produces meaningful counterfactuals while at the same time showing that commonly used intervention techniques have considerable undesired side effects.\"",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8094
    },
    {
      "source": "This reformulation allows us to model the joint distribution over original strings and their counterfactuals resulting from the same instantiation of the sampling noise. We develop an algorithm based on hindsight Gumbel sampling that allows us to infer the latent noise variables and generate counterfactuals of observed strings. Our experiments demonstrate that the approach produces meaningful counterfactuals while at the same time showing that commonly used intervention techniques have considerable undesired side effects.\"",
      "target": "However",
      "similarity": 0.8081
    },
    {
      "source": "This reformulation allows us to model the joint distribution over original strings and their counterfactuals resulting from the same instantiation of the sampling noise. We develop an algorithm based on hindsight Gumbel sampling that allows us to infer the latent noise variables and generate counterfactuals of observed strings. Our experiments demonstrate that the approach produces meaningful counterfactuals while at the same time showing that commonly used intervention techniques have considerable undesired side effects.\"",
      "target": "gVnJFY8nCM",
      "similarity": 0.7979
    },
    {
      "source": "This reformulation allows us to model the joint distribution over original strings and their counterfactuals resulting from the same instantiation of the sampling noise. We develop an algorithm based on hindsight Gumbel sampling that allows us to infer the latent noise variables and generate counterfactuals of observed strings. Our experiments demonstrate that the approach produces meaningful counterfactuals while at the same time showing that commonly used intervention techniques have considerable undesired side effects.\"",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.7958
    },
    {
      "source": "This reformulation allows us to model the joint distribution over original strings and their counterfactuals resulting from the same instantiation of the sampling noise. We develop an algorithm based on hindsight Gumbel sampling that allows us to infer the latent noise variables and generate counterfactuals of observed strings. Our experiments demonstrate that the approach produces meaningful counterfactuals while at the same time showing that commonly used intervention techniques have considerable undesired side effects.\"",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.7855
    },
    {
      "source": "v1rFkElnIn",
      "target": "jTEKTdI3K9",
      "similarity": 0.9052
    },
    {
      "source": "v1rFkElnIn",
      "target": "pq1WUegkza",
      "similarity": 0.8956
    },
    {
      "source": "v1rFkElnIn",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8846
    },
    {
      "source": "v1rFkElnIn",
      "target": "For example",
      "similarity": 0.8831
    },
    {
      "source": "v1rFkElnIn",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8769
    },
    {
      "source": "bMC1t7eLRc",
      "target": "VQwI055flA",
      "similarity": 0.8816
    },
    {
      "source": "bMC1t7eLRc",
      "target": "FrFQpAgnGE",
      "similarity": 0.8803
    },
    {
      "source": "bMC1t7eLRc",
      "target": "Furthermore",
      "similarity": 0.8791
    },
    {
      "source": "bMC1t7eLRc",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8781
    },
    {
      "source": "bMC1t7eLRc",
      "target": "2mqb8bPHeb",
      "similarity": 0.8758
    },
    {
      "source": "To achieve this",
      "target": "VGURexnlUL",
      "similarity": 0.8503
    },
    {
      "source": "To achieve this",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8065
    },
    {
      "source": "To achieve this",
      "target": "led to a surge in more expressive models exploiting higher-order structures in the data",
      "similarity": 0.7931
    },
    {
      "source": "To achieve this",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.7748
    },
    {
      "source": "To achieve this",
      "target": "uncertainty estimation and improved interpretability.\"",
      "similarity": 0.7736
    },
    {
      "source": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "target": "dermining interpretability. To address these challenges",
      "similarity": 0.8712
    },
    {
      "source": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "target": "ptjrpEGrGg",
      "similarity": 0.8368
    },
    {
      "source": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "target": "kSdWcw5mkp",
      "similarity": 0.8202
    },
    {
      "source": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8198
    },
    {
      "source": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "target": "FrFQpAgnGE",
      "similarity": 0.8169
    },
    {
      "source": "(2) The selected data instances are not diverse enough",
      "target": "TDy5Ih78b4",
      "similarity": 0.8646
    },
    {
      "source": "(2) The selected data instances are not diverse enough",
      "target": "t9lS1lX9FQ",
      "similarity": 0.85
    },
    {
      "source": "(2) The selected data instances are not diverse enough",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8479
    },
    {
      "source": "(2) The selected data instances are not diverse enough",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8388
    },
    {
      "source": "(2) The selected data instances are not diverse enough",
      "target": "1NprT9Kz0d",
      "similarity": 0.8352
    },
    {
      "source": "In this paper",
      "target": "5pd78GmXC6",
      "similarity": 0.821
    },
    {
      "source": "In this paper",
      "target": "Among these",
      "similarity": 0.8095
    },
    {
      "source": "In this paper",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8042
    },
    {
      "source": "In this paper",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8028
    },
    {
      "source": "In this paper",
      "target": "AjXkRZIvjB",
      "similarity": 0.7971
    },
    {
      "source": "To compute the influence ($i.e.",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8628
    },
    {
      "source": "To compute the influence ($i.e.",
      "target": "gVnJFY8nCM",
      "similarity": 0.862
    },
    {
      "source": "To compute the influence ($i.e.",
      "target": "aXwukBD6M6",
      "similarity": 0.8493
    },
    {
      "source": "To compute the influence ($i.e.",
      "target": "VGQugiuCQs",
      "similarity": 0.8441
    },
    {
      "source": "To compute the influence ($i.e.",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8372
    },
    {
      "source": "For the diversity",
      "target": "5pd78GmXC6",
      "similarity": 0.8378
    },
    {
      "source": "For the diversity",
      "target": "Second",
      "similarity": 0.8364
    },
    {
      "source": "For the diversity",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8342
    },
    {
      "source": "For the diversity",
      "target": "Specifically",
      "similarity": 0.8341
    },
    {
      "source": "For the diversity",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8333
    },
    {
      "source": "qZEdmyqCHF",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8945
    },
    {
      "source": "qZEdmyqCHF",
      "target": "FrFQpAgnGE",
      "similarity": 0.8901
    },
    {
      "source": "qZEdmyqCHF",
      "target": "2mqb8bPHeb",
      "similarity": 0.8769
    },
    {
      "source": "qZEdmyqCHF",
      "target": "VQwI055flA",
      "similarity": 0.8748
    },
    {
      "source": "qZEdmyqCHF",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8641
    },
    {
      "source": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "target": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "similarity": 0.8394
    },
    {
      "source": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8328
    },
    {
      "source": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "target": "INqLJwqUmc",
      "similarity": 0.8236
    },
    {
      "source": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "target": "However",
      "similarity": 0.8196
    },
    {
      "source": "different roles between AC and RC in different pathways. ACs are updated by gradients of the loss on the source domain",
      "target": "Additionally",
      "similarity": 0.8139
    },
    {
      "source": "PDnEDS244P",
      "target": "bilities",
      "similarity": 0.9023
    },
    {
      "source": "PDnEDS244P",
      "target": "2ea5TNVR0c",
      "similarity": 0.8966
    },
    {
      "source": "PDnEDS244P",
      "target": "ZadnlOHsHv",
      "similarity": 0.8768
    },
    {
      "source": "PDnEDS244P",
      "target": "In response",
      "similarity": 0.8548
    },
    {
      "source": "PDnEDS244P",
      "target": "Such models faced convergence issues due to vanishing gradient",
      "similarity": 0.8545
    },
    {
      "source": "4iFSBgxvIO",
      "target": "In this paper",
      "similarity": 0.888
    },
    {
      "source": "4iFSBgxvIO",
      "target": "4GT9uTsAJE",
      "similarity": 0.8558
    },
    {
      "source": "4iFSBgxvIO",
      "target": "{Subsequently}",
      "similarity": 0.8518
    },
    {
      "source": "4iFSBgxvIO",
      "target": "fNMKqyvuZT",
      "similarity": 0.8484
    },
    {
      "source": "4iFSBgxvIO",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8482
    },
    {
      "source": "In this paper",
      "target": "N1L5TgtkAw",
      "similarity": 0.8333
    },
    {
      "source": "In this paper",
      "target": "In addition",
      "similarity": 0.8204
    },
    {
      "source": "In this paper",
      "target": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "similarity": 0.8152
    },
    {
      "source": "In this paper",
      "target": "stacking methods. Specifically",
      "similarity": 0.8121
    },
    {
      "source": "In this paper",
      "target": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "similarity": 0.8101
    },
    {
      "source": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "target": "fXb9BbuyAD",
      "similarity": 0.8519
    },
    {
      "source": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "target": "TYSQYx9vwd",
      "similarity": 0.8517
    },
    {
      "source": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8433
    },
    {
      "source": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "target": "To remedy this problem",
      "similarity": 0.8423
    },
    {
      "source": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "target": "jj7b3p5kLY",
      "similarity": 0.8385
    },
    {
      "source": "Building on these insights",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.838
    },
    {
      "source": "Building on these insights",
      "target": "T4sMzjy7fO",
      "similarity": 0.8308
    },
    {
      "source": "Building on these insights",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8271
    },
    {
      "source": "Building on these insights",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8257
    },
    {
      "source": "Building on these insights",
      "target": "1Njl73JKjB",
      "similarity": 0.8252
    },
    {
      "source": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8557
    },
    {
      "source": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "target": "4R71pdPBZp",
      "similarity": 0.8527
    },
    {
      "source": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8518
    },
    {
      "source": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "target": "This paper introduces WebRL",
      "similarity": 0.8478
    },
    {
      "source": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "target": "rapidly converge to a uniform token or equilibrium state",
      "similarity": 0.8458
    },
    {
      "source": "With its flexible backbone for multi-LoRA fusion and a non-uniform caching strategy tailored to individual LoRAs",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8095
    },
    {
      "source": "With its flexible backbone for multi-LoRA fusion and a non-uniform caching strategy tailored to individual LoRAs",
      "target": "HN8V0flwJF",
      "similarity": 0.8088
    },
    {
      "source": "With its flexible backbone for multi-LoRA fusion and a non-uniform caching strategy tailored to individual LoRAs",
      "target": "Based on the observations",
      "similarity": 0.805
    },
    {
      "source": "With its flexible backbone for multi-LoRA fusion and a non-uniform caching strategy tailored to individual LoRAs",
      "target": "this paper",
      "similarity": 0.8036
    },
    {
      "source": "With its flexible backbone for multi-LoRA fusion and a non-uniform caching strategy tailored to individual LoRAs",
      "target": "In this work",
      "similarity": 0.8034
    },
    {
      "source": "Our experimental evaluations demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion methods by a significant margin -- it achieves an average improvement of $2.19$% in CLIPScore",
      "target": "wWnsoLhHwt",
      "similarity": 0.871
    },
    {
      "source": "Our experimental evaluations demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion methods by a significant margin -- it achieves an average improvement of $2.19$% in CLIPScore",
      "target": "Essg9kb4yx",
      "similarity": 0.8698
    },
    {
      "source": "Our experimental evaluations demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion methods by a significant margin -- it achieves an average improvement of $2.19$% in CLIPScore",
      "target": "jTEKTdI3K9",
      "similarity": 0.8698
    },
    {
      "source": "Our experimental evaluations demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion methods by a significant margin -- it achieves an average improvement of $2.19$% in CLIPScore",
      "target": "We further show that the density of long-distance referrals",
      "similarity": 0.8651
    },
    {
      "source": "Our experimental evaluations demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion methods by a significant margin -- it achieves an average improvement of $2.19$% in CLIPScore",
      "target": "v1rFkElnIn",
      "similarity": 0.8612
    },
    {
      "source": "EcrdmRT99M",
      "target": "2mqb8bPHeb",
      "similarity": 0.8661
    },
    {
      "source": "EcrdmRT99M",
      "target": "To this end",
      "similarity": 0.8642
    },
    {
      "source": "EcrdmRT99M",
      "target": "A1HhtITVEi",
      "similarity": 0.8636
    },
    {
      "source": "EcrdmRT99M",
      "target": "9qpdDiDQ2H",
      "similarity": 0.8598
    },
    {
      "source": "EcrdmRT99M",
      "target": "hoYFLRNbhc",
      "similarity": 0.8543
    },
    {
      "source": "CA06Nqa7CG",
      "target": "For example",
      "similarity": 0.88
    },
    {
      "source": "CA06Nqa7CG",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8715
    },
    {
      "source": "CA06Nqa7CG",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8711
    },
    {
      "source": "CA06Nqa7CG",
      "target": "jTEKTdI3K9",
      "similarity": 0.8661
    },
    {
      "source": "CA06Nqa7CG",
      "target": "se4vjm7h4E",
      "similarity": 0.8639
    },
    {
      "source": "UwcZEoNP19",
      "target": "v1rFkElnIn",
      "similarity": 0.8325
    },
    {
      "source": "UwcZEoNP19",
      "target": "First",
      "similarity": 0.8274
    },
    {
      "source": "UwcZEoNP19",
      "target": "has difficulty in capturing the relationship and the similarity structure of a",
      "similarity": 0.824
    },
    {
      "source": "UwcZEoNP19",
      "target": "Tv36j85SqR",
      "similarity": 0.8236
    },
    {
      "source": "UwcZEoNP19",
      "target": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "similarity": 0.8229
    },
    {
      "source": "J9eKm7j6KD",
      "target": "instances compared to 6% for the next best system.\"",
      "similarity": 0.8282
    },
    {
      "source": "J9eKm7j6KD",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8209
    },
    {
      "source": "J9eKm7j6KD",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8208
    },
    {
      "source": "J9eKm7j6KD",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8191
    },
    {
      "source": "J9eKm7j6KD",
      "target": "dEg5SdGaiq",
      "similarity": 0.8189
    },
    {
      "source": "Nq7yKYL0Bp",
      "target": "We evaluate LEAP on multiple decision-making benchmarks",
      "similarity": 0.8513
    },
    {
      "source": "Nq7yKYL0Bp",
      "target": "ujpAYpFDEA",
      "similarity": 0.84
    },
    {
      "source": "Nq7yKYL0Bp",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8361
    },
    {
      "source": "Nq7yKYL0Bp",
      "target": "Along our analysis",
      "similarity": 0.833
    },
    {
      "source": "Nq7yKYL0Bp",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8307
    },
    {
      "source": "E1m5yGMOiV",
      "target": "In this work",
      "similarity": 0.7804
    },
    {
      "source": "E1m5yGMOiV",
      "target": "Wf2ndb8nhf",
      "similarity": 0.7798
    },
    {
      "source": "E1m5yGMOiV",
      "target": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "similarity": 0.7668
    },
    {
      "source": "E1m5yGMOiV",
      "target": "To do this successfully",
      "similarity": 0.7648
    },
    {
      "source": "E1m5yGMOiV",
      "target": "Existing safety constraints are then integrated into the COP",
      "similarity": 0.7646
    },
    {
      "source": "KvaDHPhhir",
      "target": "hoYFLRNbhc",
      "similarity": 0.8177
    },
    {
      "source": "KvaDHPhhir",
      "target": "4iFSBgxvIO",
      "similarity": 0.8097
    },
    {
      "source": "KvaDHPhhir",
      "target": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "similarity": 0.8059
    },
    {
      "source": "KvaDHPhhir",
      "target": "no longer requiring computationally-intensive cryptographic techniques.",
      "similarity": 0.8043
    },
    {
      "source": "KvaDHPhhir",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.8032
    },
    {
      "source": "Vector diagrams are essential for communicating complex ideas across various fields",
      "target": "0fJfVOSUra",
      "similarity": 0.9064
    },
    {
      "source": "Vector diagrams are essential for communicating complex ideas across various fields",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.9028
    },
    {
      "source": "Vector diagrams are essential for communicating complex ideas across various fields",
      "target": "09FiNmvNMw",
      "similarity": 0.8845
    },
    {
      "source": "Vector diagrams are essential for communicating complex ideas across various fields",
      "target": "J9FgrqOOni",
      "similarity": 0.8772
    },
    {
      "source": "Vector diagrams are essential for communicating complex ideas across various fields",
      "target": "In this work",
      "similarity": 0.8744
    },
    {
      "source": "While recent research has progressed in generating diagrams from text descriptions",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8445
    },
    {
      "source": "While recent research has progressed in generating diagrams from text descriptions",
      "target": "5Jc7r5aqHJ",
      "similarity": 0.8363
    },
    {
      "source": "While recent research has progressed in generating diagrams from text descriptions",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.8336
    },
    {
      "source": "While recent research has progressed in generating diagrams from text descriptions",
      "target": "Furthermore",
      "similarity": 0.8284
    },
    {
      "source": "While recent research has progressed in generating diagrams from text descriptions",
      "target": "x33vSZUg0A",
      "similarity": 0.8278
    },
    {
      "source": "To address this gap",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.821
    },
    {
      "source": "To address this gap",
      "target": "Motivated by this insight",
      "similarity": 0.8044
    },
    {
      "source": "To address this gap",
      "target": "FSjIrOm1vz",
      "similarity": 0.7968
    },
    {
      "source": "To address this gap",
      "target": "vJgJSrYPe1",
      "similarity": 0.7952
    },
    {
      "source": "To address this gap",
      "target": "5Jc7r5aqHJ",
      "similarity": 0.7911
    },
    {
      "source": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8595
    },
    {
      "source": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "target": "tu3qwNjrtw",
      "similarity": 0.844
    },
    {
      "source": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "target": "jj7b3p5kLY",
      "similarity": 0.8367
    },
    {
      "source": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "target": "UeVx6L59fg",
      "similarity": 0.8362
    },
    {
      "source": "Our evaluations reveal the limitations of state-of-the-art vision and language models (VLMs)",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8351
    },
    {
      "source": "Along with SketikZ",
      "target": "Mjn53GtMxi",
      "similarity": 0.8564
    },
    {
      "source": "Along with SketikZ",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8481
    },
    {
      "source": "Along with SketikZ",
      "target": "(1) When the representation dimension is regarded as the time axis",
      "similarity": 0.8439
    },
    {
      "source": "Along with SketikZ",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8421
    },
    {
      "source": "Along with SketikZ",
      "target": "U42TkrEDzb",
      "similarity": 0.8388
    },
    {
      "source": "This success is driven by using our two data augmentation techniques and a multi-candidate inference strategy.",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8358
    },
    {
      "source": "This success is driven by using our two data augmentation techniques and a multi-candidate inference strategy.",
      "target": "of our approaches.",
      "similarity": 0.8294
    },
    {
      "source": "This success is driven by using our two data augmentation techniques and a multi-candidate inference strategy.",
      "target": "kRBQwlkFSP",
      "similarity": 0.8245
    },
    {
      "source": "This success is driven by using our two data augmentation techniques and a multi-candidate inference strategy.",
      "target": "E2PFv7ad3p",
      "similarity": 0.8176
    },
    {
      "source": "This success is driven by using our two data augmentation techniques and a multi-candidate inference strategy.",
      "target": "ISqx8giekS",
      "similarity": 0.8153
    },
    {
      "source": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "target": "To this end",
      "similarity": 0.8268
    },
    {
      "source": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "target": "However",
      "similarity": 0.8122
    },
    {
      "source": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "target": "yFGR36PLDJ",
      "similarity": 0.8095
    },
    {
      "source": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "target": "vRvVVb0NAz",
      "similarity": 0.8011
    },
    {
      "source": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "target": "HrdVqFSn1e",
      "similarity": 0.7977
    },
    {
      "source": "n2NidsYDop",
      "target": "KAIqwkB3dT",
      "similarity": 0.8845
    },
    {
      "source": "n2NidsYDop",
      "target": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "similarity": 0.8521
    },
    {
      "source": "n2NidsYDop",
      "target": "OuLgaHEmzi",
      "similarity": 0.845
    },
    {
      "source": "n2NidsYDop",
      "target": "HqjRlT65WX",
      "similarity": 0.8419
    },
    {
      "source": "n2NidsYDop",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8394
    },
    {
      "source": "03OkC0LKDD",
      "target": "9qpdDiDQ2H",
      "similarity": 0.8586
    },
    {
      "source": "03OkC0LKDD",
      "target": "EcrdmRT99M",
      "similarity": 0.8537
    },
    {
      "source": "03OkC0LKDD",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8525
    },
    {
      "source": "03OkC0LKDD",
      "target": "TlAdgeoDTo",
      "similarity": 0.851
    },
    {
      "source": "03OkC0LKDD",
      "target": "To overcome those challenges",
      "similarity": 0.848
    },
    {
      "source": "However",
      "target": "In the more general context",
      "similarity": 0.9117
    },
    {
      "source": "However",
      "target": "cADpvQgnqg",
      "similarity": 0.8851
    },
    {
      "source": "However",
      "target": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "similarity": 0.8566
    },
    {
      "source": "However",
      "target": "memorization.",
      "similarity": 0.8508
    },
    {
      "source": "However",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8506
    },
    {
      "source": "To address this limitation",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8365
    },
    {
      "source": "To address this limitation",
      "target": "n2NidsYDop",
      "similarity": 0.8362
    },
    {
      "source": "To address this limitation",
      "target": "DpLFmc09pC",
      "similarity": 0.8321
    },
    {
      "source": "To address this limitation",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8276
    },
    {
      "source": "To address this limitation",
      "target": "We further speculate on why LLaMA's kernel width and shape differs from classical algorithms",
      "similarity": 0.8267
    },
    {
      "source": "HfWcFs7XLR",
      "target": "nzOD1we8Z4",
      "similarity": 0.8165
    },
    {
      "source": "HfWcFs7XLR",
      "target": "tGYFikNONB",
      "similarity": 0.8086
    },
    {
      "source": "HfWcFs7XLR",
      "target": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "similarity": 0.8074
    },
    {
      "source": "HfWcFs7XLR",
      "target": "te2IdORabL",
      "similarity": 0.8031
    },
    {
      "source": "HfWcFs7XLR",
      "target": "Specifically",
      "similarity": 0.7997
    },
    {
      "source": "eXB5TCrAu9",
      "target": "UyU8ETswPg",
      "similarity": 0.7906
    },
    {
      "source": "eXB5TCrAu9",
      "target": "8rbkePAapb",
      "similarity": 0.7887
    },
    {
      "source": "eXB5TCrAu9",
      "target": "GFgn2LprFR",
      "similarity": 0.7862
    },
    {
      "source": "eXB5TCrAu9",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.777
    },
    {
      "source": "eXB5TCrAu9",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.777
    },
    {
      "source": "GRMfXcAAFh",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8709
    },
    {
      "source": "GRMfXcAAFh",
      "target": "We validate our approach on benchmarks from image and medical domains",
      "similarity": 0.8637
    },
    {
      "source": "GRMfXcAAFh",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8599
    },
    {
      "source": "GRMfXcAAFh",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8546
    },
    {
      "source": "GRMfXcAAFh",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8515
    },
    {
      "source": "D1Y2XFgsPI",
      "target": "However",
      "similarity": 0.8238
    },
    {
      "source": "D1Y2XFgsPI",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8222
    },
    {
      "source": "D1Y2XFgsPI",
      "target": "MxbEiFRf39",
      "similarity": 0.8109
    },
    {
      "source": "D1Y2XFgsPI",
      "target": "wfLuiDjQ0u",
      "similarity": 0.808
    },
    {
      "source": "D1Y2XFgsPI",
      "target": "1NprT9Kz0d",
      "similarity": 0.799
    },
    {
      "source": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "target": "Kwo20MWWCb",
      "similarity": 0.8515
    },
    {
      "source": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "target": "the lack of data for language-guided 3D scene editing",
      "similarity": 0.8513
    },
    {
      "source": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "target": "LQzN6TRFg9",
      "similarity": 0.8449
    },
    {
      "source": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "target": "In this setting",
      "similarity": 0.8412
    },
    {
      "source": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8397
    },
    {
      "source": "CIs9x2ZRgh",
      "target": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "similarity": 0.7879
    },
    {
      "source": "CIs9x2ZRgh",
      "target": "For example",
      "similarity": 0.7869
    },
    {
      "source": "CIs9x2ZRgh",
      "target": "In this work",
      "similarity": 0.7841
    },
    {
      "source": "CIs9x2ZRgh",
      "target": "pq1WUegkza",
      "similarity": 0.7813
    },
    {
      "source": "CIs9x2ZRgh",
      "target": "We evaluate LongGen on both Llama-2 7B and Llama-2 70B",
      "similarity": 0.7804
    },
    {
      "source": "whaO3482bs",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8616
    },
    {
      "source": "whaO3482bs",
      "target": "samples. However",
      "similarity": 0.8385
    },
    {
      "source": "whaO3482bs",
      "target": "78tc3EiUrN",
      "similarity": 0.8381
    },
    {
      "source": "whaO3482bs",
      "target": "We also thoroughly analyzed our pre-training dataset",
      "similarity": 0.8354
    },
    {
      "source": "whaO3482bs",
      "target": "bBoetBIN2R",
      "similarity": 0.8281
    },
    {
      "source": "However",
      "target": "We conduct a detailed analysis of early stopping in our algorithm",
      "similarity": 0.8316
    },
    {
      "source": "However",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8315
    },
    {
      "source": "However",
      "target": "MxbEiFRf39",
      "similarity": 0.8289
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8269
    },
    {
      "source": "However",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8249
    },
    {
      "source": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "target": "In particular",
      "similarity": 0.8287
    },
    {
      "source": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "target": "In parallel",
      "similarity": 0.8239
    },
    {
      "source": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8172
    },
    {
      "source": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "target": "Against grandmaster-level (2500 Elo) opponents",
      "similarity": 0.8126
    },
    {
      "source": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "target": "However",
      "similarity": 0.8101
    },
    {
      "source": "To overcome this",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8658
    },
    {
      "source": "To overcome this",
      "target": "vRvVVb0NAz",
      "similarity": 0.8346
    },
    {
      "source": "To overcome this",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8281
    },
    {
      "source": "To overcome this",
      "target": "We then propose deep Fourier features",
      "similarity": 0.8242
    },
    {
      "source": "To overcome this",
      "target": "task using images taken from 100 synonym sets of ImageNet and 3D implicit",
      "similarity": 0.8241
    },
    {
      "source": "Our benchmark distinguishes between knowledge that evolves (e.g.",
      "target": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "similarity": 0.7843
    },
    {
      "source": "Our benchmark distinguishes between knowledge that evolves (e.g.",
      "target": "MnJzJ2gvuf",
      "similarity": 0.7827
    },
    {
      "source": "Our benchmark distinguishes between knowledge that evolves (e.g.",
      "target": "on synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems",
      "similarity": 0.756
    },
    {
      "source": "Our benchmark distinguishes between knowledge that evolves (e.g.",
      "target": "L5godAOC2z",
      "similarity": 0.7556
    },
    {
      "source": "Our benchmark distinguishes between knowledge that evolves (e.g.",
      "target": "However",
      "similarity": 0.7556
    },
    {
      "source": "Building on this benchmark",
      "target": "which",
      "similarity": 0.8077
    },
    {
      "source": "Building on this benchmark",
      "target": "kNHVViEPWK",
      "similarity": 0.8052
    },
    {
      "source": "Building on this benchmark",
      "target": "Code",
      "similarity": 0.8033
    },
    {
      "source": "Building on this benchmark",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8029
    },
    {
      "source": "Building on this benchmark",
      "target": "uNomADvF3s",
      "similarity": 0.7971
    },
    {
      "source": "Our evaluation led to the following observations:",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8555
    },
    {
      "source": "Our evaluation led to the following observations:",
      "target": "7EhS3YBxjY",
      "similarity": 0.8462
    },
    {
      "source": "Our evaluation led to the following observations:",
      "target": "introduce MANTRA",
      "similarity": 0.8383
    },
    {
      "source": "Our evaluation led to the following observations:",
      "target": "that BNDL can achieve effective disentangled learning. In addition",
      "similarity": 0.8361
    },
    {
      "source": "Our evaluation led to the following observations:",
      "target": "has difficulty in capturing the relationship and the similarity structure of a",
      "similarity": 0.8358
    },
    {
      "source": "(1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on.",
      "target": "In this paper",
      "similarity": 0.8123
    },
    {
      "source": "(1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on.",
      "target": "tj5xJInWty",
      "similarity": 0.8102
    },
    {
      "source": "(1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on.",
      "target": "INyi7qUdjZ",
      "similarity": 0.7984
    },
    {
      "source": "(1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on.",
      "target": "Ouu3HnIVBc",
      "similarity": 0.7959
    },
    {
      "source": "(1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on.",
      "target": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "similarity": 0.7945
    },
    {
      "source": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "target": "1qq1QJKM5q",
      "similarity": 0.8508
    },
    {
      "source": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "target": "kbeX97jExm",
      "similarity": 0.8464
    },
    {
      "source": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8416
    },
    {
      "source": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "target": "254NJe9JEw",
      "similarity": 0.8403
    },
    {
      "source": "(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.",
      "target": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "similarity": 0.8386
    },
    {
      "source": "Thus",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.8612
    },
    {
      "source": "Thus",
      "target": "In this paper",
      "similarity": 0.8367
    },
    {
      "source": "Thus",
      "target": "constraints and dynamics",
      "similarity": 0.8112
    },
    {
      "source": "Thus",
      "target": "fjEZ2LPceZ",
      "similarity": 0.8084
    },
    {
      "source": "Thus",
      "target": "LgzRo1RpLS",
      "similarity": 0.8038
    },
    {
      "source": "We observe that it successfully recalls objects across both open-source and proprietary LLMs",
      "target": "Our code",
      "similarity": 0.7938
    },
    {
      "source": "We observe that it successfully recalls objects across both open-source and proprietary LLMs",
      "target": "CIs9x2ZRgh",
      "similarity": 0.7651
    },
    {
      "source": "We observe that it successfully recalls objects across both open-source and proprietary LLMs",
      "target": "However",
      "similarity": 0.7634
    },
    {
      "source": "We observe that it successfully recalls objects across both open-source and proprietary LLMs",
      "target": "Despite its simplicity",
      "similarity": 0.763
    },
    {
      "source": "We observe that it successfully recalls objects across both open-source and proprietary LLMs",
      "target": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "similarity": 0.7591
    },
    {
      "source": "onIro14tHv",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8425
    },
    {
      "source": "onIro14tHv",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8368
    },
    {
      "source": "onIro14tHv",
      "target": "nrvoWOWcyg",
      "similarity": 0.8352
    },
    {
      "source": "onIro14tHv",
      "target": "available at https://github.com/qiaoruiyt/GSR.\"",
      "similarity": 0.8323
    },
    {
      "source": "onIro14tHv",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.832
    },
    {
      "source": "0whx8MhysK",
      "target": "HqjRlT65WX",
      "similarity": 0.8311
    },
    {
      "source": "0whx8MhysK",
      "target": "zY37C8d6bS",
      "similarity": 0.8151
    },
    {
      "source": "0whx8MhysK",
      "target": "To overcome this",
      "similarity": 0.8147
    },
    {
      "source": "0whx8MhysK",
      "target": "effectiveness through experiments on various representative benchmarks. With an",
      "similarity": 0.8104
    },
    {
      "source": "0whx8MhysK",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8102
    },
    {
      "source": "CI4sCBMXjP",
      "target": "mzL19kKE3r",
      "similarity": 0.8476
    },
    {
      "source": "CI4sCBMXjP",
      "target": "KW8yzAOIZr",
      "similarity": 0.8296
    },
    {
      "source": "CI4sCBMXjP",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8204
    },
    {
      "source": "CI4sCBMXjP",
      "target": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "similarity": 0.8101
    },
    {
      "source": "CI4sCBMXjP",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8079
    },
    {
      "source": "Traditional fine-tuning methods require substantial data",
      "target": "q5EZ7gKcnW",
      "similarity": 0.8347
    },
    {
      "source": "Traditional fine-tuning methods require substantial data",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.8156
    },
    {
      "source": "Traditional fine-tuning methods require substantial data",
      "target": "upper bound of LLMs' generalization capabilities.",
      "similarity": 0.8135
    },
    {
      "source": "Traditional fine-tuning methods require substantial data",
      "target": "uOb7rij7sR",
      "similarity": 0.8112
    },
    {
      "source": "Traditional fine-tuning methods require substantial data",
      "target": "However",
      "similarity": 0.8107
    },
    {
      "source": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "target": "Despite their importance",
      "similarity": 0.8383
    },
    {
      "source": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "target": "6wOmHdwCC4",
      "similarity": 0.8269
    },
    {
      "source": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "target": "jlzNb1iWs3",
      "similarity": 0.8188
    },
    {
      "source": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "target": "introduce",
      "similarity": 0.8188
    },
    {
      "source": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "target": "SyVPiehSbg",
      "similarity": 0.8182
    },
    {
      "source": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "target": "As the size of the model and data grows",
      "similarity": 0.8529
    },
    {
      "source": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "target": "gWgaypDBs8",
      "similarity": 0.8196
    },
    {
      "source": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "target": "cC3LxGZasH",
      "similarity": 0.8159
    },
    {
      "source": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "target": "wg1PCg3CUP",
      "similarity": 0.8132
    },
    {
      "source": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "target": "prior to their applications to human patients. To facilitate its easy access and",
      "similarity": 0.8085
    },
    {
      "source": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "target": "BL4WBIfyrz",
      "similarity": 0.907
    },
    {
      "source": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "target": "riieAeQBJm",
      "similarity": 0.9057
    },
    {
      "source": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "target": "We found that long distance referrals",
      "similarity": 0.889
    },
    {
      "source": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8836
    },
    {
      "source": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "target": "Further",
      "similarity": 0.8802
    },
    {
      "source": "vVHc8bGRns",
      "target": "Further",
      "similarity": 0.8666
    },
    {
      "source": "vVHc8bGRns",
      "target": "We found that long distance referrals",
      "similarity": 0.8516
    },
    {
      "source": "vVHc8bGRns",
      "target": "We propose RAMEN",
      "similarity": 0.8516
    },
    {
      "source": "vVHc8bGRns",
      "target": "Further",
      "similarity": 0.8358
    },
    {
      "source": "vVHc8bGRns",
      "target": "Externally storing and reusing vectors that represent in-context learned capabilities not only shows the potential to extract modular capabilities but also significantly enhances the performance",
      "similarity": 0.8357
    },
    {
      "source": "dTPz4rEDok",
      "target": "These tasks are built from geometry problems",
      "similarity": 0.8443
    },
    {
      "source": "dTPz4rEDok",
      "target": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "similarity": 0.8314
    },
    {
      "source": "dTPz4rEDok",
      "target": "i) AUPD achieves $\\tilde{O}((1 + \\frac{\\nu^*}{\\delta b})\\sqrt{T})$ regret under the strict feasibility assumption without any prior information",
      "similarity": 0.8208
    },
    {
      "source": "dTPz4rEDok",
      "target": "FPfCUJTsCn",
      "similarity": 0.8095
    },
    {
      "source": "dTPz4rEDok",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8062
    },
    {
      "source": "However",
      "target": "Finally",
      "similarity": 0.8115
    },
    {
      "source": "However",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8078
    },
    {
      "source": "However",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8064
    },
    {
      "source": "However",
      "target": "TvGPP8i18S",
      "similarity": 0.799
    },
    {
      "source": "However",
      "target": "Adapting tools from classical sampling theory",
      "similarity": 0.7986
    },
    {
      "source": "Crucially",
      "target": "F57HPKZ6KD",
      "similarity": 0.8693
    },
    {
      "source": "Crucially",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.858
    },
    {
      "source": "Crucially",
      "target": "Overall",
      "similarity": 0.8575
    },
    {
      "source": "Crucially",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8441
    },
    {
      "source": "Crucially",
      "target": "VQwI055flA",
      "similarity": 0.8414
    },
    {
      "source": "In this work",
      "target": "90DC0IvlSs",
      "similarity": 0.8655
    },
    {
      "source": "In this work",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8639
    },
    {
      "source": "In this work",
      "target": "For TP",
      "similarity": 0.8618
    },
    {
      "source": "In this work",
      "target": "BI2int5SAC",
      "similarity": 0.8589
    },
    {
      "source": "In this work",
      "target": "EyaH1wzmao",
      "similarity": 0.8584
    },
    {
      "source": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8976
    },
    {
      "source": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8949
    },
    {
      "source": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "target": "Furthermore",
      "similarity": 0.8891
    },
    {
      "source": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "target": "However",
      "similarity": 0.8594
    },
    {
      "source": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "target": "memorization.",
      "similarity": 0.8491
    },
    {
      "source": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "target": "For TP",
      "similarity": 0.8816
    },
    {
      "source": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8746
    },
    {
      "source": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.869
    },
    {
      "source": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "target": "E4LAVLXAHW",
      "similarity": 0.8637
    },
    {
      "source": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8625
    },
    {
      "source": "We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness.  We investigate a variety of instantiations of our framework",
      "target": "0fJfVOSUra",
      "similarity": 0.8479
    },
    {
      "source": "We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness.  We investigate a variety of instantiations of our framework",
      "target": "(BoneMet) dataset",
      "similarity": 0.833
    },
    {
      "source": "We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness.  We investigate a variety of instantiations of our framework",
      "target": "In this work",
      "similarity": 0.8296
    },
    {
      "source": "We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness.  We investigate a variety of instantiations of our framework",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.8259
    },
    {
      "source": "We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness.  We investigate a variety of instantiations of our framework",
      "target": "We propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora",
      "similarity": 0.8241
    },
    {
      "source": "D2hhkU5O48",
      "target": "2p03KljxE9",
      "similarity": 0.8242
    },
    {
      "source": "D2hhkU5O48",
      "target": "wgDB1QuxIA",
      "similarity": 0.8238
    },
    {
      "source": "D2hhkU5O48",
      "target": "of 24 OOD scenarios. Further",
      "similarity": 0.8237
    },
    {
      "source": "D2hhkU5O48",
      "target": "SMK0f8JoKF",
      "similarity": 0.8215
    },
    {
      "source": "D2hhkU5O48",
      "target": "In this paper",
      "similarity": 0.8212
    },
    {
      "source": "8pusxkLEQO",
      "target": "Moreover",
      "similarity": 0.8949
    },
    {
      "source": "8pusxkLEQO",
      "target": "nIEjY4a2Lf",
      "similarity": 0.8649
    },
    {
      "source": "8pusxkLEQO",
      "target": "In experiments with GPT-4",
      "similarity": 0.8299
    },
    {
      "source": "8pusxkLEQO",
      "target": "However",
      "similarity": 0.8273
    },
    {
      "source": "8pusxkLEQO",
      "target": "QowsEic1sc",
      "similarity": 0.8239
    },
    {
      "source": "To generate high-quality",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8365
    },
    {
      "source": "To generate high-quality",
      "target": "ud8FtE1N4N",
      "similarity": 0.8232
    },
    {
      "source": "To generate high-quality",
      "target": "In the images pruning benchmark",
      "similarity": 0.8195
    },
    {
      "source": "To generate high-quality",
      "target": "WttfQGwpES",
      "similarity": 0.8174
    },
    {
      "source": "To generate high-quality",
      "target": "6VhDQP7WGX",
      "similarity": 0.8163
    },
    {
      "source": "Specifically",
      "target": "However",
      "similarity": 0.8475
    },
    {
      "source": "Specifically",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8421
    },
    {
      "source": "Specifically",
      "target": "Second",
      "similarity": 0.8378
    },
    {
      "source": "Specifically",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8372
    },
    {
      "source": "Specifically",
      "target": "compression has become increasingly crucial for reducing costs and improving",
      "similarity": 0.8363
    },
    {
      "source": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "target": "bqf0aCF3Dd",
      "similarity": 0.8225
    },
    {
      "source": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8187
    },
    {
      "source": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "target": "G82uQztzxl",
      "similarity": 0.7972
    },
    {
      "source": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "target": "NKotdPUc3L",
      "similarity": 0.7961
    },
    {
      "source": "1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens",
      "target": "CkgKSqZbuC",
      "similarity": 0.7921
    },
    {
      "source": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "target": "However",
      "similarity": 0.8834
    },
    {
      "source": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "target": "Es4RPNDtmq",
      "similarity": 0.8799
    },
    {
      "source": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8767
    },
    {
      "source": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "target": "MyVC4X5B2X",
      "similarity": 0.872
    },
    {
      "source": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8614
    },
    {
      "source": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "target": "To this end",
      "similarity": 0.846
    },
    {
      "source": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "target": "models. However",
      "similarity": 0.8459
    },
    {
      "source": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "target": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "similarity": 0.8443
    },
    {
      "source": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "target": "PDnEDS244P",
      "similarity": 0.8418
    },
    {
      "source": "3) To enhance the tolerance capability of noise introduced from the AR inference",
      "target": "Such models faced convergence issues due to vanishing gradient",
      "similarity": 0.8362
    },
    {
      "source": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "target": "0fJfVOSUra",
      "similarity": 0.9069
    },
    {
      "source": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "target": "09FiNmvNMw",
      "similarity": 0.8838
    },
    {
      "source": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "target": "In this work",
      "similarity": 0.874
    },
    {
      "source": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "target": "J9FgrqOOni",
      "similarity": 0.8698
    },
    {
      "source": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "target": "existing agent benchmarks neglect long-context video understanding",
      "similarity": 0.8535
    },
    {
      "source": "Detailed analyses of the improvements in inference efficiency are presented",
      "target": "67X93aZHII",
      "similarity": 0.8174
    },
    {
      "source": "Detailed analyses of the improvements in inference efficiency are presented",
      "target": "The challenge is particularly pronounced in entropy-seeking RL methods",
      "similarity": 0.8007
    },
    {
      "source": "Detailed analyses of the improvements in inference efficiency are presented",
      "target": "position reveals interpretable low-rank structure across toy tasks",
      "similarity": 0.7893
    },
    {
      "source": "Detailed analyses of the improvements in inference efficiency are presented",
      "target": "gfI9v7AbFg",
      "similarity": 0.7875
    },
    {
      "source": "Detailed analyses of the improvements in inference efficiency are presented",
      "target": "calibration data is also crucial to post-training pruning",
      "similarity": 0.7839
    },
    {
      "source": "b24n2LS2BJ",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8616
    },
    {
      "source": "b24n2LS2BJ",
      "target": "ZJo6Radbqq",
      "similarity": 0.8479
    },
    {
      "source": "b24n2LS2BJ",
      "target": "4es2oO9tw1",
      "similarity": 0.8477
    },
    {
      "source": "b24n2LS2BJ",
      "target": "OjAU0LLDbe",
      "similarity": 0.8464
    },
    {
      "source": "b24n2LS2BJ",
      "target": "Additionally",
      "similarity": 0.8379
    },
    {
      "source": "0ov0dMQ3mN",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8365
    },
    {
      "source": "0ov0dMQ3mN",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8316
    },
    {
      "source": "0ov0dMQ3mN",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8292
    },
    {
      "source": "0ov0dMQ3mN",
      "target": "the costliness of the labels",
      "similarity": 0.8253
    },
    {
      "source": "0ov0dMQ3mN",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8239
    },
    {
      "source": "To alleviate this problem",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8485
    },
    {
      "source": "To alleviate this problem",
      "target": "lOi6FtIwR8",
      "similarity": 0.8431
    },
    {
      "source": "To alleviate this problem",
      "target": "SOTA LLMs",
      "similarity": 0.8408
    },
    {
      "source": "To alleviate this problem",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8378
    },
    {
      "source": "To alleviate this problem",
      "target": "Building on the SpiderBoost algorithm framework",
      "similarity": 0.8366
    },
    {
      "source": "With extensive ablation studies",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8511
    },
    {
      "source": "With extensive ablation studies",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8485
    },
    {
      "source": "With extensive ablation studies",
      "target": "3bcN6xlO6f",
      "similarity": 0.8478
    },
    {
      "source": "With extensive ablation studies",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8471
    },
    {
      "source": "With extensive ablation studies",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8452
    },
    {
      "source": "IZDiRbVSVN",
      "target": "JvkuZZ04O7",
      "similarity": 0.8535
    },
    {
      "source": "IZDiRbVSVN",
      "target": "To overcome these challenges",
      "similarity": 0.8454
    },
    {
      "source": "IZDiRbVSVN",
      "target": "yu1vqQqKkx",
      "similarity": 0.8449
    },
    {
      "source": "IZDiRbVSVN",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8423
    },
    {
      "source": "IZDiRbVSVN",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8403
    },
    {
      "source": "These datasets are typically massive",
      "target": "In this paper",
      "similarity": 0.8101
    },
    {
      "source": "These datasets are typically massive",
      "target": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "similarity": 0.8098
    },
    {
      "source": "These datasets are typically massive",
      "target": "a corresponding variational inference method utilizing a Weibull variational in-",
      "similarity": 0.8078
    },
    {
      "source": "These datasets are typically massive",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8056
    },
    {
      "source": "These datasets are typically massive",
      "target": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "similarity": 0.801
    },
    {
      "source": "However",
      "target": "prefix distributions",
      "similarity": 0.895
    },
    {
      "source": "However",
      "target": "cZWCjan02B",
      "similarity": 0.8897
    },
    {
      "source": "However",
      "target": "t9lS1lX9FQ",
      "similarity": 0.8893
    },
    {
      "source": "However",
      "target": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "similarity": 0.8793
    },
    {
      "source": "However",
      "target": "pre-training data",
      "similarity": 0.8785
    },
    {
      "source": "In this study",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8461
    },
    {
      "source": "In this study",
      "target": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "similarity": 0.8138
    },
    {
      "source": "In this study",
      "target": "i3T0wvQDKg",
      "similarity": 0.8107
    },
    {
      "source": "In this study",
      "target": "eIB1UZFcFg",
      "similarity": 0.81
    },
    {
      "source": "In this study",
      "target": "vjel3nWP2a",
      "similarity": 0.8076
    },
    {
      "source": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "target": "j8WHjM9aMm",
      "similarity": 0.8444
    },
    {
      "source": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "target": "FBhKUXK7od",
      "similarity": 0.8425
    },
    {
      "source": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8352
    },
    {
      "source": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "target": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "similarity": 0.8333
    },
    {
      "source": "Our approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.8237
    },
    {
      "source": "By contrasting the predictions of these two models",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.8231
    },
    {
      "source": "By contrasting the predictions of these two models",
      "target": "yQcFniousM",
      "similarity": 0.8076
    },
    {
      "source": "By contrasting the predictions of these two models",
      "target": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "similarity": 0.8037
    },
    {
      "source": "By contrasting the predictions of these two models",
      "target": "Our codebase",
      "similarity": 0.8017
    },
    {
      "source": "By contrasting the predictions of these two models",
      "target": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "similarity": 0.8012
    },
    {
      "source": "However",
      "target": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "similarity": 0.8907
    },
    {
      "source": "However",
      "target": "htDczodFN5",
      "similarity": 0.8876
    },
    {
      "source": "However",
      "target": "To this end",
      "similarity": 0.8787
    },
    {
      "source": "However",
      "target": "Through experiments across various datasets and settings",
      "similarity": 0.8776
    },
    {
      "source": "However",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8661
    },
    {
      "source": "We address this by introducing an iterative version of CGE",
      "target": "Jszf4et48m",
      "similarity": 0.8616
    },
    {
      "source": "We address this by introducing an iterative version of CGE",
      "target": "JAMxRSXLFz",
      "similarity": 0.8571
    },
    {
      "source": "We address this by introducing an iterative version of CGE",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8568
    },
    {
      "source": "We address this by introducing an iterative version of CGE",
      "target": "Further",
      "similarity": 0.8567
    },
    {
      "source": "We address this by introducing an iterative version of CGE",
      "target": "kbeX97jExm",
      "similarity": 0.8512
    },
    {
      "source": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "target": "j8WHjM9aMm",
      "similarity": 0.8367
    },
    {
      "source": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8334
    },
    {
      "source": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8008
    },
    {
      "source": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.8004
    },
    {
      "source": "Our experiments demonstrate the effectiveness of CGE in detecting novel domains",
      "target": "In this paper",
      "similarity": 0.7989
    },
    {
      "source": "Furthermore",
      "target": "S1Bv3068Xt",
      "similarity": 0.8525
    },
    {
      "source": "Furthermore",
      "target": "rTQNGQxm4K",
      "similarity": 0.8442
    },
    {
      "source": "Furthermore",
      "target": "HqjRlT65WX",
      "similarity": 0.8427
    },
    {
      "source": "Furthermore",
      "target": "In this paper",
      "similarity": 0.835
    },
    {
      "source": "Furthermore",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8322
    },
    {
      "source": "41uZB8bDFh",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8937
    },
    {
      "source": "41uZB8bDFh",
      "target": "SOTA LLMs",
      "similarity": 0.8779
    },
    {
      "source": "41uZB8bDFh",
      "target": "3bcN6xlO6f",
      "similarity": 0.8664
    },
    {
      "source": "41uZB8bDFh",
      "target": "Furthermore",
      "similarity": 0.8638
    },
    {
      "source": "41uZB8bDFh",
      "target": "1CIUkpoata",
      "similarity": 0.8629
    },
    {
      "source": "rdAbEn5DZt",
      "target": "xiQNfYl33p",
      "similarity": 0.9016
    },
    {
      "source": "rdAbEn5DZt",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8705
    },
    {
      "source": "rdAbEn5DZt",
      "target": "stacking methods. Specifically",
      "similarity": 0.8685
    },
    {
      "source": "rdAbEn5DZt",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8569
    },
    {
      "source": "rdAbEn5DZt",
      "target": "2mqb8bPHeb",
      "similarity": 0.8567
    },
    {
      "source": "t9lS1lX9FQ",
      "target": "cZWCjan02B",
      "similarity": 0.8917
    },
    {
      "source": "t9lS1lX9FQ",
      "target": "In addition",
      "similarity": 0.8788
    },
    {
      "source": "t9lS1lX9FQ",
      "target": "prefix distributions",
      "similarity": 0.8736
    },
    {
      "source": "t9lS1lX9FQ",
      "target": "yUC8pU508S",
      "similarity": 0.8729
    },
    {
      "source": "t9lS1lX9FQ",
      "target": "pre-training data",
      "similarity": 0.8696
    },
    {
      "source": "ZCOwwRAaEl",
      "target": "At its core",
      "similarity": 0.8026
    },
    {
      "source": "ZCOwwRAaEl",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.7944
    },
    {
      "source": "ZCOwwRAaEl",
      "target": "FEpAUnS7f7",
      "similarity": 0.7898
    },
    {
      "source": "ZCOwwRAaEl",
      "target": "PUnD86UEK5",
      "similarity": 0.7895
    },
    {
      "source": "ZCOwwRAaEl",
      "target": "FjZcwQJX8D",
      "similarity": 0.7876
    },
    {
      "source": "Recent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces.",
      "target": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "similarity": 0.8597
    },
    {
      "source": "Recent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces.",
      "target": "However",
      "similarity": 0.8146
    },
    {
      "source": "Recent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces.",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8145
    },
    {
      "source": "Recent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces.",
      "target": "MBBRHDuiwM",
      "similarity": 0.8126
    },
    {
      "source": "Recent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces.",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8105
    },
    {
      "source": "However",
      "target": "we demonstrate that our method achieves state-of-the-art decomposition",
      "similarity": 0.885
    },
    {
      "source": "However",
      "target": "MxbEiFRf39",
      "similarity": 0.8404
    },
    {
      "source": "However",
      "target": "5pd78GmXC6",
      "similarity": 0.84
    },
    {
      "source": "However",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8382
    },
    {
      "source": "However",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8346
    },
    {
      "source": "This value discrepancy problem propagates errors throughout the optimization process",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8252
    },
    {
      "source": "This value discrepancy problem propagates errors throughout the optimization process",
      "target": "wUtXB43Chi",
      "similarity": 0.8245
    },
    {
      "source": "This value discrepancy problem propagates errors throughout the optimization process",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8202
    },
    {
      "source": "This value discrepancy problem propagates errors throughout the optimization process",
      "target": "To overcome those challenges",
      "similarity": 0.8075
    },
    {
      "source": "This value discrepancy problem propagates errors throughout the optimization process",
      "target": "Existing safety constraints are then integrated into the COP",
      "similarity": 0.8071
    },
    {
      "source": "To address this issue",
      "target": "increased their demand. However",
      "similarity": 0.8958
    },
    {
      "source": "To address this issue",
      "target": "uncertainty estimation. Moreover",
      "similarity": 0.8884
    },
    {
      "source": "To address this issue",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8828
    },
    {
      "source": "To address this issue",
      "target": "cC3LxGZasH",
      "similarity": 0.8818
    },
    {
      "source": "To address this issue",
      "target": "4JK2XMGUc8",
      "similarity": 0.8712
    },
    {
      "source": "In addition",
      "target": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "similarity": 0.8808
    },
    {
      "source": "In addition",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8781
    },
    {
      "source": "In addition",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8711
    },
    {
      "source": "In addition",
      "target": "In this paper",
      "similarity": 0.8683
    },
    {
      "source": "In addition",
      "target": "FrFQpAgnGE",
      "similarity": 0.8664
    },
    {
      "source": "Through extensive experiments",
      "target": "ymt4crbbXh",
      "similarity": 0.8397
    },
    {
      "source": "Through extensive experiments",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8344
    },
    {
      "source": "Through extensive experiments",
      "target": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "similarity": 0.833
    },
    {
      "source": "Through extensive experiments",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8277
    },
    {
      "source": "Through extensive experiments",
      "target": "ajxAJ8GUX4",
      "similarity": 0.8267
    },
    {
      "source": "4FVGowGzQb",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8474
    },
    {
      "source": "4FVGowGzQb",
      "target": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "similarity": 0.8459
    },
    {
      "source": "4FVGowGzQb",
      "target": "To address these challenges",
      "similarity": 0.8444
    },
    {
      "source": "4FVGowGzQb",
      "target": "s9zoyICZ4k",
      "similarity": 0.8286
    },
    {
      "source": "4FVGowGzQb",
      "target": "uhaLuZcCjH",
      "similarity": 0.8214
    },
    {
      "source": "eLLBILFRsA",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8389
    },
    {
      "source": "eLLBILFRsA",
      "target": "9QPH1YQCMn",
      "similarity": 0.8282
    },
    {
      "source": "eLLBILFRsA",
      "target": "cfGpIcOIa5",
      "similarity": 0.8269
    },
    {
      "source": "eLLBILFRsA",
      "target": "JMPOqoe4tl",
      "similarity": 0.8238
    },
    {
      "source": "eLLBILFRsA",
      "target": "3ogIALgghF",
      "similarity": 0.8216
    },
    {
      "source": "Previous detoxification methods are typically model-specific",
      "target": "l0ZzTvPfTw",
      "similarity": 0.8177
    },
    {
      "source": "Previous detoxification methods are typically model-specific",
      "target": "K3KrOsR6y9",
      "similarity": 0.8146
    },
    {
      "source": "Previous detoxification methods are typically model-specific",
      "target": "q87GUkdQBm",
      "similarity": 0.8014
    },
    {
      "source": "Previous detoxification methods are typically model-specific",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.7921
    },
    {
      "source": "Previous detoxification methods are typically model-specific",
      "target": "To enrich long documents",
      "similarity": 0.7916
    },
    {
      "source": "In contrast",
      "target": "relying on backward propagation",
      "similarity": 0.8902
    },
    {
      "source": "In contrast",
      "target": "d7pr2doXn3",
      "similarity": 0.8864
    },
    {
      "source": "In contrast",
      "target": "9qS3HzSDNv",
      "similarity": 0.8741
    },
    {
      "source": "In contrast",
      "target": "VoayJihXra",
      "similarity": 0.867
    },
    {
      "source": "In contrast",
      "target": "For TP",
      "similarity": 0.8614
    },
    {
      "source": "Specifically",
      "target": "However",
      "similarity": 0.7833
    },
    {
      "source": "Specifically",
      "target": "2PRpcmJecX",
      "similarity": 0.7621
    },
    {
      "source": "Specifically",
      "target": "DelTA features a multi-level memory structure that stores information across various granularities and spans",
      "similarity": 0.761
    },
    {
      "source": "Specifically",
      "target": "goFpCuJalN",
      "similarity": 0.7564
    },
    {
      "source": "Specifically",
      "target": "In this work",
      "similarity": 0.7557
    },
    {
      "source": "This approach distills detoxifying representations in the form of synthetic text data",
      "target": "Real-world causal structures",
      "similarity": 0.8518
    },
    {
      "source": "This approach distills detoxifying representations in the form of synthetic text data",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8377
    },
    {
      "source": "This approach distills detoxifying representations in the form of synthetic text data",
      "target": "lOi6FtIwR8",
      "similarity": 0.8345
    },
    {
      "source": "This approach distills detoxifying representations in the form of synthetic text data",
      "target": "Ke2BEL4csm",
      "similarity": 0.8327
    },
    {
      "source": "This approach distills detoxifying representations in the form of synthetic text data",
      "target": "04qx93Viwj",
      "similarity": 0.8319
    },
    {
      "source": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "target": "r5IXBlTCGc",
      "similarity": 0.8402
    },
    {
      "source": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "target": "OuLgaHEmzi",
      "similarity": 0.8371
    },
    {
      "source": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "target": "rTQNGQxm4K",
      "similarity": 0.8351
    },
    {
      "source": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "target": "S1Bv3068Xt",
      "similarity": 0.8339
    },
    {
      "source": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8331
    },
    {
      "source": "Furthermore",
      "target": "NDLmZZWATc",
      "similarity": 0.9029
    },
    {
      "source": "Furthermore",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8991
    },
    {
      "source": "Furthermore",
      "target": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "similarity": 0.8892
    },
    {
      "source": "Furthermore",
      "target": "wHebuIb6IH",
      "similarity": 0.882
    },
    {
      "source": "Furthermore",
      "target": "1eQT9OzfNQ",
      "similarity": 0.871
    },
    {
      "source": "Additionally",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8326
    },
    {
      "source": "Additionally",
      "target": "Finally",
      "similarity": 0.8306
    },
    {
      "source": "Additionally",
      "target": "4JK2XMGUc8",
      "similarity": 0.8291
    },
    {
      "source": "Additionally",
      "target": "a wide variety of tasks and architectures. Through extensive experiments in",
      "similarity": 0.8263
    },
    {
      "source": "Additionally",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8241
    },
    {
      "source": "CjXaMI2kUH",
      "target": "PgXpOOqtyd",
      "similarity": 0.8775
    },
    {
      "source": "CjXaMI2kUH",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.8518
    },
    {
      "source": "CjXaMI2kUH",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8415
    },
    {
      "source": "CjXaMI2kUH",
      "target": "Iht4NNVqk0",
      "similarity": 0.8371
    },
    {
      "source": "CjXaMI2kUH",
      "target": "that we can output a $\\kappa$-approximation using space only",
      "similarity": 0.8273
    },
    {
      "source": "ReItdfwMcg",
      "target": "For example",
      "similarity": 0.8402
    },
    {
      "source": "ReItdfwMcg",
      "target": "Furthermore",
      "similarity": 0.8338
    },
    {
      "source": "ReItdfwMcg",
      "target": "kGvXIlIVLM",
      "similarity": 0.8328
    },
    {
      "source": "ReItdfwMcg",
      "target": "Usklli4gMc",
      "similarity": 0.8284
    },
    {
      "source": "ReItdfwMcg",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8256
    },
    {
      "source": "kuYxecnlv2",
      "target": "zY37C8d6bS",
      "similarity": 0.8044
    },
    {
      "source": "kuYxecnlv2",
      "target": "a corresponding variational inference method utilizing a Weibull variational in-",
      "similarity": 0.7828
    },
    {
      "source": "kuYxecnlv2",
      "target": "We then propose deep Fourier features",
      "similarity": 0.7795
    },
    {
      "source": "kuYxecnlv2",
      "target": "sb1HgVDLjN",
      "similarity": 0.7788
    },
    {
      "source": "kuYxecnlv2",
      "target": "Based on the training dynamics",
      "similarity": 0.7755
    },
    {
      "source": "To tackle this",
      "target": "MBBRHDuiwM",
      "similarity": 0.8588
    },
    {
      "source": "To tackle this",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8579
    },
    {
      "source": "To tackle this",
      "target": "ZJo6Radbqq",
      "similarity": 0.8564
    },
    {
      "source": "To tackle this",
      "target": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "similarity": 0.855
    },
    {
      "source": "To tackle this",
      "target": "Finally",
      "similarity": 0.8545
    },
    {
      "source": "In multi-node learning environments",
      "target": "LQzN6TRFg9",
      "similarity": 0.8315
    },
    {
      "source": "In multi-node learning environments",
      "target": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "similarity": 0.8252
    },
    {
      "source": "In multi-node learning environments",
      "target": "JYwVijuNA7",
      "similarity": 0.8151
    },
    {
      "source": "In multi-node learning environments",
      "target": "efficient and adaptable tool for advancing RNA structure prediction and analysis\"",
      "similarity": 0.8037
    },
    {
      "source": "In multi-node learning environments",
      "target": "6GATHdOi1x",
      "similarity": 0.803
    },
    {
      "source": "e5mTvjXG9u",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8424
    },
    {
      "source": "e5mTvjXG9u",
      "target": "R4h5PXzUuU",
      "similarity": 0.8212
    },
    {
      "source": "e5mTvjXG9u",
      "target": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "similarity": 0.8121
    },
    {
      "source": "e5mTvjXG9u",
      "target": "GhexuBLxbO",
      "similarity": 0.8119
    },
    {
      "source": "e5mTvjXG9u",
      "target": "streaming model",
      "similarity": 0.8052
    },
    {
      "source": "gQoBw7sGAu",
      "target": "UqrFPhcmFp",
      "similarity": 0.8323
    },
    {
      "source": "gQoBw7sGAu",
      "target": "jJXZvPe5z0",
      "similarity": 0.8313
    },
    {
      "source": "gQoBw7sGAu",
      "target": "YLIsIzC74j",
      "similarity": 0.8295
    },
    {
      "source": "gQoBw7sGAu",
      "target": "Finally",
      "similarity": 0.8193
    },
    {
      "source": "gQoBw7sGAu",
      "target": "To address these limitations",
      "similarity": 0.8187
    },
    {
      "source": "wmV4cIbgl6",
      "target": "GySIAKEwtZ",
      "similarity": 0.8555
    },
    {
      "source": "wmV4cIbgl6",
      "target": "27SSnLl85x",
      "similarity": 0.8366
    },
    {
      "source": "wmV4cIbgl6",
      "target": "bsFWJ0Kget",
      "similarity": 0.8364
    },
    {
      "source": "wmV4cIbgl6",
      "target": "aTYexOYlLb",
      "similarity": 0.836
    },
    {
      "source": "wmV4cIbgl6",
      "target": "Despite their importance",
      "similarity": 0.8359
    },
    {
      "source": "Despite this",
      "target": "U834XHJuqk",
      "similarity": 0.8489
    },
    {
      "source": "Despite this",
      "target": "Moreover",
      "similarity": 0.8432
    },
    {
      "source": "Despite this",
      "target": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "similarity": 0.8308
    },
    {
      "source": "Despite this",
      "target": "GeUK3zGreN",
      "similarity": 0.8302
    },
    {
      "source": "Despite this",
      "target": "03OkC0LKDD",
      "similarity": 0.8182
    },
    {
      "source": "Real-world causal structures",
      "target": "lOi6FtIwR8",
      "similarity": 0.8447
    },
    {
      "source": "Real-world causal structures",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8421
    },
    {
      "source": "Real-world causal structures",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8397
    },
    {
      "source": "Real-world causal structures",
      "target": "JbRM5QKRDd",
      "similarity": 0.838
    },
    {
      "source": "Real-world causal structures",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8302
    },
    {
      "source": "it hard to decide on a proper causal discovery strategy.",
      "target": "xjKz6IxgCX",
      "similarity": 0.8495
    },
    {
      "source": "it hard to decide on a proper causal discovery strategy.",
      "target": "uL1H29dM0c",
      "similarity": 0.8429
    },
    {
      "source": "it hard to decide on a proper causal discovery strategy.",
      "target": "K4FAFNRpko",
      "similarity": 0.8389
    },
    {
      "source": "it hard to decide on a proper causal discovery strategy.",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8318
    },
    {
      "source": "it hard to decide on a proper causal discovery strategy.",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.8292
    },
    {
      "source": "To bridge this gap",
      "target": "DsIOUoZkVk",
      "similarity": 0.8513
    },
    {
      "source": "To bridge this gap",
      "target": "Finally",
      "similarity": 0.8288
    },
    {
      "source": "To bridge this gap",
      "target": "JWtrk7mprJ",
      "similarity": 0.8241
    },
    {
      "source": "To bridge this gap",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8228
    },
    {
      "source": "To bridge this gap",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8189
    },
    {
      "source": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "target": "In this paper",
      "similarity": 0.8266
    },
    {
      "source": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "target": "To be precise",
      "similarity": 0.8242
    },
    {
      "source": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "target": "In this work",
      "similarity": 0.8206
    },
    {
      "source": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "target": "standard training and",
      "similarity": 0.8199
    },
    {
      "source": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "target": "uHLgDEgiS5",
      "similarity": 0.8179
    },
    {
      "source": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "target": "UL2",
      "similarity": 0.848
    },
    {
      "source": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8456
    },
    {
      "source": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8425
    },
    {
      "source": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8389
    },
    {
      "source": "It spans the years 2019 to 2023 with a 15-minute temporal resolution.",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8144
    },
    {
      "source": "Further",
      "target": "We propose RAMEN",
      "similarity": 0.8679
    },
    {
      "source": "Further",
      "target": "Q6PAnqYVpo",
      "similarity": 0.8162
    },
    {
      "source": "Further",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8158
    },
    {
      "source": "Further",
      "target": "For TP",
      "similarity": 0.8154
    },
    {
      "source": "Further",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8137
    },
    {
      "source": "Leveraging multiple sources of information and time-series meta-data",
      "target": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "similarity": 0.8657
    },
    {
      "source": "Leveraging multiple sources of information and time-series meta-data",
      "target": "Second",
      "similarity": 0.8603
    },
    {
      "source": "Leveraging multiple sources of information and time-series meta-data",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8556
    },
    {
      "source": "Leveraging multiple sources of information and time-series meta-data",
      "target": "5pd78GmXC6",
      "similarity": 0.8492
    },
    {
      "source": "Leveraging multiple sources of information and time-series meta-data",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8428
    },
    {
      "source": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "target": "ymt4crbbXh",
      "similarity": 0.8328
    },
    {
      "source": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "target": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "similarity": 0.8291
    },
    {
      "source": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8128
    },
    {
      "source": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "target": "xJXq6FkqEw",
      "similarity": 0.8123
    },
    {
      "source": "These graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.",
      "target": "ByCV9xWfNK",
      "similarity": 0.8123
    },
    {
      "source": "To demonstrate the utility of CausalRivers",
      "target": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "similarity": 0.8237
    },
    {
      "source": "To demonstrate the utility of CausalRivers",
      "target": "We evaluate nearly 40 reward models on RM-Bench.",
      "similarity": 0.815
    },
    {
      "source": "To demonstrate the utility of CausalRivers",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8075
    },
    {
      "source": "To demonstrate the utility of CausalRivers",
      "target": "Finally",
      "similarity": 0.8054
    },
    {
      "source": "To demonstrate the utility of CausalRivers",
      "target": "gFvRRCnQvX",
      "similarity": 0.8042
    },
    {
      "source": "CausalRivers has the potential to facilitate robust evaluations and comparisons of causal discovery methods.",
      "target": "At the inference stage",
      "similarity": 0.8138
    },
    {
      "source": "CausalRivers has the potential to facilitate robust evaluations and comparisons of causal discovery methods.",
      "target": "In experiments with GPT-4",
      "similarity": 0.8084
    },
    {
      "source": "CausalRivers has the potential to facilitate robust evaluations and comparisons of causal discovery methods.",
      "target": "zg3ec1TdAP",
      "similarity": 0.7866
    },
    {
      "source": "CausalRivers has the potential to facilitate robust evaluations and comparisons of causal discovery methods.",
      "target": "to fully understand the compositional properties of the human language",
      "similarity": 0.7793
    },
    {
      "source": "CausalRivers has the potential to facilitate robust evaluations and comparisons of causal discovery methods.",
      "target": "yR47RmND1m",
      "similarity": 0.7778
    },
    {
      "source": "Besides this primary purpose",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8711
    },
    {
      "source": "Besides this primary purpose",
      "target": "Despite theoretically sound",
      "similarity": 0.8584
    },
    {
      "source": "Besides this primary purpose",
      "target": "However",
      "similarity": 0.8539
    },
    {
      "source": "Besides this primary purpose",
      "target": "8vzMLo8LDN",
      "similarity": 0.8519
    },
    {
      "source": "Besides this primary purpose",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.845
    },
    {
      "source": "Based on this",
      "target": "Finally",
      "similarity": 0.8375
    },
    {
      "source": "Based on this",
      "target": "oYSsbY3G4o",
      "similarity": 0.8314
    },
    {
      "source": "Based on this",
      "target": "GtvuNrk58a",
      "similarity": 0.8267
    },
    {
      "source": "Based on this",
      "target": "FEpAUnS7f7",
      "similarity": 0.8143
    },
    {
      "source": "Based on this",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.8138
    },
    {
      "source": "L0evcuybH5",
      "target": "4JK2XMGUc8",
      "similarity": 0.8592
    },
    {
      "source": "L0evcuybH5",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8577
    },
    {
      "source": "L0evcuybH5",
      "target": "To address this issue",
      "similarity": 0.8502
    },
    {
      "source": "L0evcuybH5",
      "target": "gFvRRCnQvX",
      "similarity": 0.8436
    },
    {
      "source": "L0evcuybH5",
      "target": "Besides this primary purpose",
      "similarity": 0.8426
    },
    {
      "source": "v1B4aet9ct",
      "target": "fXb9BbuyAD",
      "similarity": 0.832
    },
    {
      "source": "v1B4aet9ct",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8259
    },
    {
      "source": "v1B4aet9ct",
      "target": "rCX9l4OTCT",
      "similarity": 0.8154
    },
    {
      "source": "v1B4aet9ct",
      "target": "uHLgDEgiS5",
      "similarity": 0.8147
    },
    {
      "source": "v1B4aet9ct",
      "target": "MBBRHDuiwM",
      "similarity": 0.8125
    },
    {
      "source": "additional structural constraints",
      "target": "We introduce a novel",
      "similarity": 0.8518
    },
    {
      "source": "additional structural constraints",
      "target": "71XtUhazG0",
      "similarity": 0.851
    },
    {
      "source": "additional structural constraints",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8382
    },
    {
      "source": "additional structural constraints",
      "target": "wmV4cIbgl6",
      "similarity": 0.8313
    },
    {
      "source": "additional structural constraints",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8296
    },
    {
      "source": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "target": "increased their demand. However",
      "similarity": 0.9215
    },
    {
      "source": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "target": "However",
      "similarity": 0.9026
    },
    {
      "source": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "target": "n4wcdct43X",
      "similarity": 0.8601
    },
    {
      "source": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "target": "Finally",
      "similarity": 0.8517
    },
    {
      "source": "sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.\"",
      "target": "To address this issue",
      "similarity": 0.8514
    },
    {
      "source": "q87GUkdQBm",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8245
    },
    {
      "source": "q87GUkdQBm",
      "target": "In parallel",
      "similarity": 0.8112
    },
    {
      "source": "q87GUkdQBm",
      "target": "gWgaypDBs8",
      "similarity": 0.8099
    },
    {
      "source": "q87GUkdQBm",
      "target": "TjP1d8PP8l",
      "similarity": 0.8091
    },
    {
      "source": "q87GUkdQBm",
      "target": "Despite its simplicity",
      "similarity": 0.8072
    },
    {
      "source": "I4iZmsV4HM",
      "target": "n7qGCmluZr",
      "similarity": 0.8184
    },
    {
      "source": "I4iZmsV4HM",
      "target": "depending on the similarity between samples to mix",
      "similarity": 0.807
    },
    {
      "source": "I4iZmsV4HM",
      "target": "Third",
      "similarity": 0.801
    },
    {
      "source": "I4iZmsV4HM",
      "target": "RyWypcIMiE",
      "similarity": 0.7996
    },
    {
      "source": "I4iZmsV4HM",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.7989
    },
    {
      "source": "CbpWPbYHuv",
      "target": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "similarity": 0.8233
    },
    {
      "source": "CbpWPbYHuv",
      "target": "First",
      "similarity": 0.7905
    },
    {
      "source": "CbpWPbYHuv",
      "target": "8bjspmAMBk",
      "similarity": 0.7875
    },
    {
      "source": "CbpWPbYHuv",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.7866
    },
    {
      "source": "CbpWPbYHuv",
      "target": "of the NTK",
      "similarity": 0.7837
    },
    {
      "source": "vqbd2OQnGp",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.812
    },
    {
      "source": "vqbd2OQnGp",
      "target": "space for $p > 1$",
      "similarity": 0.811
    },
    {
      "source": "vqbd2OQnGp",
      "target": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "similarity": 0.8102
    },
    {
      "source": "vqbd2OQnGp",
      "target": "Tv36j85SqR",
      "similarity": 0.8098
    },
    {
      "source": "vqbd2OQnGp",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8053
    },
    {
      "source": "RQz7szbVDs",
      "target": "44cMlQSreK",
      "similarity": 0.8554
    },
    {
      "source": "RQz7szbVDs",
      "target": "Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples.",
      "similarity": 0.8379
    },
    {
      "source": "RQz7szbVDs",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8212
    },
    {
      "source": "RQz7szbVDs",
      "target": "gFvRRCnQvX",
      "similarity": 0.8187
    },
    {
      "source": "RQz7szbVDs",
      "target": "Yk87CwhBDx",
      "similarity": 0.8168
    },
    {
      "source": "KlN00vQEY2",
      "target": "Aye5wL6TCn",
      "similarity": 0.8469
    },
    {
      "source": "KlN00vQEY2",
      "target": "5pd78GmXC6",
      "similarity": 0.8399
    },
    {
      "source": "KlN00vQEY2",
      "target": "Beyond performance evaluations",
      "similarity": 0.8387
    },
    {
      "source": "KlN00vQEY2",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8353
    },
    {
      "source": "KlN00vQEY2",
      "target": "kX8h23UG6v",
      "similarity": 0.8339
    },
    {
      "source": "mPdmDYIQ7f",
      "target": "Our codebase",
      "similarity": 0.8321
    },
    {
      "source": "mPdmDYIQ7f",
      "target": "j1tSLYKwg8",
      "similarity": 0.8316
    },
    {
      "source": "mPdmDYIQ7f",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8313
    },
    {
      "source": "mPdmDYIQ7f",
      "target": "Subsequently",
      "similarity": 0.83
    },
    {
      "source": "mPdmDYIQ7f",
      "target": "ssRdQimeUI",
      "similarity": 0.8293
    },
    {
      "source": "5Jc7r5aqHJ",
      "target": "x33vSZUg0A",
      "similarity": 0.8034
    },
    {
      "source": "5Jc7r5aqHJ",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8026
    },
    {
      "source": "5Jc7r5aqHJ",
      "target": "kOYnXVQCtA",
      "similarity": 0.8013
    },
    {
      "source": "5Jc7r5aqHJ",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.7941
    },
    {
      "source": "5Jc7r5aqHJ",
      "target": "without access to the source dataset. Empirical evaluations with various real-world",
      "similarity": 0.7935
    },
    {
      "source": "WEQL5ksDnB",
      "target": "a two-player game and propose a novel online algorithm",
      "similarity": 0.808
    },
    {
      "source": "WEQL5ksDnB",
      "target": "TrVYEZtSQH",
      "similarity": 0.7921
    },
    {
      "source": "WEQL5ksDnB",
      "target": "BPgK5XW1Nb",
      "similarity": 0.786
    },
    {
      "source": "WEQL5ksDnB",
      "target": "L238BAx0wP",
      "similarity": 0.7847
    },
    {
      "source": "WEQL5ksDnB",
      "target": "AUCYptvAf3",
      "similarity": 0.7813
    },
    {
      "source": "QaTBHSqmH9",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8876
    },
    {
      "source": "QaTBHSqmH9",
      "target": "stacking methods. Specifically",
      "similarity": 0.8422
    },
    {
      "source": "QaTBHSqmH9",
      "target": "l6QnSQizmN",
      "similarity": 0.8397
    },
    {
      "source": "QaTBHSqmH9",
      "target": "9KxnxWOBA5",
      "similarity": 0.8353
    },
    {
      "source": "QaTBHSqmH9",
      "target": "PHg4rAXFVH",
      "similarity": 0.834
    },
    {
      "source": "rCX9l4OTCT",
      "target": "TYSQYx9vwd",
      "similarity": 0.9047
    },
    {
      "source": "rCX9l4OTCT",
      "target": "MRAG-Bench consists of 16",
      "similarity": 0.8776
    },
    {
      "source": "rCX9l4OTCT",
      "target": "K4FAFNRpko",
      "similarity": 0.8687
    },
    {
      "source": "rCX9l4OTCT",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8661
    },
    {
      "source": "rCX9l4OTCT",
      "target": "uQnvYP7yX9",
      "similarity": 0.8607
    },
    {
      "source": "Y7slJZPGCy",
      "target": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "similarity": 0.8686
    },
    {
      "source": "Y7slJZPGCy",
      "target": "bilities",
      "similarity": 0.8648
    },
    {
      "source": "Y7slJZPGCy",
      "target": "1R5BcYS8EC",
      "similarity": 0.8634
    },
    {
      "source": "Y7slJZPGCy",
      "target": "a challenge",
      "similarity": 0.8575
    },
    {
      "source": "Y7slJZPGCy",
      "target": "wHebuIb6IH",
      "similarity": 0.8541
    },
    {
      "source": "pB1XSj2y4X",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8359
    },
    {
      "source": "pB1XSj2y4X",
      "target": "To address these limitations",
      "similarity": 0.8348
    },
    {
      "source": "pB1XSj2y4X",
      "target": "of natural language. However",
      "similarity": 0.8347
    },
    {
      "source": "pB1XSj2y4X",
      "target": "Furthermore",
      "similarity": 0.8316
    },
    {
      "source": "pB1XSj2y4X",
      "target": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "similarity": 0.8308
    },
    {
      "source": "9qS3HzSDNv",
      "target": "Furthermore",
      "similarity": 0.9255
    },
    {
      "source": "9qS3HzSDNv",
      "target": "relying on backward propagation",
      "similarity": 0.9201
    },
    {
      "source": "9qS3HzSDNv",
      "target": "d7pr2doXn3",
      "similarity": 0.896
    },
    {
      "source": "9qS3HzSDNv",
      "target": "xiQNfYl33p",
      "similarity": 0.8824
    },
    {
      "source": "9qS3HzSDNv",
      "target": "named Pacmann",
      "similarity": 0.8633
    },
    {
      "source": "xvhV3LvYTc",
      "target": "ing process to enhance the model\u2019s instruction-following",
      "similarity": 0.8788
    },
    {
      "source": "xvhV3LvYTc",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8706
    },
    {
      "source": "xvhV3LvYTc",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8652
    },
    {
      "source": "xvhV3LvYTc",
      "target": "Mjn53GtMxi",
      "similarity": 0.8644
    },
    {
      "source": "xvhV3LvYTc",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8587
    },
    {
      "source": "8WQ7VTfPTl",
      "target": "hlvLM3GX8R",
      "similarity": 0.8185
    },
    {
      "source": "8WQ7VTfPTl",
      "target": "GFgn2LprFR",
      "similarity": 0.8033
    },
    {
      "source": "8WQ7VTfPTl",
      "target": "kNHVViEPWK",
      "similarity": 0.8021
    },
    {
      "source": "8WQ7VTfPTl",
      "target": "k3tbMMW8rH",
      "similarity": 0.8017
    },
    {
      "source": "8WQ7VTfPTl",
      "target": "However",
      "similarity": 0.8005
    },
    {
      "source": "Nx4PMtJ1ER",
      "target": "two main areas of focus: skill retention and factual retention. While skill retention",
      "similarity": 0.8586
    },
    {
      "source": "Nx4PMtJ1ER",
      "target": "In addition",
      "similarity": 0.8509
    },
    {
      "source": "Nx4PMtJ1ER",
      "target": "SRpq5OBpED",
      "similarity": 0.8492
    },
    {
      "source": "Nx4PMtJ1ER",
      "target": "In this setting",
      "similarity": 0.8408
    },
    {
      "source": "Nx4PMtJ1ER",
      "target": "to address these failure modes",
      "similarity": 0.8326
    },
    {
      "source": "BZrSCv2SBq",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8057
    },
    {
      "source": "BZrSCv2SBq",
      "target": "DPzQ5n3mNm",
      "similarity": 0.8026
    },
    {
      "source": "BZrSCv2SBq",
      "target": "1CIUkpoata",
      "similarity": 0.7863
    },
    {
      "source": "BZrSCv2SBq",
      "target": "1NprT9Kz0d",
      "similarity": 0.7855
    },
    {
      "source": "BZrSCv2SBq",
      "target": "WwwJfkGq0G",
      "similarity": 0.7823
    },
    {
      "source": "In this paper",
      "target": "6VhDQP7WGX",
      "similarity": 0.9209
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8228
    },
    {
      "source": "In this paper",
      "target": "WttfQGwpES",
      "similarity": 0.8219
    },
    {
      "source": "In this paper",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8113
    },
    {
      "source": "In this paper",
      "target": "In experiments with GPT-4",
      "similarity": 0.8101
    },
    {
      "source": "3ygfMPLv0P",
      "target": "Real-world causal structures",
      "similarity": 0.8251
    },
    {
      "source": "3ygfMPLv0P",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.8213
    },
    {
      "source": "3ygfMPLv0P",
      "target": "y9A2TpaGsE",
      "similarity": 0.8078
    },
    {
      "source": "3ygfMPLv0P",
      "target": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "similarity": 0.8057
    },
    {
      "source": "3ygfMPLv0P",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8006
    },
    {
      "source": "Along with improved predictive performance",
      "target": "To offer practical insights",
      "similarity": 0.7732
    },
    {
      "source": "Along with improved predictive performance",
      "target": "97rOQDPmk2",
      "similarity": 0.7714
    },
    {
      "source": "Along with improved predictive performance",
      "target": "m8yby1JfbU",
      "similarity": 0.7637
    },
    {
      "source": "Along with improved predictive performance",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.7617
    },
    {
      "source": "Along with improved predictive performance",
      "target": "CL3U0GxFRD",
      "similarity": 0.7566
    },
    {
      "source": "However",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8084
    },
    {
      "source": "However",
      "target": "S85PP4xjFD",
      "similarity": 0.8049
    },
    {
      "source": "However",
      "target": "At its core",
      "similarity": 0.8042
    },
    {
      "source": "However",
      "target": "signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to",
      "similarity": 0.8034
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.8008
    },
    {
      "source": "In this work",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.7714
    },
    {
      "source": "In this work",
      "target": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "similarity": 0.7656
    },
    {
      "source": "In this work",
      "target": "uCqxDfLYrB",
      "similarity": 0.7637
    },
    {
      "source": "To this end",
      "target": "ud8FtE1N4N",
      "similarity": 0.8452
    },
    {
      "source": "To this end",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8405
    },
    {
      "source": "To this end",
      "target": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "similarity": 0.8233
    },
    {
      "source": "To this end",
      "target": "md9qolJwLl",
      "similarity": 0.8115
    },
    {
      "source": "To this end",
      "target": "3usdM1AuI3",
      "similarity": 0.8105
    },
    {
      "source": "depending on the similarity between samples to mix",
      "target": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "similarity": 0.8237
    },
    {
      "source": "depending on the similarity between samples to mix",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8166
    },
    {
      "source": "depending on the similarity between samples to mix",
      "target": "However",
      "similarity": 0.8153
    },
    {
      "source": "depending on the similarity between samples to mix",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8143
    },
    {
      "source": "depending on the similarity between samples to mix",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8141
    },
    {
      "source": "and calibration of models",
      "target": "Mjn53GtMxi",
      "similarity": 0.817
    },
    {
      "source": "and calibration of models",
      "target": "Finally",
      "similarity": 0.8058
    },
    {
      "source": "and calibration of models",
      "target": "UL2",
      "similarity": 0.8015
    },
    {
      "source": "and calibration of models",
      "target": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "similarity": 0.7968
    },
    {
      "source": "and calibration of models",
      "target": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "similarity": 0.7964
    },
    {
      "source": "ANBuEJesgx",
      "target": "A1HhtITVEi",
      "similarity": 0.8558
    },
    {
      "source": "ANBuEJesgx",
      "target": "First",
      "similarity": 0.8508
    },
    {
      "source": "ANBuEJesgx",
      "target": "hoYFLRNbhc",
      "similarity": 0.8399
    },
    {
      "source": "ANBuEJesgx",
      "target": "9KiE3t6CsL",
      "similarity": 0.8384
    },
    {
      "source": "ANBuEJesgx",
      "target": "sion method",
      "similarity": 0.838
    },
    {
      "source": "owP2mymrTD",
      "target": "bEqI61iBue",
      "similarity": 0.8531
    },
    {
      "source": "owP2mymrTD",
      "target": "5pd78GmXC6",
      "similarity": 0.839
    },
    {
      "source": "owP2mymrTD",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8379
    },
    {
      "source": "owP2mymrTD",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8361
    },
    {
      "source": "owP2mymrTD",
      "target": "Consequently",
      "similarity": 0.8357
    },
    {
      "source": "xjKz6IxgCX",
      "target": "uL1H29dM0c",
      "similarity": 0.854
    },
    {
      "source": "xjKz6IxgCX",
      "target": "UYcUpiULmT",
      "similarity": 0.8517
    },
    {
      "source": "xjKz6IxgCX",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8467
    },
    {
      "source": "xjKz6IxgCX",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8459
    },
    {
      "source": "xjKz6IxgCX",
      "target": "K4FAFNRpko",
      "similarity": 0.8435
    },
    {
      "source": "NvDRvtrGLo",
      "target": "INow59Vurm",
      "similarity": 0.8945
    },
    {
      "source": "NvDRvtrGLo",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8918
    },
    {
      "source": "NvDRvtrGLo",
      "target": "avSocG0oFA",
      "similarity": 0.8893
    },
    {
      "source": "NvDRvtrGLo",
      "target": "3Z2flzXzBY",
      "similarity": 0.8683
    },
    {
      "source": "NvDRvtrGLo",
      "target": "design algorithms which use space much less than the entire stream",
      "similarity": 0.8648
    },
    {
      "source": "0oWGVvC6oq",
      "target": "cmfyMV45XO",
      "similarity": 0.8695
    },
    {
      "source": "0oWGVvC6oq",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8457
    },
    {
      "source": "0oWGVvC6oq",
      "target": "Antib6Uovh",
      "similarity": 0.84
    },
    {
      "source": "0oWGVvC6oq",
      "target": "6F6qwdycgJ",
      "similarity": 0.8376
    },
    {
      "source": "0oWGVvC6oq",
      "target": "To enable TTA for regression",
      "similarity": 0.8282
    },
    {
      "source": "MyVC4X5B2X",
      "target": "Ultimately",
      "similarity": 0.8789
    },
    {
      "source": "MyVC4X5B2X",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8771
    },
    {
      "source": "MyVC4X5B2X",
      "target": "Es4RPNDtmq",
      "similarity": 0.8658
    },
    {
      "source": "MyVC4X5B2X",
      "target": "However",
      "similarity": 0.8643
    },
    {
      "source": "MyVC4X5B2X",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8611
    },
    {
      "source": "ofuLWn8DFZ",
      "target": "Furthermore",
      "similarity": 0.8221
    },
    {
      "source": "ofuLWn8DFZ",
      "target": "HqjRlT65WX",
      "similarity": 0.8215
    },
    {
      "source": "ofuLWn8DFZ",
      "target": "Furthermore",
      "similarity": 0.8168
    },
    {
      "source": "ofuLWn8DFZ",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8121
    },
    {
      "source": "ofuLWn8DFZ",
      "target": "On an average of 6 diverse tasks",
      "similarity": 0.8119
    },
    {
      "source": "1yJP5TVWih",
      "target": "To remedy this problem",
      "similarity": 0.8771
    },
    {
      "source": "1yJP5TVWih",
      "target": "m8yby1JfbU",
      "similarity": 0.8486
    },
    {
      "source": "1yJP5TVWih",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.847
    },
    {
      "source": "1yJP5TVWih",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8461
    },
    {
      "source": "1yJP5TVWih",
      "target": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "similarity": 0.838
    },
    {
      "source": "rapidly converge to a uniform token or equilibrium state",
      "target": "However",
      "similarity": 0.87
    },
    {
      "source": "rapidly converge to a uniform token or equilibrium state",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8378
    },
    {
      "source": "rapidly converge to a uniform token or equilibrium state",
      "target": "Other methods have focused on the low-budget regime",
      "similarity": 0.8335
    },
    {
      "source": "rapidly converge to a uniform token or equilibrium state",
      "target": "Second",
      "similarity": 0.8294
    },
    {
      "source": "rapidly converge to a uniform token or equilibrium state",
      "target": "E2PFv7ad3p",
      "similarity": 0.826
    },
    {
      "source": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8391
    },
    {
      "source": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8238
    },
    {
      "source": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "target": "an objective which generalizes a variety of low- and high-budget objectives",
      "similarity": 0.8206
    },
    {
      "source": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "target": "1VwWi6zbxs",
      "similarity": 0.8198
    },
    {
      "source": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "target": "uMEsKEiB7J",
      "similarity": 0.8139
    },
    {
      "source": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.8613
    },
    {
      "source": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "target": "This paper introduces WebRL",
      "similarity": 0.8438
    },
    {
      "source": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "target": "04qx93Viwj",
      "similarity": 0.8418
    },
    {
      "source": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "target": "1NprT9Kz0d",
      "similarity": 0.8415
    },
    {
      "source": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "target": "owP2mymrTD",
      "similarity": 0.8341
    },
    {
      "source": "idence suggests that architectural components like skip connections",
      "target": "FhTAG591Ve",
      "similarity": 0.8311
    },
    {
      "source": "idence suggests that architectural components like skip connections",
      "target": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "similarity": 0.8097
    },
    {
      "source": "idence suggests that architectural components like skip connections",
      "target": "In this paper",
      "similarity": 0.809
    },
    {
      "source": "idence suggests that architectural components like skip connections",
      "target": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "similarity": 0.798
    },
    {
      "source": "idence suggests that architectural components like skip connections",
      "target": "JMPOqoe4tl",
      "similarity": 0.7966
    },
    {
      "source": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "target": "PY56Wur7S0",
      "similarity": 0.8207
    },
    {
      "source": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "target": "1Z6PSw7OL8",
      "similarity": 0.8142
    },
    {
      "source": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8053
    },
    {
      "source": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "target": "m73tETvFkX",
      "similarity": 0.8029
    },
    {
      "source": "and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.",
      "target": "rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard",
      "similarity": 0.8011
    },
    {
      "source": "While this issue is well-documented for transformers",
      "target": "q5EZ7gKcnW",
      "similarity": 0.8509
    },
    {
      "source": "While this issue is well-documented for transformers",
      "target": "kOJf7Dklyv",
      "similarity": 0.8488
    },
    {
      "source": "While this issue is well-documented for transformers",
      "target": "However",
      "similarity": 0.8473
    },
    {
      "source": "While this issue is well-documented for transformers",
      "target": "upper bound of LLMs' generalization capabilities.",
      "similarity": 0.8209
    },
    {
      "source": "While this issue is well-documented for transformers",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8184
    },
    {
      "source": "els",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8358
    },
    {
      "source": "els",
      "target": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "similarity": 0.833
    },
    {
      "source": "els",
      "target": "resource",
      "similarity": 0.8166
    },
    {
      "source": "els",
      "target": "Finally",
      "similarity": 0.8113
    },
    {
      "source": "els",
      "target": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "similarity": 0.7925
    },
    {
      "source": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "target": "wide dissemination",
      "similarity": 0.8717
    },
    {
      "source": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "target": "QowsEic1sc",
      "similarity": 0.8687
    },
    {
      "source": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "target": "VoayJihXra",
      "similarity": 0.8657
    },
    {
      "source": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "target": "JAMxRSXLFz",
      "similarity": 0.8619
    },
    {
      "source": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "target": "9qS3HzSDNv",
      "similarity": 0.8609
    },
    {
      "source": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.827
    },
    {
      "source": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "target": "As model size increases",
      "similarity": 0.8082
    },
    {
      "source": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "target": "contextual interactions among tasks",
      "similarity": 0.805
    },
    {
      "source": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8039
    },
    {
      "source": "the theory of rank collapse from transformers to SSMs using a unifying frame-",
      "target": "9qpdDiDQ2H",
      "similarity": 0.8031
    },
    {
      "source": "work that captures both architectures. We introduce a modification in the skip",
      "target": "Finally",
      "similarity": 0.832
    },
    {
      "source": "work that captures both architectures. We introduce a modification in the skip",
      "target": "i7jAYFYDcM",
      "similarity": 0.8293
    },
    {
      "source": "work that captures both architectures. We introduce a modification in the skip",
      "target": "OL44KtasKc",
      "similarity": 0.8289
    },
    {
      "source": "work that captures both architectures. We introduce a modification in the skip",
      "target": "2pNLknCTvG",
      "similarity": 0.823
    },
    {
      "source": "work that captures both architectures. We introduce a modification in the skip",
      "target": "xzSUdw6s76",
      "similarity": 0.821
    },
    {
      "source": "connection component",
      "target": "In this work",
      "similarity": 0.8252
    },
    {
      "source": "connection component",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8221
    },
    {
      "source": "connection component",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8179
    },
    {
      "source": "connection component",
      "target": "Wf2ndb8nhf",
      "similarity": 0.813
    },
    {
      "source": "connection component",
      "target": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "similarity": 0.8126
    },
    {
      "source": "tees for rank collapse prevention. We present",
      "target": "6wOmHdwCC4",
      "similarity": 0.8361
    },
    {
      "source": "tees for rank collapse prevention. We present",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8314
    },
    {
      "source": "tees for rank collapse prevention. We present",
      "target": "KlN00vQEY2",
      "similarity": 0.8242
    },
    {
      "source": "tees for rank collapse prevention. We present",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8241
    },
    {
      "source": "tees for rank collapse prevention. We present",
      "target": "In this paper",
      "similarity": 0.823
    },
    {
      "source": "condition to achieve the guarantee for all of the aforementioned architectures. We",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8396
    },
    {
      "source": "condition to achieve the guarantee for all of the aforementioned architectures. We",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8219
    },
    {
      "source": "condition to achieve the guarantee for all of the aforementioned architectures. We",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.8094
    },
    {
      "source": "condition to achieve the guarantee for all of the aforementioned architectures. We",
      "target": "TvGPP8i18S",
      "similarity": 0.8073
    },
    {
      "source": "condition to achieve the guarantee for all of the aforementioned architectures. We",
      "target": "YcUV5apdlq",
      "similarity": 0.7984
    },
    {
      "source": "also study the necessity of this condition via ablation studies and analytical exam-",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.8516
    },
    {
      "source": "also study the necessity of this condition via ablation studies and analytical exam-",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8435
    },
    {
      "source": "also study the necessity of this condition via ablation studies and analytical exam-",
      "target": "dEg5SdGaiq",
      "similarity": 0.8402
    },
    {
      "source": "also study the necessity of this condition via ablation studies and analytical exam-",
      "target": "Key insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU",
      "similarity": 0.8393
    },
    {
      "source": "also study the necessity of this condition via ablation studies and analytical exam-",
      "target": "hovDbX4Gh6",
      "similarity": 0.8351
    },
    {
      "source": "ples. To our knowledge",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8622
    },
    {
      "source": "ples. To our knowledge",
      "target": "wide dissemination",
      "similarity": 0.8585
    },
    {
      "source": "ples. To our knowledge",
      "target": "VmJdqhuTCh",
      "similarity": 0.8549
    },
    {
      "source": "ples. To our knowledge",
      "target": "tePFpDgyqg",
      "similarity": 0.851
    },
    {
      "source": "ples. To our knowledge",
      "target": "This paper proposes",
      "similarity": 0.8491
    },
    {
      "source": "prevent rank collapse",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.8701
    },
    {
      "source": "prevent rank collapse",
      "target": "Moreover",
      "similarity": 0.8254
    },
    {
      "source": "prevent rank collapse",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8139
    },
    {
      "source": "prevent rank collapse",
      "target": "traditional energy-based models",
      "similarity": 0.8075
    },
    {
      "source": "prevent rank collapse",
      "target": "Following these principles",
      "similarity": 0.8061
    },
    {
      "source": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "target": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "similarity": 0.8285
    },
    {
      "source": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8279
    },
    {
      "source": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8269
    },
    {
      "source": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "target": "approach that efficiently selects the most influential neuron at each layer trying to discover the crucial neuron path from input to output within the target model.",
      "similarity": 0.8161
    },
    {
      "source": "offering valuable understanding for both theoreticians and practitioners. Finally",
      "target": "aN57tSd5Us",
      "similarity": 0.8131
    },
    {
      "source": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "target": "aXwukBD6M6",
      "similarity": 0.8933
    },
    {
      "source": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8771
    },
    {
      "source": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "target": "DzbUL4AJPP",
      "similarity": 0.8534
    },
    {
      "source": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "target": "Pnk7vMbznK",
      "similarity": 0.8325
    },
    {
      "source": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8319
    },
    {
      "source": "tectural components in preventing rank collapse.\"",
      "target": "Consequently",
      "similarity": 0.8344
    },
    {
      "source": "tectural components in preventing rank collapse.\"",
      "target": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "similarity": 0.8335
    },
    {
      "source": "tectural components in preventing rank collapse.\"",
      "target": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "similarity": 0.8335
    },
    {
      "source": "tectural components in preventing rank collapse.\"",
      "target": "owP2mymrTD",
      "similarity": 0.8316
    },
    {
      "source": "tectural components in preventing rank collapse.\"",
      "target": "WwwJfkGq0G",
      "similarity": 0.8256
    },
    {
      "source": "cADpvQgnqg",
      "target": "In the more general context",
      "similarity": 0.9142
    },
    {
      "source": "cADpvQgnqg",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8689
    },
    {
      "source": "cADpvQgnqg",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8657
    },
    {
      "source": "cADpvQgnqg",
      "target": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "similarity": 0.8594
    },
    {
      "source": "cADpvQgnqg",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.858
    },
    {
      "source": "71XtUhazG0",
      "target": "ScVnYBaSEw",
      "similarity": 0.8634
    },
    {
      "source": "71XtUhazG0",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8316
    },
    {
      "source": "71XtUhazG0",
      "target": "27SSnLl85x",
      "similarity": 0.8284
    },
    {
      "source": "71XtUhazG0",
      "target": "qn9tBYQHGi",
      "similarity": 0.8274
    },
    {
      "source": "71XtUhazG0",
      "target": "UIFAJZ22ZF",
      "similarity": 0.8227
    },
    {
      "source": "https://github.com/Yuliang-Liu/Monkey.\"",
      "target": "nzjSvVZBIp",
      "similarity": 0.8885
    },
    {
      "source": "https://github.com/Yuliang-Liu/Monkey.\"",
      "target": "WttfQGwpES",
      "similarity": 0.8545
    },
    {
      "source": "https://github.com/Yuliang-Liu/Monkey.\"",
      "target": "On various mathematical benchmarks",
      "similarity": 0.8497
    },
    {
      "source": "https://github.com/Yuliang-Liu/Monkey.\"",
      "target": "fuoM5YDBX4",
      "similarity": 0.8458
    },
    {
      "source": "https://github.com/Yuliang-Liu/Monkey.\"",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8439
    },
    {
      "source": "4ktJJBvvUd",
      "target": "To this end",
      "similarity": 0.8748
    },
    {
      "source": "4ktJJBvvUd",
      "target": "FrFQpAgnGE",
      "similarity": 0.8726
    },
    {
      "source": "4ktJJBvvUd",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8652
    },
    {
      "source": "4ktJJBvvUd",
      "target": "WCRQFlji2q",
      "similarity": 0.8645
    },
    {
      "source": "4ktJJBvvUd",
      "target": "Here",
      "similarity": 0.8642
    },
    {
      "source": "2zmO1GVT0Y",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8583
    },
    {
      "source": "2zmO1GVT0Y",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8526
    },
    {
      "source": "2zmO1GVT0Y",
      "target": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "similarity": 0.8504
    },
    {
      "source": "2zmO1GVT0Y",
      "target": "gcouwCx7dG",
      "similarity": 0.8476
    },
    {
      "source": "2zmO1GVT0Y",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8448
    },
    {
      "source": "tXUkT709OJ",
      "target": "yLhJYvkKA0",
      "similarity": 0.8986
    },
    {
      "source": "tXUkT709OJ",
      "target": "nDTvP6tBMd",
      "similarity": 0.8584
    },
    {
      "source": "tXUkT709OJ",
      "target": "{Subsequently}",
      "similarity": 0.8536
    },
    {
      "source": "tXUkT709OJ",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8481
    },
    {
      "source": "tXUkT709OJ",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8479
    },
    {
      "source": "6DHIkLv5i3",
      "target": "gcouwCx7dG",
      "similarity": 0.8136
    },
    {
      "source": "6DHIkLv5i3",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.8059
    },
    {
      "source": "6DHIkLv5i3",
      "target": "samples. However",
      "similarity": 0.8037
    },
    {
      "source": "6DHIkLv5i3",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.8021
    },
    {
      "source": "6DHIkLv5i3",
      "target": "bRa4JLPzii",
      "similarity": 0.8012
    },
    {
      "source": "LO4MEPoqrG",
      "target": "Yk87CwhBDx",
      "similarity": 0.8439
    },
    {
      "source": "LO4MEPoqrG",
      "target": "4O0v4s3IzY",
      "similarity": 0.84
    },
    {
      "source": "LO4MEPoqrG",
      "target": "Finally",
      "similarity": 0.8391
    },
    {
      "source": "LO4MEPoqrG",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8386
    },
    {
      "source": "LO4MEPoqrG",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8383
    },
    {
      "source": "8vzMLo8LDN",
      "target": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "similarity": 0.8657
    },
    {
      "source": "8vzMLo8LDN",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8442
    },
    {
      "source": "8vzMLo8LDN",
      "target": "FtjLUHyZAO",
      "similarity": 0.8438
    },
    {
      "source": "8vzMLo8LDN",
      "target": "L0evcuybH5",
      "similarity": 0.8422
    },
    {
      "source": "8vzMLo8LDN",
      "target": "Despite theoretically sound",
      "similarity": 0.8402
    },
    {
      "source": "f7KxfUrRSb",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8486
    },
    {
      "source": "f7KxfUrRSb",
      "target": "bNVbOS3lrl",
      "similarity": 0.8465
    },
    {
      "source": "f7KxfUrRSb",
      "target": "We have prepared an efficient implementation",
      "similarity": 0.8373
    },
    {
      "source": "f7KxfUrRSb",
      "target": "YFxfcQMLWX",
      "similarity": 0.8368
    },
    {
      "source": "f7KxfUrRSb",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8341
    },
    {
      "source": "semTHoVGsJ",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8674
    },
    {
      "source": "semTHoVGsJ",
      "target": "To overcome those challenges",
      "similarity": 0.867
    },
    {
      "source": "semTHoVGsJ",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8622
    },
    {
      "source": "semTHoVGsJ",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.8595
    },
    {
      "source": "semTHoVGsJ",
      "target": "To tackle this challenge",
      "similarity": 0.8542
    },
    {
      "source": "This work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context;",
      "target": "To overcome these limitations",
      "similarity": 0.8505
    },
    {
      "source": "This work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context;",
      "target": "R4q3cY3kQf",
      "similarity": 0.8451
    },
    {
      "source": "This work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context;",
      "target": "TWnUgSAWNw",
      "similarity": 0.8355
    },
    {
      "source": "This work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context;",
      "target": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "similarity": 0.8321
    },
    {
      "source": "This work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context;",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8293
    },
    {
      "source": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "target": "Moreover",
      "similarity": 0.84
    },
    {
      "source": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "target": "than prior private ANN schemes",
      "similarity": 0.8387
    },
    {
      "source": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "target": "cPD2hU35x3",
      "similarity": 0.8354
    },
    {
      "source": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "target": "8y5Uf6oEiB",
      "similarity": 0.8302
    },
    {
      "source": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8271
    },
    {
      "source": "We leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models.",
      "target": "S4dItvpvAv",
      "similarity": 0.8369
    },
    {
      "source": "We leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models.",
      "target": "oVKEAFjEqv",
      "similarity": 0.8121
    },
    {
      "source": "We leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models.",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.8098
    },
    {
      "source": "We leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models.",
      "target": "which",
      "similarity": 0.7916
    },
    {
      "source": "We leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models.",
      "target": "VELhv9BBfn",
      "similarity": 0.7868
    },
    {
      "source": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "target": "To this end",
      "similarity": 0.8761
    },
    {
      "source": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "target": "In this paper",
      "similarity": 0.8718
    },
    {
      "source": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.861
    },
    {
      "source": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8606
    },
    {
      "source": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "target": "pDDODPtpx9",
      "similarity": 0.8599
    },
    {
      "source": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "target": "RWJX5F5I9g",
      "similarity": 0.8354
    },
    {
      "source": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "target": "pRCOZllZdT",
      "similarity": 0.8306
    },
    {
      "source": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "target": "For example",
      "similarity": 0.8232
    },
    {
      "source": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "target": "In parallel",
      "similarity": 0.8214
    },
    {
      "source": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "target": "v1rFkElnIn",
      "similarity": 0.8201
    },
    {
      "source": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "target": "k2uUeLCrQq",
      "similarity": 0.8231
    },
    {
      "source": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "target": "nzjSvVZBIp",
      "similarity": 0.8118
    },
    {
      "source": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "target": "LLaMA-3-8B-based SFT model",
      "similarity": 0.8087
    },
    {
      "source": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "target": "space for $p > 1$",
      "similarity": 0.8067
    },
    {
      "source": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "target": "Yet",
      "similarity": 0.8041
    },
    {
      "source": "We further speculate on why LLaMA's kernel width and shape differs from classical algorithms",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.825
    },
    {
      "source": "We further speculate on why LLaMA's kernel width and shape differs from classical algorithms",
      "target": "n2NidsYDop",
      "similarity": 0.8198
    },
    {
      "source": "We further speculate on why LLaMA's kernel width and shape differs from classical algorithms",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.8131
    },
    {
      "source": "We further speculate on why LLaMA's kernel width and shape differs from classical algorithms",
      "target": "THqWPzL00e",
      "similarity": 0.8122
    },
    {
      "source": "We further speculate on why LLaMA's kernel width and shape differs from classical algorithms",
      "target": "DpLFmc09pC",
      "similarity": 0.8119
    },
    {
      "source": "Our codebase",
      "target": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "similarity": 0.8663
    },
    {
      "source": "Our codebase",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8543
    },
    {
      "source": "Our codebase",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8399
    },
    {
      "source": "Our codebase",
      "target": "Our experiments demonstrate that LongPackis highly scalable",
      "similarity": 0.8292
    },
    {
      "source": "Our codebase",
      "target": "FCBbh0HCrF",
      "similarity": 0.8263
    },
    {
      "source": "v7YrIjpkTF",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.8305
    },
    {
      "source": "v7YrIjpkTF",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.8288
    },
    {
      "source": "v7YrIjpkTF",
      "target": "wNobG8bV5Q",
      "similarity": 0.8265
    },
    {
      "source": "v7YrIjpkTF",
      "target": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "similarity": 0.8154
    },
    {
      "source": "v7YrIjpkTF",
      "target": "Our main result is that poisoning only 0.1% of a model's pre-training dataset is sufficient for three out of four attacks to measurably persist through post-training. Moreover",
      "similarity": 0.8139
    },
    {
      "source": "Most existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.8114
    },
    {
      "source": "Most existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However",
      "target": "FEpAUnS7f7",
      "similarity": 0.7975
    },
    {
      "source": "Most existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However",
      "target": "In this paper",
      "similarity": 0.7901
    },
    {
      "source": "Most existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However",
      "target": "paradigms show promise",
      "similarity": 0.7847
    },
    {
      "source": "Most existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However",
      "target": "TtKN1TpvUu",
      "similarity": 0.7814
    },
    {
      "source": "1qgZXeMTTU",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.89
    },
    {
      "source": "1qgZXeMTTU",
      "target": "nCrJD7qPJN",
      "similarity": 0.8553
    },
    {
      "source": "1qgZXeMTTU",
      "target": "SOTA LLMs",
      "similarity": 0.8548
    },
    {
      "source": "1qgZXeMTTU",
      "target": "lOi6FtIwR8",
      "similarity": 0.8493
    },
    {
      "source": "1qgZXeMTTU",
      "target": "254NJe9JEw",
      "similarity": 0.8478
    },
    {
      "source": "ehr4oTe6XI",
      "target": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "similarity": 0.8071
    },
    {
      "source": "ehr4oTe6XI",
      "target": "uuriavczkL",
      "similarity": 0.8026
    },
    {
      "source": "ehr4oTe6XI",
      "target": "works leads to a multifaceted problem",
      "similarity": 0.8014
    },
    {
      "source": "ehr4oTe6XI",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.7979
    },
    {
      "source": "ehr4oTe6XI",
      "target": "In particular",
      "similarity": 0.7974
    },
    {
      "source": "6wOmHdwCC4",
      "target": "P6IVIoGRRg",
      "similarity": 0.8429
    },
    {
      "source": "6wOmHdwCC4",
      "target": "For scenarios with constant label distribution",
      "similarity": 0.8391
    },
    {
      "source": "6wOmHdwCC4",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.836
    },
    {
      "source": "6wOmHdwCC4",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8289
    },
    {
      "source": "6wOmHdwCC4",
      "target": "VVixJ9QavY",
      "similarity": 0.8273
    },
    {
      "source": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "target": "propose to cache and reuse KV state of prompts. However",
      "similarity": 0.8441
    },
    {
      "source": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "target": "a length of $d$.",
      "similarity": 0.8217
    },
    {
      "source": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8161
    },
    {
      "source": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.816
    },
    {
      "source": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "target": "To address this",
      "similarity": 0.8159
    },
    {
      "source": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "target": "To overcome such limitations",
      "similarity": 0.826
    },
    {
      "source": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8255
    },
    {
      "source": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "target": "kxnoqaisCT",
      "similarity": 0.8133
    },
    {
      "source": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "target": "Yet",
      "similarity": 0.8075
    },
    {
      "source": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "target": "The framework automates the generation of query-response pairs using predefined rules",
      "similarity": 0.8065
    },
    {
      "source": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "target": "LWMS4pk2vK",
      "similarity": 0.8105
    },
    {
      "source": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.802
    },
    {
      "source": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8018
    },
    {
      "source": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "target": "However",
      "similarity": 0.7977
    },
    {
      "source": "Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided context optimization methods and achieves superior performance in three challenging benchmarks. We make our code available at https://github.com/cnunlp/DeKg.\"",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.7944
    },
    {
      "source": "A1HhtITVEi",
      "target": "TlAdgeoDTo",
      "similarity": 0.8979
    },
    {
      "source": "A1HhtITVEi",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8852
    },
    {
      "source": "A1HhtITVEi",
      "target": "First",
      "similarity": 0.8699
    },
    {
      "source": "A1HhtITVEi",
      "target": "9KiE3t6CsL",
      "similarity": 0.8668
    },
    {
      "source": "A1HhtITVEi",
      "target": "WCRQFlji2q",
      "similarity": 0.8638
    },
    {
      "source": "RoN6M3i7gJ",
      "target": "2U8owdruSQ",
      "similarity": 0.8248
    },
    {
      "source": "RoN6M3i7gJ",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8244
    },
    {
      "source": "RoN6M3i7gJ",
      "target": "AjXkRZIvjB",
      "similarity": 0.8115
    },
    {
      "source": "RoN6M3i7gJ",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8106
    },
    {
      "source": "RoN6M3i7gJ",
      "target": "JbRM5QKRDd",
      "similarity": 0.8079
    },
    {
      "source": "We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior.",
      "target": "upoxXRRTQ2",
      "similarity": 0.8284
    },
    {
      "source": "We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior.",
      "target": "Ij9ilPh36h",
      "similarity": 0.8207
    },
    {
      "source": "We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior.",
      "target": "Although this approach simplifies data acquisition compared to supervised methods",
      "similarity": 0.8127
    },
    {
      "source": "We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior.",
      "target": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "similarity": 0.807
    },
    {
      "source": "We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior.",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8037
    },
    {
      "source": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "target": "TYSQYx9vwd",
      "similarity": 0.8225
    },
    {
      "source": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "target": "tijmpS9Vy2",
      "similarity": 0.8212
    },
    {
      "source": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "target": "K4FAFNRpko",
      "similarity": 0.8168
    },
    {
      "source": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8143
    },
    {
      "source": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "target": "mXHTifc1Fn",
      "similarity": 0.8068
    },
    {
      "source": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "target": "odU59TxdiB",
      "similarity": 0.9315
    },
    {
      "source": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "target": "Overall",
      "similarity": 0.9164
    },
    {
      "source": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.9082
    },
    {
      "source": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "target": "in a vector database",
      "similarity": 0.9055
    },
    {
      "source": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.9014
    },
    {
      "source": "VQwI055flA",
      "target": "To this end",
      "similarity": 0.8867
    },
    {
      "source": "VQwI055flA",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8859
    },
    {
      "source": "VQwI055flA",
      "target": "Furthermore",
      "similarity": 0.8774
    },
    {
      "source": "VQwI055flA",
      "target": "2mqb8bPHeb",
      "similarity": 0.8759
    },
    {
      "source": "VQwI055flA",
      "target": "FrFQpAgnGE",
      "similarity": 0.8755
    },
    {
      "source": "fpvgSDKXGY",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8016
    },
    {
      "source": "fpvgSDKXGY",
      "target": "Finally",
      "similarity": 0.7908
    },
    {
      "source": "fpvgSDKXGY",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.7907
    },
    {
      "source": "fpvgSDKXGY",
      "target": "5btFIv2PNb",
      "similarity": 0.783
    },
    {
      "source": "fpvgSDKXGY",
      "target": "Sd4wYYOhmY",
      "similarity": 0.782
    },
    {
      "source": "WttfQGwpES",
      "target": "6VhDQP7WGX",
      "similarity": 0.8466
    },
    {
      "source": "WttfQGwpES",
      "target": "In the images pruning benchmark",
      "similarity": 0.8441
    },
    {
      "source": "WttfQGwpES",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8362
    },
    {
      "source": "WttfQGwpES",
      "target": "nzjSvVZBIp",
      "similarity": 0.8337
    },
    {
      "source": "WttfQGwpES",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8299
    },
    {
      "source": "icDoYdUhRa",
      "target": "FCBbh0HCrF",
      "similarity": 0.8175
    },
    {
      "source": "icDoYdUhRa",
      "target": "Pj06mxCXPl",
      "similarity": 0.811
    },
    {
      "source": "icDoYdUhRa",
      "target": "no longer requiring computationally-intensive cryptographic techniques.",
      "similarity": 0.8106
    },
    {
      "source": "icDoYdUhRa",
      "target": "SG1R2H3fa1",
      "similarity": 0.7944
    },
    {
      "source": "icDoYdUhRa",
      "target": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "similarity": 0.7941
    },
    {
      "source": "VVixJ9QavY",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8363
    },
    {
      "source": "VVixJ9QavY",
      "target": "while reducing the average number of activated experts by up to 9%.",
      "similarity": 0.8342
    },
    {
      "source": "VVixJ9QavY",
      "target": "In this paper",
      "similarity": 0.8342
    },
    {
      "source": "VVixJ9QavY",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8335
    },
    {
      "source": "VVixJ9QavY",
      "target": "P6IVIoGRRg",
      "similarity": 0.8295
    },
    {
      "source": "uOb7rij7sR",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8172
    },
    {
      "source": "uOb7rij7sR",
      "target": "9qpdDiDQ2H",
      "similarity": 0.8148
    },
    {
      "source": "uOb7rij7sR",
      "target": "upper bound of LLMs' generalization capabilities.",
      "similarity": 0.8117
    },
    {
      "source": "uOb7rij7sR",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8108
    },
    {
      "source": "uOb7rij7sR",
      "target": "Next",
      "similarity": 0.81
    },
    {
      "source": "SuHScQv5gP",
      "target": "DL9txImSzm",
      "similarity": 0.8239
    },
    {
      "source": "SuHScQv5gP",
      "target": "Specifically",
      "similarity": 0.8187
    },
    {
      "source": "SuHScQv5gP",
      "target": "hzuumhfYSO",
      "similarity": 0.8132
    },
    {
      "source": "SuHScQv5gP",
      "target": "FZv3kPHTtB",
      "similarity": 0.8076
    },
    {
      "source": "SuHScQv5gP",
      "target": "BUj9VSCoET",
      "similarity": 0.8062
    },
    {
      "source": "TmCcNuo03f",
      "target": "UqrFPhcmFp",
      "similarity": 0.8269
    },
    {
      "source": "TmCcNuo03f",
      "target": "To address this",
      "similarity": 0.8261
    },
    {
      "source": "TmCcNuo03f",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8229
    },
    {
      "source": "TmCcNuo03f",
      "target": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "similarity": 0.8212
    },
    {
      "source": "TmCcNuo03f",
      "target": "vue9P1Ypk6",
      "similarity": 0.816
    },
    {
      "source": "pq1WUegkza",
      "target": "jTEKTdI3K9",
      "similarity": 0.9042
    },
    {
      "source": "pq1WUegkza",
      "target": "For example",
      "similarity": 0.873
    },
    {
      "source": "pq1WUegkza",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8691
    },
    {
      "source": "pq1WUegkza",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8634
    },
    {
      "source": "pq1WUegkza",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8584
    },
    {
      "source": "K4FAFNRpko",
      "target": "suz4utPr9Y",
      "similarity": 0.869
    },
    {
      "source": "K4FAFNRpko",
      "target": "8TERgu1Lb2",
      "similarity": 0.8672
    },
    {
      "source": "K4FAFNRpko",
      "target": "TYSQYx9vwd",
      "similarity": 0.8667
    },
    {
      "source": "K4FAFNRpko",
      "target": "uL1H29dM0c",
      "similarity": 0.8664
    },
    {
      "source": "K4FAFNRpko",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8584
    },
    {
      "source": "ff2V3UR9sC",
      "target": "p4cLtzk4oe",
      "similarity": 0.8993
    },
    {
      "source": "ff2V3UR9sC",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8604
    },
    {
      "source": "ff2V3UR9sC",
      "target": "254NJe9JEw",
      "similarity": 0.8576
    },
    {
      "source": "ff2V3UR9sC",
      "target": "zCZnEXF3bN",
      "similarity": 0.8567
    },
    {
      "source": "ff2V3UR9sC",
      "target": "Based on the observations",
      "similarity": 0.855
    },
    {
      "source": "sahQq2sH5x",
      "target": "tePFpDgyqg",
      "similarity": 0.859
    },
    {
      "source": "sahQq2sH5x",
      "target": "semTHoVGsJ",
      "similarity": 0.8481
    },
    {
      "source": "sahQq2sH5x",
      "target": "wide dissemination",
      "similarity": 0.8415
    },
    {
      "source": "sahQq2sH5x",
      "target": "fN8yLc3eA7",
      "similarity": 0.8411
    },
    {
      "source": "sahQq2sH5x",
      "target": "population shifts. In particular",
      "similarity": 0.8407
    },
    {
      "source": "mun3bGqdDM",
      "target": "while reducing the average number of activated experts by up to 9%.",
      "similarity": 0.8302
    },
    {
      "source": "mun3bGqdDM",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8081
    },
    {
      "source": "mun3bGqdDM",
      "target": "leading proprietary models (e.g.",
      "similarity": 0.798
    },
    {
      "source": "mun3bGqdDM",
      "target": "We conducted a comprehensive regret analysis of our proposed framework",
      "similarity": 0.7966
    },
    {
      "source": "mun3bGqdDM",
      "target": "vWRwdmA3wU",
      "similarity": 0.7933
    },
    {
      "source": "In this paper",
      "target": "Recent works have used Bayesian meta learning to view the problem of posterior estimation as a supervised learning task.",
      "similarity": 0.782
    },
    {
      "source": "In this paper",
      "target": "Pnk7vMbznK",
      "similarity": 0.779
    },
    {
      "source": "In this paper",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.7661
    },
    {
      "source": "In this paper",
      "target": "w7P92BEsb2",
      "similarity": 0.7649
    },
    {
      "source": "In this paper",
      "target": "ogXkmugNZw",
      "similarity": 0.7594
    },
    {
      "source": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "target": "TDy5Ih78b4",
      "similarity": 0.878
    },
    {
      "source": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8734
    },
    {
      "source": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "target": "pre-training data",
      "similarity": 0.8678
    },
    {
      "source": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "target": "yUC8pU508S",
      "similarity": 0.8665
    },
    {
      "source": "Atomas's end-to-end training framework supports understanding and generating molecules",
      "target": "t9lS1lX9FQ",
      "similarity": 0.8636
    },
    {
      "source": "pZiyCaVuti",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8874
    },
    {
      "source": "pZiyCaVuti",
      "target": "74vnDs1R97",
      "similarity": 0.8763
    },
    {
      "source": "pZiyCaVuti",
      "target": "1vrpdV9U3i",
      "similarity": 0.8761
    },
    {
      "source": "pZiyCaVuti",
      "target": "https://github.com/mint-vu/MCNC.\"",
      "similarity": 0.8683
    },
    {
      "source": "pZiyCaVuti",
      "target": "4O0v4s3IzY",
      "similarity": 0.8641
    },
    {
      "source": "o2Igqm95SJ",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8209
    },
    {
      "source": "o2Igqm95SJ",
      "target": "ogXkmugNZw",
      "similarity": 0.8118
    },
    {
      "source": "o2Igqm95SJ",
      "target": "K3KrOsR6y9",
      "similarity": 0.8101
    },
    {
      "source": "o2Igqm95SJ",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8059
    },
    {
      "source": "o2Igqm95SJ",
      "target": "WWXjMYZxfH",
      "similarity": 0.8059
    },
    {
      "source": "JTji0Jfh5a",
      "target": "1Z6PSw7OL8",
      "similarity": 0.8734
    },
    {
      "source": "JTji0Jfh5a",
      "target": "which",
      "similarity": 0.8202
    },
    {
      "source": "JTji0Jfh5a",
      "target": "CjXaMI2kUH",
      "similarity": 0.8175
    },
    {
      "source": "JTji0Jfh5a",
      "target": "Building on these insights",
      "similarity": 0.8138
    },
    {
      "source": "JTji0Jfh5a",
      "target": "Iht4NNVqk0",
      "similarity": 0.8044
    },
    {
      "source": "In this setting",
      "target": "E4LAVLXAHW",
      "similarity": 0.8691
    },
    {
      "source": "In this setting",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8625
    },
    {
      "source": "In this setting",
      "target": "AcVpLS86RT",
      "similarity": 0.8594
    },
    {
      "source": "In this setting",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8559
    },
    {
      "source": "In this setting",
      "target": "the lack of data for language-guided 3D scene editing",
      "similarity": 0.8555
    },
    {
      "source": "(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories;",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8503
    },
    {
      "source": "(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories;",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8465
    },
    {
      "source": "(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories;",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8402
    },
    {
      "source": "(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories;",
      "target": "Finally",
      "similarity": 0.8344
    },
    {
      "source": "(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories;",
      "target": "Moreover",
      "similarity": 0.833
    },
    {
      "source": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "target": "d23EVDRJ6g",
      "similarity": 0.841
    },
    {
      "source": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.838
    },
    {
      "source": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8344
    },
    {
      "source": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8333
    },
    {
      "source": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "target": "1yJP5TVWih",
      "similarity": 0.828
    },
    {
      "source": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "target": "cPD2hU35x3",
      "similarity": 0.8617
    },
    {
      "source": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "target": "HqjRlT65WX",
      "similarity": 0.8524
    },
    {
      "source": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8459
    },
    {
      "source": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8386
    },
    {
      "source": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "target": "zY37C8d6bS",
      "similarity": 0.8373
    },
    {
      "source": "We experimentally validate our proposition on a variety of tasks (Atari games and autonomous driving on highway). On the one hand",
      "target": "1Njl73JKjB",
      "similarity": 0.8349
    },
    {
      "source": "We experimentally validate our proposition on a variety of tasks (Atari games and autonomous driving on highway). On the one hand",
      "target": "where its drift term can leverage prior physics knowledge as inductive bias.",
      "similarity": 0.817
    },
    {
      "source": "We experimentally validate our proposition on a variety of tasks (Atari games and autonomous driving on highway). On the one hand",
      "target": "0e2pcSxQJS",
      "similarity": 0.8142
    },
    {
      "source": "We experimentally validate our proposition on a variety of tasks (Atari games and autonomous driving on highway). On the one hand",
      "target": "T4sMzjy7fO",
      "similarity": 0.8136
    },
    {
      "source": "We experimentally validate our proposition on a variety of tasks (Atari games and autonomous driving on highway). On the one hand",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8082
    },
    {
      "source": "7nyJBVCTGQ",
      "target": "INow59Vurm",
      "similarity": 0.879
    },
    {
      "source": "7nyJBVCTGQ",
      "target": "avSocG0oFA",
      "similarity": 0.872
    },
    {
      "source": "7nyJBVCTGQ",
      "target": "RC5FPYVQaH",
      "similarity": 0.8684
    },
    {
      "source": "7nyJBVCTGQ",
      "target": "In this paper",
      "similarity": 0.8611
    },
    {
      "source": "7nyJBVCTGQ",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8563
    },
    {
      "source": "XxCgeWSTNp",
      "target": "EQgEMAD4kv",
      "similarity": 0.8649
    },
    {
      "source": "XxCgeWSTNp",
      "target": "90DC0IvlSs",
      "similarity": 0.8563
    },
    {
      "source": "XxCgeWSTNp",
      "target": "to address these failure modes",
      "similarity": 0.8561
    },
    {
      "source": "XxCgeWSTNp",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8558
    },
    {
      "source": "XxCgeWSTNp",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.8518
    },
    {
      "source": "NfCEVihkdC",
      "target": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "similarity": 0.9021
    },
    {
      "source": "NfCEVihkdC",
      "target": "In this work",
      "similarity": 0.8283
    },
    {
      "source": "NfCEVihkdC",
      "target": "From this perspective",
      "similarity": 0.8113
    },
    {
      "source": "NfCEVihkdC",
      "target": "connection component",
      "similarity": 0.8113
    },
    {
      "source": "NfCEVihkdC",
      "target": "vjel3nWP2a",
      "similarity": 0.8106
    },
    {
      "source": "VGURexnlUL",
      "target": "LSp4KBhAom",
      "similarity": 0.8211
    },
    {
      "source": "VGURexnlUL",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8187
    },
    {
      "source": "VGURexnlUL",
      "target": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "similarity": 0.8178
    },
    {
      "source": "VGURexnlUL",
      "target": "Through task arithmetic",
      "similarity": 0.7961
    },
    {
      "source": "VGURexnlUL",
      "target": "eb5pkwIB5i",
      "similarity": 0.7957
    },
    {
      "source": "HZVIQE1MsJ",
      "target": "are effective at curbing memorization",
      "similarity": 0.8399
    },
    {
      "source": "HZVIQE1MsJ",
      "target": "Based on the hypothesis that applying multiple LoRAs could lead to \"\"semantic conflicts\"\"",
      "similarity": 0.8201
    },
    {
      "source": "HZVIQE1MsJ",
      "target": "Stick-breaking also performs well at length generalisation",
      "similarity": 0.8133
    },
    {
      "source": "HZVIQE1MsJ",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8119
    },
    {
      "source": "HZVIQE1MsJ",
      "target": "nibeaHUEJx",
      "similarity": 0.8117
    },
    {
      "source": "BL4WBIfyrz",
      "target": "riieAeQBJm",
      "similarity": 0.9045
    },
    {
      "source": "BL4WBIfyrz",
      "target": "Further",
      "similarity": 0.8906
    },
    {
      "source": "BL4WBIfyrz",
      "target": "We found that long distance referrals",
      "similarity": 0.8759
    },
    {
      "source": "BL4WBIfyrz",
      "target": "9EqQC2ct4H",
      "similarity": 0.8608
    },
    {
      "source": "BL4WBIfyrz",
      "target": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "similarity": 0.8577
    },
    {
      "source": "gkUyYcY1W9",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8565
    },
    {
      "source": "gkUyYcY1W9",
      "target": "Furthermore",
      "similarity": 0.8315
    },
    {
      "source": "gkUyYcY1W9",
      "target": "e8qXTxMgPg",
      "similarity": 0.8311
    },
    {
      "source": "gkUyYcY1W9",
      "target": "TtKN1TpvUu",
      "similarity": 0.8293
    },
    {
      "source": "gkUyYcY1W9",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8291
    },
    {
      "source": "1Ogw1SHY3p",
      "target": "VMV8gefvq8",
      "similarity": 0.8024
    },
    {
      "source": "1Ogw1SHY3p",
      "target": "Under these assumptions",
      "similarity": 0.8021
    },
    {
      "source": "1Ogw1SHY3p",
      "target": "mobile devices.\"",
      "similarity": 0.8013
    },
    {
      "source": "1Ogw1SHY3p",
      "target": "TvGPP8i18S",
      "similarity": 0.796
    },
    {
      "source": "1Ogw1SHY3p",
      "target": "To explore this",
      "similarity": 0.7959
    },
    {
      "source": "gjRhw5S3A4",
      "target": "FBhKUXK7od",
      "similarity": 0.804
    },
    {
      "source": "gjRhw5S3A4",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8006
    },
    {
      "source": "gjRhw5S3A4",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.7999
    },
    {
      "source": "gjRhw5S3A4",
      "target": "In particular",
      "similarity": 0.799
    },
    {
      "source": "gjRhw5S3A4",
      "target": "Furthermore",
      "similarity": 0.7957
    },
    {
      "source": "C45YqeBDUM",
      "target": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "similarity": 0.864
    },
    {
      "source": "C45YqeBDUM",
      "target": "70B-base from 8K to 128K tokens",
      "similarity": 0.8517
    },
    {
      "source": "C45YqeBDUM",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8513
    },
    {
      "source": "C45YqeBDUM",
      "target": "LrmPGtnros",
      "similarity": 0.8467
    },
    {
      "source": "C45YqeBDUM",
      "target": "bBoetBIN2R",
      "similarity": 0.8466
    },
    {
      "source": "INow59Vurm",
      "target": "3Z2flzXzBY",
      "similarity": 0.888
    },
    {
      "source": "INow59Vurm",
      "target": "avSocG0oFA",
      "similarity": 0.8736
    },
    {
      "source": "INow59Vurm",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8653
    },
    {
      "source": "INow59Vurm",
      "target": "design algorithms which use space much less than the entire stream",
      "similarity": 0.864
    },
    {
      "source": "INow59Vurm",
      "target": "KnoS9XxIlK",
      "similarity": 0.8576
    },
    {
      "source": "d7pr2doXn3",
      "target": "relying on backward propagation",
      "similarity": 0.8946
    },
    {
      "source": "d7pr2doXn3",
      "target": "Furthermore",
      "similarity": 0.8898
    },
    {
      "source": "d7pr2doXn3",
      "target": "fN8yLc3eA7",
      "similarity": 0.8692
    },
    {
      "source": "d7pr2doXn3",
      "target": "models. However",
      "similarity": 0.8557
    },
    {
      "source": "d7pr2doXn3",
      "target": "INow59Vurm",
      "similarity": 0.8525
    },
    {
      "source": "k2uUeLCrQq",
      "target": "dTkqaCKLPp",
      "similarity": 0.831
    },
    {
      "source": "k2uUeLCrQq",
      "target": "ed7zI29lRF",
      "similarity": 0.8305
    },
    {
      "source": "k2uUeLCrQq",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8246
    },
    {
      "source": "k2uUeLCrQq",
      "target": "7YKV7zkNpX",
      "similarity": 0.8233
    },
    {
      "source": "k2uUeLCrQq",
      "target": "LLaMA-3-8B-based SFT model",
      "similarity": 0.8201
    },
    {
      "source": "1tBvzOYTLF",
      "target": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "similarity": 0.8521
    },
    {
      "source": "1tBvzOYTLF",
      "target": "wgDB1QuxIA",
      "similarity": 0.8279
    },
    {
      "source": "1tBvzOYTLF",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8254
    },
    {
      "source": "1tBvzOYTLF",
      "target": "Moreover",
      "similarity": 0.8235
    },
    {
      "source": "1tBvzOYTLF",
      "target": "However",
      "similarity": 0.8182
    },
    {
      "source": "aXwukBD6M6",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8869
    },
    {
      "source": "aXwukBD6M6",
      "target": "fifXzmzeGy",
      "similarity": 0.8858
    },
    {
      "source": "aXwukBD6M6",
      "target": "DzbUL4AJPP",
      "similarity": 0.8838
    },
    {
      "source": "aXwukBD6M6",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8793
    },
    {
      "source": "aXwukBD6M6",
      "target": "Pnk7vMbznK",
      "similarity": 0.8637
    },
    {
      "source": "20qZK2T7fa",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8705
    },
    {
      "source": "20qZK2T7fa",
      "target": "To enrich long documents",
      "similarity": 0.8682
    },
    {
      "source": "20qZK2T7fa",
      "target": "ogXkmugNZw",
      "similarity": 0.8495
    },
    {
      "source": "20qZK2T7fa",
      "target": "jDsmB4o5S0",
      "similarity": 0.8429
    },
    {
      "source": "20qZK2T7fa",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8428
    },
    {
      "source": "F57HPKZ6KD",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8764
    },
    {
      "source": "F57HPKZ6KD",
      "target": "Overall",
      "similarity": 0.8734
    },
    {
      "source": "F57HPKZ6KD",
      "target": "VvDEuyVXkG",
      "similarity": 0.8709
    },
    {
      "source": "F57HPKZ6KD",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8706
    },
    {
      "source": "F57HPKZ6KD",
      "target": "WCRQFlji2q",
      "similarity": 0.8665
    },
    {
      "source": "Many neural combinatorial optimization (NCO) methods have been proposed to solve CO problems.",
      "target": "Second",
      "similarity": 0.849
    },
    {
      "source": "Many neural combinatorial optimization (NCO) methods have been proposed to solve CO problems.",
      "target": "kRBQwlkFSP",
      "similarity": 0.8375
    },
    {
      "source": "Many neural combinatorial optimization (NCO) methods have been proposed to solve CO problems.",
      "target": "MxbEiFRf39",
      "similarity": 0.8224
    },
    {
      "source": "Many neural combinatorial optimization (NCO) methods have been proposed to solve CO problems.",
      "target": "We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior",
      "similarity": 0.8217
    },
    {
      "source": "Many neural combinatorial optimization (NCO) methods have been proposed to solve CO problems.",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8197
    },
    {
      "source": "However",
      "target": "gFvRRCnQvX",
      "similarity": 0.8324
    },
    {
      "source": "However",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.8234
    },
    {
      "source": "However",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8221
    },
    {
      "source": "However",
      "target": "In real-world scenarios",
      "similarity": 0.8211
    },
    {
      "source": "However",
      "target": "In light of this",
      "similarity": 0.8175
    },
    {
      "source": "To address these issues",
      "target": "tu3qwNjrtw",
      "similarity": 0.8853
    },
    {
      "source": "To address these issues",
      "target": "Despite theoretically sound",
      "similarity": 0.8743
    },
    {
      "source": "To address these issues",
      "target": "To tackle this problem",
      "similarity": 0.8732
    },
    {
      "source": "To address these issues",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8601
    },
    {
      "source": "To address these issues",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8533
    },
    {
      "source": "We then leverage a popular data compression technique",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8322
    },
    {
      "source": "We then leverage a popular data compression technique",
      "target": "Along with SketikZ",
      "similarity": 0.8239
    },
    {
      "source": "We then leverage a popular data compression technique",
      "target": "However",
      "similarity": 0.8229
    },
    {
      "source": "We then leverage a popular data compression technique",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8224
    },
    {
      "source": "We then leverage a popular data compression technique",
      "target": "L0evcuybH5",
      "similarity": 0.8184
    },
    {
      "source": "However",
      "target": "stacking methods. Specifically",
      "similarity": 0.8591
    },
    {
      "source": "However",
      "target": "In contrast",
      "similarity": 0.855
    },
    {
      "source": "However",
      "target": "generative process is partially-ordered following the CGM structure. This",
      "similarity": 0.8308
    },
    {
      "source": "However",
      "target": "In addition",
      "similarity": 0.829
    },
    {
      "source": "However",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8262
    },
    {
      "source": "Further",
      "target": "We found that long distance referrals",
      "similarity": 0.8879
    },
    {
      "source": "Further",
      "target": "riieAeQBJm",
      "similarity": 0.8864
    },
    {
      "source": "Further",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8651
    },
    {
      "source": "Further",
      "target": "IuU0wcO0mo",
      "similarity": 0.861
    },
    {
      "source": "Further",
      "target": "ww3CLRhF1v",
      "similarity": 0.8592
    },
    {
      "source": "{Subsequently}",
      "target": "fNMKqyvuZT",
      "similarity": 0.9018
    },
    {
      "source": "{Subsequently}",
      "target": "yLhJYvkKA0",
      "similarity": 0.8865
    },
    {
      "source": "{Subsequently}",
      "target": "4GT9uTsAJE",
      "similarity": 0.8862
    },
    {
      "source": "{Subsequently}",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8821
    },
    {
      "source": "{Subsequently}",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8813
    },
    {
      "source": "Finally",
      "target": "Bpn8q40n1n",
      "similarity": 0.8797
    },
    {
      "source": "Finally",
      "target": "yUC8pU508S",
      "similarity": 0.8394
    },
    {
      "source": "Finally",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8372
    },
    {
      "source": "Finally",
      "target": "TtKN1TpvUu",
      "similarity": 0.829
    },
    {
      "source": "Finally",
      "target": "UL2",
      "similarity": 0.8278
    },
    {
      "source": "IjbXZdugdj",
      "target": "kRBQwlkFSP",
      "similarity": 0.843
    },
    {
      "source": "IjbXZdugdj",
      "target": "MxbEiFRf39",
      "similarity": 0.8395
    },
    {
      "source": "IjbXZdugdj",
      "target": "on manually crafted video tutorials",
      "similarity": 0.8308
    },
    {
      "source": "IjbXZdugdj",
      "target": "Second",
      "similarity": 0.8225
    },
    {
      "source": "IjbXZdugdj",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.811
    },
    {
      "source": "AcVpLS86RT",
      "target": "instructions",
      "similarity": 0.898
    },
    {
      "source": "AcVpLS86RT",
      "target": "IDJUscOjM3",
      "similarity": 0.8806
    },
    {
      "source": "AcVpLS86RT",
      "target": "YFxfcQMLWX",
      "similarity": 0.8742
    },
    {
      "source": "AcVpLS86RT",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8709
    },
    {
      "source": "AcVpLS86RT",
      "target": "3E8YNv1HjU",
      "similarity": 0.8663
    },
    {
      "source": "bwOndfohRK",
      "target": "EDoD3DgivF",
      "similarity": 0.8003
    },
    {
      "source": "bwOndfohRK",
      "target": "In this work",
      "similarity": 0.7873
    },
    {
      "source": "bwOndfohRK",
      "target": "(VLM) to generate and answer a set of validation questions to verify the generated",
      "similarity": 0.781
    },
    {
      "source": "bwOndfohRK",
      "target": "To investigate this",
      "similarity": 0.7735
    },
    {
      "source": "bwOndfohRK",
      "target": "goFpCuJalN",
      "similarity": 0.7659
    },
    {
      "source": "Fu0aggezN9",
      "target": "In this paper",
      "similarity": 0.8175
    },
    {
      "source": "Fu0aggezN9",
      "target": "41WIgfdd5o",
      "similarity": 0.8162
    },
    {
      "source": "Fu0aggezN9",
      "target": "DpLFmc09pC",
      "similarity": 0.8118
    },
    {
      "source": "Fu0aggezN9",
      "target": "ScVnYBaSEw",
      "similarity": 0.8086
    },
    {
      "source": "Fu0aggezN9",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8034
    },
    {
      "source": "S85PP4xjFD",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8542
    },
    {
      "source": "S85PP4xjFD",
      "target": "uL1H29dM0c",
      "similarity": 0.8522
    },
    {
      "source": "S85PP4xjFD",
      "target": "To tackle this challenge",
      "similarity": 0.8501
    },
    {
      "source": "S85PP4xjFD",
      "target": "9D2QvO1uWj",
      "similarity": 0.8406
    },
    {
      "source": "S85PP4xjFD",
      "target": "rCX9l4OTCT",
      "similarity": 0.8336
    },
    {
      "source": "q1UyoY3MgJ",
      "target": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "similarity": 0.9032
    },
    {
      "source": "q1UyoY3MgJ",
      "target": "2mqb8bPHeb",
      "similarity": 0.893
    },
    {
      "source": "q1UyoY3MgJ",
      "target": "stacking methods. Specifically",
      "similarity": 0.8858
    },
    {
      "source": "q1UyoY3MgJ",
      "target": "xiQNfYl33p",
      "similarity": 0.8789
    },
    {
      "source": "q1UyoY3MgJ",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8618
    },
    {
      "source": "TVQLu34bdw",
      "target": "However",
      "similarity": 0.8676
    },
    {
      "source": "TVQLu34bdw",
      "target": "pDDODPtpx9",
      "similarity": 0.8618
    },
    {
      "source": "TVQLu34bdw",
      "target": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "similarity": 0.8581
    },
    {
      "source": "TVQLu34bdw",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8545
    },
    {
      "source": "TVQLu34bdw",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.854
    },
    {
      "source": "wUtXB43Chi",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8762
    },
    {
      "source": "wUtXB43Chi",
      "target": "p4cLtzk4oe",
      "similarity": 0.8689
    },
    {
      "source": "wUtXB43Chi",
      "target": "U3PBITXNG6",
      "similarity": 0.8606
    },
    {
      "source": "wUtXB43Chi",
      "target": "Qja5s0K3VX",
      "similarity": 0.8606
    },
    {
      "source": "wUtXB43Chi",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8553
    },
    {
      "source": "T7bmHkwzS6",
      "target": "bc2H72hGxB",
      "similarity": 0.8541
    },
    {
      "source": "T7bmHkwzS6",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8479
    },
    {
      "source": "T7bmHkwzS6",
      "target": "In this paper",
      "similarity": 0.8332
    },
    {
      "source": "T7bmHkwzS6",
      "target": "RFqeoVfLHa",
      "similarity": 0.8159
    },
    {
      "source": "T7bmHkwzS6",
      "target": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "similarity": 0.8113
    },
    {
      "source": "However",
      "target": "UyU8ETswPg",
      "similarity": 0.7979
    },
    {
      "source": "However",
      "target": "zXCnIyX9MG",
      "similarity": 0.7945
    },
    {
      "source": "However",
      "target": "goFpCuJalN",
      "similarity": 0.793
    },
    {
      "source": "However",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.7928
    },
    {
      "source": "However",
      "target": "wAXsx2MYgV",
      "similarity": 0.7926
    },
    {
      "source": "To address these issues",
      "target": "sLKDbuyq99",
      "similarity": 0.8318
    },
    {
      "source": "To address these issues",
      "target": "As expected",
      "similarity": 0.8314
    },
    {
      "source": "To address these issues",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8307
    },
    {
      "source": "To address these issues",
      "target": "This includes evaluating capabilities",
      "similarity": 0.8292
    },
    {
      "source": "To address these issues",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8277
    },
    {
      "source": "Specifically",
      "target": "tu3qwNjrtw",
      "similarity": 0.8553
    },
    {
      "source": "Specifically",
      "target": "jj7b3p5kLY",
      "similarity": 0.8509
    },
    {
      "source": "Specifically",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8468
    },
    {
      "source": "Specifically",
      "target": "zxO4WuVGns",
      "similarity": 0.8432
    },
    {
      "source": "Specifically",
      "target": "In addition",
      "similarity": 0.8408
    },
    {
      "source": "Moreover",
      "target": "In experiments with GPT-4",
      "similarity": 0.8773
    },
    {
      "source": "Moreover",
      "target": "nIEjY4a2Lf",
      "similarity": 0.8468
    },
    {
      "source": "Moreover",
      "target": "We5z3UEnUY",
      "similarity": 0.8222
    },
    {
      "source": "Moreover",
      "target": "ja4rpheN2n",
      "similarity": 0.8208
    },
    {
      "source": "Moreover",
      "target": "In a client-server setting",
      "similarity": 0.8155
    },
    {
      "source": "In particular",
      "target": "qn9tBYQHGi",
      "similarity": 0.8104
    },
    {
      "source": "In particular",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8086
    },
    {
      "source": "In particular",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.8007
    },
    {
      "source": "In particular",
      "target": "71XtUhazG0",
      "similarity": 0.7999
    },
    {
      "source": "In particular",
      "target": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "similarity": 0.7965
    },
    {
      "source": "44cMlQSreK",
      "target": "7HEMpBTb3R",
      "similarity": 0.8764
    },
    {
      "source": "44cMlQSreK",
      "target": "WLSrq1254E",
      "similarity": 0.8501
    },
    {
      "source": "44cMlQSreK",
      "target": "Overall",
      "similarity": 0.8451
    },
    {
      "source": "44cMlQSreK",
      "target": "A1HhtITVEi",
      "similarity": 0.8446
    },
    {
      "source": "44cMlQSreK",
      "target": "we propose positive-unlabeled diffusion models",
      "similarity": 0.8378
    },
    {
      "source": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "target": "Pacmann shows better scalability",
      "similarity": 0.8244
    },
    {
      "source": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "target": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "similarity": 0.821
    },
    {
      "source": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "target": "fL4qWkSmtM",
      "similarity": 0.8156
    },
    {
      "source": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "target": "daUQ7vmGap",
      "similarity": 0.8115
    },
    {
      "source": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "target": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "similarity": 0.8081
    },
    {
      "source": "HZgZrtIreg",
      "target": "JMPOqoe4tl",
      "similarity": 0.8228
    },
    {
      "source": "HZgZrtIreg",
      "target": "L238BAx0wP",
      "similarity": 0.822
    },
    {
      "source": "HZgZrtIreg",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8195
    },
    {
      "source": "HZgZrtIreg",
      "target": "This is because the model's position embedding mechanisms are limited to positions encountered during training",
      "similarity": 0.8098
    },
    {
      "source": "HZgZrtIreg",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8094
    },
    {
      "source": "8jvVNPHtVJ",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8286
    },
    {
      "source": "8jvVNPHtVJ",
      "target": "than prior private ANN schemes",
      "similarity": 0.819
    },
    {
      "source": "8jvVNPHtVJ",
      "target": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "similarity": 0.81
    },
    {
      "source": "8jvVNPHtVJ",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8096
    },
    {
      "source": "8jvVNPHtVJ",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8048
    },
    {
      "source": "fL4qWkSmtM",
      "target": "n34taxF0TC",
      "similarity": 0.8621
    },
    {
      "source": "fL4qWkSmtM",
      "target": "G328D1xt4W",
      "similarity": 0.858
    },
    {
      "source": "fL4qWkSmtM",
      "target": "Inspired by these findings",
      "similarity": 0.8497
    },
    {
      "source": "fL4qWkSmtM",
      "target": "reZKq6hjOZ",
      "similarity": 0.8486
    },
    {
      "source": "fL4qWkSmtM",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8459
    },
    {
      "source": "5oSUgTzs8Y",
      "target": "ods",
      "similarity": 0.8607
    },
    {
      "source": "5oSUgTzs8Y",
      "target": "Moreover",
      "similarity": 0.8542
    },
    {
      "source": "5oSUgTzs8Y",
      "target": "kbeX97jExm",
      "similarity": 0.8404
    },
    {
      "source": "5oSUgTzs8Y",
      "target": "mkNVPGpEPm",
      "similarity": 0.8346
    },
    {
      "source": "5oSUgTzs8Y",
      "target": "underscore the necessity for future research to focus on improving the accuracy of",
      "similarity": 0.8333
    },
    {
      "source": "dsP91M4hDL",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.8369
    },
    {
      "source": "dsP91M4hDL",
      "target": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "similarity": 0.8342
    },
    {
      "source": "dsP91M4hDL",
      "target": "78tc3EiUrN",
      "similarity": 0.8337
    },
    {
      "source": "dsP91M4hDL",
      "target": "We also thoroughly analyzed our pre-training dataset",
      "similarity": 0.826
    },
    {
      "source": "dsP91M4hDL",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.8256
    },
    {
      "source": "The effectiveness of MoE models depends primarily on their routing mechanisms",
      "target": "1R5BcYS8EC",
      "similarity": 0.8423
    },
    {
      "source": "The effectiveness of MoE models depends primarily on their routing mechanisms",
      "target": "However",
      "similarity": 0.8393
    },
    {
      "source": "The effectiveness of MoE models depends primarily on their routing mechanisms",
      "target": "eWocmTQn7H",
      "similarity": 0.8372
    },
    {
      "source": "The effectiveness of MoE models depends primarily on their routing mechanisms",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8359
    },
    {
      "source": "The effectiveness of MoE models depends primarily on their routing mechanisms",
      "target": "4ub9gpx9xw",
      "similarity": 0.8341
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.7956
    },
    {
      "source": "However",
      "target": "Deep networks composed entirely of deep Fourier features are highly trainable and sustain their trainability over the course of learning.",
      "similarity": 0.7946
    },
    {
      "source": "However",
      "target": "Notably",
      "similarity": 0.7934
    },
    {
      "source": "However",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.7929
    },
    {
      "source": "However",
      "target": "eIgGesYKLG",
      "similarity": 0.7843
    },
    {
      "source": "including unnecessary activations and underutilization of experts.",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8795
    },
    {
      "source": "including unnecessary activations and underutilization of experts.",
      "target": "frozen nonlinear manifolds",
      "similarity": 0.8734
    },
    {
      "source": "including unnecessary activations and underutilization of experts.",
      "target": "h8yg0hT96f",
      "similarity": 0.8687
    },
    {
      "source": "including unnecessary activations and underutilization of experts.",
      "target": "ptjrpEGrGg",
      "similarity": 0.8542
    },
    {
      "source": "including unnecessary activations and underutilization of experts.",
      "target": "TYSQYx9vwd",
      "similarity": 0.8504
    },
    {
      "source": "In this work",
      "target": "Aye5wL6TCn",
      "similarity": 0.847
    },
    {
      "source": "In this work",
      "target": "Extensive experiments validate BiGR's superior performance in generation quality",
      "similarity": 0.8346
    },
    {
      "source": "In this work",
      "target": "In this paper",
      "similarity": 0.8306
    },
    {
      "source": "In this work",
      "target": "Beyond performance evaluations",
      "similarity": 0.8286
    },
    {
      "source": "In this work",
      "target": "In addition",
      "similarity": 0.8278
    },
    {
      "source": "rather than modifying the routing mechanism as done in previous studies",
      "target": "nibeaHUEJx",
      "similarity": 0.8665
    },
    {
      "source": "rather than modifying the routing mechanism as done in previous studies",
      "target": "agHddsQhsL",
      "similarity": 0.8414
    },
    {
      "source": "rather than modifying the routing mechanism as done in previous studies",
      "target": "nzjSvVZBIp",
      "similarity": 0.8291
    },
    {
      "source": "rather than modifying the routing mechanism as done in previous studies",
      "target": "QowsEic1sc",
      "similarity": 0.8272
    },
    {
      "source": "rather than modifying the routing mechanism as done in previous studies",
      "target": "xI71dsS3o4",
      "similarity": 0.8262
    },
    {
      "source": "we propose the Ternary Choice MoE (TC-MoE)",
      "target": "Moreover",
      "similarity": 0.8685
    },
    {
      "source": "we propose the Ternary Choice MoE (TC-MoE)",
      "target": "given the unique characteristics of the expanded expert space",
      "similarity": 0.86
    },
    {
      "source": "we propose the Ternary Choice MoE (TC-MoE)",
      "target": "pre-training data",
      "similarity": 0.8545
    },
    {
      "source": "we propose the Ternary Choice MoE (TC-MoE)",
      "target": "uNd289HjLi",
      "similarity": 0.8499
    },
    {
      "source": "we propose the Ternary Choice MoE (TC-MoE)",
      "target": "JytL2MrlLT",
      "similarity": 0.847
    },
    {
      "source": "a novel approach that expands the expert space by applying the ternary set {-1",
      "target": "gFvRRCnQvX",
      "similarity": 0.8286
    },
    {
      "source": "a novel approach that expands the expert space by applying the ternary set {-1",
      "target": "Our code and additional resources are available at https://structuredllm.com.\"",
      "similarity": 0.8186
    },
    {
      "source": "a novel approach that expands the expert space by applying the ternary set {-1",
      "target": "gkUyYcY1W9",
      "similarity": 0.8107
    },
    {
      "source": "a novel approach that expands the expert space by applying the ternary set {-1",
      "target": "$^1$ GitHub: [https://github.com/pytorch/torchtitan](https://github.com/pytorch/torchtitan)\"",
      "similarity": 0.8105
    },
    {
      "source": "a novel approach that expands the expert space by applying the ternary set {-1",
      "target": "paradigms show promise",
      "similarity": 0.8081
    },
    {
      "source": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8235
    },
    {
      "source": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8138
    },
    {
      "source": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "target": "They operate by maintaining a set of vectors---often referred to as the codebook---and quantizing each encoder output to the nearest vector in the codebook.",
      "similarity": 0.8111
    },
    {
      "source": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "target": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "similarity": 0.8097
    },
    {
      "source": "This expansion allows more efficient and effective expert activations without incurring significant computational costs.",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8095
    },
    {
      "source": "Additionally",
      "target": "is often a non-linear function",
      "similarity": 0.8673
    },
    {
      "source": "Additionally",
      "target": "4O0v4s3IzY",
      "similarity": 0.864
    },
    {
      "source": "Additionally",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.857
    },
    {
      "source": "Additionally",
      "target": "phAlw3JPms",
      "similarity": 0.8523
    },
    {
      "source": "Additionally",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8448
    },
    {
      "source": "given the unique characteristics of the expanded expert space",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8694
    },
    {
      "source": "given the unique characteristics of the expanded expert space",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8668
    },
    {
      "source": "given the unique characteristics of the expanded expert space",
      "target": "However",
      "similarity": 0.8607
    },
    {
      "source": "given the unique characteristics of the expanded expert space",
      "target": "1CIUkpoata",
      "similarity": 0.8589
    },
    {
      "source": "given the unique characteristics of the expanded expert space",
      "target": "Furthermore",
      "similarity": 0.858
    },
    {
      "source": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "target": "LqTz13JS2P",
      "similarity": 0.8531
    },
    {
      "source": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "target": "0fJfVOSUra",
      "similarity": 0.8482
    },
    {
      "source": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "target": "(BoneMet) dataset",
      "similarity": 0.8413
    },
    {
      "source": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "target": "J9FgrqOOni",
      "similarity": 0.84
    },
    {
      "source": "we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.",
      "target": "Mjn53GtMxi",
      "similarity": 0.8325
    },
    {
      "source": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "target": "We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.",
      "similarity": 0.8047
    },
    {
      "source": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "target": "ogXkmugNZw",
      "similarity": 0.8044
    },
    {
      "source": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "target": "m8yby1JfbU",
      "similarity": 0.8043
    },
    {
      "source": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "target": "AoIKgHu9Si",
      "similarity": 0.8036
    },
    {
      "source": "Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches",
      "target": "To address this",
      "similarity": 0.801
    },
    {
      "source": "while reducing the average number of activated experts by up to 9%.",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8357
    },
    {
      "source": "while reducing the average number of activated experts by up to 9%.",
      "target": "Finally",
      "similarity": 0.8262
    },
    {
      "source": "while reducing the average number of activated experts by up to 9%.",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8219
    },
    {
      "source": "while reducing the average number of activated experts by up to 9%.",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8212
    },
    {
      "source": "while reducing the average number of activated experts by up to 9%.",
      "target": "aKkDY1Wca0",
      "similarity": 0.8186
    },
    {
      "source": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "target": "dEg5SdGaiq",
      "similarity": 0.853
    },
    {
      "source": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "target": "propose the use of weighted point sets",
      "similarity": 0.8414
    },
    {
      "source": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "target": "wide dissemination",
      "similarity": 0.8404
    },
    {
      "source": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8355
    },
    {
      "source": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "target": "mqNKiEB6pd",
      "similarity": 0.8352
    },
    {
      "source": "offering a more efficient and scalable solution for MoE-based large language models.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.9029
    },
    {
      "source": "offering a more efficient and scalable solution for MoE-based large language models.",
      "target": "U3PBITXNG6",
      "similarity": 0.8588
    },
    {
      "source": "offering a more efficient and scalable solution for MoE-based large language models.",
      "target": "hoYFLRNbhc",
      "similarity": 0.8569
    },
    {
      "source": "offering a more efficient and scalable solution for MoE-based large language models.",
      "target": "SOTA LLMs",
      "similarity": 0.8549
    },
    {
      "source": "offering a more efficient and scalable solution for MoE-based large language models.",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8548
    },
    {
      "source": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "target": "implementation",
      "similarity": 0.8282
    },
    {
      "source": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "target": "20qZK2T7fa",
      "similarity": 0.8258
    },
    {
      "source": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "target": "L0evcuybH5",
      "similarity": 0.8174
    },
    {
      "source": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8121
    },
    {
      "source": "Code and models are available at https://github.com/stiger1000/TC-MoE.\"",
      "target": "In addition",
      "similarity": 0.8067
    },
    {
      "source": "ujpAYpFDEA",
      "target": "hgwGi81ndj",
      "similarity": 0.8315
    },
    {
      "source": "ujpAYpFDEA",
      "target": "However",
      "similarity": 0.8256
    },
    {
      "source": "ujpAYpFDEA",
      "target": "Our framework",
      "similarity": 0.8245
    },
    {
      "source": "ujpAYpFDEA",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8233
    },
    {
      "source": "ujpAYpFDEA",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.8227
    },
    {
      "source": "However",
      "target": "Moreover",
      "similarity": 0.8115
    },
    {
      "source": "However",
      "target": "gVnJFY8nCM",
      "similarity": 0.8007
    },
    {
      "source": "However",
      "target": "WoPovNkM5h",
      "similarity": 0.7939
    },
    {
      "source": "However",
      "target": "PY56Wur7S0",
      "similarity": 0.7916
    },
    {
      "source": "However",
      "target": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "similarity": 0.789
    },
    {
      "source": "This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios",
      "target": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "similarity": 0.8167
    },
    {
      "source": "This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8089
    },
    {
      "source": "This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios",
      "target": "HqjRlT65WX",
      "similarity": 0.8089
    },
    {
      "source": "This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8063
    },
    {
      "source": "This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios",
      "target": "OuLgaHEmzi",
      "similarity": 0.8048
    },
    {
      "source": "while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs.",
      "target": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "similarity": 0.8198
    },
    {
      "source": "while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs.",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8073
    },
    {
      "source": "while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs.",
      "target": "mobile devices.\"",
      "similarity": 0.8014
    },
    {
      "source": "while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs.",
      "target": "Subsequently",
      "similarity": 0.8014
    },
    {
      "source": "while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs.",
      "target": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "similarity": 0.8012
    },
    {
      "source": "Finally",
      "target": "oYSsbY3G4o",
      "similarity": 0.8225
    },
    {
      "source": "Finally",
      "target": "m5qpn0KTMZ",
      "similarity": 0.8019
    },
    {
      "source": "Finally",
      "target": "In this work",
      "similarity": 0.7942
    },
    {
      "source": "Finally",
      "target": "GtvuNrk58a",
      "similarity": 0.79
    },
    {
      "source": "Finally",
      "target": "Prior work developed UCB-style",
      "similarity": 0.7866
    },
    {
      "source": "pHe4P1IVnb",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8647
    },
    {
      "source": "pHe4P1IVnb",
      "target": "F57HPKZ6KD",
      "similarity": 0.8616
    },
    {
      "source": "pHe4P1IVnb",
      "target": "WCRQFlji2q",
      "similarity": 0.8566
    },
    {
      "source": "pHe4P1IVnb",
      "target": "Furthermore",
      "similarity": 0.8532
    },
    {
      "source": "pHe4P1IVnb",
      "target": "bMC1t7eLRc",
      "similarity": 0.8461
    },
    {
      "source": "URPwT55i6O",
      "target": "However",
      "similarity": 0.8394
    },
    {
      "source": "URPwT55i6O",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8257
    },
    {
      "source": "URPwT55i6O",
      "target": "hgwGi81ndj",
      "similarity": 0.825
    },
    {
      "source": "URPwT55i6O",
      "target": "A4eCzSohhx",
      "similarity": 0.8218
    },
    {
      "source": "URPwT55i6O",
      "target": "To make this efficient",
      "similarity": 0.8157
    },
    {
      "source": "upoxXRRTQ2",
      "target": "Ij9ilPh36h",
      "similarity": 0.8485
    },
    {
      "source": "upoxXRRTQ2",
      "target": "mXHTifc1Fn",
      "similarity": 0.8205
    },
    {
      "source": "upoxXRRTQ2",
      "target": "solutions",
      "similarity": 0.8159
    },
    {
      "source": "upoxXRRTQ2",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8081
    },
    {
      "source": "upoxXRRTQ2",
      "target": "jDsmB4o5S0",
      "similarity": 0.8079
    },
    {
      "source": "tj5xJInWty",
      "target": "wSkvf2WyYz",
      "similarity": 0.8618
    },
    {
      "source": "tj5xJInWty",
      "target": "iVMcYxTiVM",
      "similarity": 0.8472
    },
    {
      "source": "tj5xJInWty",
      "target": "We start by showing numerically that several variants used in practice",
      "similarity": 0.8471
    },
    {
      "source": "tj5xJInWty",
      "target": "fNMKqyvuZT",
      "similarity": 0.8457
    },
    {
      "source": "tj5xJInWty",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8433
    },
    {
      "source": "oVKEAFjEqv",
      "target": "ZNnmcddaB3",
      "similarity": 0.8199
    },
    {
      "source": "oVKEAFjEqv",
      "target": "To address this gap",
      "similarity": 0.8049
    },
    {
      "source": "oVKEAFjEqv",
      "target": "ZJo6Radbqq",
      "similarity": 0.7984
    },
    {
      "source": "oVKEAFjEqv",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.7963
    },
    {
      "source": "oVKEAFjEqv",
      "target": "x83w6yGIWb",
      "similarity": 0.7914
    },
    {
      "source": "However",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8512
    },
    {
      "source": "However",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8328
    },
    {
      "source": "However",
      "target": "dw9VUsSHGB",
      "similarity": 0.8296
    },
    {
      "source": "However",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8266
    },
    {
      "source": "However",
      "target": "thereby avoiding local optima. Our theoretical analysis illustrates how these",
      "similarity": 0.8234
    },
    {
      "source": "This paper introduces WebRL",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8812
    },
    {
      "source": "This paper introduces WebRL",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8598
    },
    {
      "source": "This paper introduces WebRL",
      "target": "U42TkrEDzb",
      "similarity": 0.8525
    },
    {
      "source": "This paper introduces WebRL",
      "target": "JytL2MrlLT",
      "similarity": 0.8512
    },
    {
      "source": "This paper introduces WebRL",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8469
    },
    {
      "source": "Our approach addresses key challenges in this domain",
      "target": "4GT9uTsAJE",
      "similarity": 0.8457
    },
    {
      "source": "Our approach addresses key challenges in this domain",
      "target": "In this paper",
      "similarity": 0.8454
    },
    {
      "source": "Our approach addresses key challenges in this domain",
      "target": "4iFSBgxvIO",
      "similarity": 0.8284
    },
    {
      "source": "Our approach addresses key challenges in this domain",
      "target": "c61unr33XA",
      "similarity": 0.8197
    },
    {
      "source": "Our approach addresses key challenges in this domain",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8193
    },
    {
      "source": "WebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts",
      "target": "dermining interpretability. To address these challenges",
      "similarity": 0.8142
    },
    {
      "source": "WebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts",
      "target": "B8akWa62Da",
      "similarity": 0.801
    },
    {
      "source": "WebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.7931
    },
    {
      "source": "WebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts",
      "target": "To enable structural learning with the language model",
      "similarity": 0.7908
    },
    {
      "source": "WebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts",
      "target": "NCrFA7dq8T",
      "similarity": 0.7858
    },
    {
      "source": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8894
    },
    {
      "source": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "target": "To develop SoundCTM",
      "similarity": 0.8459
    },
    {
      "source": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.8409
    },
    {
      "source": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8366
    },
    {
      "source": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "target": "UL2",
      "similarity": 0.8351
    },
    {
      "source": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "target": "In this paper",
      "similarity": 0.837
    },
    {
      "source": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8339
    },
    {
      "source": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "target": "O6znYvxC1U",
      "similarity": 0.8252
    },
    {
      "source": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "target": "owP2mymrTD",
      "similarity": 0.8218
    },
    {
      "source": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "target": "Instruct",
      "similarity": 0.8192
    },
    {
      "source": "These results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM",
      "target": "Beyond performance evaluations",
      "similarity": 0.8232
    },
    {
      "source": "These results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM",
      "target": "In this work",
      "similarity": 0.8106
    },
    {
      "source": "These results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM",
      "target": "While existing T2S distillation models address this limitation through $1$-step generation",
      "similarity": 0.7982
    },
    {
      "source": "These results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM",
      "target": "In this paper",
      "similarity": 0.7949
    },
    {
      "source": "These results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM",
      "target": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "similarity": 0.793
    },
    {
      "source": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "target": "First",
      "similarity": 0.8411
    },
    {
      "source": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "target": "OwpLQrpdwE",
      "similarity": 0.8106
    },
    {
      "source": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "target": "over 67 terabytes of multi-modal medical data",
      "similarity": 0.8097
    },
    {
      "source": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "target": "UL2",
      "similarity": 0.8082
    },
    {
      "source": "Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents",
      "target": "ZadnlOHsHv",
      "similarity": 0.8065
    },
    {
      "source": "SCBn8MCLwc",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8619
    },
    {
      "source": "SCBn8MCLwc",
      "target": "uMEsKEiB7J",
      "similarity": 0.8104
    },
    {
      "source": "SCBn8MCLwc",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8079
    },
    {
      "source": "SCBn8MCLwc",
      "target": "gyHoR6uFhU",
      "similarity": 0.8068
    },
    {
      "source": "SCBn8MCLwc",
      "target": "1VwWi6zbxs",
      "similarity": 0.8023
    },
    {
      "source": "ww3CLRhF1v",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8557
    },
    {
      "source": "ww3CLRhF1v",
      "target": "We further demonstrate that by fine-tuning the pre-trained model with speech dialogue data",
      "similarity": 0.8513
    },
    {
      "source": "ww3CLRhF1v",
      "target": "We found that long distance referrals",
      "similarity": 0.8483
    },
    {
      "source": "ww3CLRhF1v",
      "target": "riieAeQBJm",
      "similarity": 0.8466
    },
    {
      "source": "ww3CLRhF1v",
      "target": "dAeET8gxqg",
      "similarity": 0.8413
    },
    {
      "source": "HyjIEf90Tn",
      "target": "ScVnYBaSEw",
      "similarity": 0.8297
    },
    {
      "source": "HyjIEf90Tn",
      "target": "71XtUhazG0",
      "similarity": 0.809
    },
    {
      "source": "HyjIEf90Tn",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8045
    },
    {
      "source": "HyjIEf90Tn",
      "target": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "similarity": 0.8028
    },
    {
      "source": "HyjIEf90Tn",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.8026
    },
    {
      "source": "ymt4crbbXh",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.9083
    },
    {
      "source": "ymt4crbbXh",
      "target": "xJXq6FkqEw",
      "similarity": 0.8744
    },
    {
      "source": "ymt4crbbXh",
      "target": "j1tSLYKwg8",
      "similarity": 0.8663
    },
    {
      "source": "ymt4crbbXh",
      "target": "In this paper",
      "similarity": 0.8618
    },
    {
      "source": "ymt4crbbXh",
      "target": "ByCV9xWfNK",
      "similarity": 0.85
    },
    {
      "source": "4R71pdPBZp",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8336
    },
    {
      "source": "4R71pdPBZp",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.831
    },
    {
      "source": "4R71pdPBZp",
      "target": "MxbEiFRf39",
      "similarity": 0.8258
    },
    {
      "source": "4R71pdPBZp",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8246
    },
    {
      "source": "4R71pdPBZp",
      "target": "of our approaches.",
      "similarity": 0.816
    },
    {
      "source": "To address this limitation",
      "target": "4O0v4s3IzY",
      "similarity": 0.856
    },
    {
      "source": "To address this limitation",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8443
    },
    {
      "source": "To address this limitation",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8394
    },
    {
      "source": "To address this limitation",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8388
    },
    {
      "source": "To address this limitation",
      "target": "OL44KtasKc",
      "similarity": 0.8317
    },
    {
      "source": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8351
    },
    {
      "source": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "target": "xI71dsS3o4",
      "similarity": 0.8203
    },
    {
      "source": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "target": "On various mathematical benchmarks",
      "similarity": 0.8144
    },
    {
      "source": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "target": "1durmugh3I",
      "similarity": 0.8107
    },
    {
      "source": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "target": "WttfQGwpES",
      "similarity": 0.8074
    },
    {
      "source": "Our experiments show that:",
      "target": "X0epAjg0hd",
      "similarity": 0.8582
    },
    {
      "source": "Our experiments show that:",
      "target": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "similarity": 0.8321
    },
    {
      "source": "Our experiments show that:",
      "target": "The vulnerability exists for a wide range of modern LMs that span Llama2",
      "similarity": 0.8128
    },
    {
      "source": "Our experiments show that:",
      "target": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "similarity": 0.8084
    },
    {
      "source": "Our experiments show that:",
      "target": "Experiments on five frequently-used strong LLMs demonstrate the effectiveness of our method",
      "similarity": 0.8057
    },
    {
      "source": "i) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations",
      "target": "QKBu1BOAwd",
      "similarity": 0.8191
    },
    {
      "source": "i) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations",
      "target": "ANBuEJesgx",
      "similarity": 0.8003
    },
    {
      "source": "i) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations",
      "target": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "similarity": 0.7995
    },
    {
      "source": "i) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations",
      "target": "e32cI4r8Eo",
      "similarity": 0.7984
    },
    {
      "source": "i) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations",
      "target": "SG1R2H3fa1",
      "similarity": 0.7961
    },
    {
      "source": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "target": "improving convergence and enabling efficient gradient-based optimization",
      "similarity": 0.8254
    },
    {
      "source": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "target": "aN57tSd5Us",
      "similarity": 0.811
    },
    {
      "source": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "target": "ZadnlOHsHv",
      "similarity": 0.8059
    },
    {
      "source": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "target": "Bpn8q40n1n",
      "similarity": 0.8032
    },
    {
      "source": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "target": "Finally",
      "similarity": 0.803
    },
    {
      "source": "HAwZGLcye3",
      "target": "5btFIv2PNb",
      "similarity": 0.8304
    },
    {
      "source": "HAwZGLcye3",
      "target": "Under these assumptions",
      "similarity": 0.8256
    },
    {
      "source": "HAwZGLcye3",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8223
    },
    {
      "source": "HAwZGLcye3",
      "target": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "similarity": 0.8159
    },
    {
      "source": "HAwZGLcye3",
      "target": "dmCGjPFVhF",
      "similarity": 0.802
    },
    {
      "source": "UstOpZCESc",
      "target": "We further analyze the key effects of these neurons on the image classification task",
      "similarity": 0.828
    },
    {
      "source": "UstOpZCESc",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.826
    },
    {
      "source": "UstOpZCESc",
      "target": "To this end",
      "similarity": 0.8247
    },
    {
      "source": "UstOpZCESc",
      "target": "Reweighting (GSR)",
      "similarity": 0.8239
    },
    {
      "source": "UstOpZCESc",
      "target": "hwnObmOTrV",
      "similarity": 0.82
    },
    {
      "source": "SqZ0KY4qBD",
      "target": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "similarity": 0.8793
    },
    {
      "source": "SqZ0KY4qBD",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8588
    },
    {
      "source": "SqZ0KY4qBD",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.853
    },
    {
      "source": "SqZ0KY4qBD",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.843
    },
    {
      "source": "SqZ0KY4qBD",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.842
    },
    {
      "source": "rTQNGQxm4K",
      "target": "HqjRlT65WX",
      "similarity": 0.8738
    },
    {
      "source": "rTQNGQxm4K",
      "target": "First",
      "similarity": 0.8697
    },
    {
      "source": "rTQNGQxm4K",
      "target": "than existing search techniques",
      "similarity": 0.8547
    },
    {
      "source": "rTQNGQxm4K",
      "target": "yitH9xAHQs",
      "similarity": 0.8508
    },
    {
      "source": "rTQNGQxm4K",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8481
    },
    {
      "source": "aN57tSd5Us",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8599
    },
    {
      "source": "aN57tSd5Us",
      "target": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "similarity": 0.8335
    },
    {
      "source": "aN57tSd5Us",
      "target": "Next",
      "similarity": 0.8281
    },
    {
      "source": "aN57tSd5Us",
      "target": "higher throughput compared to Transformers with grouped-query attention for user",
      "similarity": 0.8216
    },
    {
      "source": "aN57tSd5Us",
      "target": "uQnvYP7yX9",
      "similarity": 0.8209
    },
    {
      "source": "riieAeQBJm",
      "target": "We found that long distance referrals",
      "similarity": 0.9059
    },
    {
      "source": "riieAeQBJm",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8769
    },
    {
      "source": "riieAeQBJm",
      "target": "Jszf4et48m",
      "similarity": 0.876
    },
    {
      "source": "riieAeQBJm",
      "target": "In this paper",
      "similarity": 0.8729
    },
    {
      "source": "riieAeQBJm",
      "target": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "similarity": 0.8682
    },
    {
      "source": "l0ZzTvPfTw",
      "target": "q87GUkdQBm",
      "similarity": 0.8055
    },
    {
      "source": "l0ZzTvPfTw",
      "target": "7liN6uHAQZ",
      "similarity": 0.8053
    },
    {
      "source": "l0ZzTvPfTw",
      "target": "6ouZaBzeNO",
      "similarity": 0.8029
    },
    {
      "source": "l0ZzTvPfTw",
      "target": "NfCEVihkdC",
      "similarity": 0.7983
    },
    {
      "source": "l0ZzTvPfTw",
      "target": "memorization",
      "similarity": 0.7975
    },
    {
      "source": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8335
    },
    {
      "source": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "target": "than existing search techniques",
      "similarity": 0.8317
    },
    {
      "source": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "target": "bsFWJ0Kget",
      "similarity": 0.8305
    },
    {
      "source": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8297
    },
    {
      "source": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "target": "rTQNGQxm4K",
      "similarity": 0.8238
    },
    {
      "source": "JWtrk7mprJ",
      "target": "P7O1Vt1BdU",
      "similarity": 0.797
    },
    {
      "source": "JWtrk7mprJ",
      "target": "FPQzXME9NK",
      "similarity": 0.7924
    },
    {
      "source": "JWtrk7mprJ",
      "target": "9vTAkJ9Tik",
      "similarity": 0.7887
    },
    {
      "source": "JWtrk7mprJ",
      "target": "Moreover",
      "similarity": 0.7878
    },
    {
      "source": "JWtrk7mprJ",
      "target": "DsIOUoZkVk",
      "similarity": 0.7844
    },
    {
      "source": "With manifold-to-manifold hidden layers and an arbitrary last layer",
      "target": "This paper introduces PANGEA",
      "similarity": 0.7974
    },
    {
      "source": "With manifold-to-manifold hidden layers and an arbitrary last layer",
      "target": "7El7K1DoyX",
      "similarity": 0.7969
    },
    {
      "source": "With manifold-to-manifold hidden layers and an arbitrary last layer",
      "target": "Ahlrf2HGJR",
      "similarity": 0.796
    },
    {
      "source": "With manifold-to-manifold hidden layers and an arbitrary last layer",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.792
    },
    {
      "source": "With manifold-to-manifold hidden layers and an arbitrary last layer",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.7865
    },
    {
      "source": "We target data inherently supported on manifolds",
      "target": "Pacmann shows better scalability",
      "similarity": 0.8247
    },
    {
      "source": "We target data inherently supported on manifolds",
      "target": "YOpa6dTrpt",
      "similarity": 0.8217
    },
    {
      "source": "We target data inherently supported on manifolds",
      "target": "stacking methods. Specifically",
      "similarity": 0.7899
    },
    {
      "source": "We target data inherently supported on manifolds",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.7859
    },
    {
      "source": "We target data inherently supported on manifolds",
      "target": "oZkqkkvdND",
      "similarity": 0.7845
    },
    {
      "source": "For example",
      "target": "In parallel",
      "similarity": 0.822
    },
    {
      "source": "For example",
      "target": "From this perspective",
      "similarity": 0.8165
    },
    {
      "source": "For example",
      "target": "kam84eEmub",
      "similarity": 0.8122
    },
    {
      "source": "For example",
      "target": "HZgZrtIreg",
      "similarity": 0.8075
    },
    {
      "source": "For example",
      "target": "In this work",
      "similarity": 0.8046
    },
    {
      "source": "Our models significantly improve performance in these settings",
      "target": "Pnk7vMbznK",
      "similarity": 0.861
    },
    {
      "source": "Our models significantly improve performance in these settings",
      "target": "gVnJFY8nCM",
      "similarity": 0.8584
    },
    {
      "source": "Our models significantly improve performance in these settings",
      "target": "VGQugiuCQs",
      "similarity": 0.8569
    },
    {
      "source": "Our models significantly improve performance in these settings",
      "target": "fifXzmzeGy",
      "similarity": 0.8494
    },
    {
      "source": "Our models significantly improve performance in these settings",
      "target": "By incorporating generative models into the BOED framework",
      "similarity": 0.8476
    },
    {
      "source": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "target": "j8WHjM9aMm",
      "similarity": 0.851
    },
    {
      "source": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8464
    },
    {
      "source": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "target": "In this paper",
      "similarity": 0.8443
    },
    {
      "source": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "target": "e8qXTxMgPg",
      "similarity": 0.8426
    },
    {
      "source": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.825
    },
    {
      "source": "Finally",
      "target": "To address these limitations",
      "similarity": 0.8518
    },
    {
      "source": "Finally",
      "target": "YLIsIzC74j",
      "similarity": 0.8316
    },
    {
      "source": "Finally",
      "target": "pB1XSj2y4X",
      "similarity": 0.8216
    },
    {
      "source": "Finally",
      "target": "0LSAmFCc4p",
      "similarity": 0.8211
    },
    {
      "source": "Finally",
      "target": "eGqQyTAbXC",
      "similarity": 0.8196
    },
    {
      "source": "3RSLW9YSgk",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8121
    },
    {
      "source": "3RSLW9YSgk",
      "target": "X0epAjg0hd",
      "similarity": 0.8102
    },
    {
      "source": "3RSLW9YSgk",
      "target": "7bAjVh3CG3",
      "similarity": 0.8085
    },
    {
      "source": "3RSLW9YSgk",
      "target": "faceswaps",
      "similarity": 0.8006
    },
    {
      "source": "3RSLW9YSgk",
      "target": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "similarity": 0.7995
    },
    {
      "source": "To overcome those challenges",
      "target": "pDDODPtpx9",
      "similarity": 0.8778
    },
    {
      "source": "To overcome those challenges",
      "target": "To this end",
      "similarity": 0.8722
    },
    {
      "source": "To overcome those challenges",
      "target": "Jszf4et48m",
      "similarity": 0.8685
    },
    {
      "source": "To overcome those challenges",
      "target": "pRCOZllZdT",
      "similarity": 0.8669
    },
    {
      "source": "To overcome those challenges",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8649
    },
    {
      "source": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "target": "However",
      "similarity": 0.8758
    },
    {
      "source": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "target": "sion method",
      "similarity": 0.8581
    },
    {
      "source": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "target": "2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model",
      "similarity": 0.8535
    },
    {
      "source": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8508
    },
    {
      "source": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8473
    },
    {
      "source": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "target": "INqLJwqUmc",
      "similarity": 0.824
    },
    {
      "source": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "target": "unlimited streaming.\"",
      "similarity": 0.8226
    },
    {
      "source": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8145
    },
    {
      "source": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "target": "uy4EavBEwl",
      "similarity": 0.8109
    },
    {
      "source": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "target": "a hypergraph",
      "similarity": 0.8107
    },
    {
      "source": "As a highlight",
      "target": "To enrich long documents",
      "similarity": 0.8503
    },
    {
      "source": "As a highlight",
      "target": "VGQugiuCQs",
      "similarity": 0.8401
    },
    {
      "source": "As a highlight",
      "target": "97rOQDPmk2",
      "similarity": 0.8357
    },
    {
      "source": "As a highlight",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.829
    },
    {
      "source": "As a highlight",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.827
    },
    {
      "source": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.8085
    },
    {
      "source": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "target": "However",
      "similarity": 0.8078
    },
    {
      "source": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "target": "To address this",
      "similarity": 0.8014
    },
    {
      "source": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "target": "77gQUdQhE7",
      "similarity": 0.8004
    },
    {
      "source": "Our project page can be found in: https://dreamtomanipulate.github.io/.\"",
      "target": "irrtPRFksw",
      "similarity": 0.798
    },
    {
      "source": "KEXoZxTwbr",
      "target": "XBF63bHDZw",
      "similarity": 0.782
    },
    {
      "source": "KEXoZxTwbr",
      "target": "bNVbOS3lrl",
      "similarity": 0.7616
    },
    {
      "source": "KEXoZxTwbr",
      "target": "improve performance. Results are empirically validated on a 2D image regression",
      "similarity": 0.7589
    },
    {
      "source": "KEXoZxTwbr",
      "target": "However",
      "similarity": 0.7546
    },
    {
      "source": "KEXoZxTwbr",
      "target": "benchmarking higher-order models",
      "similarity": 0.7523
    },
    {
      "source": "jointly reconstructs and optimizes explicit geometry",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8324
    },
    {
      "source": "jointly reconstructs and optimizes explicit geometry",
      "target": "HsHxSN23rM",
      "similarity": 0.8292
    },
    {
      "source": "jointly reconstructs and optimizes explicit geometry",
      "target": "Among these",
      "similarity": 0.8286
    },
    {
      "source": "jointly reconstructs and optimizes explicit geometry",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.818
    },
    {
      "source": "jointly reconstructs and optimizes explicit geometry",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8162
    },
    {
      "source": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "target": "KAIqwkB3dT",
      "similarity": 0.845
    },
    {
      "source": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "target": "5xSRg3eYZz",
      "similarity": 0.8447
    },
    {
      "source": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.839
    },
    {
      "source": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "target": "optimization (INPO). The key idea is to let the policy play against itself via no-",
      "similarity": 0.8387
    },
    {
      "source": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "target": "N0ETIi580T",
      "similarity": 0.8367
    },
    {
      "source": "stage that extracts an explicit triangular mesh. In the second stage",
      "target": "FBhKUXK7od",
      "similarity": 0.8358
    },
    {
      "source": "stage that extracts an explicit triangular mesh. In the second stage",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8307
    },
    {
      "source": "stage that extracts an explicit triangular mesh. In the second stage",
      "target": "RZwtbg3qYD",
      "similarity": 0.8269
    },
    {
      "source": "stage that extracts an explicit triangular mesh. In the second stage",
      "target": "In light of this",
      "similarity": 0.8244
    },
    {
      "source": "stage that extracts an explicit triangular mesh. In the second stage",
      "target": "e8qXTxMgPg",
      "similarity": 0.8238
    },
    {
      "source": "with multi-bounce path tracing and Monte Carlo integration. This enables our method to accurately estimate indirect illumination effects",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8613
    },
    {
      "source": "with multi-bounce path tracing and Monte Carlo integration. This enables our method to accurately estimate indirect illumination effects",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8549
    },
    {
      "source": "with multi-bounce path tracing and Monte Carlo integration. This enables our method to accurately estimate indirect illumination effects",
      "target": "Experiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach",
      "similarity": 0.854
    },
    {
      "source": "with multi-bounce path tracing and Monte Carlo integration. This enables our method to accurately estimate indirect illumination effects",
      "target": "JytL2MrlLT",
      "similarity": 0.8536
    },
    {
      "source": "with multi-bounce path tracing and Monte Carlo integration. This enables our method to accurately estimate indirect illumination effects",
      "target": "uNd289HjLi",
      "similarity": 0.8435
    },
    {
      "source": "intrinsic decomposition of shape",
      "target": "h1XoHOd19I",
      "similarity": 0.8651
    },
    {
      "source": "intrinsic decomposition of shape",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8583
    },
    {
      "source": "intrinsic decomposition of shape",
      "target": "lvw3UgeVxS",
      "similarity": 0.858
    },
    {
      "source": "intrinsic decomposition of shape",
      "target": "We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.\"",
      "similarity": 0.8568
    },
    {
      "source": "intrinsic decomposition of shape",
      "target": "hjROBHstZ3",
      "similarity": 0.8561
    },
    {
      "source": "noise issue in Monte Carlo integration",
      "target": "To address this",
      "similarity": 0.8164
    },
    {
      "source": "noise issue in Monte Carlo integration",
      "target": "enhance reliability. This study investigates the efficacy of such approaches",
      "similarity": 0.8148
    },
    {
      "source": "noise issue in Monte Carlo integration",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8099
    },
    {
      "source": "noise issue in Monte Carlo integration",
      "target": "relying on backward propagation",
      "similarity": 0.8072
    },
    {
      "source": "noise issue in Monte Carlo integration",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8069
    },
    {
      "source": "improving convergence and enabling efficient gradient-based optimization",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8427
    },
    {
      "source": "improving convergence and enabling efficient gradient-based optimization",
      "target": "Bpn8q40n1n",
      "similarity": 0.8423
    },
    {
      "source": "improving convergence and enabling efficient gradient-based optimization",
      "target": "jY5oml9fe9",
      "similarity": 0.815
    },
    {
      "source": "improving convergence and enabling efficient gradient-based optimization",
      "target": "In this paper",
      "similarity": 0.8127
    },
    {
      "source": "improving convergence and enabling efficient gradient-based optimization",
      "target": "First",
      "similarity": 0.8046
    },
    {
      "source": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "target": "8EfxjTCg2k",
      "similarity": 0.8733
    },
    {
      "source": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8683
    },
    {
      "source": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "target": "xsELpEPn4A",
      "similarity": 0.8586
    },
    {
      "source": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8523
    },
    {
      "source": "with low sample counts. Through both qualitative and quantitative assessments across various scenarios",
      "target": "sZJNkorXMk",
      "similarity": 0.8518
    },
    {
      "source": "we demonstrate that our method achieves state-of-the-art decomposition",
      "target": "Specifically",
      "similarity": 0.7961
    },
    {
      "source": "we demonstrate that our method achieves state-of-the-art decomposition",
      "target": "MxbEiFRf39",
      "similarity": 0.7937
    },
    {
      "source": "we demonstrate that our method achieves state-of-the-art decomposition",
      "target": "wfLuiDjQ0u",
      "similarity": 0.7936
    },
    {
      "source": "we demonstrate that our method achieves state-of-the-art decomposition",
      "target": "2U8owdruSQ",
      "similarity": 0.7888
    },
    {
      "source": "we demonstrate that our method achieves state-of-the-art decomposition",
      "target": "Code is available at https://github.com/CORE-Robotics-Lab/GSD.\"",
      "similarity": 0.7842
    },
    {
      "source": "performance. Furthermore",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.813
    },
    {
      "source": "performance. Furthermore",
      "target": "dbuFJg7eaw",
      "similarity": 0.8085
    },
    {
      "source": "performance. Furthermore",
      "target": "7HEMpBTb3R",
      "similarity": 0.7999
    },
    {
      "source": "performance. Furthermore",
      "target": "FBhKUXK7od",
      "similarity": 0.7945
    },
    {
      "source": "performance. Furthermore",
      "target": "gkUyYcY1W9",
      "similarity": 0.7917
    },
    {
      "source": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "target": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "similarity": 0.8309
    },
    {
      "source": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8238
    },
    {
      "source": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "target": "wxPnuFp8fZ",
      "similarity": 0.8201
    },
    {
      "source": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "target": "component of real-world software development.\"",
      "similarity": 0.8188
    },
    {
      "source": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "target": "7VkHffT5X2",
      "similarity": 0.816
    },
    {
      "source": "QogcGNXJVw",
      "target": "N4rYbQowE3",
      "similarity": 0.8228
    },
    {
      "source": "QogcGNXJVw",
      "target": "By leveraging online data collection",
      "similarity": 0.8202
    },
    {
      "source": "QogcGNXJVw",
      "target": "standard training and",
      "similarity": 0.8101
    },
    {
      "source": "QogcGNXJVw",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8093
    },
    {
      "source": "QogcGNXJVw",
      "target": "RC5FPYVQaH",
      "similarity": 0.8017
    },
    {
      "source": "cfGpIcOIa5",
      "target": "JMPOqoe4tl",
      "similarity": 0.8481
    },
    {
      "source": "cfGpIcOIa5",
      "target": "3ogIALgghF",
      "similarity": 0.8479
    },
    {
      "source": "cfGpIcOIa5",
      "target": "uClUUJk05H",
      "similarity": 0.8465
    },
    {
      "source": "cfGpIcOIa5",
      "target": "Third",
      "similarity": 0.8404
    },
    {
      "source": "cfGpIcOIa5",
      "target": "sYNWqQYJhz",
      "similarity": 0.837
    },
    {
      "source": "While existing ILP systems can successfully solve small-scale tasks",
      "target": "this simple method is computationally fast",
      "similarity": 0.8297
    },
    {
      "source": "While existing ILP systems can successfully solve small-scale tasks",
      "target": "DhHIw9Nbl1",
      "similarity": 0.8267
    },
    {
      "source": "While existing ILP systems can successfully solve small-scale tasks",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.805
    },
    {
      "source": "While existing ILP systems can successfully solve small-scale tasks",
      "target": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "similarity": 0.8009
    },
    {
      "source": "While existing ILP systems can successfully solve small-scale tasks",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8001
    },
    {
      "source": "Besides",
      "target": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "similarity": 0.874
    },
    {
      "source": "Besides",
      "target": "of top-k chunks",
      "similarity": 0.8656
    },
    {
      "source": "Besides",
      "target": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "similarity": 0.8153
    },
    {
      "source": "Besides",
      "target": "lgsyLSsDRe",
      "similarity": 0.8113
    },
    {
      "source": "Besides",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8082
    },
    {
      "source": "In this paper",
      "target": "jTEKTdI3K9",
      "similarity": 0.841
    },
    {
      "source": "In this paper",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8282
    },
    {
      "source": "In this paper",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8218
    },
    {
      "source": "In this paper",
      "target": "pRCOZllZdT",
      "similarity": 0.8214
    },
    {
      "source": "In this paper",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8212
    },
    {
      "source": "These tasks are built from geometry problems",
      "target": "tijmpS9Vy2",
      "similarity": 0.8701
    },
    {
      "source": "These tasks are built from geometry problems",
      "target": "rCX9l4OTCT",
      "similarity": 0.8602
    },
    {
      "source": "These tasks are built from geometry problems",
      "target": "In addition",
      "similarity": 0.856
    },
    {
      "source": "These tasks are built from geometry problems",
      "target": "TYSQYx9vwd",
      "similarity": 0.8418
    },
    {
      "source": "These tasks are built from geometry problems",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8363
    },
    {
      "source": "These problems are elaborately selected to cover all challenging language biases",
      "target": "To tackle this problem",
      "similarity": 0.8455
    },
    {
      "source": "These problems are elaborately selected to cover all challenging language biases",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8447
    },
    {
      "source": "These problems are elaborately selected to cover all challenging language biases",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8435
    },
    {
      "source": "These problems are elaborately selected to cover all challenging language biases",
      "target": "However",
      "similarity": 0.842
    },
    {
      "source": "These problems are elaborately selected to cover all challenging language biases",
      "target": "To address these issues",
      "similarity": 0.833
    },
    {
      "source": "Experimental results show that no existing method can solve GeoILP tasks.",
      "target": "fifXzmzeGy",
      "similarity": 0.8768
    },
    {
      "source": "Experimental results show that no existing method can solve GeoILP tasks.",
      "target": "Pnk7vMbznK",
      "similarity": 0.8468
    },
    {
      "source": "Experimental results show that no existing method can solve GeoILP tasks.",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8399
    },
    {
      "source": "Experimental results show that no existing method can solve GeoILP tasks.",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8366
    },
    {
      "source": "Experimental results show that no existing method can solve GeoILP tasks.",
      "target": "DzbUL4AJPP",
      "similarity": 0.8323
    },
    {
      "source": "In addition",
      "target": "jj7b3p5kLY",
      "similarity": 0.8855
    },
    {
      "source": "In addition",
      "target": "Thus",
      "similarity": 0.8635
    },
    {
      "source": "In addition",
      "target": "First",
      "similarity": 0.8563
    },
    {
      "source": "In addition",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8513
    },
    {
      "source": "In addition",
      "target": "tu3qwNjrtw",
      "similarity": 0.8425
    },
    {
      "source": "AAXBfJNHDt",
      "target": "ScVnYBaSEw",
      "similarity": 0.8461
    },
    {
      "source": "AAXBfJNHDt",
      "target": "27SSnLl85x",
      "similarity": 0.8295
    },
    {
      "source": "AAXBfJNHDt",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8186
    },
    {
      "source": "AAXBfJNHDt",
      "target": "First",
      "similarity": 0.8144
    },
    {
      "source": "AAXBfJNHDt",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8122
    },
    {
      "source": "A4eCzSohhx",
      "target": "To make this efficient",
      "similarity": 0.8687
    },
    {
      "source": "A4eCzSohhx",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8626
    },
    {
      "source": "A4eCzSohhx",
      "target": "hgwGi81ndj",
      "similarity": 0.8514
    },
    {
      "source": "A4eCzSohhx",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8391
    },
    {
      "source": "A4eCzSohhx",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8359
    },
    {
      "source": "dbuFJg7eaw",
      "target": "paradigms show promise",
      "similarity": 0.8188
    },
    {
      "source": "dbuFJg7eaw",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8175
    },
    {
      "source": "dbuFJg7eaw",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8106
    },
    {
      "source": "dbuFJg7eaw",
      "target": "In this paper",
      "similarity": 0.8051
    },
    {
      "source": "dbuFJg7eaw",
      "target": "stage that extracts an explicit triangular mesh. In the second stage",
      "similarity": 0.8015
    },
    {
      "source": "sZJNkorXMk",
      "target": "8EfxjTCg2k",
      "similarity": 0.8865
    },
    {
      "source": "sZJNkorXMk",
      "target": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "similarity": 0.8472
    },
    {
      "source": "sZJNkorXMk",
      "target": "In practice",
      "similarity": 0.8431
    },
    {
      "source": "sZJNkorXMk",
      "target": "This method constrains the parameter space to low-dimensional pre-defined and",
      "similarity": 0.8428
    },
    {
      "source": "sZJNkorXMk",
      "target": "TrKRpaOk8y",
      "similarity": 0.8413
    },
    {
      "source": "However",
      "target": "This study highlights a major",
      "similarity": 0.8292
    },
    {
      "source": "However",
      "target": "On the other hand",
      "similarity": 0.8234
    },
    {
      "source": "However",
      "target": "Moreover",
      "similarity": 0.8169
    },
    {
      "source": "However",
      "target": "CtM5xjRSfm",
      "similarity": 0.7986
    },
    {
      "source": "However",
      "target": "pXlmOmlHJZ",
      "similarity": 0.7951
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8111
    },
    {
      "source": "In this paper",
      "target": "We compare our meta-Bayesian causal discovery against existing Bayesian causal discovery methods",
      "similarity": 0.8005
    },
    {
      "source": "In this paper",
      "target": "owP2mymrTD",
      "similarity": 0.7991
    },
    {
      "source": "In this paper",
      "target": "xGs7Ch3Vyo",
      "similarity": 0.7952
    },
    {
      "source": "In this paper",
      "target": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "similarity": 0.7923
    },
    {
      "source": "Specifically",
      "target": "To address this challenge",
      "similarity": 0.8086
    },
    {
      "source": "Specifically",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.8044
    },
    {
      "source": "Specifically",
      "target": "BUj9VSCoET",
      "similarity": 0.7945
    },
    {
      "source": "Specifically",
      "target": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "similarity": 0.7864
    },
    {
      "source": "Specifically",
      "target": "In response",
      "similarity": 0.7846
    },
    {
      "source": "xKDZAW0He3",
      "target": "space for $p > 1$",
      "similarity": 0.8269
    },
    {
      "source": "xKDZAW0He3",
      "target": "tive subcomponents within Transformer blocks",
      "similarity": 0.8269
    },
    {
      "source": "xKDZAW0He3",
      "target": "Aided Design (CAD) scripting code",
      "similarity": 0.8244
    },
    {
      "source": "xKDZAW0He3",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8226
    },
    {
      "source": "xKDZAW0He3",
      "target": "However",
      "similarity": 0.8148
    },
    {
      "source": "In this paper",
      "target": "NHhjczmJjo",
      "similarity": 0.8522
    },
    {
      "source": "In this paper",
      "target": "Yk87CwhBDx",
      "similarity": 0.846
    },
    {
      "source": "In this paper",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8415
    },
    {
      "source": "In this paper",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.841
    },
    {
      "source": "In this paper",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8405
    },
    {
      "source": "(2) The redundancy in natural language introduces noise",
      "target": "pDDODPtpx9",
      "similarity": 0.8539
    },
    {
      "source": "(2) The redundancy in natural language introduces noise",
      "target": "In this paper",
      "similarity": 0.8528
    },
    {
      "source": "(2) The redundancy in natural language introduces noise",
      "target": "instructions",
      "similarity": 0.8507
    },
    {
      "source": "(2) The redundancy in natural language introduces noise",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8502
    },
    {
      "source": "(2) The redundancy in natural language introduces noise",
      "target": "1qq1QJKM5q",
      "similarity": 0.8491
    },
    {
      "source": "Building on these insights",
      "target": "VpWki1v2P8",
      "similarity": 0.8983
    },
    {
      "source": "Building on these insights",
      "target": "To this end",
      "similarity": 0.8616
    },
    {
      "source": "Building on these insights",
      "target": "OhauMUNW8T",
      "similarity": 0.8567
    },
    {
      "source": "Building on these insights",
      "target": "Traditionally",
      "similarity": 0.856
    },
    {
      "source": "Building on these insights",
      "target": "1qGkuxI9UX",
      "similarity": 0.8527
    },
    {
      "source": "Experimental results show that **SeCom** outperforms turn-level",
      "target": "XdRIno98gG",
      "similarity": 0.851
    },
    {
      "source": "Experimental results show that **SeCom** outperforms turn-level",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8411
    },
    {
      "source": "Experimental results show that **SeCom** outperforms turn-level",
      "target": "However",
      "similarity": 0.8384
    },
    {
      "source": "Experimental results show that **SeCom** outperforms turn-level",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8333
    },
    {
      "source": "Experimental results show that **SeCom** outperforms turn-level",
      "target": "oDbiL9CLoS",
      "similarity": 0.8274
    },
    {
      "source": "XdRIno98gG",
      "target": "myYzr50xBh",
      "similarity": 0.8554
    },
    {
      "source": "XdRIno98gG",
      "target": "U3PBITXNG6",
      "similarity": 0.8478
    },
    {
      "source": "XdRIno98gG",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8442
    },
    {
      "source": "XdRIno98gG",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8401
    },
    {
      "source": "XdRIno98gG",
      "target": "P4XmKjXTrM",
      "similarity": 0.8376
    },
    {
      "source": "Although this approach simplifies data acquisition compared to supervised methods",
      "target": "Ij9ilPh36h",
      "similarity": 0.7906
    },
    {
      "source": "Although this approach simplifies data acquisition compared to supervised methods",
      "target": "rpouyo09V0",
      "similarity": 0.7894
    },
    {
      "source": "Although this approach simplifies data acquisition compared to supervised methods",
      "target": "mXHTifc1Fn",
      "similarity": 0.7886
    },
    {
      "source": "Although this approach simplifies data acquisition compared to supervised methods",
      "target": "This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a non-linear structure-preserving latent space and the associated low-dimensional dynamics.",
      "similarity": 0.7882
    },
    {
      "source": "Although this approach simplifies data acquisition compared to supervised methods",
      "target": "lS2SGfWizd",
      "similarity": 0.788
    },
    {
      "source": "To tackle this problem",
      "target": "Despite theoretically sound",
      "similarity": 0.8704
    },
    {
      "source": "To tackle this problem",
      "target": "However",
      "similarity": 0.8677
    },
    {
      "source": "To tackle this problem",
      "target": "tu3qwNjrtw",
      "similarity": 0.8583
    },
    {
      "source": "To tackle this problem",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.857
    },
    {
      "source": "To tackle this problem",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8559
    },
    {
      "source": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "target": "Bpn8q40n1n",
      "similarity": 0.8649
    },
    {
      "source": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "target": "This toolkit consists of 300 manually collected benign multimodal queries",
      "similarity": 0.8379
    },
    {
      "source": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "target": "M5t0WvjfCg",
      "similarity": 0.8378
    },
    {
      "source": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "target": "FEpAUnS7f7",
      "similarity": 0.8368
    },
    {
      "source": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "target": "UL2",
      "similarity": 0.8321
    },
    {
      "source": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8596
    },
    {
      "source": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "target": "xiQNfYl33p",
      "similarity": 0.8529
    },
    {
      "source": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "target": "Second",
      "similarity": 0.8505
    },
    {
      "source": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8446
    },
    {
      "source": "We also incorporate a reflection-aware knowledge distillation method that enables a student model to selectively learn the pixel-level knowledge from reflective and non-reflective regions. This results in robust depth estimation across areas.",
      "target": "q1UyoY3MgJ",
      "similarity": 0.8369
    },
    {
      "source": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "target": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "similarity": 0.8029
    },
    {
      "source": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "target": "b57IG6N20B",
      "similarity": 0.7899
    },
    {
      "source": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "target": "ZadnlOHsHv",
      "similarity": 0.7865
    },
    {
      "source": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "target": "Further",
      "similarity": 0.7827
    },
    {
      "source": "Evaluation results on multiple datasets demonstrate that our method effectively enhances depth quality on reflective surfaces and outperforms state-of-the-art SSMDE baselines.\"",
      "target": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "similarity": 0.7779
    },
    {
      "source": "VoI4d6uhdr",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8506
    },
    {
      "source": "VoI4d6uhdr",
      "target": "52x04chyQs",
      "similarity": 0.8502
    },
    {
      "source": "VoI4d6uhdr",
      "target": "In the more general context",
      "similarity": 0.849
    },
    {
      "source": "VoI4d6uhdr",
      "target": "Notably",
      "similarity": 0.8447
    },
    {
      "source": "VoI4d6uhdr",
      "target": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "similarity": 0.8406
    },
    {
      "source": "xDrFWUmCne",
      "target": "Additionally",
      "similarity": 0.7904
    },
    {
      "source": "xDrFWUmCne",
      "target": "Ij9ilPh36h",
      "similarity": 0.7886
    },
    {
      "source": "xDrFWUmCne",
      "target": "g6syfIrVuS",
      "similarity": 0.7833
    },
    {
      "source": "xDrFWUmCne",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.7824
    },
    {
      "source": "xDrFWUmCne",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.7803
    },
    {
      "source": "ih3BJmIZbC",
      "target": "ajSmXqgS24",
      "similarity": 0.8264
    },
    {
      "source": "ih3BJmIZbC",
      "target": "60GeEoG5kD",
      "similarity": 0.8217
    },
    {
      "source": "ih3BJmIZbC",
      "target": "wkbx7BRAsM",
      "similarity": 0.8123
    },
    {
      "source": "ih3BJmIZbC",
      "target": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "similarity": 0.8108
    },
    {
      "source": "ih3BJmIZbC",
      "target": "with up to 62\\% reduction in computation time",
      "similarity": 0.8107
    },
    {
      "source": "s9zoyICZ4k",
      "target": "uhaLuZcCjH",
      "similarity": 0.9013
    },
    {
      "source": "s9zoyICZ4k",
      "target": "the state-of-the-art private ANN search schemes",
      "similarity": 0.8849
    },
    {
      "source": "s9zoyICZ4k",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8765
    },
    {
      "source": "s9zoyICZ4k",
      "target": "To address these challenges",
      "similarity": 0.8698
    },
    {
      "source": "s9zoyICZ4k",
      "target": "non-private ANN algorithm.",
      "similarity": 0.8218
    },
    {
      "source": "WzCEiBILHu",
      "target": "SOTA LLMs",
      "similarity": 0.8826
    },
    {
      "source": "WzCEiBILHu",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8469
    },
    {
      "source": "WzCEiBILHu",
      "target": "In this task",
      "similarity": 0.8453
    },
    {
      "source": "WzCEiBILHu",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.844
    },
    {
      "source": "WzCEiBILHu",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8414
    },
    {
      "source": "eUEMjwh5wK",
      "target": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "similarity": 0.8317
    },
    {
      "source": "eUEMjwh5wK",
      "target": "Second",
      "similarity": 0.8164
    },
    {
      "source": "eUEMjwh5wK",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8124
    },
    {
      "source": "eUEMjwh5wK",
      "target": "All experimental resources",
      "similarity": 0.8124
    },
    {
      "source": "eUEMjwh5wK",
      "target": "7El7K1DoyX",
      "similarity": 0.8115
    },
    {
      "source": "J1J5eGJsKZ",
      "target": "uClUUJk05H",
      "similarity": 0.849
    },
    {
      "source": "J1J5eGJsKZ",
      "target": "L238BAx0wP",
      "similarity": 0.7795
    },
    {
      "source": "J1J5eGJsKZ",
      "target": "BPgK5XW1Nb",
      "similarity": 0.7789
    },
    {
      "source": "J1J5eGJsKZ",
      "target": "JV8zULNh24",
      "similarity": 0.7739
    },
    {
      "source": "J1J5eGJsKZ",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.7712
    },
    {
      "source": "eGqQyTAbXC",
      "target": "Y5LjYI4N6P",
      "similarity": 0.8652
    },
    {
      "source": "eGqQyTAbXC",
      "target": "6yENDA7J4G",
      "similarity": 0.8613
    },
    {
      "source": "eGqQyTAbXC",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8532
    },
    {
      "source": "eGqQyTAbXC",
      "target": "9KiE3t6CsL",
      "similarity": 0.8508
    },
    {
      "source": "eGqQyTAbXC",
      "target": "bRa4JLPzii",
      "similarity": 0.8463
    },
    {
      "source": "8y5Uf6oEiB",
      "target": "access to labeled test samples",
      "similarity": 0.8577
    },
    {
      "source": "8y5Uf6oEiB",
      "target": "HqjRlT65WX",
      "similarity": 0.8555
    },
    {
      "source": "8y5Uf6oEiB",
      "target": "cPD2hU35x3",
      "similarity": 0.8461
    },
    {
      "source": "8y5Uf6oEiB",
      "target": "PwxYoMvmvy",
      "similarity": 0.8418
    },
    {
      "source": "8y5Uf6oEiB",
      "target": "r5IXBlTCGc",
      "similarity": 0.8409
    },
    {
      "source": "GeUK3zGreN",
      "target": "U834XHJuqk",
      "similarity": 0.8708
    },
    {
      "source": "GeUK3zGreN",
      "target": "03OkC0LKDD",
      "similarity": 0.8312
    },
    {
      "source": "GeUK3zGreN",
      "target": "Moreover",
      "similarity": 0.825
    },
    {
      "source": "GeUK3zGreN",
      "target": "f7O3hITh5s",
      "similarity": 0.8146
    },
    {
      "source": "GeUK3zGreN",
      "target": "ZGqd0cbBvm",
      "similarity": 0.8089
    },
    {
      "source": "To remedy this problem",
      "target": "m8yby1JfbU",
      "similarity": 0.8564
    },
    {
      "source": "To remedy this problem",
      "target": "P4XmKjXTrM",
      "similarity": 0.8525
    },
    {
      "source": "To remedy this problem",
      "target": "fXb9BbuyAD",
      "similarity": 0.8499
    },
    {
      "source": "To remedy this problem",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8485
    },
    {
      "source": "To remedy this problem",
      "target": "To overcome such limitations",
      "similarity": 0.847
    },
    {
      "source": "S8gbnkCgxZ",
      "target": "Vanilla SFT (i.e.",
      "similarity": 0.828
    },
    {
      "source": "S8gbnkCgxZ",
      "target": "YslOW2SO6S",
      "similarity": 0.8245
    },
    {
      "source": "S8gbnkCgxZ",
      "target": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "similarity": 0.8077
    },
    {
      "source": "S8gbnkCgxZ",
      "target": "In addition",
      "similarity": 0.7941
    },
    {
      "source": "S8gbnkCgxZ",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.7925
    },
    {
      "source": "pRCOZllZdT",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8761
    },
    {
      "source": "pRCOZllZdT",
      "target": "jTEKTdI3K9",
      "similarity": 0.8647
    },
    {
      "source": "pRCOZllZdT",
      "target": "JSB171dSUU",
      "similarity": 0.8617
    },
    {
      "source": "pRCOZllZdT",
      "target": "For example",
      "similarity": 0.8612
    },
    {
      "source": "pRCOZllZdT",
      "target": "oYemKnlIrO",
      "similarity": 0.8577
    },
    {
      "source": "0fJfVOSUra",
      "target": "In this work",
      "similarity": 0.8943
    },
    {
      "source": "0fJfVOSUra",
      "target": "09FiNmvNMw",
      "similarity": 0.8905
    },
    {
      "source": "0fJfVOSUra",
      "target": "J9FgrqOOni",
      "similarity": 0.8833
    },
    {
      "source": "0fJfVOSUra",
      "target": "LqTz13JS2P",
      "similarity": 0.8762
    },
    {
      "source": "0fJfVOSUra",
      "target": "xsELpEPn4A",
      "similarity": 0.8643
    },
    {
      "source": "INe4otjryz",
      "target": "vRvVVb0NAz",
      "similarity": 0.8285
    },
    {
      "source": "INe4otjryz",
      "target": "Our findings show that ICL with transformers",
      "similarity": 0.7954
    },
    {
      "source": "INe4otjryz",
      "target": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "similarity": 0.7924
    },
    {
      "source": "INe4otjryz",
      "target": "However",
      "similarity": 0.791
    },
    {
      "source": "INe4otjryz",
      "target": "Our findings open promising directions for future research in sketch-to-diagram conversion and broader image-to-code generation tasks. SketikZ is publicly available.\"",
      "similarity": 0.7904
    },
    {
      "source": "EQgEMAD4kv",
      "target": "(1) make no assumptions on the data",
      "similarity": 0.902
    },
    {
      "source": "EQgEMAD4kv",
      "target": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "similarity": 0.9
    },
    {
      "source": "EQgEMAD4kv",
      "target": "For TP",
      "similarity": 0.8722
    },
    {
      "source": "EQgEMAD4kv",
      "target": "254NJe9JEw",
      "similarity": 0.8721
    },
    {
      "source": "EQgEMAD4kv",
      "target": "BI2int5SAC",
      "similarity": 0.8692
    },
    {
      "source": "CAKE assesses layer-specific preferences by considering attention dynamics in both spatial and temporal dimensions",
      "target": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "similarity": 0.8087
    },
    {
      "source": "CAKE assesses layer-specific preferences by considering attention dynamics in both spatial and temporal dimensions",
      "target": "ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3",
      "similarity": 0.8086
    },
    {
      "source": "CAKE assesses layer-specific preferences by considering attention dynamics in both spatial and temporal dimensions",
      "target": "44cMlQSreK",
      "similarity": 0.8048
    },
    {
      "source": "CAKE assesses layer-specific preferences by considering attention dynamics in both spatial and temporal dimensions",
      "target": "4JK2XMGUc8",
      "similarity": 0.7999
    },
    {
      "source": "CAKE assesses layer-specific preferences by considering attention dynamics in both spatial and temporal dimensions",
      "target": "Finally",
      "similarity": 0.7992
    },
    {
      "source": "CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time",
      "target": "fs2Z2z3GRx",
      "similarity": 0.8537
    },
    {
      "source": "CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time",
      "target": "xiQNfYl33p",
      "similarity": 0.849
    },
    {
      "source": "CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8456
    },
    {
      "source": "CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8454
    },
    {
      "source": "CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8439
    },
    {
      "source": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "target": "jTEKTdI3K9",
      "similarity": 0.8517
    },
    {
      "source": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8502
    },
    {
      "source": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "target": "v1rFkElnIn",
      "similarity": 0.8388
    },
    {
      "source": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "target": "9kJperA2a4",
      "similarity": 0.8371
    },
    {
      "source": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8332
    },
    {
      "source": "lvw3UgeVxS",
      "target": "h1XoHOd19I",
      "similarity": 0.8453
    },
    {
      "source": "lvw3UgeVxS",
      "target": "(1) *Multi-Frame Gain*",
      "similarity": 0.8415
    },
    {
      "source": "lvw3UgeVxS",
      "target": "By combining hot spot sampling with fragment-based extension",
      "similarity": 0.8356
    },
    {
      "source": "lvw3UgeVxS",
      "target": "a single GPU in a few hours",
      "similarity": 0.8297
    },
    {
      "source": "lvw3UgeVxS",
      "target": "Remarkably",
      "similarity": 0.8274
    },
    {
      "source": "kGvXIlIVLM",
      "target": "Furthermore",
      "similarity": 0.8292
    },
    {
      "source": "kGvXIlIVLM",
      "target": "propose to cache and reuse KV state of prompts. However",
      "similarity": 0.8146
    },
    {
      "source": "kGvXIlIVLM",
      "target": "To overcome this limitation",
      "similarity": 0.8114
    },
    {
      "source": "kGvXIlIVLM",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8088
    },
    {
      "source": "kGvXIlIVLM",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8064
    },
    {
      "source": "JytL2MrlLT",
      "target": "1CIUkpoata",
      "similarity": 0.9066
    },
    {
      "source": "JytL2MrlLT",
      "target": "wgRQ2WAORJ",
      "similarity": 0.87
    },
    {
      "source": "JytL2MrlLT",
      "target": "However",
      "similarity": 0.8696
    },
    {
      "source": "JytL2MrlLT",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8677
    },
    {
      "source": "JytL2MrlLT",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8658
    },
    {
      "source": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "target": "rCX9l4OTCT",
      "similarity": 0.859
    },
    {
      "source": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "target": "tpGkEgxMJT",
      "similarity": 0.8571
    },
    {
      "source": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "target": "tu3qwNjrtw",
      "similarity": 0.8535
    },
    {
      "source": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "target": "zxO4WuVGns",
      "similarity": 0.8525
    },
    {
      "source": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "target": "However",
      "similarity": 0.8525
    },
    {
      "source": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "target": "ERv8ptegFi",
      "similarity": 0.8459
    },
    {
      "source": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "target": "U3PBITXNG6",
      "similarity": 0.8437
    },
    {
      "source": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "target": "NKotdPUc3L",
      "similarity": 0.8402
    },
    {
      "source": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8395
    },
    {
      "source": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8374
    },
    {
      "source": "5btFIv2PNb",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8185
    },
    {
      "source": "5btFIv2PNb",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8144
    },
    {
      "source": "5btFIv2PNb",
      "target": "dmCGjPFVhF",
      "similarity": 0.8133
    },
    {
      "source": "5btFIv2PNb",
      "target": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "similarity": 0.813
    },
    {
      "source": "5btFIv2PNb",
      "target": "GhexuBLxbO",
      "similarity": 0.809
    },
    {
      "source": "GsR3zRCRX5",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.8226
    },
    {
      "source": "GsR3zRCRX5",
      "target": "hyfe5q5TD0",
      "similarity": 0.8199
    },
    {
      "source": "GsR3zRCRX5",
      "target": "Furthermore",
      "similarity": 0.8172
    },
    {
      "source": "GsR3zRCRX5",
      "target": "nx9Z5Kva96",
      "similarity": 0.8166
    },
    {
      "source": "GsR3zRCRX5",
      "target": "*if* and *when* investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 19 datasets",
      "similarity": 0.8146
    },
    {
      "source": "Iht4NNVqk0",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8214
    },
    {
      "source": "Iht4NNVqk0",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8174
    },
    {
      "source": "Iht4NNVqk0",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.8126
    },
    {
      "source": "Iht4NNVqk0",
      "target": "hJVdwBpWjt",
      "similarity": 0.8092
    },
    {
      "source": "Iht4NNVqk0",
      "target": "kNHVViEPWK",
      "similarity": 0.8069
    },
    {
      "source": "In this paper",
      "target": "0LSAmFCc4p",
      "similarity": 0.8216
    },
    {
      "source": "In this paper",
      "target": "7IzeL0kflu",
      "similarity": 0.8114
    },
    {
      "source": "In this paper",
      "target": "which",
      "similarity": 0.8076
    },
    {
      "source": "In this paper",
      "target": "Finally",
      "similarity": 0.8065
    },
    {
      "source": "In this paper",
      "target": "1H90Gb9rJ9",
      "similarity": 0.8055
    },
    {
      "source": "mNVR9jJYqK",
      "target": "FPQzXME9NK",
      "similarity": 0.8236
    },
    {
      "source": "mNVR9jJYqK",
      "target": "xiQNfYl33p",
      "similarity": 0.8078
    },
    {
      "source": "mNVR9jJYqK",
      "target": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "similarity": 0.8077
    },
    {
      "source": "mNVR9jJYqK",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.7996
    },
    {
      "source": "mNVR9jJYqK",
      "target": "h0ZfDIrj7T",
      "similarity": 0.7951
    },
    {
      "source": "9OMvtboTJg",
      "target": "XMgpnZ2ET7",
      "similarity": 0.8203
    },
    {
      "source": "9OMvtboTJg",
      "target": "yaQbTAD2JJ",
      "similarity": 0.814
    },
    {
      "source": "9OMvtboTJg",
      "target": "imprecise understanding of ground-truth features in realistic scenarios makes it",
      "similarity": 0.8075
    },
    {
      "source": "9OMvtboTJg",
      "target": "tU074jg2vS",
      "similarity": 0.8007
    },
    {
      "source": "9OMvtboTJg",
      "target": "5btFIv2PNb",
      "similarity": 0.8007
    },
    {
      "source": "TtKN1TpvUu",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.8431
    },
    {
      "source": "TtKN1TpvUu",
      "target": "FBhKUXK7od",
      "similarity": 0.8295
    },
    {
      "source": "TtKN1TpvUu",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.829
    },
    {
      "source": "TtKN1TpvUu",
      "target": "Bpn8q40n1n",
      "similarity": 0.8263
    },
    {
      "source": "TtKN1TpvUu",
      "target": "UL2",
      "similarity": 0.8201
    },
    {
      "source": "OZVTqoli2N",
      "target": "However",
      "similarity": 0.8297
    },
    {
      "source": "OZVTqoli2N",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.826
    },
    {
      "source": "OZVTqoli2N",
      "target": "0fJfVOSUra",
      "similarity": 0.8232
    },
    {
      "source": "OZVTqoli2N",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8194
    },
    {
      "source": "OZVTqoli2N",
      "target": "Specifically",
      "similarity": 0.8191
    },
    {
      "source": "tpYeermigp",
      "target": "BCP5nAHXqs",
      "similarity": 0.8651
    },
    {
      "source": "tpYeermigp",
      "target": "We perform detailed analyses",
      "similarity": 0.8457
    },
    {
      "source": "tpYeermigp",
      "target": "pPQPQ7Yd58",
      "similarity": 0.842
    },
    {
      "source": "tpYeermigp",
      "target": "fXb9BbuyAD",
      "similarity": 0.8324
    },
    {
      "source": "tpYeermigp",
      "target": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "similarity": 0.8302
    },
    {
      "source": "IxmWIkcKs5",
      "target": "Using this approach",
      "similarity": 0.8742
    },
    {
      "source": "IxmWIkcKs5",
      "target": "GySIAKEwtZ",
      "similarity": 0.8526
    },
    {
      "source": "IxmWIkcKs5",
      "target": "We propose RAMEN",
      "similarity": 0.8449
    },
    {
      "source": "IxmWIkcKs5",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8415
    },
    {
      "source": "IxmWIkcKs5",
      "target": "A conjecture by Hertrich",
      "similarity": 0.8322
    },
    {
      "source": "d16mJDyQN6",
      "target": "1F8xTfv6ah",
      "similarity": 0.8095
    },
    {
      "source": "d16mJDyQN6",
      "target": "Second",
      "similarity": 0.7983
    },
    {
      "source": "d16mJDyQN6",
      "target": "The experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks",
      "similarity": 0.7903
    },
    {
      "source": "d16mJDyQN6",
      "target": "While existing T2S distillation models address this limitation through $1$-step generation",
      "similarity": 0.7807
    },
    {
      "source": "d16mJDyQN6",
      "target": "reparametrization (e.g.",
      "similarity": 0.7742
    },
    {
      "source": "LYHEY783Np",
      "target": "In this work",
      "similarity": 0.8633
    },
    {
      "source": "LYHEY783Np",
      "target": "In this work",
      "similarity": 0.7998
    },
    {
      "source": "LYHEY783Np",
      "target": "nt8gBX58Kh",
      "similarity": 0.7964
    },
    {
      "source": "LYHEY783Np",
      "target": "1jcnvghayD",
      "similarity": 0.7951
    },
    {
      "source": "LYHEY783Np",
      "target": "Our novel resource",
      "similarity": 0.794
    },
    {
      "source": "j8WHjM9aMm",
      "target": "FBhKUXK7od",
      "similarity": 0.8468
    },
    {
      "source": "j8WHjM9aMm",
      "target": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "similarity": 0.8306
    },
    {
      "source": "j8WHjM9aMm",
      "target": "gFvRRCnQvX",
      "similarity": 0.8289
    },
    {
      "source": "j8WHjM9aMm",
      "target": "e8qXTxMgPg",
      "similarity": 0.8211
    },
    {
      "source": "j8WHjM9aMm",
      "target": "gkUyYcY1W9",
      "similarity": 0.8197
    },
    {
      "source": "TEmE9PSC65",
      "target": "These findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses",
      "similarity": 0.8238
    },
    {
      "source": "TEmE9PSC65",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8225
    },
    {
      "source": "TEmE9PSC65",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.8217
    },
    {
      "source": "TEmE9PSC65",
      "target": "IQxBDLmVpT",
      "similarity": 0.8126
    },
    {
      "source": "TEmE9PSC65",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.802
    },
    {
      "source": "FyMjfDQ9RO",
      "target": "For example",
      "similarity": 0.8852
    },
    {
      "source": "FyMjfDQ9RO",
      "target": "se4vjm7h4E",
      "similarity": 0.8747
    },
    {
      "source": "FyMjfDQ9RO",
      "target": "jTEKTdI3K9",
      "similarity": 0.8708
    },
    {
      "source": "FyMjfDQ9RO",
      "target": "Essg9kb4yx",
      "similarity": 0.8691
    },
    {
      "source": "FyMjfDQ9RO",
      "target": "pZiyCaVuti",
      "similarity": 0.8592
    },
    {
      "source": "GfXMTAJaxZ",
      "target": "PSiijdQjNU",
      "similarity": 0.8466
    },
    {
      "source": "GfXMTAJaxZ",
      "target": "GTcEe5fayC",
      "similarity": 0.8449
    },
    {
      "source": "GfXMTAJaxZ",
      "target": "In the more general context",
      "similarity": 0.8365
    },
    {
      "source": "GfXMTAJaxZ",
      "target": "cADpvQgnqg",
      "similarity": 0.8346
    },
    {
      "source": "GfXMTAJaxZ",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.8295
    },
    {
      "source": "8DBTq09LgN",
      "target": "xiQNfYl33p",
      "similarity": 0.8804
    },
    {
      "source": "8DBTq09LgN",
      "target": "QowsEic1sc",
      "similarity": 0.8557
    },
    {
      "source": "8DBTq09LgN",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8476
    },
    {
      "source": "8DBTq09LgN",
      "target": "hoYFLRNbhc",
      "similarity": 0.8458
    },
    {
      "source": "8DBTq09LgN",
      "target": "named Pacmann",
      "similarity": 0.8439
    },
    {
      "source": "SOWZ59UyNc",
      "target": "In this paper",
      "similarity": 0.8153
    },
    {
      "source": "SOWZ59UyNc",
      "target": "In $\\texttt{ProAdvPrompter}$",
      "similarity": 0.7916
    },
    {
      "source": "SOWZ59UyNc",
      "target": "performance gains. For instance",
      "similarity": 0.7894
    },
    {
      "source": "SOWZ59UyNc",
      "target": "HMrcv7Q4Ub",
      "similarity": 0.7889
    },
    {
      "source": "SOWZ59UyNc",
      "target": "To overcome such limitations",
      "similarity": 0.7834
    },
    {
      "source": "1CLzLXSFNn",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.792
    },
    {
      "source": "1CLzLXSFNn",
      "target": "We identify prototypical challenges that users face when specifying preferences",
      "similarity": 0.79
    },
    {
      "source": "1CLzLXSFNn",
      "target": "problem in interpretability. Sparse autoencoders (SAEs) have recently attracted",
      "similarity": 0.7778
    },
    {
      "source": "1CLzLXSFNn",
      "target": "a hypergraph",
      "similarity": 0.776
    },
    {
      "source": "1CLzLXSFNn",
      "target": "In this work",
      "similarity": 0.7757
    },
    {
      "source": "nsCOeCLR8e",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8278
    },
    {
      "source": "nsCOeCLR8e",
      "target": "B2Fqu7Y2cd",
      "similarity": 0.818
    },
    {
      "source": "nsCOeCLR8e",
      "target": "To fill this gap",
      "similarity": 0.8168
    },
    {
      "source": "nsCOeCLR8e",
      "target": "Nevertheless",
      "similarity": 0.8098
    },
    {
      "source": "nsCOeCLR8e",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8079
    },
    {
      "source": "1p6xFLBU4J",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8528
    },
    {
      "source": "1p6xFLBU4J",
      "target": "or after the model training. In this paper",
      "similarity": 0.8437
    },
    {
      "source": "1p6xFLBU4J",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8397
    },
    {
      "source": "1p6xFLBU4J",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8362
    },
    {
      "source": "1p6xFLBU4J",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8331
    },
    {
      "source": "sYNWqQYJhz",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.8231
    },
    {
      "source": "sYNWqQYJhz",
      "target": "L238BAx0wP",
      "similarity": 0.8226
    },
    {
      "source": "sYNWqQYJhz",
      "target": "FEpAUnS7f7",
      "similarity": 0.8221
    },
    {
      "source": "sYNWqQYJhz",
      "target": "3ogIALgghF",
      "similarity": 0.8175
    },
    {
      "source": "sYNWqQYJhz",
      "target": "understanding of LLMs' generalization capabilities.\"",
      "similarity": 0.8132
    },
    {
      "source": "1pXzC30ry5",
      "target": "with distinct prompts dedicated to each task for better representation learning. To properly select these task-specific components and mitigate potential feature shifts caused by misprediction",
      "similarity": 0.7925
    },
    {
      "source": "1pXzC30ry5",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.7901
    },
    {
      "source": "1pXzC30ry5",
      "target": "hoYFLRNbhc",
      "similarity": 0.7848
    },
    {
      "source": "1pXzC30ry5",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.7847
    },
    {
      "source": "1pXzC30ry5",
      "target": "CAssIgPN4I",
      "similarity": 0.7826
    },
    {
      "source": "However",
      "target": "Crucially",
      "similarity": 0.8121
    },
    {
      "source": "However",
      "target": "6wOmHdwCC4",
      "similarity": 0.7996
    },
    {
      "source": "However",
      "target": "Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge",
      "similarity": 0.7886
    },
    {
      "source": "However",
      "target": "Inspired by the expression of in-context learned capabilities through task vectors and the concept of modular capability or knowledge",
      "similarity": 0.7843
    },
    {
      "source": "However",
      "target": "dmCGjPFVhF",
      "similarity": 0.7812
    },
    {
      "source": "To explore real-time segmentation",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8443
    },
    {
      "source": "To explore real-time segmentation",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.843
    },
    {
      "source": "To explore real-time segmentation",
      "target": "bMC1t7eLRc",
      "similarity": 0.8425
    },
    {
      "source": "To explore real-time segmentation",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8406
    },
    {
      "source": "To explore real-time segmentation",
      "target": "VQwI055flA",
      "similarity": 0.8383
    },
    {
      "source": "Therefore",
      "target": "wWnsoLhHwt",
      "similarity": 0.8435
    },
    {
      "source": "Therefore",
      "target": "jTEKTdI3K9",
      "similarity": 0.8418
    },
    {
      "source": "Therefore",
      "target": "JSB171dSUU",
      "similarity": 0.8314
    },
    {
      "source": "Therefore",
      "target": "The best-performing model",
      "similarity": 0.8254
    },
    {
      "source": "Therefore",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.818
    },
    {
      "source": "It contains three fundamental sub-tasks: interactive segmentation",
      "target": "that",
      "similarity": 0.894
    },
    {
      "source": "It contains three fundamental sub-tasks: interactive segmentation",
      "target": "ULorFBST6X",
      "similarity": 0.8843
    },
    {
      "source": "It contains three fundamental sub-tasks: interactive segmentation",
      "target": "However",
      "similarity": 0.8603
    },
    {
      "source": "It contains three fundamental sub-tasks: interactive segmentation",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8437
    },
    {
      "source": "It contains three fundamental sub-tasks: interactive segmentation",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.839
    },
    {
      "source": "Unlike previous methods",
      "target": "J0qTpmbSbh",
      "similarity": 0.828
    },
    {
      "source": "Unlike previous methods",
      "target": "0uRc3CfJIQ",
      "similarity": 0.8221
    },
    {
      "source": "Unlike previous methods",
      "target": "real-world datasets than prior work and",
      "similarity": 0.7938
    },
    {
      "source": "Unlike previous methods",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.7844
    },
    {
      "source": "Unlike previous methods",
      "target": "GMwRl2e9Y1",
      "similarity": 0.7832
    },
    {
      "source": "To meet real-time requirements and balance multi-task learning",
      "target": "wSkvf2WyYz",
      "similarity": 0.8305
    },
    {
      "source": "To meet real-time requirements and balance multi-task learning",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8139
    },
    {
      "source": "To meet real-time requirements and balance multi-task learning",
      "target": "lS2SGfWizd",
      "similarity": 0.8105
    },
    {
      "source": "To meet real-time requirements and balance multi-task learning",
      "target": "N4NhVN30ph",
      "similarity": 0.8104
    },
    {
      "source": "To meet real-time requirements and balance multi-task learning",
      "target": "tQyh0gnfqW",
      "similarity": 0.8095
    },
    {
      "source": "It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding.",
      "target": "JYTQ6ELUVO",
      "similarity": 0.8393
    },
    {
      "source": "It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding.",
      "target": "EyaH1wzmao",
      "similarity": 0.835
    },
    {
      "source": "It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding.",
      "target": "bMC1t7eLRc",
      "similarity": 0.8319
    },
    {
      "source": "It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding.",
      "target": "AD5yx2xq8R",
      "similarity": 0.8319
    },
    {
      "source": "It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding.",
      "target": "Recent literature has focused on compressing the original weights or reducing the",
      "similarity": 0.8302
    },
    {
      "source": "Moreover",
      "target": "03OkC0LKDD",
      "similarity": 0.8412
    },
    {
      "source": "Moreover",
      "target": "contextual interactions among tasks",
      "similarity": 0.816
    },
    {
      "source": "Moreover",
      "target": "Notably",
      "similarity": 0.8143
    },
    {
      "source": "Moreover",
      "target": "This work presents Physics-Informed Experimental Design (PIED)",
      "similarity": 0.8142
    },
    {
      "source": "Moreover",
      "target": "hSZaCIznB2",
      "similarity": 0.8074
    },
    {
      "source": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "target": "JAMxRSXLFz",
      "similarity": 0.8646
    },
    {
      "source": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "target": "g0rnZeBguq",
      "similarity": 0.8616
    },
    {
      "source": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "target": "In response",
      "similarity": 0.8596
    },
    {
      "source": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "target": "254NJe9JEw",
      "similarity": 0.8585
    },
    {
      "source": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "target": "PHg4rAXFVH",
      "similarity": 0.8574
    },
    {
      "source": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "target": "position reveals interpretable low-rank structure across toy tasks",
      "similarity": 0.8394
    },
    {
      "source": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "target": "y9A2TpaGsE",
      "similarity": 0.8277
    },
    {
      "source": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "target": "WwwJfkGq0G",
      "similarity": 0.8255
    },
    {
      "source": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "target": "Other methods have focused on the low-budget regime",
      "similarity": 0.8209
    },
    {
      "source": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8206
    },
    {
      "source": "Our implementation of RMP-SAM achieves the optimal balance between accuracy and speed for these tasks. The code is released at",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8285
    },
    {
      "source": "Our implementation of RMP-SAM achieves the optimal balance between accuracy and speed for these tasks. The code is released at",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.8233
    },
    {
      "source": "Our implementation of RMP-SAM achieves the optimal balance between accuracy and speed for these tasks. The code is released at",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.815
    },
    {
      "source": "Our implementation of RMP-SAM achieves the optimal balance between accuracy and speed for these tasks. The code is released at",
      "target": "dRz3cizftU",
      "similarity": 0.8141
    },
    {
      "source": "Our implementation of RMP-SAM achieves the optimal balance between accuracy and speed for these tasks. The code is released at",
      "target": "KlN00vQEY2",
      "similarity": 0.8131
    },
    {
      "source": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "target": "HqjRlT65WX",
      "similarity": 0.8575
    },
    {
      "source": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "target": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "similarity": 0.8332
    },
    {
      "source": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "target": "FS2nukC2jv",
      "similarity": 0.8322
    },
    {
      "source": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "target": "We then propose deep Fourier features",
      "similarity": 0.8263
    },
    {
      "source": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.826
    },
    {
      "source": "fmJUYgmMbL",
      "target": "UVnD9Ze6mF",
      "similarity": 0.8521
    },
    {
      "source": "fmJUYgmMbL",
      "target": "gY08Ou8EL7",
      "similarity": 0.8347
    },
    {
      "source": "fmJUYgmMbL",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.8268
    },
    {
      "source": "fmJUYgmMbL",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8208
    },
    {
      "source": "fmJUYgmMbL",
      "target": "This paper introduces PANGEA",
      "similarity": 0.8183
    },
    {
      "source": "fNMKqyvuZT",
      "target": "Motivated by this observation",
      "similarity": 0.8896
    },
    {
      "source": "fNMKqyvuZT",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8835
    },
    {
      "source": "fNMKqyvuZT",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8761
    },
    {
      "source": "fNMKqyvuZT",
      "target": "Lut5t3qElA",
      "similarity": 0.8688
    },
    {
      "source": "fNMKqyvuZT",
      "target": "RAyRXQjsFl",
      "similarity": 0.8682
    },
    {
      "source": "PSiijdQjNU",
      "target": "an upper bound of excess risk on downstream classification tasks of representations",
      "similarity": 0.832
    },
    {
      "source": "PSiijdQjNU",
      "target": "60GeEoG5kD",
      "similarity": 0.8269
    },
    {
      "source": "PSiijdQjNU",
      "target": "GTcEe5fayC",
      "similarity": 0.8264
    },
    {
      "source": "PSiijdQjNU",
      "target": "wkbx7BRAsM",
      "similarity": 0.8228
    },
    {
      "source": "PSiijdQjNU",
      "target": "Our main contribution is to prove the exact computational complexities showing that languages allowing addition and marginalization (via the summation operator) yield NP^{PP}-",
      "similarity": 0.8164
    },
    {
      "source": "nYjAzwor9R",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8386
    },
    {
      "source": "nYjAzwor9R",
      "target": "kSdWcw5mkp",
      "similarity": 0.8352
    },
    {
      "source": "nYjAzwor9R",
      "target": "Crucially",
      "similarity": 0.8311
    },
    {
      "source": "nYjAzwor9R",
      "target": "jlhBFm7T2J",
      "similarity": 0.8283
    },
    {
      "source": "nYjAzwor9R",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8264
    },
    {
      "source": "Q150eWkQ4I",
      "target": "wide dissemination",
      "similarity": 0.8673
    },
    {
      "source": "Q150eWkQ4I",
      "target": "To develop SoundCTM",
      "similarity": 0.8586
    },
    {
      "source": "Q150eWkQ4I",
      "target": "named Pacmann",
      "similarity": 0.8584
    },
    {
      "source": "Q150eWkQ4I",
      "target": "zGzs5SIwT8",
      "similarity": 0.8483
    },
    {
      "source": "Q150eWkQ4I",
      "target": "VmJdqhuTCh",
      "similarity": 0.8469
    },
    {
      "source": "GhexuBLxbO",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8695
    },
    {
      "source": "GhexuBLxbO",
      "target": "R4h5PXzUuU",
      "similarity": 0.8442
    },
    {
      "source": "GhexuBLxbO",
      "target": "streaming model",
      "similarity": 0.8393
    },
    {
      "source": "GhexuBLxbO",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8363
    },
    {
      "source": "GhexuBLxbO",
      "target": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "similarity": 0.8323
    },
    {
      "source": "However",
      "target": "ogXkmugNZw",
      "similarity": 0.8535
    },
    {
      "source": "However",
      "target": "xjKz6IxgCX",
      "similarity": 0.8413
    },
    {
      "source": "However",
      "target": "K3KrOsR6y9",
      "similarity": 0.8405
    },
    {
      "source": "However",
      "target": "model weights",
      "similarity": 0.8376
    },
    {
      "source": "However",
      "target": "84WmbzikPP",
      "similarity": 0.8371
    },
    {
      "source": "This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation.",
      "target": "EjJGND0m1x",
      "similarity": 0.8082
    },
    {
      "source": "This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation.",
      "target": "However",
      "similarity": 0.799
    },
    {
      "source": "This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation.",
      "target": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "similarity": 0.7918
    },
    {
      "source": "This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation.",
      "target": "However",
      "similarity": 0.7909
    },
    {
      "source": "This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation.",
      "target": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "similarity": 0.786
    },
    {
      "source": "In this paper",
      "target": "9ca9eHNrdH",
      "similarity": 0.873
    },
    {
      "source": "In this paper",
      "target": "Motivated by this observation",
      "similarity": 0.8688
    },
    {
      "source": "In this paper",
      "target": "4GT9uTsAJE",
      "similarity": 0.8679
    },
    {
      "source": "In this paper",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.867
    },
    {
      "source": "In this paper",
      "target": "wSkvf2WyYz",
      "similarity": 0.8662
    },
    {
      "source": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "target": "VxvnV6slP0",
      "similarity": 0.8232
    },
    {
      "source": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "target": "gFvRRCnQvX",
      "similarity": 0.8138
    },
    {
      "source": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "target": "We evaluate nearly 40 reward models on RM-Bench.",
      "similarity": 0.8084
    },
    {
      "source": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "target": "ofuLWn8DFZ",
      "similarity": 0.8078
    },
    {
      "source": "Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance",
      "target": "xzSUdw6s76",
      "similarity": 0.806
    },
    {
      "source": "9QPH1YQCMn",
      "target": "Qja5s0K3VX",
      "similarity": 0.8532
    },
    {
      "source": "9QPH1YQCMn",
      "target": "JYwVijuNA7",
      "similarity": 0.8494
    },
    {
      "source": "9QPH1YQCMn",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8483
    },
    {
      "source": "9QPH1YQCMn",
      "target": "size in stages. We show that this approach not only generalizes prior works like",
      "similarity": 0.847
    },
    {
      "source": "9QPH1YQCMn",
      "target": "Additionally",
      "similarity": 0.8459
    },
    {
      "source": "VxvnV6slP0",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8222
    },
    {
      "source": "VxvnV6slP0",
      "target": "RQz7szbVDs",
      "similarity": 0.8092
    },
    {
      "source": "VxvnV6slP0",
      "target": "gFvRRCnQvX",
      "similarity": 0.8044
    },
    {
      "source": "VxvnV6slP0",
      "target": "L0evcuybH5",
      "similarity": 0.7985
    },
    {
      "source": "VxvnV6slP0",
      "target": "We evaluate nearly 40 reward models on RM-Bench.",
      "similarity": 0.7957
    },
    {
      "source": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8553
    },
    {
      "source": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "target": "Our experiments demonstrate that LongPackis highly scalable",
      "similarity": 0.8414
    },
    {
      "source": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "target": "In this paper",
      "similarity": 0.836
    },
    {
      "source": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "target": "BChpQU64RG",
      "similarity": 0.8325
    },
    {
      "source": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "target": "eGqQyTAbXC",
      "similarity": 0.8313
    },
    {
      "source": "rpouyo09V0",
      "target": "In the more general context",
      "similarity": 0.8076
    },
    {
      "source": "rpouyo09V0",
      "target": "Notably",
      "similarity": 0.8052
    },
    {
      "source": "rpouyo09V0",
      "target": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "similarity": 0.8018
    },
    {
      "source": "rpouyo09V0",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.7967
    },
    {
      "source": "rpouyo09V0",
      "target": "cADpvQgnqg",
      "similarity": 0.7956
    },
    {
      "source": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "target": "yLhJYvkKA0",
      "similarity": 0.8757
    },
    {
      "source": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8705
    },
    {
      "source": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "target": "c61unr33XA",
      "similarity": 0.8702
    },
    {
      "source": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "target": "{Subsequently}",
      "similarity": 0.8685
    },
    {
      "source": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8607
    },
    {
      "source": "nmvmPIi185",
      "target": "FBhKUXK7od",
      "similarity": 0.8224
    },
    {
      "source": "nmvmPIi185",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8104
    },
    {
      "source": "nmvmPIi185",
      "target": "G328D1xt4W",
      "similarity": 0.8094
    },
    {
      "source": "nmvmPIi185",
      "target": "tyEyYT267x",
      "similarity": 0.8064
    },
    {
      "source": "nmvmPIi185",
      "target": "our proposal matches or beats state-of-the-art performance in essentially all cases;",
      "similarity": 0.8023
    },
    {
      "source": "eW4yh6HKz4",
      "target": "First",
      "similarity": 0.8009
    },
    {
      "source": "eW4yh6HKz4",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8006
    },
    {
      "source": "eW4yh6HKz4",
      "target": "Finally",
      "similarity": 0.7975
    },
    {
      "source": "eW4yh6HKz4",
      "target": "TlAdgeoDTo",
      "similarity": 0.7973
    },
    {
      "source": "eW4yh6HKz4",
      "target": "Discoveries of such relations",
      "similarity": 0.792
    },
    {
      "source": "ogKE7LcvW6",
      "target": "pHOH8FVrTp",
      "similarity": 0.8015
    },
    {
      "source": "ogKE7LcvW6",
      "target": "v1rFkElnIn",
      "similarity": 0.8011
    },
    {
      "source": "ogKE7LcvW6",
      "target": "9kJperA2a4",
      "similarity": 0.8005
    },
    {
      "source": "ogKE7LcvW6",
      "target": "Comprehensive experiments on LongBench and NeedleBench show that CAKE maintains model performance with only 3.2\\% of the KV cache and consistently outperforms current baselines across various models and memory constraints",
      "similarity": 0.7993
    },
    {
      "source": "ogKE7LcvW6",
      "target": "9Ieq8jQNAl",
      "similarity": 0.7959
    },
    {
      "source": "O0sQ9CPzai",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.8236
    },
    {
      "source": "O0sQ9CPzai",
      "target": "However",
      "similarity": 0.8126
    },
    {
      "source": "O0sQ9CPzai",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8072
    },
    {
      "source": "O0sQ9CPzai",
      "target": "generating time series of tabular data",
      "similarity": 0.7997
    },
    {
      "source": "O0sQ9CPzai",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.7986
    },
    {
      "source": "unDQOUah0F",
      "target": "iVMcYxTiVM",
      "similarity": 0.8542
    },
    {
      "source": "unDQOUah0F",
      "target": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "similarity": 0.8367
    },
    {
      "source": "unDQOUah0F",
      "target": "Our experiments demonstrate that LongPackis highly scalable",
      "similarity": 0.8276
    },
    {
      "source": "unDQOUah0F",
      "target": "Second",
      "similarity": 0.8262
    },
    {
      "source": "unDQOUah0F",
      "target": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "similarity": 0.8235
    },
    {
      "source": "tasks in ways different than what text or static imagery can provide. However",
      "target": "However",
      "similarity": 0.7911
    },
    {
      "source": "tasks in ways different than what text or static imagery can provide. However",
      "target": "irrtPRFksw",
      "similarity": 0.791
    },
    {
      "source": "tasks in ways different than what text or static imagery can provide. However",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.7904
    },
    {
      "source": "tasks in ways different than what text or static imagery can provide. However",
      "target": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "similarity": 0.786
    },
    {
      "source": "tasks in ways different than what text or static imagery can provide. However",
      "target": "oZkqkkvdND",
      "similarity": 0.7854
    },
    {
      "source": "existing agent benchmarks neglect long-context video understanding",
      "target": "0fJfVOSUra",
      "similarity": 0.8639
    },
    {
      "source": "existing agent benchmarks neglect long-context video understanding",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.8598
    },
    {
      "source": "existing agent benchmarks neglect long-context video understanding",
      "target": "r01fcKhzT5",
      "similarity": 0.8574
    },
    {
      "source": "existing agent benchmarks neglect long-context video understanding",
      "target": "Furthermore",
      "similarity": 0.8532
    },
    {
      "source": "existing agent benchmarks neglect long-context video understanding",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8452
    },
    {
      "source": "ing on text or static image inputs. To bridge this gap",
      "target": "streaming model",
      "similarity": 0.8379
    },
    {
      "source": "ing on text or static image inputs. To bridge this gap",
      "target": "R4h5PXzUuU",
      "similarity": 0.8337
    },
    {
      "source": "ing on text or static image inputs. To bridge this gap",
      "target": "Although employing a cascaded pipeline introduces more stages",
      "similarity": 0.829
    },
    {
      "source": "ing on text or static image inputs. To bridge this gap",
      "target": "require resource-intensive iterative training and only needs a small amount of",
      "similarity": 0.8278
    },
    {
      "source": "ing on text or static image inputs. To bridge this gap",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8235
    },
    {
      "source": "(VideoWA)",
      "target": "70B-base from 8K to 128K tokens",
      "similarity": 0.8819
    },
    {
      "source": "(VideoWA)",
      "target": "C45YqeBDUM",
      "similarity": 0.8385
    },
    {
      "source": "(VideoWA)",
      "target": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "similarity": 0.8337
    },
    {
      "source": "(VideoWA)",
      "target": "KL8Sm4xRn7",
      "similarity": 0.8319
    },
    {
      "source": "(VideoWA)",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8318
    },
    {
      "source": "agents for video understanding. VideoWA consists of 2",
      "target": "In this work",
      "similarity": 0.8557
    },
    {
      "source": "agents for video understanding. VideoWA consists of 2",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8253
    },
    {
      "source": "agents for video understanding. VideoWA consists of 2",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8209
    },
    {
      "source": "agents for video understanding. VideoWA consists of 2",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8184
    },
    {
      "source": "agents for video understanding. VideoWA consists of 2",
      "target": "nrvoWOWcyg",
      "similarity": 0.8153
    },
    {
      "source": "on manually crafted video tutorials",
      "target": "4anfpHj0wf",
      "similarity": 0.8355
    },
    {
      "source": "on manually crafted video tutorials",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8285
    },
    {
      "source": "on manually crafted video tutorials",
      "target": "Second",
      "similarity": 0.8282
    },
    {
      "source": "on manually crafted video tutorials",
      "target": "kRBQwlkFSP",
      "similarity": 0.8267
    },
    {
      "source": "on manually crafted video tutorials",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8194
    },
    {
      "source": "our benchmark",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8532
    },
    {
      "source": "our benchmark",
      "target": "Dl3MsjaIdp",
      "similarity": 0.841
    },
    {
      "source": "our benchmark",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8344
    },
    {
      "source": "our benchmark",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8222
    },
    {
      "source": "our benchmark",
      "target": "1p6xFLBU4J",
      "similarity": 0.8217
    },
    {
      "source": "two main areas of focus: skill retention and factual retention. While skill retention",
      "target": "In addition",
      "similarity": 0.8714
    },
    {
      "source": "two main areas of focus: skill retention and factual retention. While skill retention",
      "target": "TDy5Ih78b4",
      "similarity": 0.8577
    },
    {
      "source": "two main areas of focus: skill retention and factual retention. While skill retention",
      "target": "SRpq5OBpED",
      "similarity": 0.8573
    },
    {
      "source": "two main areas of focus: skill retention and factual retention. While skill retention",
      "target": "t9lS1lX9FQ",
      "similarity": 0.8516
    },
    {
      "source": "two main areas of focus: skill retention and factual retention. While skill retention",
      "target": "1R5BcYS8EC",
      "similarity": 0.8494
    },
    {
      "source": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "target": "It contains three fundamental sub-tasks: interactive segmentation",
      "similarity": 0.8383
    },
    {
      "source": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "target": "ZJo6Radbqq",
      "similarity": 0.8374
    },
    {
      "source": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "target": "x1An5a3U9I",
      "similarity": 0.8373
    },
    {
      "source": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8352
    },
    {
      "source": "tasks evaluate whether an agent can use a given human demonstration to complete",
      "target": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "similarity": 0.8339
    },
    {
      "source": "a task efficiently",
      "target": "0fJfVOSUra",
      "similarity": 0.8569
    },
    {
      "source": "a task efficiently",
      "target": "(BoneMet) dataset",
      "similarity": 0.8477
    },
    {
      "source": "a task efficiently",
      "target": "Vector diagrams are essential for communicating complex ideas across various fields",
      "similarity": 0.833
    },
    {
      "source": "a task efficiently",
      "target": "r01fcKhzT5",
      "similarity": 0.8299
    },
    {
      "source": "a task efficiently",
      "target": "existing agent benchmarks neglect long-context video understanding",
      "similarity": 0.8268
    },
    {
      "source": "instruction-relevant information from a video to complete a task. We find that the",
      "target": "KlxK4ncqWZ",
      "similarity": 0.8633
    },
    {
      "source": "instruction-relevant information from a video to complete a task. We find that the",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8397
    },
    {
      "source": "instruction-relevant information from a video to complete a task. We find that the",
      "target": "9KiE3t6CsL",
      "similarity": 0.8372
    },
    {
      "source": "instruction-relevant information from a video to complete a task. We find that the",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8361
    },
    {
      "source": "instruction-relevant information from a video to complete a task. We find that the",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8282
    },
    {
      "source": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8414
    },
    {
      "source": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "target": "than prior private ANN schemes",
      "similarity": 0.8333
    },
    {
      "source": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "target": "*progress*: a change in the likelihood of producing a correct response in the future",
      "similarity": 0.8242
    },
    {
      "source": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "target": "Notably",
      "similarity": 0.8227
    },
    {
      "source": "best model achieves a 13.3% success rate on factual retention tasks and 45.8% on",
      "target": "We show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We have open-sourced our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling here: https://github.com/NX-AI/flashrnn\"",
      "similarity": 0.8223
    },
    {
      "source": "factual retention QA pairs\u2014far below human success rates of 73.9% and 79.3%",
      "target": "In this task",
      "similarity": 0.846
    },
    {
      "source": "factual retention QA pairs\u2014far below human success rates of 73.9% and 79.3%",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8426
    },
    {
      "source": "factual retention QA pairs\u2014far below human success rates of 73.9% and 79.3%",
      "target": "This paper introduces PANGEA",
      "similarity": 0.8408
    },
    {
      "source": "factual retention QA pairs\u2014far below human success rates of 73.9% and 79.3%",
      "target": "44hcrfzydU",
      "similarity": 0.8367
    },
    {
      "source": "factual retention QA pairs\u2014far below human success rates of 73.9% and 79.3%",
      "target": "zpENPcQSj1",
      "similarity": 0.8336
    },
    {
      "source": "respectively. On skill retention tasks",
      "target": "kbeX97jExm",
      "similarity": 0.8528
    },
    {
      "source": "respectively. On skill retention tasks",
      "target": "iXCeQ2m6vT",
      "similarity": 0.849
    },
    {
      "source": "respectively. On skill retention tasks",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8456
    },
    {
      "source": "respectively. On skill retention tasks",
      "target": "u2QdCiOgwA",
      "similarity": 0.8403
    },
    {
      "source": "respectively. On skill retention tasks",
      "target": "Neural methods have shown promising results for subgraph matching.",
      "similarity": 0.8389
    },
    {
      "source": "tutorials than without",
      "target": "jqmptcSNVG",
      "similarity": 0.8347
    },
    {
      "source": "tutorials than without",
      "target": "size in stages. We show that this approach not only generalizes prior works like",
      "similarity": 0.8311
    },
    {
      "source": "tutorials than without",
      "target": "Such an ability is well-suited for and often optimized by preference learning.",
      "similarity": 0.8304
    },
    {
      "source": "tutorials than without",
      "target": "Traditionally",
      "similarity": 0.8297
    },
    {
      "source": "tutorials than without",
      "target": "Second",
      "similarity": 0.8282
    },
    {
      "source": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "target": "Usklli4gMc",
      "similarity": 0.8562
    },
    {
      "source": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8559
    },
    {
      "source": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "target": "46xYl55hdc",
      "similarity": 0.8523
    },
    {
      "source": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "target": "d7pr2doXn3",
      "similarity": 0.8359
    },
    {
      "source": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "target": "sgbI8Pxwie",
      "similarity": 0.8304
    },
    {
      "source": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8478
    },
    {
      "source": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "target": "Q6PAnqYVpo",
      "similarity": 0.8476
    },
    {
      "source": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "target": "dataset. We provide theoretical analysis for our approach and demonstrate its",
      "similarity": 0.8345
    },
    {
      "source": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "target": "Our method uses pairs of out-of-distribution samples and random labels as secret *keys*",
      "similarity": 0.8312
    },
    {
      "source": "gaps in the agentic abilities of long-context multimodal models and provides as a",
      "target": "In this work",
      "similarity": 0.8305
    },
    {
      "source": "testbed for the future development of long-context video agents.\"",
      "target": "However",
      "similarity": 0.8543
    },
    {
      "source": "testbed for the future development of long-context video agents.\"",
      "target": "tractably condition on the constraint. To generate samples that satisfy the constraint",
      "similarity": 0.8475
    },
    {
      "source": "testbed for the future development of long-context video agents.\"",
      "target": "yUC8pU508S",
      "similarity": 0.8455
    },
    {
      "source": "testbed for the future development of long-context video agents.\"",
      "target": "a challenge",
      "similarity": 0.8445
    },
    {
      "source": "testbed for the future development of long-context video agents.\"",
      "target": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "similarity": 0.84
    },
    {
      "source": "zGzs5SIwT8",
      "target": "Utilizing VideoNIAH",
      "similarity": 0.8676
    },
    {
      "source": "zGzs5SIwT8",
      "target": "VoayJihXra",
      "similarity": 0.833
    },
    {
      "source": "zGzs5SIwT8",
      "target": "However",
      "similarity": 0.8284
    },
    {
      "source": "zGzs5SIwT8",
      "target": "This paper proposes",
      "similarity": 0.8253
    },
    {
      "source": "zGzs5SIwT8",
      "target": "wide dissemination",
      "similarity": 0.8244
    },
    {
      "source": "q5EZ7gKcnW",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8208
    },
    {
      "source": "q5EZ7gKcnW",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.8182
    },
    {
      "source": "q5EZ7gKcnW",
      "target": "kOJf7Dklyv",
      "similarity": 0.8062
    },
    {
      "source": "q5EZ7gKcnW",
      "target": "FEZOLWexPb",
      "similarity": 0.8058
    },
    {
      "source": "q5EZ7gKcnW",
      "target": "However",
      "similarity": 0.8033
    },
    {
      "source": "KlxK4ncqWZ",
      "target": "hoYFLRNbhc",
      "similarity": 0.8443
    },
    {
      "source": "KlxK4ncqWZ",
      "target": "In particular",
      "similarity": 0.8423
    },
    {
      "source": "KlxK4ncqWZ",
      "target": "LQzN6TRFg9",
      "similarity": 0.8414
    },
    {
      "source": "KlxK4ncqWZ",
      "target": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "similarity": 0.8411
    },
    {
      "source": "KlxK4ncqWZ",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8405
    },
    {
      "source": "ja4rpheN2n",
      "target": "S1Bv3068Xt",
      "similarity": 0.8334
    },
    {
      "source": "ja4rpheN2n",
      "target": "HqjRlT65WX",
      "similarity": 0.8258
    },
    {
      "source": "ja4rpheN2n",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8238
    },
    {
      "source": "ja4rpheN2n",
      "target": "eHehzSDUFp",
      "similarity": 0.8238
    },
    {
      "source": "ja4rpheN2n",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8206
    },
    {
      "source": "UN6Ik6OCx8",
      "target": "sEMJ1PLSZR",
      "similarity": 0.8434
    },
    {
      "source": "UN6Ik6OCx8",
      "target": "4ytRL3HJrq",
      "similarity": 0.8228
    },
    {
      "source": "UN6Ik6OCx8",
      "target": "Next",
      "similarity": 0.8226
    },
    {
      "source": "UN6Ik6OCx8",
      "target": "x1An5a3U9I",
      "similarity": 0.8196
    },
    {
      "source": "UN6Ik6OCx8",
      "target": "xI71dsS3o4",
      "similarity": 0.8184
    },
    {
      "source": "lS2SGfWizd",
      "target": "reaching 90\\% quality of a state-of-the-art",
      "similarity": 0.8492
    },
    {
      "source": "lS2SGfWizd",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8437
    },
    {
      "source": "lS2SGfWizd",
      "target": "that",
      "similarity": 0.843
    },
    {
      "source": "lS2SGfWizd",
      "target": "In this paper",
      "similarity": 0.8387
    },
    {
      "source": "lS2SGfWizd",
      "target": "Moreover",
      "similarity": 0.8361
    },
    {
      "source": "WLSrq1254E",
      "target": "we propose positive-unlabeled diffusion models",
      "similarity": 0.8851
    },
    {
      "source": "WLSrq1254E",
      "target": "7HEMpBTb3R",
      "similarity": 0.8658
    },
    {
      "source": "WLSrq1254E",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8652
    },
    {
      "source": "WLSrq1254E",
      "target": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "similarity": 0.8547
    },
    {
      "source": "WLSrq1254E",
      "target": "WCRQFlji2q",
      "similarity": 0.8533
    },
    {
      "source": "2pNLknCTvG",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8678
    },
    {
      "source": "2pNLknCTvG",
      "target": "real-world datasets than prior work and",
      "similarity": 0.8639
    },
    {
      "source": "2pNLknCTvG",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.862
    },
    {
      "source": "2pNLknCTvG",
      "target": "zpENPcQSj1",
      "similarity": 0.8607
    },
    {
      "source": "2pNLknCTvG",
      "target": "First",
      "similarity": 0.8601
    },
    {
      "source": "To be precise",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8193
    },
    {
      "source": "To be precise",
      "target": "Moreover",
      "similarity": 0.8191
    },
    {
      "source": "To be precise",
      "target": "97rOQDPmk2",
      "similarity": 0.815
    },
    {
      "source": "To be precise",
      "target": "ogXkmugNZw",
      "similarity": 0.814
    },
    {
      "source": "To be precise",
      "target": "Ian00SaFHg",
      "similarity": 0.8102
    },
    {
      "source": "bNVbOS3lrl",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.8593
    },
    {
      "source": "bNVbOS3lrl",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8517
    },
    {
      "source": "bNVbOS3lrl",
      "target": "Finally",
      "similarity": 0.8492
    },
    {
      "source": "bNVbOS3lrl",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8453
    },
    {
      "source": "bNVbOS3lrl",
      "target": "i7jAYFYDcM",
      "similarity": 0.8446
    },
    {
      "source": "cZWCjan02B",
      "target": "prefix distributions",
      "similarity": 0.8934
    },
    {
      "source": "cZWCjan02B",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8785
    },
    {
      "source": "cZWCjan02B",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8619
    },
    {
      "source": "cZWCjan02B",
      "target": "We perform detailed analyses",
      "similarity": 0.8564
    },
    {
      "source": "cZWCjan02B",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8517
    },
    {
      "source": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "target": "HqjRlT65WX",
      "similarity": 0.8549
    },
    {
      "source": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "target": "Additionally",
      "similarity": 0.8417
    },
    {
      "source": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "target": "5xSRg3eYZz",
      "similarity": 0.8407
    },
    {
      "source": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "target": "than existing search techniques",
      "similarity": 0.8382
    },
    {
      "source": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8332
    },
    {
      "source": "JMPOqoe4tl",
      "target": "uClUUJk05H",
      "similarity": 0.8536
    },
    {
      "source": "JMPOqoe4tl",
      "target": "BPgK5XW1Nb",
      "similarity": 0.8346
    },
    {
      "source": "JMPOqoe4tl",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.8273
    },
    {
      "source": "JMPOqoe4tl",
      "target": "EDoD3DgivF",
      "similarity": 0.8194
    },
    {
      "source": "JMPOqoe4tl",
      "target": "Third",
      "similarity": 0.8123
    },
    {
      "source": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "target": "To address these challenges",
      "similarity": 0.8839
    },
    {
      "source": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "target": "the state-of-the-art private ANN search schemes",
      "similarity": 0.8751
    },
    {
      "source": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "target": "uhaLuZcCjH",
      "similarity": 0.8743
    },
    {
      "source": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "target": "BChpQU64RG",
      "similarity": 0.8441
    },
    {
      "source": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "target": "0iscEAo2xB",
      "similarity": 0.8407
    },
    {
      "source": "In particular",
      "target": "zXCnIyX9MG",
      "similarity": 0.8138
    },
    {
      "source": "In particular",
      "target": "PgXpOOqtyd",
      "similarity": 0.8086
    },
    {
      "source": "In particular",
      "target": "evaluate the current state-of-the-art deep learning models and Numerical Weather",
      "similarity": 0.8033
    },
    {
      "source": "In particular",
      "target": "gLa96FlWwn",
      "similarity": 0.7972
    },
    {
      "source": "In particular",
      "target": "spDUv05cEq",
      "similarity": 0.789
    },
    {
      "source": "However",
      "target": "reZKq6hjOZ",
      "similarity": 0.8337
    },
    {
      "source": "However",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8274
    },
    {
      "source": "However",
      "target": "G328D1xt4W",
      "similarity": 0.8267
    },
    {
      "source": "However",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8145
    },
    {
      "source": "However",
      "target": "jlhBFm7T2J",
      "similarity": 0.8034
    },
    {
      "source": "In this work",
      "target": "In this paper",
      "similarity": 0.8466
    },
    {
      "source": "In this work",
      "target": "ScVnYBaSEw",
      "similarity": 0.8383
    },
    {
      "source": "In this work",
      "target": "DpLFmc09pC",
      "similarity": 0.8283
    },
    {
      "source": "In this work",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8221
    },
    {
      "source": "In this work",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8189
    },
    {
      "source": "Extensive evaluations using MNIST",
      "target": "xiQNfYl33p",
      "similarity": 0.8349
    },
    {
      "source": "Extensive evaluations using MNIST",
      "target": "nibeaHUEJx",
      "similarity": 0.8298
    },
    {
      "source": "Extensive evaluations using MNIST",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8227
    },
    {
      "source": "Extensive evaluations using MNIST",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8225
    },
    {
      "source": "Extensive evaluations using MNIST",
      "target": "dEg5SdGaiq",
      "similarity": 0.8203
    },
    {
      "source": "p4cLtzk4oe",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8706
    },
    {
      "source": "p4cLtzk4oe",
      "target": "zCZnEXF3bN",
      "similarity": 0.8699
    },
    {
      "source": "p4cLtzk4oe",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8654
    },
    {
      "source": "p4cLtzk4oe",
      "target": "E4LAVLXAHW",
      "similarity": 0.8645
    },
    {
      "source": "p4cLtzk4oe",
      "target": "YFxfcQMLWX",
      "similarity": 0.8637
    },
    {
      "source": "N0ETIi580T",
      "target": "with compression rates of 25-30%. The compression process can be completed on",
      "similarity": 0.8581
    },
    {
      "source": "N0ETIi580T",
      "target": "TYSQYx9vwd",
      "similarity": 0.8368
    },
    {
      "source": "N0ETIi580T",
      "target": "zxO4WuVGns",
      "similarity": 0.8341
    },
    {
      "source": "N0ETIi580T",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8331
    },
    {
      "source": "N0ETIi580T",
      "target": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "similarity": 0.8291
    },
    {
      "source": "access to labeled test samples",
      "target": "cPD2hU35x3",
      "similarity": 0.8358
    },
    {
      "source": "access to labeled test samples",
      "target": "OuLgaHEmzi",
      "similarity": 0.8349
    },
    {
      "source": "access to labeled test samples",
      "target": "works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a model-free",
      "similarity": 0.8344
    },
    {
      "source": "access to labeled test samples",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8332
    },
    {
      "source": "access to labeled test samples",
      "target": "r5IXBlTCGc",
      "similarity": 0.8273
    },
    {
      "source": "CvjXlsBLCX",
      "target": "h0ZfDIrj7T",
      "similarity": 0.817
    },
    {
      "source": "CvjXlsBLCX",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8121
    },
    {
      "source": "CvjXlsBLCX",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8106
    },
    {
      "source": "CvjXlsBLCX",
      "target": "H9UnNgdq0g",
      "similarity": 0.8079
    },
    {
      "source": "CvjXlsBLCX",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.807
    },
    {
      "source": "FXw0okNcOb",
      "target": "Qja5s0K3VX",
      "similarity": 0.8682
    },
    {
      "source": "FXw0okNcOb",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.86
    },
    {
      "source": "FXw0okNcOb",
      "target": "tDIL7UXmSS",
      "similarity": 0.8597
    },
    {
      "source": "FXw0okNcOb",
      "target": "EyaH1wzmao",
      "similarity": 0.8494
    },
    {
      "source": "FXw0okNcOb",
      "target": "1qq1QJKM5q",
      "similarity": 0.8469
    },
    {
      "source": "sEMJ1PLSZR",
      "target": "comprehensive experiments",
      "similarity": 0.8388
    },
    {
      "source": "sEMJ1PLSZR",
      "target": "PY56Wur7S0",
      "similarity": 0.8118
    },
    {
      "source": "sEMJ1PLSZR",
      "target": "To address this",
      "similarity": 0.8096
    },
    {
      "source": "sEMJ1PLSZR",
      "target": "Next",
      "similarity": 0.8076
    },
    {
      "source": "sEMJ1PLSZR",
      "target": "In this paper",
      "similarity": 0.806
    },
    {
      "source": "Lut5t3qElA",
      "target": "{Subsequently}",
      "similarity": 0.8812
    },
    {
      "source": "Lut5t3qElA",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8789
    },
    {
      "source": "Lut5t3qElA",
      "target": "yLhJYvkKA0",
      "similarity": 0.8731
    },
    {
      "source": "Lut5t3qElA",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8668
    },
    {
      "source": "Lut5t3qElA",
      "target": "nDTvP6tBMd",
      "similarity": 0.8662
    },
    {
      "source": "nYPuSzGE3X",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8395
    },
    {
      "source": "nYPuSzGE3X",
      "target": "qIbbBSzH6n",
      "similarity": 0.8328
    },
    {
      "source": "nYPuSzGE3X",
      "target": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "similarity": 0.8306
    },
    {
      "source": "nYPuSzGE3X",
      "target": "xnF2U0ro7b",
      "similarity": 0.8301
    },
    {
      "source": "nYPuSzGE3X",
      "target": "In this paper",
      "similarity": 0.8293
    },
    {
      "source": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "target": "In contrast",
      "similarity": 0.8601
    },
    {
      "source": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "target": "h1XoHOd19I",
      "similarity": 0.8529
    },
    {
      "source": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "target": "NGKQoaqLpo",
      "similarity": 0.8443
    },
    {
      "source": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "target": "In addition",
      "similarity": 0.844
    },
    {
      "source": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8426
    },
    {
      "source": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "target": "L5godAOC2z",
      "similarity": 0.8157
    },
    {
      "source": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8096
    },
    {
      "source": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "target": "we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time",
      "similarity": 0.809
    },
    {
      "source": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "target": "fN8yLc3eA7",
      "similarity": 0.8041
    },
    {
      "source": "In order to decode the complex knowledge of multiple properties in the inversion path",
      "target": "VIUisLx8lQ",
      "similarity": 0.8005
    },
    {
      "source": "Additionally",
      "target": "Mjn53GtMxi",
      "similarity": 0.8568
    },
    {
      "source": "Additionally",
      "target": "AcVpLS86RT",
      "similarity": 0.8561
    },
    {
      "source": "Additionally",
      "target": "In this task",
      "similarity": 0.85
    },
    {
      "source": "Additionally",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8489
    },
    {
      "source": "Additionally",
      "target": "Due to the high costs of setting up and running experiments",
      "similarity": 0.8427
    },
    {
      "source": "4xWQS2z77v",
      "target": "Moreover",
      "similarity": 0.863
    },
    {
      "source": "4xWQS2z77v",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8622
    },
    {
      "source": "4xWQS2z77v",
      "target": "In this paper",
      "similarity": 0.8593
    },
    {
      "source": "4xWQS2z77v",
      "target": "74vnDs1R97",
      "similarity": 0.8573
    },
    {
      "source": "4xWQS2z77v",
      "target": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "similarity": 0.8531
    },
    {
      "source": "BChpQU64RG",
      "target": "In this paper",
      "similarity": 0.8234
    },
    {
      "source": "BChpQU64RG",
      "target": "4iFSBgxvIO",
      "similarity": 0.8127
    },
    {
      "source": "BChpQU64RG",
      "target": "6yENDA7J4G",
      "similarity": 0.8119
    },
    {
      "source": "BChpQU64RG",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.8117
    },
    {
      "source": "BChpQU64RG",
      "target": "eGqQyTAbXC",
      "similarity": 0.8027
    },
    {
      "source": "AoraWUmpLU",
      "target": "OL44KtasKc",
      "similarity": 0.7984
    },
    {
      "source": "AoraWUmpLU",
      "target": "xzSUdw6s76",
      "similarity": 0.7973
    },
    {
      "source": "AoraWUmpLU",
      "target": "It was numerically observed that the linear interpolation",
      "similarity": 0.7881
    },
    {
      "source": "AoraWUmpLU",
      "target": "Rz0kozh3LE",
      "similarity": 0.7863
    },
    {
      "source": "AoraWUmpLU",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.7826
    },
    {
      "source": "Fs9EabmQrJ",
      "target": "In this paper",
      "similarity": 0.8369
    },
    {
      "source": "Fs9EabmQrJ",
      "target": "pDDODPtpx9",
      "similarity": 0.8296
    },
    {
      "source": "Fs9EabmQrJ",
      "target": "Based on the observations",
      "similarity": 0.8263
    },
    {
      "source": "Fs9EabmQrJ",
      "target": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "similarity": 0.8219
    },
    {
      "source": "Fs9EabmQrJ",
      "target": "7El7K1DoyX",
      "similarity": 0.8204
    },
    {
      "source": "RTHbao4Mib",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.7887
    },
    {
      "source": "RTHbao4Mib",
      "target": "AAXBfJNHDt",
      "similarity": 0.7883
    },
    {
      "source": "RTHbao4Mib",
      "target": "INqLJwqUmc",
      "similarity": 0.7731
    },
    {
      "source": "RTHbao4Mib",
      "target": "ScVnYBaSEw",
      "similarity": 0.7706
    },
    {
      "source": "RTHbao4Mib",
      "target": "uy4EavBEwl",
      "similarity": 0.7702
    },
    {
      "source": "5YbuOTUFQ4",
      "target": "We propose RAMEN",
      "similarity": 0.844
    },
    {
      "source": "5YbuOTUFQ4",
      "target": "DpLFmc09pC",
      "similarity": 0.8298
    },
    {
      "source": "5YbuOTUFQ4",
      "target": "Xj66fkrlTk",
      "similarity": 0.8279
    },
    {
      "source": "5YbuOTUFQ4",
      "target": "GySIAKEwtZ",
      "similarity": 0.8278
    },
    {
      "source": "5YbuOTUFQ4",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8268
    },
    {
      "source": "kNHVViEPWK",
      "target": "which",
      "similarity": 0.8325
    },
    {
      "source": "kNHVViEPWK",
      "target": "sound",
      "similarity": 0.8206
    },
    {
      "source": "kNHVViEPWK",
      "target": "However",
      "similarity": 0.8184
    },
    {
      "source": "kNHVViEPWK",
      "target": "In offline evaluations",
      "similarity": 0.8184
    },
    {
      "source": "kNHVViEPWK",
      "target": "UL2",
      "similarity": 0.816
    },
    {
      "source": "DhHIw9Nbl1",
      "target": "4JK2XMGUc8",
      "similarity": 0.8592
    },
    {
      "source": "DhHIw9Nbl1",
      "target": "NHhjczmJjo",
      "similarity": 0.8565
    },
    {
      "source": "DhHIw9Nbl1",
      "target": "Finally",
      "similarity": 0.8517
    },
    {
      "source": "DhHIw9Nbl1",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8509
    },
    {
      "source": "DhHIw9Nbl1",
      "target": "To address these challenges",
      "similarity": 0.8476
    },
    {
      "source": "YOc5t8PHf2",
      "target": "wide dissemination",
      "similarity": 0.8179
    },
    {
      "source": "YOc5t8PHf2",
      "target": "To overcome those challenges",
      "similarity": 0.8159
    },
    {
      "source": "YOc5t8PHf2",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8086
    },
    {
      "source": "YOc5t8PHf2",
      "target": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "similarity": 0.8084
    },
    {
      "source": "YOc5t8PHf2",
      "target": "yORSk4Ycsa",
      "similarity": 0.8079
    },
    {
      "source": "Reducing the number of layers can decrease this delay",
      "target": "Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.",
      "similarity": 0.827
    },
    {
      "source": "Reducing the number of layers can decrease this delay",
      "target": "with compression rates of 25-30%. The compression process can be completed on",
      "similarity": 0.8099
    },
    {
      "source": "Reducing the number of layers can decrease this delay",
      "target": "effectiveness through experiments on various representative benchmarks. With an",
      "similarity": 0.8052
    },
    {
      "source": "Reducing the number of layers can decrease this delay",
      "target": "aVfDrl7xDV",
      "similarity": 0.8023
    },
    {
      "source": "Reducing the number of layers can decrease this delay",
      "target": "vl7kf0YHwj",
      "similarity": 0.8013
    },
    {
      "source": "x33vSZUg0A",
      "target": "FrFQpAgnGE",
      "similarity": 0.8448
    },
    {
      "source": "x33vSZUg0A",
      "target": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "similarity": 0.8378
    },
    {
      "source": "x33vSZUg0A",
      "target": "We release models",
      "similarity": 0.8334
    },
    {
      "source": "x33vSZUg0A",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8321
    },
    {
      "source": "x33vSZUg0A",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8317
    },
    {
      "source": "gFvRRCnQvX",
      "target": "cC3LxGZasH",
      "similarity": 0.8744
    },
    {
      "source": "gFvRRCnQvX",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8721
    },
    {
      "source": "gFvRRCnQvX",
      "target": "in reinforcement learning (RL)",
      "similarity": 0.8582
    },
    {
      "source": "gFvRRCnQvX",
      "target": "To address this issue",
      "similarity": 0.8556
    },
    {
      "source": "gFvRRCnQvX",
      "target": "4JK2XMGUc8",
      "similarity": 0.8524
    },
    {
      "source": "cKlzKs3Nnb",
      "target": "PxlfzEePC0",
      "similarity": 0.867
    },
    {
      "source": "cKlzKs3Nnb",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8584
    },
    {
      "source": "cKlzKs3Nnb",
      "target": "reaching 90\\% quality of a state-of-the-art",
      "similarity": 0.8553
    },
    {
      "source": "cKlzKs3Nnb",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8537
    },
    {
      "source": "cKlzKs3Nnb",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8532
    },
    {
      "source": "U3PBITXNG6",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8865
    },
    {
      "source": "U3PBITXNG6",
      "target": "Finally",
      "similarity": 0.8682
    },
    {
      "source": "U3PBITXNG6",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8678
    },
    {
      "source": "U3PBITXNG6",
      "target": "zd0iX5xBhA",
      "similarity": 0.8661
    },
    {
      "source": "U3PBITXNG6",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8659
    },
    {
      "source": "However",
      "target": "rWQDzq3O5c",
      "similarity": 0.844
    },
    {
      "source": "However",
      "target": "wSkvf2WyYz",
      "similarity": 0.8391
    },
    {
      "source": "However",
      "target": "tj5xJInWty",
      "similarity": 0.8307
    },
    {
      "source": "However",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8296
    },
    {
      "source": "However",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8286
    },
    {
      "source": "3E8YNv1HjU",
      "target": "IDJUscOjM3",
      "similarity": 0.8788
    },
    {
      "source": "3E8YNv1HjU",
      "target": "IuU0wcO0mo",
      "similarity": 0.8718
    },
    {
      "source": "3E8YNv1HjU",
      "target": "pDDODPtpx9",
      "similarity": 0.8697
    },
    {
      "source": "3E8YNv1HjU",
      "target": "In this paper",
      "similarity": 0.8685
    },
    {
      "source": "3E8YNv1HjU",
      "target": "VpWki1v2P8",
      "similarity": 0.868
    },
    {
      "source": "3Z2flzXzBY",
      "target": "bSq0XGS3kW",
      "similarity": 0.8838
    },
    {
      "source": "3Z2flzXzBY",
      "target": "other baselines across all metrics",
      "similarity": 0.8693
    },
    {
      "source": "3Z2flzXzBY",
      "target": "Following the derived guidelines",
      "similarity": 0.854
    },
    {
      "source": "3Z2flzXzBY",
      "target": "avSocG0oFA",
      "similarity": 0.8494
    },
    {
      "source": "3Z2flzXzBY",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8453
    },
    {
      "source": "LgzRo1RpLS",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.8142
    },
    {
      "source": "LgzRo1RpLS",
      "target": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "similarity": 0.8018
    },
    {
      "source": "LgzRo1RpLS",
      "target": "introduce a novel inductive graph framework",
      "similarity": 0.8014
    },
    {
      "source": "LgzRo1RpLS",
      "target": "constraints and dynamics",
      "similarity": 0.7984
    },
    {
      "source": "LgzRo1RpLS",
      "target": "cfKZ5VrhXt",
      "similarity": 0.7984
    },
    {
      "source": "Using this approach",
      "target": "254NJe9JEw",
      "similarity": 0.868
    },
    {
      "source": "Using this approach",
      "target": "TArmA033BU",
      "similarity": 0.8641
    },
    {
      "source": "Using this approach",
      "target": "eiqrnVaeIw",
      "similarity": 0.86
    },
    {
      "source": "Using this approach",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8587
    },
    {
      "source": "Using this approach",
      "target": "YFxfcQMLWX",
      "similarity": 0.8564
    },
    {
      "source": "LQzN6TRFg9",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8576
    },
    {
      "source": "LQzN6TRFg9",
      "target": "9KiE3t6CsL",
      "similarity": 0.8559
    },
    {
      "source": "LQzN6TRFg9",
      "target": "Furthermore",
      "similarity": 0.8482
    },
    {
      "source": "LQzN6TRFg9",
      "target": "Kwo20MWWCb",
      "similarity": 0.8479
    },
    {
      "source": "LQzN6TRFg9",
      "target": "yIlyHJdYV3",
      "similarity": 0.8444
    },
    {
      "source": "Previous video generation models often struggled with limited motion and short durations.",
      "target": "dOAkHmsjRX",
      "similarity": 0.8722
    },
    {
      "source": "Previous video generation models often struggled with limited motion and short durations.",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8709
    },
    {
      "source": "Previous video generation models often struggled with limited motion and short durations.",
      "target": "instructions",
      "similarity": 0.8682
    },
    {
      "source": "Previous video generation models often struggled with limited motion and short durations.",
      "target": "3E8YNv1HjU",
      "similarity": 0.867
    },
    {
      "source": "Previous video generation models often struggled with limited motion and short durations.",
      "target": "IuU0wcO0mo",
      "similarity": 0.8614
    },
    {
      "source": "It is especially difficult to generate videos with coherent narratives based on text.",
      "target": "lgsyLSsDRe",
      "similarity": 0.8469
    },
    {
      "source": "It is especially difficult to generate videos with coherent narratives based on text.",
      "target": "(including gradient-based",
      "similarity": 0.824
    },
    {
      "source": "It is especially difficult to generate videos with coherent narratives based on text.",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8197
    },
    {
      "source": "It is especially difficult to generate videos with coherent narratives based on text.",
      "target": "Validated using our collected college-level circuit analysis problems",
      "similarity": 0.817
    },
    {
      "source": "It is especially difficult to generate videos with coherent narratives based on text.",
      "target": "We further showcase our models on Bayesian optimisation problems on manifolds",
      "similarity": 0.8169
    },
    {
      "source": "We propose several designs to address these issues.",
      "target": "approximation",
      "similarity": 0.8517
    },
    {
      "source": "We propose several designs to address these issues.",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8482
    },
    {
      "source": "We propose several designs to address these issues.",
      "target": "wNobG8bV5Q",
      "similarity": 0.8471
    },
    {
      "source": "We propose several designs to address these issues.",
      "target": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "similarity": 0.8469
    },
    {
      "source": "We propose several designs to address these issues.",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8414
    },
    {
      "source": "First",
      "target": "HqjRlT65WX",
      "similarity": 0.8524
    },
    {
      "source": "First",
      "target": "KAIqwkB3dT",
      "similarity": 0.8502
    },
    {
      "source": "First",
      "target": "S1Bv3068Xt",
      "similarity": 0.8492
    },
    {
      "source": "First",
      "target": "yitH9xAHQs",
      "similarity": 0.8489
    },
    {
      "source": "First",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8457
    },
    {
      "source": "Second",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8569
    },
    {
      "source": "Second",
      "target": "kRBQwlkFSP",
      "similarity": 0.853
    },
    {
      "source": "Second",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.85
    },
    {
      "source": "Second",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8424
    },
    {
      "source": "Second",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8416
    },
    {
      "source": "Third",
      "target": "uClUUJk05H",
      "similarity": 0.8507
    },
    {
      "source": "Third",
      "target": "BPgK5XW1Nb",
      "similarity": 0.828
    },
    {
      "source": "Third",
      "target": "EDoD3DgivF",
      "similarity": 0.8171
    },
    {
      "source": "Third",
      "target": "Our approach extends Iterative Markovian Fitting to discrete domains",
      "similarity": 0.8162
    },
    {
      "source": "Third",
      "target": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "similarity": 0.8134
    },
    {
      "source": "In addition",
      "target": "78tc3EiUrN",
      "similarity": 0.8336
    },
    {
      "source": "In addition",
      "target": "dsP91M4hDL",
      "similarity": 0.8176
    },
    {
      "source": "In addition",
      "target": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "similarity": 0.816
    },
    {
      "source": "In addition",
      "target": "aKJr5NnN8U",
      "similarity": 0.8149
    },
    {
      "source": "In addition",
      "target": "To overcome those challenges",
      "similarity": 0.8088
    },
    {
      "source": "Our innovative video captioning model significantly improves generation quality and semantic alignment.",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.7992
    },
    {
      "source": "Our innovative video captioning model significantly improves generation quality and semantic alignment.",
      "target": "We validate our approach in two tasks",
      "similarity": 0.7945
    },
    {
      "source": "Our innovative video captioning model significantly improves generation quality and semantic alignment.",
      "target": "dual shape representation",
      "similarity": 0.7921
    },
    {
      "source": "Our innovative video captioning model significantly improves generation quality and semantic alignment.",
      "target": "To fill this gap",
      "similarity": 0.7894
    },
    {
      "source": "Our innovative video captioning model significantly improves generation quality and semantic alignment.",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.784
    },
    {
      "source": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.85
    },
    {
      "source": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "target": "Our findings emphasize the importance of quality ranking",
      "similarity": 0.829
    },
    {
      "source": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "target": "eIB1UZFcFg",
      "similarity": 0.8262
    },
    {
      "source": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8256
    },
    {
      "source": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.8246
    },
    {
      "source": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "target": "Jszf4et48m",
      "similarity": 0.8726
    },
    {
      "source": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "target": "Yet",
      "similarity": 0.8685
    },
    {
      "source": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "target": "hxUMQ4fic3",
      "similarity": 0.8657
    },
    {
      "source": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "target": "To this end",
      "similarity": 0.8628
    },
    {
      "source": "We publish the code and model checkpoints of CogVideoX along with our VAE model and video captioning model at https://github.com/THUDM/CogVideo.\"",
      "target": "In this paper",
      "similarity": 0.8612
    },
    {
      "source": "tQ1PmLfPBL",
      "target": "Our experiments demonstrate that LongPackis highly scalable",
      "similarity": 0.8513
    },
    {
      "source": "tQ1PmLfPBL",
      "target": "h7GAgbLSmC",
      "similarity": 0.8472
    },
    {
      "source": "tQ1PmLfPBL",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8421
    },
    {
      "source": "tQ1PmLfPBL",
      "target": "In this paper",
      "similarity": 0.8396
    },
    {
      "source": "tQ1PmLfPBL",
      "target": "To tackle these challenges",
      "similarity": 0.8355
    },
    {
      "source": "g0rnZeBguq",
      "target": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "similarity": 0.8321
    },
    {
      "source": "g0rnZeBguq",
      "target": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "similarity": 0.8313
    },
    {
      "source": "g0rnZeBguq",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8312
    },
    {
      "source": "g0rnZeBguq",
      "target": "BOQpRtI4F5",
      "similarity": 0.8263
    },
    {
      "source": "g0rnZeBguq",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.8241
    },
    {
      "source": "Ke2BEL4csm",
      "target": "FFE.\"",
      "similarity": 0.8308
    },
    {
      "source": "Ke2BEL4csm",
      "target": "The code is available at https://github.com/LAMDA-Tabular/TALENT.\"",
      "similarity": 0.8304
    },
    {
      "source": "Ke2BEL4csm",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.8266
    },
    {
      "source": "Ke2BEL4csm",
      "target": "prompts. As such",
      "similarity": 0.8224
    },
    {
      "source": "Ke2BEL4csm",
      "target": "tU074jg2vS",
      "similarity": 0.8204
    },
    {
      "source": "samples. However",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8808
    },
    {
      "source": "samples. However",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8779
    },
    {
      "source": "samples. However",
      "target": "yIlyHJdYV3",
      "similarity": 0.8767
    },
    {
      "source": "samples. However",
      "target": "FrFQpAgnGE",
      "similarity": 0.8728
    },
    {
      "source": "samples. However",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8642
    },
    {
      "source": "3ddi7Uss2A",
      "target": "However",
      "similarity": 0.826
    },
    {
      "source": "3ddi7Uss2A",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8199
    },
    {
      "source": "3ddi7Uss2A",
      "target": "Instruct",
      "similarity": 0.8167
    },
    {
      "source": "3ddi7Uss2A",
      "target": "In this work",
      "similarity": 0.816
    },
    {
      "source": "3ddi7Uss2A",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8147
    },
    {
      "source": "8EfxjTCg2k",
      "target": "This method constrains the parameter space to low-dimensional pre-defined and",
      "similarity": 0.8711
    },
    {
      "source": "8EfxjTCg2k",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8702
    },
    {
      "source": "8EfxjTCg2k",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8676
    },
    {
      "source": "8EfxjTCg2k",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8603
    },
    {
      "source": "8EfxjTCg2k",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.86
    },
    {
      "source": "While recent compression methods based on low-rank matrices show potential",
      "target": "WCRQFlji2q",
      "similarity": 0.8925
    },
    {
      "source": "While recent compression methods based on low-rank matrices show potential",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8766
    },
    {
      "source": "While recent compression methods based on low-rank matrices show potential",
      "target": "VvDEuyVXkG",
      "similarity": 0.8656
    },
    {
      "source": "While recent compression methods based on low-rank matrices show potential",
      "target": "9KiE3t6CsL",
      "similarity": 0.8643
    },
    {
      "source": "While recent compression methods based on low-rank matrices show potential",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8639
    },
    {
      "source": "solutions",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8398
    },
    {
      "source": "solutions",
      "target": "TYSQYx9vwd",
      "similarity": 0.8339
    },
    {
      "source": "solutions",
      "target": "Our framework",
      "similarity": 0.8336
    },
    {
      "source": "solutions",
      "target": "rCX9l4OTCT",
      "similarity": 0.8299
    },
    {
      "source": "solutions",
      "target": "K4FAFNRpko",
      "similarity": 0.8299
    },
    {
      "source": "overhead in parameters and inference time. In this paper",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8442
    },
    {
      "source": "overhead in parameters and inference time. In this paper",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8416
    },
    {
      "source": "overhead in parameters and inference time. In this paper",
      "target": "To remedy this problem",
      "similarity": 0.8409
    },
    {
      "source": "overhead in parameters and inference time. In this paper",
      "target": "However",
      "similarity": 0.8388
    },
    {
      "source": "overhead in parameters and inference time. In this paper",
      "target": "jckKNzYYA6",
      "similarity": 0.8385
    },
    {
      "source": "composition (MoDeGPT)",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8375
    },
    {
      "source": "composition (MoDeGPT)",
      "target": "TljGdvzFq2",
      "similarity": 0.8134
    },
    {
      "source": "composition (MoDeGPT)",
      "target": "C06kww3Qky",
      "similarity": 0.8106
    },
    {
      "source": "composition (MoDeGPT)",
      "target": "oZkqkkvdND",
      "similarity": 0.8022
    },
    {
      "source": "composition (MoDeGPT)",
      "target": "In this paper",
      "similarity": 0.8011
    },
    {
      "source": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "target": "SOTA LLMs",
      "similarity": 0.9291
    },
    {
      "source": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "target": "3bcN6xlO6f",
      "similarity": 0.8833
    },
    {
      "source": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8749
    },
    {
      "source": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8746
    },
    {
      "source": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8721
    },
    {
      "source": "tive subcomponents within Transformer blocks",
      "target": "xI71dsS3o4",
      "similarity": 0.8359
    },
    {
      "source": "tive subcomponents within Transformer blocks",
      "target": "yR47RmND1m",
      "similarity": 0.8279
    },
    {
      "source": "tive subcomponents within Transformer blocks",
      "target": "6VhDQP7WGX",
      "similarity": 0.8264
    },
    {
      "source": "tive subcomponents within Transformer blocks",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8256
    },
    {
      "source": "tive subcomponents within Transformer blocks",
      "target": "KxQRHOre9D",
      "similarity": 0.8231
    },
    {
      "source": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8355
    },
    {
      "source": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "target": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "similarity": 0.829
    },
    {
      "source": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8286
    },
    {
      "source": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "target": "ByCV9xWfNK",
      "similarity": 0.8255
    },
    {
      "source": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "target": "samples. However",
      "similarity": 0.8234
    },
    {
      "source": "ods",
      "target": "Moreover",
      "similarity": 0.8778
    },
    {
      "source": "ods",
      "target": "1) We directly compress the activations (i.e. keys and values at every layer)",
      "similarity": 0.852
    },
    {
      "source": "ods",
      "target": "G5DziesYxL",
      "similarity": 0.8471
    },
    {
      "source": "ods",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8469
    },
    {
      "source": "ods",
      "target": "In response",
      "similarity": 0.8436
    },
    {
      "source": "approximation",
      "target": "RWJX5F5I9g",
      "similarity": 0.8531
    },
    {
      "source": "approximation",
      "target": "In this paper",
      "similarity": 0.8373
    },
    {
      "source": "approximation",
      "target": "pDDODPtpx9",
      "similarity": 0.8359
    },
    {
      "source": "approximation",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8354
    },
    {
      "source": "approximation",
      "target": "From these insights",
      "similarity": 0.834
    },
    {
      "source": "novel decomposition approach. Our experiments show that MoDeGPT",
      "target": "uQnvYP7yX9",
      "similarity": 0.8145
    },
    {
      "source": "novel decomposition approach. Our experiments show that MoDeGPT",
      "target": "uHLgDEgiS5",
      "similarity": 0.8123
    },
    {
      "source": "novel decomposition approach. Our experiments show that MoDeGPT",
      "target": "Bpn8q40n1n",
      "similarity": 0.8111
    },
    {
      "source": "novel decomposition approach. Our experiments show that MoDeGPT",
      "target": "show that BoneMet can be readily adopted to build versatile",
      "similarity": 0.8103
    },
    {
      "source": "novel decomposition approach. Our experiments show that MoDeGPT",
      "target": "ogXkmugNZw",
      "similarity": 0.8074
    },
    {
      "source": "relying on backward propagation",
      "target": "Furthermore",
      "similarity": 0.8959
    },
    {
      "source": "relying on backward propagation",
      "target": "works leads to a multifaceted problem",
      "similarity": 0.8793
    },
    {
      "source": "relying on backward propagation",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8718
    },
    {
      "source": "relying on backward propagation",
      "target": "Second",
      "similarity": 0.8707
    },
    {
      "source": "relying on backward propagation",
      "target": "xiQNfYl33p",
      "similarity": 0.8654
    },
    {
      "source": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "target": "K4FAFNRpko",
      "similarity": 0.8406
    },
    {
      "source": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "target": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "similarity": 0.838
    },
    {
      "source": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8324
    },
    {
      "source": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8312
    },
    {
      "source": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "target": "Furthermore",
      "similarity": 0.8292
    },
    {
      "source": "LLaMA-2/3 and OPT models",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8447
    },
    {
      "source": "LLaMA-2/3 and OPT models",
      "target": "To remedy this problem",
      "similarity": 0.8388
    },
    {
      "source": "LLaMA-2/3 and OPT models",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8296
    },
    {
      "source": "LLaMA-2/3 and OPT models",
      "target": "gsShHPxkUW",
      "similarity": 0.8258
    },
    {
      "source": "LLaMA-2/3 and OPT models",
      "target": "1yJP5TVWih",
      "similarity": 0.8232
    },
    {
      "source": "with compression rates of 25-30%. The compression process can be completed on",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8198
    },
    {
      "source": "with compression rates of 25-30%. The compression process can be completed on",
      "target": "from multi-view images. Unlike previous methods that rely on implicit irradiance fields or oversimplified ray tracing",
      "similarity": 0.8138
    },
    {
      "source": "with compression rates of 25-30%. The compression process can be completed on",
      "target": "te2IdORabL",
      "similarity": 0.8115
    },
    {
      "source": "with compression rates of 25-30%. The compression process can be completed on",
      "target": "Our codebase",
      "similarity": 0.8056
    },
    {
      "source": "with compression rates of 25-30%. The compression process can be completed on",
      "target": "PwxYoMvmvy",
      "similarity": 0.8052
    },
    {
      "source": "a single GPU in a few hours",
      "target": "To develop SoundCTM",
      "similarity": 0.8411
    },
    {
      "source": "a single GPU in a few hours",
      "target": "h1XoHOd19I",
      "similarity": 0.8402
    },
    {
      "source": "a single GPU in a few hours",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8356
    },
    {
      "source": "a single GPU in a few hours",
      "target": "Then the learned chemical knowledge helps the inversion generation path to generate molecules with required properties.",
      "similarity": 0.8353
    },
    {
      "source": "a single GPU in a few hours",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8349
    },
    {
      "source": "1GTARJhxtq",
      "target": "Next",
      "similarity": 0.7908
    },
    {
      "source": "1GTARJhxtq",
      "target": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "similarity": 0.7907
    },
    {
      "source": "1GTARJhxtq",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.788
    },
    {
      "source": "1GTARJhxtq",
      "target": "XsgHl54yO7",
      "similarity": 0.783
    },
    {
      "source": "1GTARJhxtq",
      "target": "Prediction (NWP) systems on HR-Extreme",
      "similarity": 0.7697
    },
    {
      "source": "4NTrco82W0",
      "target": "27SSnLl85x",
      "similarity": 0.8351
    },
    {
      "source": "4NTrco82W0",
      "target": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "similarity": 0.8306
    },
    {
      "source": "4NTrco82W0",
      "target": "By playing against itself",
      "similarity": 0.8237
    },
    {
      "source": "4NTrco82W0",
      "target": "target node would not have been anomalous. Prior methods of assessing the fix",
      "similarity": 0.8213
    },
    {
      "source": "4NTrco82W0",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8213
    },
    {
      "source": "TjP1d8PP8l",
      "target": "Finally",
      "similarity": 0.8311
    },
    {
      "source": "TjP1d8PP8l",
      "target": "implementation",
      "similarity": 0.821
    },
    {
      "source": "TjP1d8PP8l",
      "target": "To tackle this",
      "similarity": 0.8156
    },
    {
      "source": "TjP1d8PP8l",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8121
    },
    {
      "source": "TjP1d8PP8l",
      "target": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "similarity": 0.8108
    },
    {
      "source": "PUnD86UEK5",
      "target": "M5t0WvjfCg",
      "similarity": 0.8336
    },
    {
      "source": "PUnD86UEK5",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8325
    },
    {
      "source": "PUnD86UEK5",
      "target": "FCMpUOZkxi",
      "similarity": 0.8247
    },
    {
      "source": "PUnD86UEK5",
      "target": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "similarity": 0.8222
    },
    {
      "source": "PUnD86UEK5",
      "target": "46xYl55hdc",
      "similarity": 0.8205
    },
    {
      "source": "HVtu26XDAA",
      "target": "To bridge this gap",
      "similarity": 0.8239
    },
    {
      "source": "HVtu26XDAA",
      "target": "B5iOSxM2I0",
      "similarity": 0.8158
    },
    {
      "source": "HVtu26XDAA",
      "target": "FPfCUJTsCn",
      "similarity": 0.8065
    },
    {
      "source": "HVtu26XDAA",
      "target": "We also present GRE-bench (Generating Review Evaluation Benchmark) which evaluates LLMs based on how well they can generate high-quality peer reviews for academic research papers.  Because GRE-bench is based upon GEM",
      "similarity": 0.7983
    },
    {
      "source": "HVtu26XDAA",
      "target": "CGON8Btleu",
      "similarity": 0.797
    },
    {
      "source": "2OMyAFjiJJ",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.841
    },
    {
      "source": "2OMyAFjiJJ",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8396
    },
    {
      "source": "2OMyAFjiJJ",
      "target": "enhance reliability. This study investigates the efficacy of such approaches",
      "similarity": 0.8329
    },
    {
      "source": "2OMyAFjiJJ",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8305
    },
    {
      "source": "2OMyAFjiJJ",
      "target": "Second",
      "similarity": 0.8301
    },
    {
      "source": "mUXdysoxEP",
      "target": "VGQugiuCQs",
      "similarity": 0.8555
    },
    {
      "source": "mUXdysoxEP",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8315
    },
    {
      "source": "mUXdysoxEP",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.83
    },
    {
      "source": "mUXdysoxEP",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8282
    },
    {
      "source": "mUXdysoxEP",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8279
    },
    {
      "source": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.8298
    },
    {
      "source": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "target": "JsVIGVntnQ",
      "similarity": 0.8238
    },
    {
      "source": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8226
    },
    {
      "source": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "target": "space are required in general even for outputting a constant factor",
      "similarity": 0.8205
    },
    {
      "source": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "target": "In this task",
      "similarity": 0.82
    },
    {
      "source": "qIbbBSzH6n",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8428
    },
    {
      "source": "qIbbBSzH6n",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8354
    },
    {
      "source": "qIbbBSzH6n",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.832
    },
    {
      "source": "qIbbBSzH6n",
      "target": "We develop a safe curriculum generation approach (SCG) that aligns the objectives of constrained RL and curriculum learning: improving safety during training and boosting sample efficiency.",
      "similarity": 0.831
    },
    {
      "source": "qIbbBSzH6n",
      "target": "DC8bsa9bzY",
      "similarity": 0.8288
    },
    {
      "source": "GBfYgjOfSe",
      "target": "we give an analytical example",
      "similarity": 0.8409
    },
    {
      "source": "GBfYgjOfSe",
      "target": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "similarity": 0.836
    },
    {
      "source": "GBfYgjOfSe",
      "target": "Se6MgCtRhz",
      "similarity": 0.8351
    },
    {
      "source": "GBfYgjOfSe",
      "target": "pZiyCaVuti",
      "similarity": 0.8337
    },
    {
      "source": "GBfYgjOfSe",
      "target": "variables encourage the model to learn disentangled representations and decision",
      "similarity": 0.8331
    },
    {
      "source": "Usklli4gMc",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8905
    },
    {
      "source": "Usklli4gMc",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8756
    },
    {
      "source": "Usklli4gMc",
      "target": "First",
      "similarity": 0.8677
    },
    {
      "source": "Usklli4gMc",
      "target": "3E8YNv1HjU",
      "similarity": 0.8634
    },
    {
      "source": "Usklli4gMc",
      "target": "JAMxRSXLFz",
      "similarity": 0.8619
    },
    {
      "source": "In this paper",
      "target": "Moreover",
      "similarity": 0.8223
    },
    {
      "source": "In this paper",
      "target": "1tBvzOYTLF",
      "similarity": 0.8174
    },
    {
      "source": "In this paper",
      "target": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "similarity": 0.793
    },
    {
      "source": "In this paper",
      "target": "2p03KljxE9",
      "similarity": 0.7874
    },
    {
      "source": "In this paper",
      "target": "zZ8fgXHkXi",
      "similarity": 0.7839
    },
    {
      "source": "MRAG-Bench consists of 16",
      "target": "TYSQYx9vwd",
      "similarity": 0.8638
    },
    {
      "source": "MRAG-Bench consists of 16",
      "target": "tpGkEgxMJT",
      "similarity": 0.8514
    },
    {
      "source": "MRAG-Bench consists of 16",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8425
    },
    {
      "source": "MRAG-Bench consists of 16",
      "target": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "similarity": 0.8348
    },
    {
      "source": "MRAG-Bench consists of 16",
      "target": "In addition",
      "similarity": 0.8336
    },
    {
      "source": "ogXkmugNZw",
      "target": "gsShHPxkUW",
      "similarity": 0.8625
    },
    {
      "source": "ogXkmugNZw",
      "target": "Finally",
      "similarity": 0.8533
    },
    {
      "source": "ogXkmugNZw",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8511
    },
    {
      "source": "ogXkmugNZw",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8493
    },
    {
      "source": "ogXkmugNZw",
      "target": "vVxeFSR4fU",
      "similarity": 0.845
    },
    {
      "source": "To address these considerations",
      "target": "In this work",
      "similarity": 0.7933
    },
    {
      "source": "To address these considerations",
      "target": "However",
      "similarity": 0.7901
    },
    {
      "source": "To address these considerations",
      "target": "vue9P1Ypk6",
      "similarity": 0.7865
    },
    {
      "source": "To address these considerations",
      "target": "First",
      "similarity": 0.7862
    },
    {
      "source": "To address these considerations",
      "target": "entities of a sentence (subject",
      "similarity": 0.784
    },
    {
      "source": "In the field of multi-objective optimization",
      "target": "rWui9vLhOc",
      "similarity": 0.825
    },
    {
      "source": "In the field of multi-objective optimization",
      "target": "yZ7sn9pyqb",
      "similarity": 0.802
    },
    {
      "source": "In the field of multi-objective optimization",
      "target": "We show that independently trained agents under this algorithm coordinate successfully in Overcooked.",
      "similarity": 0.7987
    },
    {
      "source": "In the field of multi-objective optimization",
      "target": "TId1SHe8JG",
      "similarity": 0.7943
    },
    {
      "source": "In the field of multi-objective optimization",
      "target": "6ouZaBzeNO",
      "similarity": 0.7867
    },
    {
      "source": "It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.",
      "target": "mFY0tPDWK8",
      "similarity": 0.8439
    },
    {
      "source": "It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.",
      "target": "e0X9l4kecx",
      "similarity": 0.807
    },
    {
      "source": "It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.",
      "target": "fvkElsJOsN",
      "similarity": 0.7985
    },
    {
      "source": "It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.",
      "target": "Fortunately",
      "similarity": 0.7954
    },
    {
      "source": "It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.",
      "target": "60GeEoG5kD",
      "similarity": 0.7944
    },
    {
      "source": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8222
    },
    {
      "source": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "target": "Bl3e8HV9xW",
      "similarity": 0.8201
    },
    {
      "source": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "target": "Adapting tools from classical sampling theory",
      "similarity": 0.8169
    },
    {
      "source": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "target": "D2hhkU5O48",
      "similarity": 0.8098
    },
    {
      "source": "We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP)",
      "target": "In this paper",
      "similarity": 0.8073
    },
    {
      "source": "Existing safety constraints are then integrated into the COP",
      "target": "kxnoqaisCT",
      "similarity": 0.8404
    },
    {
      "source": "Existing safety constraints are then integrated into the COP",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8321
    },
    {
      "source": "Existing safety constraints are then integrated into the COP",
      "target": "However",
      "similarity": 0.8179
    },
    {
      "source": "Existing safety constraints are then integrated into the COP",
      "target": "Remarkably",
      "similarity": 0.8172
    },
    {
      "source": "Existing safety constraints are then integrated into the COP",
      "target": "7PLpiVdnUC",
      "similarity": 0.8129
    },
    {
      "source": "Despite its simplicity",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8637
    },
    {
      "source": "Despite its simplicity",
      "target": "semTHoVGsJ",
      "similarity": 0.8497
    },
    {
      "source": "Despite its simplicity",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.8442
    },
    {
      "source": "Despite its simplicity",
      "target": "To address these challenges",
      "similarity": 0.8391
    },
    {
      "source": "Despite its simplicity",
      "target": "To overcome those challenges",
      "similarity": 0.8373
    },
    {
      "source": "Through various experiments",
      "target": "ANBuEJesgx",
      "similarity": 0.8098
    },
    {
      "source": "Through various experiments",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8097
    },
    {
      "source": "Through various experiments",
      "target": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "similarity": 0.8065
    },
    {
      "source": "Through various experiments",
      "target": "SG1R2H3fa1",
      "similarity": 0.8033
    },
    {
      "source": "Through various experiments",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8018
    },
    {
      "source": "d23EVDRJ6g",
      "target": "OiQttMHwce",
      "similarity": 0.8256
    },
    {
      "source": "d23EVDRJ6g",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8219
    },
    {
      "source": "d23EVDRJ6g",
      "target": "eiqrnVaeIw",
      "similarity": 0.8212
    },
    {
      "source": "d23EVDRJ6g",
      "target": "it hard to decide on a proper causal discovery strategy.",
      "similarity": 0.8199
    },
    {
      "source": "d23EVDRJ6g",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8177
    },
    {
      "source": "IdAyXxBud7",
      "target": "In parallel",
      "similarity": 0.8091
    },
    {
      "source": "IdAyXxBud7",
      "target": "In this work",
      "similarity": 0.8084
    },
    {
      "source": "IdAyXxBud7",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8073
    },
    {
      "source": "IdAyXxBud7",
      "target": "d8hYXbxX71",
      "similarity": 0.8049
    },
    {
      "source": "IdAyXxBud7",
      "target": "Wf2ndb8nhf",
      "similarity": 0.8006
    },
    {
      "source": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "target": "NDLmZZWATc",
      "similarity": 0.8957
    },
    {
      "source": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "target": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "similarity": 0.884
    },
    {
      "source": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "target": "1CIUkpoata",
      "similarity": 0.8819
    },
    {
      "source": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8708
    },
    {
      "source": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "target": "wHebuIb6IH",
      "similarity": 0.8571
    },
    {
      "source": "To address these challenges",
      "target": "Nfd7z9d6Bb",
      "similarity": 0.8463
    },
    {
      "source": "To address these challenges",
      "target": "this simple method is computationally fast",
      "similarity": 0.8373
    },
    {
      "source": "To address these challenges",
      "target": "4JK2XMGUc8",
      "similarity": 0.8343
    },
    {
      "source": "To address these challenges",
      "target": "PHg4rAXFVH",
      "similarity": 0.8309
    },
    {
      "source": "To address these challenges",
      "target": "rySLejeB1k",
      "similarity": 0.8293
    },
    {
      "source": "Experiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8533
    },
    {
      "source": "Experiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8506
    },
    {
      "source": "Experiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8455
    },
    {
      "source": "Experiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach",
      "target": "fv9XU7CyN2",
      "similarity": 0.8416
    },
    {
      "source": "Experiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach",
      "target": "a challenge",
      "similarity": 0.8354
    },
    {
      "source": "09FiNmvNMw",
      "target": "- In discrete image-based control (e.g.",
      "similarity": 0.8761
    },
    {
      "source": "09FiNmvNMw",
      "target": "In this work",
      "similarity": 0.8736
    },
    {
      "source": "09FiNmvNMw",
      "target": "se4vjm7h4E",
      "similarity": 0.8708
    },
    {
      "source": "09FiNmvNMw",
      "target": "J9FgrqOOni",
      "similarity": 0.8511
    },
    {
      "source": "09FiNmvNMw",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8509
    },
    {
      "source": "KW8yzAOIZr",
      "target": "hjROBHstZ3",
      "similarity": 0.8581
    },
    {
      "source": "KW8yzAOIZr",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8508
    },
    {
      "source": "KW8yzAOIZr",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8429
    },
    {
      "source": "KW8yzAOIZr",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8359
    },
    {
      "source": "KW8yzAOIZr",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8342
    },
    {
      "source": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.8556
    },
    {
      "source": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "target": "dw9VUsSHGB",
      "similarity": 0.8505
    },
    {
      "source": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "target": "We apply GenerativeAdapter to two pretrained LMs (Mistral-7B-Instruct and Llama2-7B-Chat) and evaluate the adapted models across  knowledge acquisition from documents",
      "similarity": 0.8456
    },
    {
      "source": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "target": "oZkqkkvdND",
      "similarity": 0.8276
    },
    {
      "source": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "target": "0fJfVOSUra",
      "similarity": 0.8274
    },
    {
      "source": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "target": "FBhKUXK7od",
      "similarity": 0.8394
    },
    {
      "source": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8388
    },
    {
      "source": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "target": "However",
      "similarity": 0.8238
    },
    {
      "source": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "target": "gkUyYcY1W9",
      "similarity": 0.8208
    },
    {
      "source": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "target": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "similarity": 0.8193
    },
    {
      "source": "Moreover",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8376
    },
    {
      "source": "Moreover",
      "target": "4v4RcAODj9",
      "similarity": 0.8203
    },
    {
      "source": "Moreover",
      "target": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "similarity": 0.8188
    },
    {
      "source": "Moreover",
      "target": "PY56Wur7S0",
      "similarity": 0.8098
    },
    {
      "source": "Moreover",
      "target": "WoPovNkM5h",
      "similarity": 0.8088
    },
    {
      "source": "We  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods",
      "target": "jTEKTdI3K9",
      "similarity": 0.8752
    },
    {
      "source": "We  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8748
    },
    {
      "source": "We  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8634
    },
    {
      "source": "We  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods",
      "target": "JSB171dSUU",
      "similarity": 0.859
    },
    {
      "source": "We  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods",
      "target": "5AtlfHYCPa",
      "similarity": 0.856
    },
    {
      "source": "7gGl6HB5Zd",
      "target": "SOTA LLMs",
      "similarity": 0.8602
    },
    {
      "source": "7gGl6HB5Zd",
      "target": "WzCEiBILHu",
      "similarity": 0.8193
    },
    {
      "source": "7gGl6HB5Zd",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8143
    },
    {
      "source": "7gGl6HB5Zd",
      "target": "41uZB8bDFh",
      "similarity": 0.8126
    },
    {
      "source": "7gGl6HB5Zd",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.8113
    },
    {
      "source": "8TERgu1Lb2",
      "target": "gradual stacking and layer dropping (Reddi et al.",
      "similarity": 0.851
    },
    {
      "source": "8TERgu1Lb2",
      "target": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "similarity": 0.8252
    },
    {
      "source": "8TERgu1Lb2",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.825
    },
    {
      "source": "8TERgu1Lb2",
      "target": "LQzN6TRFg9",
      "similarity": 0.8239
    },
    {
      "source": "8TERgu1Lb2",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.819
    },
    {
      "source": "ud8FtE1N4N",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8239
    },
    {
      "source": "ud8FtE1N4N",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8159
    },
    {
      "source": "ud8FtE1N4N",
      "target": "KxQRHOre9D",
      "similarity": 0.8136
    },
    {
      "source": "ud8FtE1N4N",
      "target": "1tBvzOYTLF",
      "similarity": 0.8133
    },
    {
      "source": "ud8FtE1N4N",
      "target": "md9qolJwLl",
      "similarity": 0.809
    },
    {
      "source": "While many focus on post-training pruning",
      "target": "However",
      "similarity": 0.8077
    },
    {
      "source": "While many focus on post-training pruning",
      "target": "1qgZXeMTTU",
      "similarity": 0.7993
    },
    {
      "source": "While many focus on post-training pruning",
      "target": "However",
      "similarity": 0.7949
    },
    {
      "source": "While many focus on post-training pruning",
      "target": "benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective.\"",
      "similarity": 0.7925
    },
    {
      "source": "While many focus on post-training pruning",
      "target": "edge insertion graph stream",
      "similarity": 0.7916
    },
    {
      "source": "In this work",
      "target": "YcUV5apdlq",
      "similarity": 0.8523
    },
    {
      "source": "In this work",
      "target": "depth-wise",
      "similarity": 0.8438
    },
    {
      "source": "In this work",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8404
    },
    {
      "source": "In this work",
      "target": "nrvoWOWcyg",
      "similarity": 0.839
    },
    {
      "source": "In this work",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8348
    },
    {
      "source": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "target": "suz4utPr9Y",
      "similarity": 0.8968
    },
    {
      "source": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8475
    },
    {
      "source": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "target": "For instance",
      "similarity": 0.8453
    },
    {
      "source": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8448
    },
    {
      "source": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8424
    },
    {
      "source": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "target": "rJ5g8ueQaI",
      "similarity": 0.7968
    },
    {
      "source": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "target": "XsgHl54yO7",
      "similarity": 0.7943
    },
    {
      "source": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "target": "This study highlights a major",
      "similarity": 0.7857
    },
    {
      "source": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "target": "mOpNrrV2zH",
      "similarity": 0.7832
    },
    {
      "source": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "target": "For example",
      "similarity": 0.7822
    },
    {
      "source": "Furthermore",
      "target": "SMK0f8JoKF",
      "similarity": 0.8293
    },
    {
      "source": "Furthermore",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8143
    },
    {
      "source": "Furthermore",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8092
    },
    {
      "source": "Furthermore",
      "target": "5qg6JPSgCj",
      "similarity": 0.809
    },
    {
      "source": "Furthermore",
      "target": "Ev4iw23gdI",
      "similarity": 0.8065
    },
    {
      "source": "Through empirical and theoretical validation",
      "target": "FEpAUnS7f7",
      "similarity": 0.838
    },
    {
      "source": "Through empirical and theoretical validation",
      "target": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "similarity": 0.8344
    },
    {
      "source": "Through empirical and theoretical validation",
      "target": "In experiments with GPT-4",
      "similarity": 0.8339
    },
    {
      "source": "Through empirical and theoretical validation",
      "target": "TrVYEZtSQH",
      "similarity": 0.8338
    },
    {
      "source": "Through empirical and theoretical validation",
      "target": "Finally",
      "similarity": 0.8301
    },
    {
      "source": "Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8119
    },
    {
      "source": "Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets",
      "target": "previous pixel-wise approach on the perspective of open-world. Moreover",
      "similarity": 0.7981
    },
    {
      "source": "Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets",
      "target": "In experiments with GPT-4",
      "similarity": 0.7972
    },
    {
      "source": "Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets",
      "target": "However",
      "similarity": 0.796
    },
    {
      "source": "Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets",
      "target": "8pusxkLEQO",
      "similarity": 0.7957
    },
    {
      "source": "74vnDs1R97",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8623
    },
    {
      "source": "74vnDs1R97",
      "target": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "similarity": 0.8598
    },
    {
      "source": "74vnDs1R97",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8563
    },
    {
      "source": "74vnDs1R97",
      "target": "FyMjfDQ9RO",
      "similarity": 0.8505
    },
    {
      "source": "74vnDs1R97",
      "target": "IuU0wcO0mo",
      "similarity": 0.8491
    },
    {
      "source": "ExuBFYtCQU",
      "target": "In this work",
      "similarity": 0.8351
    },
    {
      "source": "ExuBFYtCQU",
      "target": "l0fn10vSyM",
      "similarity": 0.8264
    },
    {
      "source": "ExuBFYtCQU",
      "target": "x1yOHtFfDh",
      "similarity": 0.8232
    },
    {
      "source": "ExuBFYtCQU",
      "target": "Experimental results show that **SeCom** outperforms turn-level",
      "similarity": 0.8203
    },
    {
      "source": "ExuBFYtCQU",
      "target": "5o9JJJPPm6",
      "similarity": 0.82
    },
    {
      "source": "In this paper",
      "target": "To remedy this problem",
      "similarity": 0.8451
    },
    {
      "source": "In this paper",
      "target": "SFN6Wm7YBI",
      "similarity": 0.84
    },
    {
      "source": "In this paper",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8276
    },
    {
      "source": "In this paper",
      "target": "gsShHPxkUW",
      "similarity": 0.8251
    },
    {
      "source": "In this paper",
      "target": "can effectively construct data-dependent learning algorithms instead of directly follow existing ones",
      "similarity": 0.8232
    },
    {
      "source": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "target": "From this perspective",
      "similarity": 0.8205
    },
    {
      "source": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "target": "In this work",
      "similarity": 0.8052
    },
    {
      "source": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "target": "Finally",
      "similarity": 0.7987
    },
    {
      "source": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.7961
    },
    {
      "source": "Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality",
      "target": "connection component",
      "similarity": 0.7911
    },
    {
      "source": "mOpNrrV2zH",
      "target": "97rOQDPmk2",
      "similarity": 0.8479
    },
    {
      "source": "mOpNrrV2zH",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8393
    },
    {
      "source": "mOpNrrV2zH",
      "target": "assessing and advancing topological methods",
      "similarity": 0.8366
    },
    {
      "source": "mOpNrrV2zH",
      "target": "ogXkmugNZw",
      "similarity": 0.8329
    },
    {
      "source": "mOpNrrV2zH",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8321
    },
    {
      "source": "EjJGND0m1x",
      "target": "minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of",
      "similarity": 0.793
    },
    {
      "source": "EjJGND0m1x",
      "target": "tGYFikNONB",
      "similarity": 0.7815
    },
    {
      "source": "EjJGND0m1x",
      "target": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "similarity": 0.7771
    },
    {
      "source": "EjJGND0m1x",
      "target": "However",
      "similarity": 0.7759
    },
    {
      "source": "EjJGND0m1x",
      "target": "mkuB677eMM",
      "similarity": 0.7745
    },
    {
      "source": "Yet",
      "target": "8VtGeyJyx9",
      "similarity": 0.8851
    },
    {
      "source": "Yet",
      "target": "To this end",
      "similarity": 0.8694
    },
    {
      "source": "Yet",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8673
    },
    {
      "source": "Yet",
      "target": "AJpUZd8Clb",
      "similarity": 0.8662
    },
    {
      "source": "Yet",
      "target": "riieAeQBJm",
      "similarity": 0.8617
    },
    {
      "source": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8383
    },
    {
      "source": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8184
    },
    {
      "source": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "target": "Our findings show the potential of using these methods to predict training stability.\"",
      "similarity": 0.8102
    },
    {
      "source": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8099
    },
    {
      "source": "We address this inefficiency by introducing self-introspection capabilities to the network",
      "target": "4DiM is the first-ever NVS method with intuitive metric-scale camera pose control enabled by our novel calibration pipeline for structure-from-motion-posed data. Experiments demonstrate that 4DiM outperforms prior 3D NVS models both in terms of",
      "similarity": 0.805
    },
    {
      "source": "This enables the network to adaptively reuse parameters across tasks",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8683
    },
    {
      "source": "This enables the network to adaptively reuse parameters across tasks",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8679
    },
    {
      "source": "This enables the network to adaptively reuse parameters across tasks",
      "target": "latent variables",
      "similarity": 0.8555
    },
    {
      "source": "This enables the network to adaptively reuse parameters across tasks",
      "target": "nx9Z5Kva96",
      "similarity": 0.8541
    },
    {
      "source": "This enables the network to adaptively reuse parameters across tasks",
      "target": "matched mask pairs between prediction and annotation respectively. Extensive",
      "similarity": 0.8534
    },
    {
      "source": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "target": "NDLmZZWATc",
      "similarity": 0.9031
    },
    {
      "source": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "target": "wHebuIb6IH",
      "similarity": 0.8675
    },
    {
      "source": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "target": "With regards to improving Shampoo's computational efficiency",
      "similarity": 0.8654
    },
    {
      "source": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "target": "1R5BcYS8EC",
      "similarity": 0.8638
    },
    {
      "source": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "target": "Moreover",
      "similarity": 0.8595
    },
    {
      "source": "Notably",
      "target": "MxbEiFRf39",
      "similarity": 0.8453
    },
    {
      "source": "Notably",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8297
    },
    {
      "source": "Notably",
      "target": "zl3pfz4VCV",
      "similarity": 0.8198
    },
    {
      "source": "Notably",
      "target": "This game-solving approach is both computationally expensive and difficult to stabilize.",
      "similarity": 0.8143
    },
    {
      "source": "Notably",
      "target": "NUD03NBDOE",
      "similarity": 0.8118
    },
    {
      "source": "These results showcase the potential for dynamic and reflective computation",
      "target": "depth-wise",
      "similarity": 0.8658
    },
    {
      "source": "These results showcase the potential for dynamic and reflective computation",
      "target": "TYSQYx9vwd",
      "similarity": 0.8629
    },
    {
      "source": "These results showcase the potential for dynamic and reflective computation",
      "target": "We validate our approach on benchmarks from image and medical domains",
      "similarity": 0.8609
    },
    {
      "source": "These results showcase the potential for dynamic and reflective computation",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8532
    },
    {
      "source": "These results showcase the potential for dynamic and reflective computation",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8505
    },
    {
      "source": "VGQugiuCQs",
      "target": "m8yby1JfbU",
      "similarity": 0.8432
    },
    {
      "source": "VGQugiuCQs",
      "target": "iXbUquaWbl",
      "similarity": 0.8323
    },
    {
      "source": "VGQugiuCQs",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8286
    },
    {
      "source": "VGQugiuCQs",
      "target": "uHLgDEgiS5",
      "similarity": 0.8199
    },
    {
      "source": "VGQugiuCQs",
      "target": "HE6pJoNnFp",
      "similarity": 0.8172
    },
    {
      "source": "6RjQ54M1rM",
      "target": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "similarity": 0.8056
    },
    {
      "source": "6RjQ54M1rM",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.7972
    },
    {
      "source": "6RjQ54M1rM",
      "target": "In this paper",
      "similarity": 0.7971
    },
    {
      "source": "6RjQ54M1rM",
      "target": "h8yg0hT96f",
      "similarity": 0.7941
    },
    {
      "source": "6RjQ54M1rM",
      "target": "C45YqeBDUM",
      "similarity": 0.794
    },
    {
      "source": "lgsyLSsDRe",
      "target": "rCX9l4OTCT",
      "similarity": 0.8331
    },
    {
      "source": "lgsyLSsDRe",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8273
    },
    {
      "source": "lgsyLSsDRe",
      "target": "mnna9LUg7P",
      "similarity": 0.8255
    },
    {
      "source": "lgsyLSsDRe",
      "target": "Fk3eod9aaD",
      "similarity": 0.8235
    },
    {
      "source": "lgsyLSsDRe",
      "target": "FBhKUXK7od",
      "similarity": 0.8201
    },
    {
      "source": "I8af9JdQTy",
      "target": "works leads to a multifaceted problem",
      "similarity": 0.8397
    },
    {
      "source": "I8af9JdQTy",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8198
    },
    {
      "source": "I8af9JdQTy",
      "target": "This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks",
      "similarity": 0.8134
    },
    {
      "source": "I8af9JdQTy",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8128
    },
    {
      "source": "I8af9JdQTy",
      "target": "over methods trained using much larger datasets.",
      "similarity": 0.8128
    },
    {
      "source": "klpdEThT8q",
      "target": "wmV4cIbgl6",
      "similarity": 0.8354
    },
    {
      "source": "klpdEThT8q",
      "target": "GySIAKEwtZ",
      "similarity": 0.8337
    },
    {
      "source": "klpdEThT8q",
      "target": "We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance",
      "similarity": 0.8192
    },
    {
      "source": "klpdEThT8q",
      "target": "g3VCIM94ke",
      "similarity": 0.8164
    },
    {
      "source": "klpdEThT8q",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.811
    },
    {
      "source": "dSneEp59yX",
      "target": "HD6bWcj87Y",
      "similarity": 0.8086
    },
    {
      "source": "dSneEp59yX",
      "target": "xI71dsS3o4",
      "similarity": 0.8044
    },
    {
      "source": "dSneEp59yX",
      "target": "We provide a parallelized GPU implementation of this regularizer",
      "similarity": 0.8002
    },
    {
      "source": "dSneEp59yX",
      "target": "m51BgoqvbP",
      "similarity": 0.7917
    },
    {
      "source": "dSneEp59yX",
      "target": "PY56Wur7S0",
      "similarity": 0.7906
    },
    {
      "source": "jQP5o1VAVc",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.8947
    },
    {
      "source": "jQP5o1VAVc",
      "target": "QWunLKbBGF",
      "similarity": 0.8701
    },
    {
      "source": "jQP5o1VAVc",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8674
    },
    {
      "source": "jQP5o1VAVc",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8655
    },
    {
      "source": "jQP5o1VAVc",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8653
    },
    {
      "source": "In this work",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.868
    },
    {
      "source": "In this work",
      "target": "INqLJwqUmc",
      "similarity": 0.8404
    },
    {
      "source": "In this work",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8327
    },
    {
      "source": "In this work",
      "target": "task.",
      "similarity": 0.8291
    },
    {
      "source": "In this work",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8252
    },
    {
      "source": "Inspired by these findings",
      "target": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "similarity": 0.8325
    },
    {
      "source": "Inspired by these findings",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.8323
    },
    {
      "source": "Inspired by these findings",
      "target": "1xzqz73hvL",
      "similarity": 0.8307
    },
    {
      "source": "Inspired by these findings",
      "target": "03EkqSCKuO",
      "similarity": 0.8281
    },
    {
      "source": "Inspired by these findings",
      "target": "counterfactual bias)",
      "similarity": 0.8215
    },
    {
      "source": "jj7b3p5kLY",
      "target": "correct for biases in the sample weights",
      "similarity": 0.8526
    },
    {
      "source": "jj7b3p5kLY",
      "target": "We perform detailed analyses",
      "similarity": 0.8422
    },
    {
      "source": "jj7b3p5kLY",
      "target": "First",
      "similarity": 0.8416
    },
    {
      "source": "jj7b3p5kLY",
      "target": "Moreover on large datasets with up to 100 million vectors",
      "similarity": 0.841
    },
    {
      "source": "jj7b3p5kLY",
      "target": "tu3qwNjrtw",
      "similarity": 0.8395
    },
    {
      "source": "fs2Z2z3GRx",
      "target": "wHebuIb6IH",
      "similarity": 0.8708
    },
    {
      "source": "fs2Z2z3GRx",
      "target": "Furthermore",
      "similarity": 0.8604
    },
    {
      "source": "fs2Z2z3GRx",
      "target": "ngmEcEer8a",
      "similarity": 0.8562
    },
    {
      "source": "fs2Z2z3GRx",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8551
    },
    {
      "source": "fs2Z2z3GRx",
      "target": "3bcN6xlO6f",
      "similarity": 0.8499
    },
    {
      "source": "tePFpDgyqg",
      "target": "VmJdqhuTCh",
      "similarity": 0.8673
    },
    {
      "source": "tePFpDgyqg",
      "target": "wide dissemination",
      "similarity": 0.8547
    },
    {
      "source": "tePFpDgyqg",
      "target": "This paper proposes",
      "similarity": 0.8509
    },
    {
      "source": "tePFpDgyqg",
      "target": "propose the use of weighted point sets",
      "similarity": 0.8475
    },
    {
      "source": "tePFpDgyqg",
      "target": "named Pacmann",
      "similarity": 0.8441
    },
    {
      "source": "Previous data engineering approaches mechanically concatenate short documents",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8191
    },
    {
      "source": "Previous data engineering approaches mechanically concatenate short documents",
      "target": "Ij9ilPh36h",
      "similarity": 0.7946
    },
    {
      "source": "Previous data engineering approaches mechanically concatenate short documents",
      "target": "x$",
      "similarity": 0.7894
    },
    {
      "source": "Previous data engineering approaches mechanically concatenate short documents",
      "target": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "similarity": 0.7879
    },
    {
      "source": "Previous data engineering approaches mechanically concatenate short documents",
      "target": "adapt to both existing and newly introduced LLMs without requiring retraining.",
      "similarity": 0.7832
    },
    {
      "source": "In this paper",
      "target": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "similarity": 0.8248
    },
    {
      "source": "In this paper",
      "target": "at https://github.com/nlokeshiisc/IDI_release.\"",
      "similarity": 0.8228
    },
    {
      "source": "In this paper",
      "target": "Additionally",
      "similarity": 0.8145
    },
    {
      "source": "In this paper",
      "target": "HsHxSN23rM",
      "similarity": 0.8139
    },
    {
      "source": "In this paper",
      "target": "In this work",
      "similarity": 0.808
    },
    {
      "source": "such data.",
      "target": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "similarity": 0.8116
    },
    {
      "source": "such data.",
      "target": "HD6bWcj87Y",
      "similarity": 0.7957
    },
    {
      "source": "such data.",
      "target": "This custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters.",
      "similarity": 0.7932
    },
    {
      "source": "such data.",
      "target": "k2uUeLCrQq",
      "similarity": 0.7913
    },
    {
      "source": "such data.",
      "target": "For example",
      "similarity": 0.7888
    },
    {
      "source": "We found that long distance referrals",
      "target": "kwCHcaeHrf",
      "similarity": 0.8774
    },
    {
      "source": "We found that long distance referrals",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8693
    },
    {
      "source": "We found that long distance referrals",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8669
    },
    {
      "source": "We found that long distance referrals",
      "target": "UxzKcIZedp",
      "similarity": 0.8594
    },
    {
      "source": "We found that long distance referrals",
      "target": "IuU0wcO0mo",
      "similarity": 0.8575
    },
    {
      "source": "However",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8432
    },
    {
      "source": "However",
      "target": "Second",
      "similarity": 0.8366
    },
    {
      "source": "However",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8359
    },
    {
      "source": "However",
      "target": "BQwsRy1h3U",
      "similarity": 0.8344
    },
    {
      "source": "However",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8305
    },
    {
      "source": "We further show that the density of long-distance referrals",
      "target": "Essg9kb4yx",
      "similarity": 0.9163
    },
    {
      "source": "We further show that the density of long-distance referrals",
      "target": "jTEKTdI3K9",
      "similarity": 0.8676
    },
    {
      "source": "We further show that the density of long-distance referrals",
      "target": "For example",
      "similarity": 0.8658
    },
    {
      "source": "We further show that the density of long-distance referrals",
      "target": "has difficulty in capturing the relationship and the similarity structure of a",
      "similarity": 0.8519
    },
    {
      "source": "We further show that the density of long-distance referrals",
      "target": "9kJperA2a4",
      "similarity": 0.8442
    },
    {
      "source": "To enrich long documents",
      "target": "jckKNzYYA6",
      "similarity": 0.8532
    },
    {
      "source": "To enrich long documents",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8345
    },
    {
      "source": "To enrich long documents",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8341
    },
    {
      "source": "To enrich long documents",
      "target": "Finally",
      "similarity": 0.8306
    },
    {
      "source": "To enrich long documents",
      "target": "97rOQDPmk2",
      "similarity": 0.8293
    },
    {
      "source": "Specifically",
      "target": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "similarity": 0.8691
    },
    {
      "source": "Specifically",
      "target": "JCiF03qnmi",
      "similarity": 0.8189
    },
    {
      "source": "Specifically",
      "target": "First",
      "similarity": 0.8114
    },
    {
      "source": "Specifically",
      "target": "However",
      "similarity": 0.8067
    },
    {
      "source": "Specifically",
      "target": "nYjAzwor9R",
      "similarity": 0.8029
    },
    {
      "source": "By packing web pages through their hyper-link connection",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8519
    },
    {
      "source": "By packing web pages through their hyper-link connection",
      "target": "3) We train the model through compression-based auto-regression",
      "similarity": 0.8437
    },
    {
      "source": "By packing web pages through their hyper-link connection",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8429
    },
    {
      "source": "By packing web pages through their hyper-link connection",
      "target": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "similarity": 0.8375
    },
    {
      "source": "By packing web pages through their hyper-link connection",
      "target": "However",
      "similarity": 0.8372
    },
    {
      "source": "Our experiments demonstrate that LongPackis highly scalable",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8738
    },
    {
      "source": "Our experiments demonstrate that LongPackis highly scalable",
      "target": "FCBbh0HCrF",
      "similarity": 0.8597
    },
    {
      "source": "Our experiments demonstrate that LongPackis highly scalable",
      "target": "G8U2nGP3Vi",
      "similarity": 0.837
    },
    {
      "source": "Our experiments demonstrate that LongPackis highly scalable",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8352
    },
    {
      "source": "Our experiments demonstrate that LongPackis highly scalable",
      "target": "group-unlabeled data",
      "similarity": 0.8226
    },
    {
      "source": "Furthermore",
      "target": "K7xpl3LZQp",
      "similarity": 0.8542
    },
    {
      "source": "Furthermore",
      "target": "In contrast",
      "similarity": 0.8536
    },
    {
      "source": "Furthermore",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8503
    },
    {
      "source": "Furthermore",
      "target": "rdAbEn5DZt",
      "similarity": 0.8477
    },
    {
      "source": "Furthermore",
      "target": "mqNKiEB6pd",
      "similarity": 0.8461
    },
    {
      "source": "FN7n7JRjsk",
      "target": "Using this approach",
      "similarity": 0.8423
    },
    {
      "source": "FN7n7JRjsk",
      "target": "bmbRCRiNDu",
      "similarity": 0.8319
    },
    {
      "source": "FN7n7JRjsk",
      "target": "Vanilla SFT (i.e.",
      "similarity": 0.8241
    },
    {
      "source": "FN7n7JRjsk",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8234
    },
    {
      "source": "FN7n7JRjsk",
      "target": "2kGKsyhtvh",
      "similarity": 0.8226
    },
    {
      "source": "However",
      "target": "Neb17mimVH",
      "similarity": 0.8631
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8629
    },
    {
      "source": "However",
      "target": "Conversely",
      "similarity": 0.8613
    },
    {
      "source": "However",
      "target": "To strike a balance between scalability and minimal supervision",
      "similarity": 0.8563
    },
    {
      "source": "However",
      "target": "Es4RPNDtmq",
      "similarity": 0.8532
    },
    {
      "source": "In this paper",
      "target": "KeRwLLwZaw",
      "similarity": 0.8237
    },
    {
      "source": "In this paper",
      "target": "xQCXInDq0m",
      "similarity": 0.8218
    },
    {
      "source": "In this paper",
      "target": "04qx93Viwj",
      "similarity": 0.8161
    },
    {
      "source": "In this paper",
      "target": "CLIP",
      "similarity": 0.8124
    },
    {
      "source": "In this paper",
      "target": "E2PFv7ad3p",
      "similarity": 0.8119
    },
    {
      "source": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "target": "space for $p > 1$",
      "similarity": 0.8591
    },
    {
      "source": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8378
    },
    {
      "source": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "target": "Aided Design (CAD) scripting code",
      "similarity": 0.8132
    },
    {
      "source": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "target": "7YKV7zkNpX",
      "similarity": 0.8123
    },
    {
      "source": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "target": "entities of a sentence (subject",
      "similarity": 0.8115
    },
    {
      "source": "Specifically",
      "target": "Ax0i933gtp",
      "similarity": 0.8548
    },
    {
      "source": "Specifically",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8438
    },
    {
      "source": "Specifically",
      "target": "xjKz6IxgCX",
      "similarity": 0.8421
    },
    {
      "source": "Specifically",
      "target": "We perform detailed analyses",
      "similarity": 0.8391
    },
    {
      "source": "Specifically",
      "target": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "similarity": 0.8386
    },
    {
      "source": "Based on DLC",
      "target": "jTEKTdI3K9",
      "similarity": 0.8578
    },
    {
      "source": "Based on DLC",
      "target": "v1rFkElnIn",
      "similarity": 0.854
    },
    {
      "source": "Based on DLC",
      "target": "9kJperA2a4",
      "similarity": 0.8463
    },
    {
      "source": "Based on DLC",
      "target": "5AtlfHYCPa",
      "similarity": 0.8434
    },
    {
      "source": "Based on DLC",
      "target": "To tackle this challenge",
      "similarity": 0.8429
    },
    {
      "source": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "target": "To make this efficient",
      "similarity": 0.8985
    },
    {
      "source": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "target": "tu3qwNjrtw",
      "similarity": 0.8683
    },
    {
      "source": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "target": "PxlfzEePC0",
      "similarity": 0.8636
    },
    {
      "source": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "target": "hgwGi81ndj",
      "similarity": 0.8566
    },
    {
      "source": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8548
    },
    {
      "source": "In the images pruning benchmark",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8394
    },
    {
      "source": "In the images pruning benchmark",
      "target": "nzjSvVZBIp",
      "similarity": 0.8338
    },
    {
      "source": "In the images pruning benchmark",
      "target": "yR47RmND1m",
      "similarity": 0.8297
    },
    {
      "source": "In the images pruning benchmark",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8284
    },
    {
      "source": "In the images pruning benchmark",
      "target": "zg3ec1TdAP",
      "similarity": 0.8205
    },
    {
      "source": "FCBbh0HCrF",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8592
    },
    {
      "source": "FCBbh0HCrF",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8511
    },
    {
      "source": "FCBbh0HCrF",
      "target": "Crucially",
      "similarity": 0.8362
    },
    {
      "source": "FCBbh0HCrF",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8345
    },
    {
      "source": "FCBbh0HCrF",
      "target": "INyi7qUdjZ",
      "similarity": 0.8288
    },
    {
      "source": "However",
      "target": "MxbEiFRf39",
      "similarity": 0.832
    },
    {
      "source": "However",
      "target": "Second",
      "similarity": 0.8299
    },
    {
      "source": "However",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8257
    },
    {
      "source": "However",
      "target": "Specifically",
      "similarity": 0.8248
    },
    {
      "source": "However",
      "target": "H9UnNgdq0g",
      "similarity": 0.823
    },
    {
      "source": "In real-world scenarios",
      "target": "U834XHJuqk",
      "similarity": 0.8252
    },
    {
      "source": "In real-world scenarios",
      "target": "gFvRRCnQvX",
      "similarity": 0.8209
    },
    {
      "source": "In real-world scenarios",
      "target": "Despite this",
      "similarity": 0.8094
    },
    {
      "source": "In real-world scenarios",
      "target": "Moreover",
      "similarity": 0.805
    },
    {
      "source": "In real-world scenarios",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.7947
    },
    {
      "source": "We are the first to identify these challenges in online VFL",
      "target": "fMNRYBvcQN",
      "similarity": 0.8251
    },
    {
      "source": "We are the first to identify these challenges in online VFL",
      "target": "K2jOacHUlO",
      "similarity": 0.8247
    },
    {
      "source": "We are the first to identify these challenges in online VFL",
      "target": "scaling over text. Based on this perspective",
      "similarity": 0.8219
    },
    {
      "source": "We are the first to identify these challenges in online VFL",
      "target": "1durmugh3I",
      "similarity": 0.8218
    },
    {
      "source": "We are the first to identify these challenges in online VFL",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8177
    },
    {
      "source": "Furthermore",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8988
    },
    {
      "source": "Furthermore",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8472
    },
    {
      "source": "Furthermore",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8457
    },
    {
      "source": "Furthermore",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8456
    },
    {
      "source": "Furthermore",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8442
    },
    {
      "source": "We conducted a comprehensive regret analysis of our proposed framework",
      "target": "P6IVIoGRRg",
      "similarity": 0.8611
    },
    {
      "source": "We conducted a comprehensive regret analysis of our proposed framework",
      "target": "1F8xTfv6ah",
      "similarity": 0.8547
    },
    {
      "source": "We conducted a comprehensive regret analysis of our proposed framework",
      "target": "Finally",
      "similarity": 0.838
    },
    {
      "source": "We conducted a comprehensive regret analysis of our proposed framework",
      "target": "xnF2U0ro7b",
      "similarity": 0.8354
    },
    {
      "source": "We conducted a comprehensive regret analysis of our proposed framework",
      "target": "Additionally",
      "similarity": 0.8303
    },
    {
      "source": "Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.\"",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.7902
    },
    {
      "source": "Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.\"",
      "target": "Pnk7vMbznK",
      "similarity": 0.7769
    },
    {
      "source": "Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.\"",
      "target": "LM4PYXBId5",
      "similarity": 0.7717
    },
    {
      "source": "Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.\"",
      "target": "iVxxgZlXh6",
      "similarity": 0.7701
    },
    {
      "source": "Extensive experiments demonstrated that our proposed framework was more stable than the existing online VFL framework under non-stationary data conditions while also significantly reducing communication and computation costs.\"",
      "target": "m8yby1JfbU",
      "similarity": 0.7695
    },
    {
      "source": "ajSmXqgS24",
      "target": "In this work",
      "similarity": 0.8592
    },
    {
      "source": "ajSmXqgS24",
      "target": "dmCGjPFVhF",
      "similarity": 0.8443
    },
    {
      "source": "ajSmXqgS24",
      "target": "e0X9l4kecx",
      "similarity": 0.843
    },
    {
      "source": "ajSmXqgS24",
      "target": "require resource-intensive iterative training and only needs a small amount of",
      "similarity": 0.8336
    },
    {
      "source": "ajSmXqgS24",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.831
    },
    {
      "source": "TvGPP8i18S",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8581
    },
    {
      "source": "TvGPP8i18S",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8532
    },
    {
      "source": "TvGPP8i18S",
      "target": "To further demonstrate the effectiveness of CNL-P",
      "similarity": 0.8496
    },
    {
      "source": "TvGPP8i18S",
      "target": "As a byproduct of our methods",
      "similarity": 0.8424
    },
    {
      "source": "TvGPP8i18S",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.8409
    },
    {
      "source": "T4sMzjy7fO",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8808
    },
    {
      "source": "T4sMzjy7fO",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8589
    },
    {
      "source": "T4sMzjy7fO",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8586
    },
    {
      "source": "T4sMzjy7fO",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.849
    },
    {
      "source": "T4sMzjy7fO",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8429
    },
    {
      "source": "JsVIGVntnQ",
      "target": "space are required in general even for outputting a constant factor",
      "similarity": 0.8441
    },
    {
      "source": "JsVIGVntnQ",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8372
    },
    {
      "source": "JsVIGVntnQ",
      "target": "In response",
      "similarity": 0.8322
    },
    {
      "source": "JsVIGVntnQ",
      "target": "hidden activations over an input dataset but generally cannot explain how MLP",
      "similarity": 0.8296
    },
    {
      "source": "JsVIGVntnQ",
      "target": "UyhRtB4hjN",
      "similarity": 0.8291
    },
    {
      "source": "WwpYSOkkCt",
      "target": "To address these challenges",
      "similarity": 0.8231
    },
    {
      "source": "WwpYSOkkCt",
      "target": "zxO4WuVGns",
      "similarity": 0.804
    },
    {
      "source": "WwpYSOkkCt",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.7958
    },
    {
      "source": "WwpYSOkkCt",
      "target": "s9zoyICZ4k",
      "similarity": 0.7912
    },
    {
      "source": "WwpYSOkkCt",
      "target": "gcouwCx7dG",
      "similarity": 0.788
    },
    {
      "source": "8g4XgC8HPF",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.855
    },
    {
      "source": "8g4XgC8HPF",
      "target": "WzCEiBILHu",
      "similarity": 0.833
    },
    {
      "source": "8g4XgC8HPF",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.8271
    },
    {
      "source": "8g4XgC8HPF",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8262
    },
    {
      "source": "8g4XgC8HPF",
      "target": "In this task",
      "similarity": 0.8222
    },
    {
      "source": "of natural language. However",
      "target": "AnL6BuWzxa",
      "similarity": 0.8816
    },
    {
      "source": "of natural language. However",
      "target": "yIlyHJdYV3",
      "similarity": 0.8573
    },
    {
      "source": "of natural language. However",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8537
    },
    {
      "source": "of natural language. However",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8483
    },
    {
      "source": "of natural language. However",
      "target": "To address these limitations",
      "similarity": 0.8453
    },
    {
      "source": "logical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence",
      "target": "memorization.",
      "similarity": 0.83
    },
    {
      "source": "logical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence",
      "target": "EMMnAd3apQ",
      "similarity": 0.8292
    },
    {
      "source": "logical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8155
    },
    {
      "source": "logical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence",
      "target": "GRMfXcAAFh",
      "similarity": 0.8154
    },
    {
      "source": "logical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence",
      "target": "Our framework",
      "similarity": 0.8148
    },
    {
      "source": "tractably condition on the constraint. To generate samples that satisfy the constraint",
      "target": "6bKEWevgSd",
      "similarity": 0.839
    },
    {
      "source": "tractably condition on the constraint. To generate samples that satisfy the constraint",
      "target": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "similarity": 0.8323
    },
    {
      "source": "tractably condition on the constraint. To generate samples that satisfy the constraint",
      "target": "In response",
      "similarity": 0.8304
    },
    {
      "source": "tractably condition on the constraint. To generate samples that satisfy the constraint",
      "target": "R2834dhBlo",
      "similarity": 0.8281
    },
    {
      "source": "tractably condition on the constraint. To generate samples that satisfy the constraint",
      "target": "Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.",
      "similarity": 0.8258
    },
    {
      "source": "correct for biases in the sample weights",
      "target": "OjAU0LLDbe",
      "similarity": 0.8246
    },
    {
      "source": "correct for biases in the sample weights",
      "target": "(including gradient-based",
      "similarity": 0.8232
    },
    {
      "source": "correct for biases in the sample weights",
      "target": "L0evcuybH5",
      "similarity": 0.821
    },
    {
      "source": "correct for biases in the sample weights",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.818
    },
    {
      "source": "correct for biases in the sample weights",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8178
    },
    {
      "source": "B8akWa62Da",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8524
    },
    {
      "source": "B8akWa62Da",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8383
    },
    {
      "source": "B8akWa62Da",
      "target": "comprehensive experiments",
      "similarity": 0.8337
    },
    {
      "source": "B8akWa62Da",
      "target": "However",
      "similarity": 0.8232
    },
    {
      "source": "B8akWa62Da",
      "target": "T4sMzjy7fO",
      "similarity": 0.8193
    },
    {
      "source": "We5z3UEnUY",
      "target": "In experiments with GPT-4",
      "similarity": 0.8645
    },
    {
      "source": "We5z3UEnUY",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8271
    },
    {
      "source": "We5z3UEnUY",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8247
    },
    {
      "source": "We5z3UEnUY",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8239
    },
    {
      "source": "We5z3UEnUY",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.8225
    },
    {
      "source": "i7k2sXSW1b",
      "target": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "similarity": 0.8109
    },
    {
      "source": "i7k2sXSW1b",
      "target": "We start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique)",
      "similarity": 0.8022
    },
    {
      "source": "i7k2sXSW1b",
      "target": "OQqNieeivq",
      "similarity": 0.7932
    },
    {
      "source": "i7k2sXSW1b",
      "target": "In this paper",
      "similarity": 0.7901
    },
    {
      "source": "i7k2sXSW1b",
      "target": "We find that this modification improves compositional generalization on abstract reasoning tasks.",
      "similarity": 0.79
    },
    {
      "source": "I0n3EyogMi",
      "target": "Against grandmaster-level (2500 Elo) opponents",
      "similarity": 0.7875
    },
    {
      "source": "I0n3EyogMi",
      "target": "This study highlights a major",
      "similarity": 0.7831
    },
    {
      "source": "I0n3EyogMi",
      "target": "However",
      "similarity": 0.7819
    },
    {
      "source": "I0n3EyogMi",
      "target": "These findings provide valuable insights for efficient and effective sparse pre-training of LLMs.",
      "similarity": 0.7797
    },
    {
      "source": "I0n3EyogMi",
      "target": "To address these considerations",
      "similarity": 0.778
    },
    {
      "source": "Following this new setting",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8671
    },
    {
      "source": "Following this new setting",
      "target": "4FWAwZtd2n",
      "similarity": 0.8366
    },
    {
      "source": "Following this new setting",
      "target": "llSiIJosDj",
      "similarity": 0.8281
    },
    {
      "source": "Following this new setting",
      "target": "Reweighting (GSR)",
      "similarity": 0.8191
    },
    {
      "source": "Following this new setting",
      "target": "Usklli4gMc",
      "similarity": 0.8159
    },
    {
      "source": "fMNRYBvcQN",
      "target": "xI71dsS3o4",
      "similarity": 0.8301
    },
    {
      "source": "fMNRYBvcQN",
      "target": "However",
      "similarity": 0.8284
    },
    {
      "source": "fMNRYBvcQN",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8262
    },
    {
      "source": "fMNRYBvcQN",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8253
    },
    {
      "source": "fMNRYBvcQN",
      "target": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "similarity": 0.8214
    },
    {
      "source": "SUc1UOWndp",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8392
    },
    {
      "source": "SUc1UOWndp",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8347
    },
    {
      "source": "SUc1UOWndp",
      "target": "To tackle this challenge",
      "similarity": 0.8343
    },
    {
      "source": "SUc1UOWndp",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8326
    },
    {
      "source": "SUc1UOWndp",
      "target": "Moreover",
      "similarity": 0.8324
    },
    {
      "source": "EMMnAd3apQ",
      "target": "Notably",
      "similarity": 0.8847
    },
    {
      "source": "EMMnAd3apQ",
      "target": "depth-wise",
      "similarity": 0.8606
    },
    {
      "source": "EMMnAd3apQ",
      "target": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "similarity": 0.856
    },
    {
      "source": "EMMnAd3apQ",
      "target": "cADpvQgnqg",
      "similarity": 0.8527
    },
    {
      "source": "EMMnAd3apQ",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8508
    },
    {
      "source": "aBnVU5DL3I",
      "target": "Ax3uliEBVR",
      "similarity": 0.8183
    },
    {
      "source": "aBnVU5DL3I",
      "target": "tQyh0gnfqW",
      "similarity": 0.8115
    },
    {
      "source": "aBnVU5DL3I",
      "target": "03EkqSCKuO",
      "similarity": 0.8109
    },
    {
      "source": "aBnVU5DL3I",
      "target": "K5yeB4dTtS",
      "similarity": 0.8088
    },
    {
      "source": "aBnVU5DL3I",
      "target": "ptjrpEGrGg",
      "similarity": 0.8078
    },
    {
      "source": "6F6qwdycgJ",
      "target": "cmfyMV45XO",
      "similarity": 0.8505
    },
    {
      "source": "6F6qwdycgJ",
      "target": "To this end",
      "similarity": 0.8487
    },
    {
      "source": "6F6qwdycgJ",
      "target": "AJpUZd8Clb",
      "similarity": 0.8445
    },
    {
      "source": "6F6qwdycgJ",
      "target": "context window",
      "similarity": 0.8431
    },
    {
      "source": "6F6qwdycgJ",
      "target": "To enable TTA for regression",
      "similarity": 0.8426
    },
    {
      "source": "OjAU0LLDbe",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8615
    },
    {
      "source": "OjAU0LLDbe",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8465
    },
    {
      "source": "OjAU0LLDbe",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8441
    },
    {
      "source": "OjAU0LLDbe",
      "target": "To overcome such limitations",
      "similarity": 0.8431
    },
    {
      "source": "OjAU0LLDbe",
      "target": "rCX9l4OTCT",
      "similarity": 0.8367
    },
    {
      "source": "pOO9cqLq7Q",
      "target": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "similarity": 0.8549
    },
    {
      "source": "pOO9cqLq7Q",
      "target": "nYjAzwor9R",
      "similarity": 0.8173
    },
    {
      "source": "pOO9cqLq7Q",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8142
    },
    {
      "source": "pOO9cqLq7Q",
      "target": "JCiF03qnmi",
      "similarity": 0.8008
    },
    {
      "source": "pOO9cqLq7Q",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.7989
    },
    {
      "source": "cPD2hU35x3",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8422
    },
    {
      "source": "cPD2hU35x3",
      "target": "HqjRlT65WX",
      "similarity": 0.8405
    },
    {
      "source": "cPD2hU35x3",
      "target": "rTQNGQxm4K",
      "similarity": 0.8373
    },
    {
      "source": "cPD2hU35x3",
      "target": "eHehzSDUFp",
      "similarity": 0.8341
    },
    {
      "source": "cPD2hU35x3",
      "target": "PwxYoMvmvy",
      "similarity": 0.8338
    },
    {
      "source": "context window",
      "target": "In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding",
      "similarity": 0.8324
    },
    {
      "source": "context window",
      "target": "MscdsFVZrN",
      "similarity": 0.8048
    },
    {
      "source": "context window",
      "target": "behavior across compute scale? We find that small- and large-scale language",
      "similarity": 0.8043
    },
    {
      "source": "context window",
      "target": "zY37C8d6bS",
      "similarity": 0.8024
    },
    {
      "source": "context window",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8006
    },
    {
      "source": "leading proprietary models (e.g.",
      "target": "PY56Wur7S0",
      "similarity": 0.8334
    },
    {
      "source": "leading proprietary models (e.g.",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8167
    },
    {
      "source": "leading proprietary models (e.g.",
      "target": "mzL19kKE3r",
      "similarity": 0.8131
    },
    {
      "source": "leading proprietary models (e.g.",
      "target": "rnJxelIZrq",
      "similarity": 0.813
    },
    {
      "source": "leading proprietary models (e.g.",
      "target": "4ytRL3HJrq",
      "similarity": 0.813
    },
    {
      "source": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "target": "iVMcYxTiVM",
      "similarity": 0.8466
    },
    {
      "source": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "target": "60GeEoG5kD",
      "similarity": 0.8306
    },
    {
      "source": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "target": "hgwGi81ndj",
      "similarity": 0.8186
    },
    {
      "source": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "target": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "similarity": 0.8109
    },
    {
      "source": "derstanding and retrieval-augmented generation (RAG) capabilities. These two",
      "target": "general loss and HR-Extreme compared to others. Our results reveal that the",
      "similarity": 0.807
    },
    {
      "source": "capabilities are complementary to each other and essential for LLMs to process",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8199
    },
    {
      "source": "capabilities are complementary to each other and essential for LLMs to process",
      "target": "high-quality labels is often required to obtain noticeable improvements. Given",
      "similarity": 0.8189
    },
    {
      "source": "capabilities are complementary to each other and essential for LLMs to process",
      "target": "We identify prototypical challenges that users face when specifying preferences",
      "similarity": 0.7963
    },
    {
      "source": "capabilities are complementary to each other and essential for LLMs to process",
      "target": "While these models are designed to respond queries under safety mechanism",
      "similarity": 0.7954
    },
    {
      "source": "capabilities are complementary to each other and essential for LLMs to process",
      "target": "remains a largely unexplored domain.",
      "similarity": 0.7952
    },
    {
      "source": "large volumes of information that cannot fit into a single prompt. We present",
      "target": "Finally",
      "similarity": 0.9139
    },
    {
      "source": "large volumes of information that cannot fit into a single prompt. We present",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8711
    },
    {
      "source": "large volumes of information that cannot fit into a single prompt. We present",
      "target": "To this end",
      "similarity": 0.8644
    },
    {
      "source": "large volumes of information that cannot fit into a single prompt. We present",
      "target": "First",
      "similarity": 0.8643
    },
    {
      "source": "large volumes of information that cannot fit into a single prompt. We present",
      "target": "FviefuxmeW",
      "similarity": 0.8625
    },
    {
      "source": "a detailed continued training recipe to extend the context window of Llama3-",
      "target": "oCUYc7BzXQ",
      "similarity": 0.8163
    },
    {
      "source": "a detailed continued training recipe to extend the context window of Llama3-",
      "target": "N4rYbQowE3",
      "similarity": 0.8097
    },
    {
      "source": "a detailed continued training recipe to extend the context window of Llama3-",
      "target": "OQqNieeivq",
      "similarity": 0.8033
    },
    {
      "source": "a detailed continued training recipe to extend the context window of Llama3-",
      "target": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "similarity": 0.803
    },
    {
      "source": "a detailed continued training recipe to extend the context window of Llama3-",
      "target": "Yet",
      "similarity": 0.7972
    },
    {
      "source": "70B-base from 8K to 128K tokens",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8334
    },
    {
      "source": "70B-base from 8K to 128K tokens",
      "target": "This enables the network to adaptively reuse parameters across tasks",
      "similarity": 0.8306
    },
    {
      "source": "70B-base from 8K to 128K tokens",
      "target": "GpdO9r73xT",
      "similarity": 0.8286
    },
    {
      "source": "70B-base from 8K to 128K tokens",
      "target": "latent variables",
      "similarity": 0.8242
    },
    {
      "source": "70B-base from 8K to 128K tokens",
      "target": "kbm6tsICar",
      "similarity": 0.8219
    },
    {
      "source": "ing process to enhance the model\u2019s instruction-following",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8864
    },
    {
      "source": "ing process to enhance the model\u2019s instruction-following",
      "target": "To this end",
      "similarity": 0.8678
    },
    {
      "source": "ing process to enhance the model\u2019s instruction-following",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8655
    },
    {
      "source": "ing process to enhance the model\u2019s instruction-following",
      "target": "xPTzjpIQNp",
      "similarity": 0.8642
    },
    {
      "source": "ing process to enhance the model\u2019s instruction-following",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8621
    },
    {
      "source": "and long-context understanding capabilities. Our results demonstrate that the",
      "target": "b57IG6N20B",
      "similarity": 0.8228
    },
    {
      "source": "and long-context understanding capabilities. Our results demonstrate that the",
      "target": "HE6pJoNnFp",
      "similarity": 0.8222
    },
    {
      "source": "and long-context understanding capabilities. Our results demonstrate that the",
      "target": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "similarity": 0.8203
    },
    {
      "source": "and long-context understanding capabilities. Our results demonstrate that the",
      "target": "Second",
      "similarity": 0.819
    },
    {
      "source": "and long-context understanding capabilities. Our results demonstrate that the",
      "target": "UN6Ik6OCx8",
      "similarity": 0.8044
    },
    {
      "source": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "target": "Notably",
      "similarity": 0.8337
    },
    {
      "source": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "target": "cADpvQgnqg",
      "similarity": 0.8285
    },
    {
      "source": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "target": "GRMfXcAAFh",
      "similarity": 0.8279
    },
    {
      "source": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "target": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "similarity": 0.8271
    },
    {
      "source": "Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models",
      "target": "nrvoWOWcyg",
      "similarity": 0.827
    },
    {
      "source": "including GPT-4-Turbo-2024-04-09",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8676
    },
    {
      "source": "including GPT-4-Turbo-2024-04-09",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8613
    },
    {
      "source": "including GPT-4-Turbo-2024-04-09",
      "target": "5pd78GmXC6",
      "similarity": 0.8408
    },
    {
      "source": "including GPT-4-Turbo-2024-04-09",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8367
    },
    {
      "source": "including GPT-4-Turbo-2024-04-09",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8352
    },
    {
      "source": "Instruct",
      "target": "g6v09VxgFw",
      "similarity": 0.8474
    },
    {
      "source": "Instruct",
      "target": "Second",
      "similarity": 0.8385
    },
    {
      "source": "Instruct",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8351
    },
    {
      "source": "Instruct",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8341
    },
    {
      "source": "Instruct",
      "target": "To address these challenges",
      "similarity": 0.8331
    },
    {
      "source": "using only a 4K context window",
      "target": "gradual stacking and layer dropping (Reddi et al.",
      "similarity": 0.8439
    },
    {
      "source": "using only a 4K context window",
      "target": "lS2SGfWizd",
      "similarity": 0.8313
    },
    {
      "source": "using only a 4K context window",
      "target": "Moreover",
      "similarity": 0.8269
    },
    {
      "source": "using only a 4K context window",
      "target": "rWQDzq3O5c",
      "similarity": 0.8237
    },
    {
      "source": "using only a 4K context window",
      "target": "rvXdGL4pCJ",
      "similarity": 0.8232
    },
    {
      "source": "varying sequence lengths. We further provide extensive comparisons between",
      "target": "HN8V0flwJF",
      "similarity": 0.8635
    },
    {
      "source": "varying sequence lengths. We further provide extensive comparisons between",
      "target": "In this paper",
      "similarity": 0.8556
    },
    {
      "source": "varying sequence lengths. We further provide extensive comparisons between",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8519
    },
    {
      "source": "varying sequence lengths. We further provide extensive comparisons between",
      "target": "GySIAKEwtZ",
      "similarity": 0.8519
    },
    {
      "source": "varying sequence lengths. We further provide extensive comparisons between",
      "target": "These findings highlight the significant room for improvement in current reward models.\"",
      "similarity": 0.8495
    },
    {
      "source": "direct long-context and RAG solutions using the same state-of-the-art long-context",
      "target": "To validate OvercookedV2",
      "similarity": 0.8038
    },
    {
      "source": "direct long-context and RAG solutions using the same state-of-the-art long-context",
      "target": "(1) Sparse attention patterns",
      "similarity": 0.8007
    },
    {
      "source": "direct long-context and RAG solutions using the same state-of-the-art long-context",
      "target": "CGON8Btleu",
      "similarity": 0.7851
    },
    {
      "source": "direct long-context and RAG solutions using the same state-of-the-art long-context",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.7822
    },
    {
      "source": "direct long-context and RAG solutions using the same state-of-the-art long-context",
      "target": "BPAZ6yW3K7",
      "similarity": 0.7812
    },
    {
      "source": "LLMs. Interestingly",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8649
    },
    {
      "source": "LLMs. Interestingly",
      "target": "AJpUZd8Clb",
      "similarity": 0.8608
    },
    {
      "source": "LLMs. Interestingly",
      "target": "GySIAKEwtZ",
      "similarity": 0.8585
    },
    {
      "source": "LLMs. Interestingly",
      "target": "HN8V0flwJF",
      "similarity": 0.8544
    },
    {
      "source": "LLMs. Interestingly",
      "target": "To this end",
      "similarity": 0.8462
    },
    {
      "source": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "target": "Our experiments show that a LLaMA3-8B model",
      "similarity": 0.7839
    },
    {
      "source": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "target": "In this paper",
      "similarity": 0.7775
    },
    {
      "source": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.7762
    },
    {
      "source": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "target": "sb1HgVDLjN",
      "similarity": 0.7759
    },
    {
      "source": "using RAG improves when retrieving a larger number of chunks. With a large set",
      "target": "O6znYvxC1U",
      "similarity": 0.7742
    },
    {
      "source": "of top-k chunks",
      "target": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "similarity": 0.8739
    },
    {
      "source": "of top-k chunks",
      "target": "the same state-of-the-art long-context models (e.g.",
      "similarity": 0.8716
    },
    {
      "source": "of top-k chunks",
      "target": "Ian00SaFHg",
      "similarity": 0.847
    },
    {
      "source": "of top-k chunks",
      "target": "This corresponds to",
      "similarity": 0.8302
    },
    {
      "source": "of top-k chunks",
      "target": "xjKz6IxgCX",
      "similarity": 0.8297
    },
    {
      "source": "the same state-of-the-art long-context models (e.g.",
      "target": "mYgoNEsUDi",
      "similarity": 0.8394
    },
    {
      "source": "the same state-of-the-art long-context models (e.g.",
      "target": "QfhU3ZC2g1",
      "similarity": 0.8332
    },
    {
      "source": "the same state-of-the-art long-context models (e.g.",
      "target": "97rOQDPmk2",
      "similarity": 0.8323
    },
    {
      "source": "the same state-of-the-art long-context models (e.g.",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8155
    },
    {
      "source": "the same state-of-the-art long-context models (e.g.",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8133
    },
    {
      "source": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "target": "However",
      "similarity": 0.8306
    },
    {
      "source": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "target": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "similarity": 0.8301
    },
    {
      "source": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "target": "uHLgDEgiS5",
      "similarity": 0.8296
    },
    {
      "source": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "target": "FUaDMRVrbS",
      "similarity": 0.8283
    },
    {
      "source": "Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the",
      "target": "ugyqNEOjoU",
      "similarity": 0.8269
    },
    {
      "source": "model weights",
      "target": "il5yUQsrjC",
      "similarity": 0.8552
    },
    {
      "source": "model weights",
      "target": "myYzr50xBh",
      "similarity": 0.8492
    },
    {
      "source": "model weights",
      "target": "In particular",
      "similarity": 0.8432
    },
    {
      "source": "model weights",
      "target": "show that BoneMet can be readily adopted to build versatile",
      "similarity": 0.8404
    },
    {
      "source": "model weights",
      "target": "84WmbzikPP",
      "similarity": 0.8376
    },
    {
      "source": "https://chatqa2-project.github.io/\"",
      "target": "FSjIrOm1vz",
      "similarity": 0.8268
    },
    {
      "source": "https://chatqa2-project.github.io/\"",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8184
    },
    {
      "source": "https://chatqa2-project.github.io/\"",
      "target": "CS2JWaziYr",
      "similarity": 0.8081
    },
    {
      "source": "https://chatqa2-project.github.io/\"",
      "target": "kOYnXVQCtA",
      "similarity": 0.8078
    },
    {
      "source": "https://chatqa2-project.github.io/\"",
      "target": "propose to cache and reuse KV state of prompts. However",
      "similarity": 0.8037
    },
    {
      "source": "wHebuIb6IH",
      "target": "J9VogDTa1W",
      "similarity": 0.8949
    },
    {
      "source": "wHebuIb6IH",
      "target": "3bcN6xlO6f",
      "similarity": 0.875
    },
    {
      "source": "wHebuIb6IH",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8733
    },
    {
      "source": "wHebuIb6IH",
      "target": "NDLmZZWATc",
      "similarity": 0.8677
    },
    {
      "source": "wHebuIb6IH",
      "target": "pre-training data",
      "similarity": 0.867
    },
    {
      "source": "0OTVNEm9N4",
      "target": "7El7K1DoyX",
      "similarity": 0.8462
    },
    {
      "source": "0OTVNEm9N4",
      "target": "However",
      "similarity": 0.8377
    },
    {
      "source": "0OTVNEm9N4",
      "target": "Second",
      "similarity": 0.8363
    },
    {
      "source": "0OTVNEm9N4",
      "target": "Mjn53GtMxi",
      "similarity": 0.8358
    },
    {
      "source": "0OTVNEm9N4",
      "target": "Empirically",
      "similarity": 0.8358
    },
    {
      "source": "QKBu1BOAwd",
      "target": "ssRdQimeUI",
      "similarity": 0.8349
    },
    {
      "source": "QKBu1BOAwd",
      "target": "SG1R2H3fa1",
      "similarity": 0.8339
    },
    {
      "source": "QKBu1BOAwd",
      "target": "Here",
      "similarity": 0.8257
    },
    {
      "source": "QKBu1BOAwd",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8246
    },
    {
      "source": "QKBu1BOAwd",
      "target": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "similarity": 0.8231
    },
    {
      "source": "bU1JOvdXXK",
      "target": "bc2H72hGxB",
      "similarity": 0.8012
    },
    {
      "source": "bU1JOvdXXK",
      "target": "03EkqSCKuO",
      "similarity": 0.7934
    },
    {
      "source": "bU1JOvdXXK",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.7853
    },
    {
      "source": "bU1JOvdXXK",
      "target": "memorization.",
      "similarity": 0.779
    },
    {
      "source": "bU1JOvdXXK",
      "target": "EMMnAd3apQ",
      "similarity": 0.7787
    },
    {
      "source": "However",
      "target": "While existing ILP systems can successfully solve small-scale tasks",
      "similarity": 0.7931
    },
    {
      "source": "However",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.7881
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.7874
    },
    {
      "source": "However",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.781
    },
    {
      "source": "However",
      "target": "mDKxlfraAn",
      "similarity": 0.7772
    },
    {
      "source": "K2jOacHUlO",
      "target": "conjugate exponent of $p$. For $p = 2$",
      "similarity": 0.8328
    },
    {
      "source": "K2jOacHUlO",
      "target": "m73tETvFkX",
      "similarity": 0.8274
    },
    {
      "source": "K2jOacHUlO",
      "target": "rfdblE10qm",
      "similarity": 0.8117
    },
    {
      "source": "K2jOacHUlO",
      "target": "gVnJFY8nCM",
      "similarity": 0.8079
    },
    {
      "source": "K2jOacHUlO",
      "target": "uREg3OHjLL",
      "similarity": 0.8076
    },
    {
      "source": "Our results show that for LLMs with strong reasoning capabilities",
      "target": "cmfyMV45XO",
      "similarity": 0.8909
    },
    {
      "source": "Our results show that for LLMs with strong reasoning capabilities",
      "target": "9EqQC2ct4H",
      "similarity": 0.8374
    },
    {
      "source": "Our results show that for LLMs with strong reasoning capabilities",
      "target": "To address this",
      "similarity": 0.8354
    },
    {
      "source": "Our results show that for LLMs with strong reasoning capabilities",
      "target": "pCj2sLNoJq",
      "similarity": 0.8318
    },
    {
      "source": "Our results show that for LLMs with strong reasoning capabilities",
      "target": "gVkX9QMBO3",
      "similarity": 0.8263
    },
    {
      "source": "tozlOEN4qp",
      "target": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "similarity": 0.8466
    },
    {
      "source": "tozlOEN4qp",
      "target": "84WmbzikPP",
      "similarity": 0.8419
    },
    {
      "source": "tozlOEN4qp",
      "target": "l6QnSQizmN",
      "similarity": 0.8383
    },
    {
      "source": "tozlOEN4qp",
      "target": "il5yUQsrjC",
      "similarity": 0.8379
    },
    {
      "source": "tozlOEN4qp",
      "target": "8eNLKk5by4",
      "similarity": 0.8359
    },
    {
      "source": "VpWki1v2P8",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8779
    },
    {
      "source": "VpWki1v2P8",
      "target": "instructions",
      "similarity": 0.8649
    },
    {
      "source": "VpWki1v2P8",
      "target": "Mjn53GtMxi",
      "similarity": 0.8603
    },
    {
      "source": "VpWki1v2P8",
      "target": "To this end",
      "similarity": 0.8597
    },
    {
      "source": "VpWki1v2P8",
      "target": "In this paper",
      "similarity": 0.8574
    },
    {
      "source": "ACSNlt77hq",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8376
    },
    {
      "source": "ACSNlt77hq",
      "target": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "similarity": 0.8298
    },
    {
      "source": "ACSNlt77hq",
      "target": "iVMcYxTiVM",
      "similarity": 0.8267
    },
    {
      "source": "ACSNlt77hq",
      "target": "By incorporating generative models into the BOED framework",
      "similarity": 0.8212
    },
    {
      "source": "ACSNlt77hq",
      "target": "NkGDNM8LB0",
      "similarity": 0.8191
    },
    {
      "source": "HqjRlT65WX",
      "target": "than existing search techniques",
      "similarity": 0.8654
    },
    {
      "source": "HqjRlT65WX",
      "target": "YvKJGYL4j7",
      "similarity": 0.8626
    },
    {
      "source": "HqjRlT65WX",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8531
    },
    {
      "source": "HqjRlT65WX",
      "target": "yitH9xAHQs",
      "similarity": 0.8501
    },
    {
      "source": "HqjRlT65WX",
      "target": "This work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.\"",
      "similarity": 0.8476
    },
    {
      "source": "8egnwady4b",
      "target": "Moreover",
      "similarity": 0.8233
    },
    {
      "source": "8egnwady4b",
      "target": "At the inference stage",
      "similarity": 0.8172
    },
    {
      "source": "8egnwady4b",
      "target": "standard training and",
      "similarity": 0.8136
    },
    {
      "source": "8egnwady4b",
      "target": "kam84eEmub",
      "similarity": 0.8123
    },
    {
      "source": "8egnwady4b",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.8098
    },
    {
      "source": "BQwsRy1h3U",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8358
    },
    {
      "source": "BQwsRy1h3U",
      "target": "WOt1owGfuN",
      "similarity": 0.8336
    },
    {
      "source": "BQwsRy1h3U",
      "target": "AjXkRZIvjB",
      "similarity": 0.8259
    },
    {
      "source": "BQwsRy1h3U",
      "target": "errors of extreme weather cases are significantly larger than overall forecast error",
      "similarity": 0.8252
    },
    {
      "source": "BQwsRy1h3U",
      "target": "terms of linear operations using a third-order tensor",
      "similarity": 0.8217
    },
    {
      "source": "As the size of the model and data grows",
      "target": "gWgaypDBs8",
      "similarity": 0.849
    },
    {
      "source": "As the size of the model and data grows",
      "target": "For detailed information",
      "similarity": 0.8267
    },
    {
      "source": "As the size of the model and data grows",
      "target": "CLIP",
      "similarity": 0.8186
    },
    {
      "source": "As the size of the model and data grows",
      "target": "wg1PCg3CUP",
      "similarity": 0.8178
    },
    {
      "source": "As the size of the model and data grows",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8177
    },
    {
      "source": "To address this",
      "target": "L5godAOC2z",
      "similarity": 0.8167
    },
    {
      "source": "To address this",
      "target": "spDUv05cEq",
      "similarity": 0.8166
    },
    {
      "source": "To address this",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.7962
    },
    {
      "source": "To address this",
      "target": "6awxwQEI82",
      "similarity": 0.7911
    },
    {
      "source": "To address this",
      "target": "wg1PCg3CUP",
      "similarity": 0.785
    },
    {
      "source": "This paper supplements them",
      "target": "NKotdPUc3L",
      "similarity": 0.8386
    },
    {
      "source": "This paper supplements them",
      "target": "P6IVIoGRRg",
      "similarity": 0.8113
    },
    {
      "source": "This paper supplements them",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8085
    },
    {
      "source": "This paper supplements them",
      "target": "INyi7qUdjZ",
      "similarity": 0.8072
    },
    {
      "source": "This paper supplements them",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8025
    },
    {
      "source": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "target": "Finally",
      "similarity": 0.8138
    },
    {
      "source": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "target": "XRtyVELwr6",
      "similarity": 0.8133
    },
    {
      "source": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8122
    },
    {
      "source": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "target": "awvJBtB2op",
      "similarity": 0.8113
    },
    {
      "source": "by utilizing low-rank projection matrices to transform the cache features into spaces with reduced dimensions.",
      "target": "4JK2XMGUc8",
      "similarity": 0.8065
    },
    {
      "source": "We begin by investigating the canonical orthogonal projection method for data compression through principal component analysis (PCA).",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8546
    },
    {
      "source": "We begin by investigating the canonical orthogonal projection method for data compression through principal component analysis (PCA).",
      "target": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "similarity": 0.8377
    },
    {
      "source": "We begin by investigating the canonical orthogonal projection method for data compression through principal component analysis (PCA).",
      "target": "By packing web pages through their hyper-link connection",
      "similarity": 0.8315
    },
    {
      "source": "We begin by investigating the canonical orthogonal projection method for data compression through principal component analysis (PCA).",
      "target": "pHe4P1IVnb",
      "similarity": 0.8303
    },
    {
      "source": "We begin by investigating the canonical orthogonal projection method for data compression through principal component analysis (PCA).",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8271
    },
    {
      "source": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.907
    },
    {
      "source": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8727
    },
    {
      "source": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "target": "kvLenbZZgg",
      "similarity": 0.8687
    },
    {
      "source": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "target": "03EkqSCKuO",
      "similarity": 0.8559
    },
    {
      "source": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "target": "EMMnAd3apQ",
      "similarity": 0.8495
    },
    {
      "source": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "target": "In response",
      "similarity": 0.8525
    },
    {
      "source": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "target": "gI0kPklUKS",
      "similarity": 0.8494
    },
    {
      "source": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "target": "jQP5o1VAVc",
      "similarity": 0.846
    },
    {
      "source": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "target": "eiqrnVaeIw",
      "similarity": 0.8438
    },
    {
      "source": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "target": "kxnoqaisCT",
      "similarity": 0.8423
    },
    {
      "source": "To bridge the gap",
      "target": "zDC3iCBxJb",
      "similarity": 0.793
    },
    {
      "source": "To bridge the gap",
      "target": "comprehensive experiments",
      "similarity": 0.7887
    },
    {
      "source": "To bridge the gap",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.7873
    },
    {
      "source": "To bridge the gap",
      "target": "efficient and automated methods for generating and modifying 3D objects. One",
      "similarity": 0.7865
    },
    {
      "source": "To bridge the gap",
      "target": "dEg5SdGaiq",
      "similarity": 0.7855
    },
    {
      "source": "Thanks to such a strategy",
      "target": "FJFVmeXusW",
      "similarity": 0.8301
    },
    {
      "source": "Thanks to such a strategy",
      "target": "PDtMrogheZ",
      "similarity": 0.8111
    },
    {
      "source": "Thanks to such a strategy",
      "target": "uL1H29dM0c",
      "similarity": 0.8093
    },
    {
      "source": "Thanks to such a strategy",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8093
    },
    {
      "source": "Thanks to such a strategy",
      "target": "GM7cmQfk2F",
      "similarity": 0.8063
    },
    {
      "source": "Compared to Multi-head Latent Attention (MLA)",
      "target": "As the size of the model and data grows",
      "similarity": 0.8069
    },
    {
      "source": "Compared to Multi-head Latent Attention (MLA)",
      "target": "gWgaypDBs8",
      "similarity": 0.8042
    },
    {
      "source": "Compared to Multi-head Latent Attention (MLA)",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.7903
    },
    {
      "source": "Compared to Multi-head Latent Attention (MLA)",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.7862
    },
    {
      "source": "Compared to Multi-head Latent Attention (MLA)",
      "target": "Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats",
      "similarity": 0.7837
    },
    {
      "source": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "target": "L5godAOC2z",
      "similarity": 0.8067
    },
    {
      "source": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "target": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "similarity": 0.7968
    },
    {
      "source": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "target": "gWgaypDBs8",
      "similarity": 0.7903
    },
    {
      "source": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.7889
    },
    {
      "source": "We witness the high data efficiency of our training procedure and find that our method can sustain over 90\\% performance with an average KV cache compression rate of 60% (and up to 75% in certain extreme scenarios) for popular LLMs like LLaMA2 and Mistral.\"",
      "target": "Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn",
      "similarity": 0.7748
    },
    {
      "source": "gWgaypDBs8",
      "target": "6H4jRWKFc3",
      "similarity": 0.8227
    },
    {
      "source": "gWgaypDBs8",
      "target": "For detailed information",
      "similarity": 0.8217
    },
    {
      "source": "gWgaypDBs8",
      "target": "L5godAOC2z",
      "similarity": 0.8161
    },
    {
      "source": "gWgaypDBs8",
      "target": "We5z3UEnUY",
      "similarity": 0.8135
    },
    {
      "source": "gWgaypDBs8",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8124
    },
    {
      "source": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8334
    },
    {
      "source": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "target": "To fill this gap",
      "similarity": 0.8292
    },
    {
      "source": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "target": "FS2nukC2jv",
      "similarity": 0.8292
    },
    {
      "source": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.814
    },
    {
      "source": "Our Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8124
    },
    {
      "source": "From this perspective",
      "target": "In parallel",
      "similarity": 0.828
    },
    {
      "source": "From this perspective",
      "target": "However",
      "similarity": 0.8208
    },
    {
      "source": "From this perspective",
      "target": "3usdM1AuI3",
      "similarity": 0.8089
    },
    {
      "source": "From this perspective",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8076
    },
    {
      "source": "From this perspective",
      "target": "To improve reconstruction",
      "similarity": 0.8045
    },
    {
      "source": "In contrast",
      "target": "NGKQoaqLpo",
      "similarity": 0.8388
    },
    {
      "source": "In contrast",
      "target": "daUQ7vmGap",
      "similarity": 0.8241
    },
    {
      "source": "In contrast",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8213
    },
    {
      "source": "In contrast",
      "target": "1qq1QJKM5q",
      "similarity": 0.8191
    },
    {
      "source": "In contrast",
      "target": "To tackle these challenges",
      "similarity": 0.8156
    },
    {
      "source": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8286
    },
    {
      "source": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8272
    },
    {
      "source": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "target": "U49N5V51rU",
      "similarity": 0.8037
    },
    {
      "source": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "target": "In this work",
      "similarity": 0.8017
    },
    {
      "source": "Our Representative Guidance achieves superior performance and demonstrates the potential of pre-trained self-supervised models in guiding diffusion sampling. Our findings show that RepG not only significantly improves vanilla diffusion sampling",
      "target": "However",
      "similarity": 0.8004
    },
    {
      "source": "zCZnEXF3bN",
      "target": "In this paper",
      "similarity": 0.8715
    },
    {
      "source": "zCZnEXF3bN",
      "target": "HaX48yksVL",
      "similarity": 0.8653
    },
    {
      "source": "zCZnEXF3bN",
      "target": "While several vision-based math benchmarks have been developed to assess VLMs' problem-solving capabilities",
      "similarity": 0.8571
    },
    {
      "source": "zCZnEXF3bN",
      "target": "pDDODPtpx9",
      "similarity": 0.8567
    },
    {
      "source": "zCZnEXF3bN",
      "target": "Using this extension",
      "similarity": 0.8531
    },
    {
      "source": "Our key innovation is a novel gradient estimator based on a double-momentum mechanism that combines two recent momentum-based techniques. Utilizing this estimator",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8167
    },
    {
      "source": "Our key innovation is a novel gradient estimator based on a double-momentum mechanism that combines two recent momentum-based techniques. Utilizing this estimator",
      "target": "Prior work has shown that: (1) web-scraped pre-training datasets can be practically poisoned by malicious actors; and (2) adversaries can compromise language models after poisoning fine-tuning datasets.",
      "similarity": 0.8109
    },
    {
      "source": "Our key innovation is a novel gradient estimator based on a double-momentum mechanism that combines two recent momentum-based techniques. Utilizing this estimator",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8067
    },
    {
      "source": "Our key innovation is a novel gradient estimator based on a double-momentum mechanism that combines two recent momentum-based techniques. Utilizing this estimator",
      "target": "The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically",
      "similarity": 0.7977
    },
    {
      "source": "Our key innovation is a novel gradient estimator based on a double-momentum mechanism that combines two recent momentum-based techniques. Utilizing this estimator",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.7937
    },
    {
      "source": "tcsZt9ZNKD",
      "target": "Building on these insights",
      "similarity": 0.8523
    },
    {
      "source": "tcsZt9ZNKD",
      "target": "Second",
      "similarity": 0.8499
    },
    {
      "source": "tcsZt9ZNKD",
      "target": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "similarity": 0.8456
    },
    {
      "source": "tcsZt9ZNKD",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8427
    },
    {
      "source": "tcsZt9ZNKD",
      "target": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "similarity": 0.8412
    },
    {
      "source": "gsShHPxkUW",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8853
    },
    {
      "source": "gsShHPxkUW",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8593
    },
    {
      "source": "gsShHPxkUW",
      "target": "To remedy this problem",
      "similarity": 0.8468
    },
    {
      "source": "gsShHPxkUW",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8463
    },
    {
      "source": "gsShHPxkUW",
      "target": "2fojNANZSv",
      "similarity": 0.8436
    },
    {
      "source": "uL1H29dM0c",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8774
    },
    {
      "source": "uL1H29dM0c",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8482
    },
    {
      "source": "uL1H29dM0c",
      "target": "ugyqNEOjoU",
      "similarity": 0.8418
    },
    {
      "source": "uL1H29dM0c",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8413
    },
    {
      "source": "uL1H29dM0c",
      "target": "Moreover",
      "similarity": 0.8411
    },
    {
      "source": "fuoM5YDBX4",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8574
    },
    {
      "source": "fuoM5YDBX4",
      "target": "nibeaHUEJx",
      "similarity": 0.8374
    },
    {
      "source": "fuoM5YDBX4",
      "target": "Yet",
      "similarity": 0.8273
    },
    {
      "source": "fuoM5YDBX4",
      "target": "At the inference stage",
      "similarity": 0.8202
    },
    {
      "source": "fuoM5YDBX4",
      "target": "In experiments with GPT-4",
      "similarity": 0.8191
    },
    {
      "source": "rWjZWHYPcz",
      "target": "R4h5PXzUuU",
      "similarity": 0.8187
    },
    {
      "source": "rWjZWHYPcz",
      "target": "NHMuM84tRT",
      "similarity": 0.8147
    },
    {
      "source": "rWjZWHYPcz",
      "target": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "similarity": 0.8091
    },
    {
      "source": "rWjZWHYPcz",
      "target": "OhUoTMxFIH",
      "similarity": 0.7911
    },
    {
      "source": "rWjZWHYPcz",
      "target": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "similarity": 0.7891
    },
    {
      "source": "6awxwQEI82",
      "target": "spDUv05cEq",
      "similarity": 0.8013
    },
    {
      "source": "6awxwQEI82",
      "target": "tkiZQlL04w",
      "similarity": 0.7773
    },
    {
      "source": "6awxwQEI82",
      "target": "kNHVViEPWK",
      "similarity": 0.7722
    },
    {
      "source": "6awxwQEI82",
      "target": "BPgK5XW1Nb",
      "similarity": 0.768
    },
    {
      "source": "6awxwQEI82",
      "target": "We consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia",
      "similarity": 0.7662
    },
    {
      "source": "21rSeWJHPF",
      "target": "a well-calibrated probabilistic model of the system and plans optimistically",
      "similarity": 0.8307
    },
    {
      "source": "21rSeWJHPF",
      "target": "lIVRgt4nLv",
      "similarity": 0.8027
    },
    {
      "source": "21rSeWJHPF",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.7903
    },
    {
      "source": "21rSeWJHPF",
      "target": "PUnD86UEK5",
      "similarity": 0.788
    },
    {
      "source": "21rSeWJHPF",
      "target": "FEZOLWexPb",
      "similarity": 0.787
    },
    {
      "source": "In this paper",
      "target": "xP1radUi32",
      "similarity": 0.8404
    },
    {
      "source": "In this paper",
      "target": "ScVnYBaSEw",
      "similarity": 0.8404
    },
    {
      "source": "In this paper",
      "target": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "similarity": 0.8231
    },
    {
      "source": "In this paper",
      "target": "vVxeFSR4fU",
      "similarity": 0.8182
    },
    {
      "source": "In this paper",
      "target": "9.5% boost in effect and a significant reduction in computational demands. This",
      "similarity": 0.8141
    },
    {
      "source": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "target": "vRvVVb0NAz",
      "similarity": 0.8255
    },
    {
      "source": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "target": "jlhBFm7T2J",
      "similarity": 0.8131
    },
    {
      "source": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "target": "However",
      "similarity": 0.8073
    },
    {
      "source": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8063
    },
    {
      "source": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "target": "In a client-server setting",
      "similarity": 0.8047
    },
    {
      "source": "Finally",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8685
    },
    {
      "source": "Finally",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8674
    },
    {
      "source": "Finally",
      "target": "AJpUZd8Clb",
      "similarity": 0.8654
    },
    {
      "source": "Finally",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8601
    },
    {
      "source": "Finally",
      "target": "254NJe9JEw",
      "similarity": 0.8581
    },
    {
      "source": "7YKV7zkNpX",
      "target": "dTkqaCKLPp",
      "similarity": 0.8159
    },
    {
      "source": "7YKV7zkNpX",
      "target": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "similarity": 0.814
    },
    {
      "source": "7YKV7zkNpX",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8087
    },
    {
      "source": "7YKV7zkNpX",
      "target": "LNL7zKvm7e",
      "similarity": 0.8047
    },
    {
      "source": "7YKV7zkNpX",
      "target": "NWb128pSCb",
      "similarity": 0.8045
    },
    {
      "source": "PDtMrogheZ",
      "target": "FJFVmeXusW",
      "similarity": 0.852
    },
    {
      "source": "PDtMrogheZ",
      "target": "mZptYYttFj",
      "similarity": 0.8001
    },
    {
      "source": "PDtMrogheZ",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8001
    },
    {
      "source": "PDtMrogheZ",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.7973
    },
    {
      "source": "PDtMrogheZ",
      "target": "oDbiL9CLoS",
      "similarity": 0.7963
    },
    {
      "source": "myYzr50xBh",
      "target": "K3KrOsR6y9",
      "similarity": 0.8603
    },
    {
      "source": "myYzr50xBh",
      "target": "Second",
      "similarity": 0.8537
    },
    {
      "source": "myYzr50xBh",
      "target": "84WmbzikPP",
      "similarity": 0.8522
    },
    {
      "source": "myYzr50xBh",
      "target": "show that BoneMet can be readily adopted to build versatile",
      "similarity": 0.8424
    },
    {
      "source": "myYzr50xBh",
      "target": "dCcY2pyNIO",
      "similarity": 0.8422
    },
    {
      "source": "i7jAYFYDcM",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8628
    },
    {
      "source": "i7jAYFYDcM",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.8503
    },
    {
      "source": "i7jAYFYDcM",
      "target": "pZiyCaVuti",
      "similarity": 0.8491
    },
    {
      "source": "i7jAYFYDcM",
      "target": "p4cLtzk4oe",
      "similarity": 0.8465
    },
    {
      "source": "i7jAYFYDcM",
      "target": "4O0v4s3IzY",
      "similarity": 0.843
    },
    {
      "source": "zDC3iCBxJb",
      "target": "comprehensive experiments",
      "similarity": 0.8249
    },
    {
      "source": "zDC3iCBxJb",
      "target": "zg3ec1TdAP",
      "similarity": 0.8174
    },
    {
      "source": "zDC3iCBxJb",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8134
    },
    {
      "source": "zDC3iCBxJb",
      "target": "fuoM5YDBX4",
      "similarity": 0.8124
    },
    {
      "source": "zDC3iCBxJb",
      "target": "zBbZ2vdLzH",
      "similarity": 0.8121
    },
    {
      "source": "1NevL7zdHS",
      "target": "1qq1QJKM5q",
      "similarity": 0.8615
    },
    {
      "source": "1NevL7zdHS",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8553
    },
    {
      "source": "1NevL7zdHS",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8532
    },
    {
      "source": "1NevL7zdHS",
      "target": "ngmEcEer8a",
      "similarity": 0.8484
    },
    {
      "source": "1NevL7zdHS",
      "target": "eWocmTQn7H",
      "similarity": 0.8455
    },
    {
      "source": "VvDEuyVXkG",
      "target": "WCRQFlji2q",
      "similarity": 0.8656
    },
    {
      "source": "VvDEuyVXkG",
      "target": "4ktJJBvvUd",
      "similarity": 0.8507
    },
    {
      "source": "VvDEuyVXkG",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8491
    },
    {
      "source": "VvDEuyVXkG",
      "target": "txD9llAYn9",
      "similarity": 0.8477
    },
    {
      "source": "VvDEuyVXkG",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8429
    },
    {
      "source": "4GT9uTsAJE",
      "target": "Motivated by this observation",
      "similarity": 0.8974
    },
    {
      "source": "4GT9uTsAJE",
      "target": "Kpjvm2mB0K",
      "similarity": 0.869
    },
    {
      "source": "4GT9uTsAJE",
      "target": "c61unr33XA",
      "similarity": 0.8628
    },
    {
      "source": "4GT9uTsAJE",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8626
    },
    {
      "source": "4GT9uTsAJE",
      "target": "iVMcYxTiVM",
      "similarity": 0.8592
    },
    {
      "source": "GySIAKEwtZ",
      "target": "HN8V0flwJF",
      "similarity": 0.8424
    },
    {
      "source": "GySIAKEwtZ",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8422
    },
    {
      "source": "GySIAKEwtZ",
      "target": "To this end",
      "similarity": 0.8387
    },
    {
      "source": "GySIAKEwtZ",
      "target": "For TP",
      "similarity": 0.838
    },
    {
      "source": "GySIAKEwtZ",
      "target": "bsFWJ0Kget",
      "similarity": 0.8356
    },
    {
      "source": "vl7kf0YHwj",
      "target": "rTQNGQxm4K",
      "similarity": 0.8286
    },
    {
      "source": "vl7kf0YHwj",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8253
    },
    {
      "source": "vl7kf0YHwj",
      "target": "We demonstrate our method in autonomous driving and robot manipulation tasks",
      "similarity": 0.8207
    },
    {
      "source": "vl7kf0YHwj",
      "target": "iLUcsecZJp",
      "similarity": 0.8205
    },
    {
      "source": "vl7kf0YHwj",
      "target": "This limitation hinders the ability to transfer models or knowledge learned from one sensor to another.",
      "similarity": 0.8203
    },
    {
      "source": "QsA3YzNUxA",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8099
    },
    {
      "source": "QsA3YzNUxA",
      "target": "mqNKiEB6pd",
      "similarity": 0.8017
    },
    {
      "source": "QsA3YzNUxA",
      "target": "These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes",
      "similarity": 0.7969
    },
    {
      "source": "QsA3YzNUxA",
      "target": "Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters.",
      "similarity": 0.7881
    },
    {
      "source": "QsA3YzNUxA",
      "target": "dEg5SdGaiq",
      "similarity": 0.787
    },
    {
      "source": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "target": "a challenge",
      "similarity": 0.8614
    },
    {
      "source": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "target": "bilities",
      "similarity": 0.8499
    },
    {
      "source": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "target": "1R5BcYS8EC",
      "similarity": 0.8491
    },
    {
      "source": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "target": "To this end",
      "similarity": 0.8451
    },
    {
      "source": "This paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.",
      "target": "htDczodFN5",
      "similarity": 0.8381
    },
    {
      "source": "While these models are designed to respond queries under safety mechanism",
      "target": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "similarity": 0.8248
    },
    {
      "source": "While these models are designed to respond queries under safety mechanism",
      "target": "generating time series of tabular data",
      "similarity": 0.8133
    },
    {
      "source": "While these models are designed to respond queries under safety mechanism",
      "target": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "similarity": 0.813
    },
    {
      "source": "While these models are designed to respond queries under safety mechanism",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8097
    },
    {
      "source": "While these models are designed to respond queries under safety mechanism",
      "target": "ONfWFluZBI",
      "similarity": 0.8088
    },
    {
      "source": "As the initial step in investigating this behavior",
      "target": "d8hYXbxX71",
      "similarity": 0.8261
    },
    {
      "source": "As the initial step in investigating this behavior",
      "target": "In this work",
      "similarity": 0.824
    },
    {
      "source": "As the initial step in investigating this behavior",
      "target": "At the inference stage",
      "similarity": 0.8177
    },
    {
      "source": "As the initial step in investigating this behavior",
      "target": "KxQRHOre9D",
      "similarity": 0.8176
    },
    {
      "source": "As the initial step in investigating this behavior",
      "target": "6H4jRWKFc3",
      "similarity": 0.8151
    },
    {
      "source": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "target": "dw9VUsSHGB",
      "similarity": 0.8812
    },
    {
      "source": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "target": "propose the use of weighted point sets",
      "similarity": 0.826
    },
    {
      "source": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "target": "In addition",
      "similarity": 0.824
    },
    {
      "source": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "target": "Meanwhile",
      "similarity": 0.8214
    },
    {
      "source": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8189
    },
    {
      "source": "This toolkit consists of 300 manually collected benign multimodal queries",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.8472
    },
    {
      "source": "This toolkit consists of 300 manually collected benign multimodal queries",
      "target": "Subsequently",
      "similarity": 0.8436
    },
    {
      "source": "This toolkit consists of 300 manually collected benign multimodal queries",
      "target": "ssRdQimeUI",
      "similarity": 0.8366
    },
    {
      "source": "This toolkit consists of 300 manually collected benign multimodal queries",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8338
    },
    {
      "source": "This toolkit consists of 300 manually collected benign multimodal queries",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.83
    },
    {
      "source": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.818
    },
    {
      "source": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8141
    },
    {
      "source": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8136
    },
    {
      "source": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "target": "Recently proposed diffusion bridge models provide a potential solution",
      "similarity": 0.8134
    },
    {
      "source": "Empirical studies using MOSSBench on 20 MLLMs reveal several insights:",
      "target": "than prior private ANN schemes",
      "similarity": 0.813
    },
    {
      "source": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8766
    },
    {
      "source": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "target": "otW0TJOUYF",
      "similarity": 0.8691
    },
    {
      "source": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8618
    },
    {
      "source": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8564
    },
    {
      "source": "(1). Oversensitivity is prevalent among SOTA MLLMs",
      "target": "bRa4JLPzii",
      "similarity": 0.8525
    },
    {
      "source": "(2). Safer models are more oversensitive: increasing safety may inadvertently raise caution and conservatism in the model\u2019s responses.",
      "target": "8g4XgC8HPF",
      "similarity": 0.8161
    },
    {
      "source": "(2). Safer models are more oversensitive: increasing safety may inadvertently raise caution and conservatism in the model\u2019s responses.",
      "target": "Lastly",
      "similarity": 0.8141
    },
    {
      "source": "(2). Safer models are more oversensitive: increasing safety may inadvertently raise caution and conservatism in the model\u2019s responses.",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.8097
    },
    {
      "source": "(2). Safer models are more oversensitive: increasing safety may inadvertently raise caution and conservatism in the model\u2019s responses.",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8085
    },
    {
      "source": "(2). Safer models are more oversensitive: increasing safety may inadvertently raise caution and conservatism in the model\u2019s responses.",
      "target": "methods (e.g.",
      "similarity": 0.8068
    },
    {
      "source": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "target": "By leveraging online data collection",
      "similarity": 0.8327
    },
    {
      "source": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "target": "6H4jRWKFc3",
      "similarity": 0.8041
    },
    {
      "source": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "target": "standard training and",
      "similarity": 0.7976
    },
    {
      "source": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "target": "7bAjVh3CG3",
      "similarity": 0.7926
    },
    {
      "source": "(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception",
      "target": "QogcGNXJVw",
      "similarity": 0.7902
    },
    {
      "source": "These findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8147
    },
    {
      "source": "These findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses",
      "target": "BkftcwIVmR",
      "similarity": 0.8103
    },
    {
      "source": "These findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses",
      "target": "To overcome this limitation",
      "similarity": 0.8035
    },
    {
      "source": "These findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses",
      "target": "IQxBDLmVpT",
      "similarity": 0.8023
    },
    {
      "source": "These findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses",
      "target": "YH4M1Tbxfz",
      "similarity": 0.8009
    },
    {
      "source": "BPAZ6yW3K7",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8364
    },
    {
      "source": "BPAZ6yW3K7",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8222
    },
    {
      "source": "BPAZ6yW3K7",
      "target": "To overcome this limitation",
      "similarity": 0.8177
    },
    {
      "source": "BPAZ6yW3K7",
      "target": "LNL7zKvm7e",
      "similarity": 0.8159
    },
    {
      "source": "BPAZ6yW3K7",
      "target": "IQxBDLmVpT",
      "similarity": 0.8137
    },
    {
      "source": "mzL19kKE3r",
      "target": "1DVgysiIt7",
      "similarity": 0.8323
    },
    {
      "source": "mzL19kKE3r",
      "target": "4ytRL3HJrq",
      "similarity": 0.8191
    },
    {
      "source": "mzL19kKE3r",
      "target": "KW8yzAOIZr",
      "similarity": 0.8168
    },
    {
      "source": "mzL19kKE3r",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8161
    },
    {
      "source": "mzL19kKE3r",
      "target": "Xbl6t6zxZs",
      "similarity": 0.8149
    },
    {
      "source": "OCpxDSn0G4",
      "target": "wide dissemination",
      "similarity": 0.8717
    },
    {
      "source": "OCpxDSn0G4",
      "target": "JDm7oIcx4Y",
      "similarity": 0.846
    },
    {
      "source": "OCpxDSn0G4",
      "target": "propose the use of weighted point sets",
      "similarity": 0.8425
    },
    {
      "source": "OCpxDSn0G4",
      "target": "ples. To our knowledge",
      "similarity": 0.8415
    },
    {
      "source": "OCpxDSn0G4",
      "target": "VmJdqhuTCh",
      "similarity": 0.8398
    },
    {
      "source": "yitH9xAHQs",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8414
    },
    {
      "source": "yitH9xAHQs",
      "target": "KAIqwkB3dT",
      "similarity": 0.8406
    },
    {
      "source": "yitH9xAHQs",
      "target": "5xSRg3eYZz",
      "similarity": 0.8403
    },
    {
      "source": "yitH9xAHQs",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8403
    },
    {
      "source": "yitH9xAHQs",
      "target": "S1Bv3068Xt",
      "similarity": 0.8371
    },
    {
      "source": "UVnD9Ze6mF",
      "target": "To this end",
      "similarity": 0.8406
    },
    {
      "source": "UVnD9Ze6mF",
      "target": "2kGKsyhtvh",
      "similarity": 0.8301
    },
    {
      "source": "UVnD9Ze6mF",
      "target": "2mqb8bPHeb",
      "similarity": 0.8289
    },
    {
      "source": "UVnD9Ze6mF",
      "target": "iOMnn1hSBO",
      "similarity": 0.8271
    },
    {
      "source": "UVnD9Ze6mF",
      "target": "To explore real-time segmentation",
      "similarity": 0.8217
    },
    {
      "source": "ZJo6Radbqq",
      "target": "MBBRHDuiwM",
      "similarity": 0.8577
    },
    {
      "source": "ZJo6Radbqq",
      "target": "20qZK2T7fa",
      "similarity": 0.8404
    },
    {
      "source": "ZJo6Radbqq",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8377
    },
    {
      "source": "ZJo6Radbqq",
      "target": "4es2oO9tw1",
      "similarity": 0.837
    },
    {
      "source": "ZJo6Radbqq",
      "target": "showing up to 2.5$\\times$ better search accuracy on",
      "similarity": 0.8351
    },
    {
      "source": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "target": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "similarity": 0.8461
    },
    {
      "source": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8274
    },
    {
      "source": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "target": "irrtPRFksw",
      "similarity": 0.8213
    },
    {
      "source": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "target": "high-quality labels is often required to obtain noticeable improvements. Given",
      "similarity": 0.8208
    },
    {
      "source": "Various benchmarks are introduced for better evaluating the MLLMs.",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8165
    },
    {
      "source": "Nevertheless",
      "target": "st7XqFgbAH",
      "similarity": 0.8361
    },
    {
      "source": "Nevertheless",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8266
    },
    {
      "source": "Nevertheless",
      "target": "aXwukBD6M6",
      "similarity": 0.8229
    },
    {
      "source": "Nevertheless",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8218
    },
    {
      "source": "Nevertheless",
      "target": "m8yby1JfbU",
      "similarity": 0.8215
    },
    {
      "source": "In this paper",
      "target": "aKkDY1Wca0",
      "similarity": 0.8536
    },
    {
      "source": "In this paper",
      "target": "Beyond performance evaluations",
      "similarity": 0.8454
    },
    {
      "source": "In this paper",
      "target": "Aye5wL6TCn",
      "similarity": 0.845
    },
    {
      "source": "In this paper",
      "target": "P6IVIoGRRg",
      "similarity": 0.8384
    },
    {
      "source": "In this paper",
      "target": "Finally",
      "similarity": 0.8368
    },
    {
      "source": "VideoNIAH decouples video content from their query-responses by inserting unrelated visual 'needles' into original videos.",
      "target": "In addition",
      "similarity": 0.8223
    },
    {
      "source": "VideoNIAH decouples video content from their query-responses by inserting unrelated visual 'needles' into original videos.",
      "target": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "similarity": 0.8207
    },
    {
      "source": "VideoNIAH decouples video content from their query-responses by inserting unrelated visual 'needles' into original videos.",
      "target": "Moreover",
      "similarity": 0.8151
    },
    {
      "source": "VideoNIAH decouples video content from their query-responses by inserting unrelated visual 'needles' into original videos.",
      "target": "JYTQ6ELUVO",
      "similarity": 0.8144
    },
    {
      "source": "VideoNIAH decouples video content from their query-responses by inserting unrelated visual 'needles' into original videos.",
      "target": "sampling methods",
      "similarity": 0.8127
    },
    {
      "source": "The framework automates the generation of query-response pairs using predefined rules",
      "target": "However",
      "similarity": 0.8136
    },
    {
      "source": "The framework automates the generation of query-response pairs using predefined rules",
      "target": "8TBGdH3t6a",
      "similarity": 0.7977
    },
    {
      "source": "The framework automates the generation of query-response pairs using predefined rules",
      "target": "zd0iX5xBhA",
      "similarity": 0.7923
    },
    {
      "source": "The framework automates the generation of query-response pairs using predefined rules",
      "target": "h1XoHOd19I",
      "similarity": 0.7901
    },
    {
      "source": "The framework automates the generation of query-response pairs using predefined rules",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.7885
    },
    {
      "source": "Utilizing VideoNIAH",
      "target": "Mjn53GtMxi",
      "similarity": 0.8506
    },
    {
      "source": "Utilizing VideoNIAH",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.838
    },
    {
      "source": "Utilizing VideoNIAH",
      "target": "hjROBHstZ3",
      "similarity": 0.8359
    },
    {
      "source": "Utilizing VideoNIAH",
      "target": "nibeaHUEJx",
      "similarity": 0.8353
    },
    {
      "source": "Utilizing VideoNIAH",
      "target": "ue1Tt3h1VC",
      "similarity": 0.835
    },
    {
      "source": "M8gXSFGkn2",
      "target": "2ET561DyPe",
      "similarity": 0.8416
    },
    {
      "source": "M8gXSFGkn2",
      "target": "RC5FPYVQaH",
      "similarity": 0.8387
    },
    {
      "source": "M8gXSFGkn2",
      "target": "T2d0geb6y0",
      "similarity": 0.8384
    },
    {
      "source": "M8gXSFGkn2",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8363
    },
    {
      "source": "M8gXSFGkn2",
      "target": "Empirically",
      "similarity": 0.8327
    },
    {
      "source": "YUYJsHOf3c",
      "target": "YcUV5apdlq",
      "similarity": 0.8607
    },
    {
      "source": "YUYJsHOf3c",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8491
    },
    {
      "source": "YUYJsHOf3c",
      "target": "yORSk4Ycsa",
      "similarity": 0.8479
    },
    {
      "source": "YUYJsHOf3c",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8458
    },
    {
      "source": "YUYJsHOf3c",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8444
    },
    {
      "source": "DzbUL4AJPP",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8433
    },
    {
      "source": "DzbUL4AJPP",
      "target": "fifXzmzeGy",
      "similarity": 0.8312
    },
    {
      "source": "DzbUL4AJPP",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8262
    },
    {
      "source": "DzbUL4AJPP",
      "target": "Pnk7vMbznK",
      "similarity": 0.8236
    },
    {
      "source": "DzbUL4AJPP",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8235
    },
    {
      "source": "j9VVzueEbG",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8501
    },
    {
      "source": "j9VVzueEbG",
      "target": "number of parameters required for fine-tuning these models. These compression",
      "similarity": 0.8298
    },
    {
      "source": "j9VVzueEbG",
      "target": "04qx93Viwj",
      "similarity": 0.8273
    },
    {
      "source": "j9VVzueEbG",
      "target": "1NprT9Kz0d",
      "similarity": 0.8236
    },
    {
      "source": "j9VVzueEbG",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8151
    },
    {
      "source": "SqoL14HDm0",
      "target": "mkuB677eMM",
      "similarity": 0.8515
    },
    {
      "source": "SqoL14HDm0",
      "target": "Bpn8q40n1n",
      "similarity": 0.8458
    },
    {
      "source": "SqoL14HDm0",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8304
    },
    {
      "source": "SqoL14HDm0",
      "target": "M5t0WvjfCg",
      "similarity": 0.8265
    },
    {
      "source": "SqoL14HDm0",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8096
    },
    {
      "source": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8276
    },
    {
      "source": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "target": "j1tSLYKwg8",
      "similarity": 0.826
    },
    {
      "source": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "target": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "similarity": 0.8207
    },
    {
      "source": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "target": "9KiE3t6CsL",
      "similarity": 0.8174
    },
    {
      "source": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "target": "kSdWcw5mkp",
      "similarity": 0.8174
    },
    {
      "source": "To improve prompt quality",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.7954
    },
    {
      "source": "To improve prompt quality",
      "target": "C06kww3Qky",
      "similarity": 0.7942
    },
    {
      "source": "To improve prompt quality",
      "target": "However",
      "similarity": 0.7898
    },
    {
      "source": "To improve prompt quality",
      "target": "FCMpUOZkxi",
      "similarity": 0.7897
    },
    {
      "source": "To improve prompt quality",
      "target": "xiQNfYl33p",
      "similarity": 0.7874
    },
    {
      "source": "Building on this",
      "target": "kwCHcaeHrf",
      "similarity": 0.8503
    },
    {
      "source": "Building on this",
      "target": "For production-level generation",
      "similarity": 0.846
    },
    {
      "source": "Building on this",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8446
    },
    {
      "source": "Building on this",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8322
    },
    {
      "source": "Building on this",
      "target": "potential algorithms to solve one task",
      "similarity": 0.8315
    },
    {
      "source": "CNL-P introduces precise grammar structures and strict semantic norms",
      "target": "gQoBw7sGAu",
      "similarity": 0.8055
    },
    {
      "source": "CNL-P introduces precise grammar structures and strict semantic norms",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8011
    },
    {
      "source": "CNL-P introduces precise grammar structures and strict semantic norms",
      "target": "UN6Ik6OCx8",
      "similarity": 0.7975
    },
    {
      "source": "CNL-P introduces precise grammar structures and strict semantic norms",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.7948
    },
    {
      "source": "CNL-P introduces precise grammar structures and strict semantic norms",
      "target": "In contrast",
      "similarity": 0.7944
    },
    {
      "source": "This helps LLMs better interpret and execute the prompts",
      "target": "Next",
      "similarity": 0.8269
    },
    {
      "source": "This helps LLMs better interpret and execute the prompts",
      "target": "To further demonstrate the effectiveness of CNL-P",
      "similarity": 0.8254
    },
    {
      "source": "This helps LLMs better interpret and execute the prompts",
      "target": "TvGPP8i18S",
      "similarity": 0.8233
    },
    {
      "source": "This helps LLMs better interpret and execute the prompts",
      "target": "8TBGdH3t6a",
      "similarity": 0.8201
    },
    {
      "source": "This helps LLMs better interpret and execute the prompts",
      "target": "1yJP5TVWih",
      "similarity": 0.8178
    },
    {
      "source": "We also introduce an NL2CNL-P conversion tool based on LLMs",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.8147
    },
    {
      "source": "We also introduce an NL2CNL-P conversion tool based on LLMs",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8113
    },
    {
      "source": "We also introduce an NL2CNL-P conversion tool based on LLMs",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.809
    },
    {
      "source": "We also introduce an NL2CNL-P conversion tool based on LLMs",
      "target": "goBaGHLAdP",
      "similarity": 0.8076
    },
    {
      "source": "We also introduce an NL2CNL-P conversion tool based on LLMs",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8072
    },
    {
      "source": "In particular",
      "target": "PstM8YfhvI",
      "similarity": 0.8602
    },
    {
      "source": "In particular",
      "target": "ki7b0qD11r",
      "similarity": 0.8554
    },
    {
      "source": "In particular",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8543
    },
    {
      "source": "In particular",
      "target": "To tackle this challenge",
      "similarity": 0.8518
    },
    {
      "source": "In particular",
      "target": "yIlyHJdYV3",
      "similarity": 0.8514
    },
    {
      "source": "Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE.",
      "target": "Conversely",
      "similarity": 0.8528
    },
    {
      "source": "Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE.",
      "target": "However",
      "similarity": 0.8333
    },
    {
      "source": "Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE.",
      "target": "From these insights",
      "similarity": 0.8314
    },
    {
      "source": "Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE.",
      "target": "Neb17mimVH",
      "similarity": 0.8313
    },
    {
      "source": "Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE.",
      "target": "TUvg5uwdeG",
      "similarity": 0.8192
    },
    {
      "source": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "target": "otW0TJOUYF",
      "similarity": 0.8748
    },
    {
      "source": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8552
    },
    {
      "source": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "target": "TWnUgSAWNw",
      "similarity": 0.8516
    },
    {
      "source": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "target": "FrFQpAgnGE",
      "similarity": 0.8478
    },
    {
      "source": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "target": "To this end",
      "similarity": 0.8466
    },
    {
      "source": "To further demonstrate the effectiveness of CNL-P",
      "target": "Moreover",
      "similarity": 0.8105
    },
    {
      "source": "To further demonstrate the effectiveness of CNL-P",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.8086
    },
    {
      "source": "To further demonstrate the effectiveness of CNL-P",
      "target": "Yet",
      "similarity": 0.8079
    },
    {
      "source": "To further demonstrate the effectiveness of CNL-P",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8078
    },
    {
      "source": "To further demonstrate the effectiveness of CNL-P",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8076
    },
    {
      "source": "For detailed information",
      "target": "In parallel",
      "similarity": 0.8242
    },
    {
      "source": "For detailed information",
      "target": "In this work",
      "similarity": 0.7972
    },
    {
      "source": "For detailed information",
      "target": "Despite its simplicity",
      "similarity": 0.794
    },
    {
      "source": "For detailed information",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.7921
    },
    {
      "source": "For detailed information",
      "target": "However",
      "similarity": 0.7821
    },
    {
      "source": "4GSOESJrk6",
      "target": "hyfe5q5TD0",
      "similarity": 0.7912
    },
    {
      "source": "4GSOESJrk6",
      "target": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "similarity": 0.7869
    },
    {
      "source": "4GSOESJrk6",
      "target": "oYemKnlIrO",
      "similarity": 0.7777
    },
    {
      "source": "4GSOESJrk6",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.7774
    },
    {
      "source": "4GSOESJrk6",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.7764
    },
    {
      "source": "KlV5CkNQkl",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8425
    },
    {
      "source": "KlV5CkNQkl",
      "target": "uxVBbSlKQ4",
      "similarity": 0.823
    },
    {
      "source": "KlV5CkNQkl",
      "target": "ptjrpEGrGg",
      "similarity": 0.823
    },
    {
      "source": "KlV5CkNQkl",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8217
    },
    {
      "source": "KlV5CkNQkl",
      "target": "kSdWcw5mkp",
      "similarity": 0.8207
    },
    {
      "source": "UqrFPhcmFp",
      "target": "To address this",
      "similarity": 0.8291
    },
    {
      "source": "UqrFPhcmFp",
      "target": "PY56Wur7S0",
      "similarity": 0.8279
    },
    {
      "source": "UqrFPhcmFp",
      "target": "To fill this gap",
      "similarity": 0.8156
    },
    {
      "source": "UqrFPhcmFp",
      "target": "Next",
      "similarity": 0.8089
    },
    {
      "source": "UqrFPhcmFp",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8068
    },
    {
      "source": "mkuB677eMM",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8406
    },
    {
      "source": "mkuB677eMM",
      "target": "M5t0WvjfCg",
      "similarity": 0.8404
    },
    {
      "source": "mkuB677eMM",
      "target": "However",
      "similarity": 0.8241
    },
    {
      "source": "mkuB677eMM",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8178
    },
    {
      "source": "mkuB677eMM",
      "target": "VLM performance by providing visual feedback",
      "similarity": 0.8108
    },
    {
      "source": "BCP5nAHXqs",
      "target": "Moreover",
      "similarity": 0.8795
    },
    {
      "source": "BCP5nAHXqs",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8675
    },
    {
      "source": "BCP5nAHXqs",
      "target": "pPQPQ7Yd58",
      "similarity": 0.8629
    },
    {
      "source": "BCP5nAHXqs",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.8563
    },
    {
      "source": "BCP5nAHXqs",
      "target": "Ax0i933gtp",
      "similarity": 0.8525
    },
    {
      "source": "3ogIALgghF",
      "target": "uClUUJk05H",
      "similarity": 0.8382
    },
    {
      "source": "3ogIALgghF",
      "target": "understanding of LLMs' generalization capabilities.\"",
      "similarity": 0.8214
    },
    {
      "source": "3ogIALgghF",
      "target": "JMPOqoe4tl",
      "similarity": 0.8096
    },
    {
      "source": "3ogIALgghF",
      "target": "a novel approach that expands the expert space by applying the ternary set {-1",
      "similarity": 0.8034
    },
    {
      "source": "3ogIALgghF",
      "target": "Third",
      "similarity": 0.8022
    },
    {
      "source": "FiyS0ecSm0",
      "target": "named Pacmann",
      "similarity": 0.8672
    },
    {
      "source": "FiyS0ecSm0",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8605
    },
    {
      "source": "FiyS0ecSm0",
      "target": "variables encourage the model to learn disentangled representations and decision",
      "similarity": 0.8534
    },
    {
      "source": "FiyS0ecSm0",
      "target": "QOfswj7hij",
      "similarity": 0.849
    },
    {
      "source": "FiyS0ecSm0",
      "target": "VoayJihXra",
      "similarity": 0.8486
    },
    {
      "source": "4v4RcAODj9",
      "target": "ptjrpEGrGg",
      "similarity": 0.8298
    },
    {
      "source": "4v4RcAODj9",
      "target": "space",
      "similarity": 0.8294
    },
    {
      "source": "4v4RcAODj9",
      "target": "uSz2K30RRd",
      "similarity": 0.8285
    },
    {
      "source": "4v4RcAODj9",
      "target": "goBaGHLAdP",
      "similarity": 0.8253
    },
    {
      "source": "4v4RcAODj9",
      "target": "PY56Wur7S0",
      "similarity": 0.8211
    },
    {
      "source": "avSocG0oFA",
      "target": "other baselines across all metrics",
      "similarity": 0.8615
    },
    {
      "source": "avSocG0oFA",
      "target": "Following the derived guidelines",
      "similarity": 0.8614
    },
    {
      "source": "avSocG0oFA",
      "target": "KnoS9XxIlK",
      "similarity": 0.8588
    },
    {
      "source": "avSocG0oFA",
      "target": "design algorithms which use space much less than the entire stream",
      "similarity": 0.8332
    },
    {
      "source": "avSocG0oFA",
      "target": "potential algorithms to solve one task",
      "similarity": 0.827
    },
    {
      "source": "28abpUEICJ",
      "target": "ptjrpEGrGg",
      "similarity": 0.8315
    },
    {
      "source": "28abpUEICJ",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8314
    },
    {
      "source": "28abpUEICJ",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.8312
    },
    {
      "source": "28abpUEICJ",
      "target": "F57HPKZ6KD",
      "similarity": 0.8237
    },
    {
      "source": "28abpUEICJ",
      "target": "KlV5CkNQkl",
      "similarity": 0.8202
    },
    {
      "source": "We discover the neural ensembles underlying non-simultaneous observations",
      "target": "vRvVVb0NAz",
      "similarity": 0.8758
    },
    {
      "source": "We discover the neural ensembles underlying non-simultaneous observations",
      "target": "PwxYoMvmvy",
      "similarity": 0.8351
    },
    {
      "source": "We discover the neural ensembles underlying non-simultaneous observations",
      "target": "HqjRlT65WX",
      "similarity": 0.8306
    },
    {
      "source": "We discover the neural ensembles underlying non-simultaneous observations",
      "target": "We then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.",
      "similarity": 0.8245
    },
    {
      "source": "We discover the neural ensembles underlying non-simultaneous observations",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8242
    },
    {
      "source": "RFqeoVfLHa",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8324
    },
    {
      "source": "RFqeoVfLHa",
      "target": "tQyh0gnfqW",
      "similarity": 0.8258
    },
    {
      "source": "RFqeoVfLHa",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.818
    },
    {
      "source": "RFqeoVfLHa",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8152
    },
    {
      "source": "RFqeoVfLHa",
      "target": "In this paper",
      "similarity": 0.8109
    },
    {
      "source": "R4h5PXzUuU",
      "target": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "similarity": 0.8574
    },
    {
      "source": "R4h5PXzUuU",
      "target": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "similarity": 0.8248
    },
    {
      "source": "R4h5PXzUuU",
      "target": "streaming model",
      "similarity": 0.8236
    },
    {
      "source": "R4h5PXzUuU",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8233
    },
    {
      "source": "R4h5PXzUuU",
      "target": "Interestingly",
      "similarity": 0.8174
    },
    {
      "source": "6guG2OlXsr",
      "target": "jTEKTdI3K9",
      "similarity": 0.863
    },
    {
      "source": "6guG2OlXsr",
      "target": "9Ieq8jQNAl",
      "similarity": 0.8613
    },
    {
      "source": "6guG2OlXsr",
      "target": "Y6LPWBo2HP",
      "similarity": 0.8573
    },
    {
      "source": "6guG2OlXsr",
      "target": "The best-performing model",
      "similarity": 0.8487
    },
    {
      "source": "6guG2OlXsr",
      "target": "For example",
      "similarity": 0.8297
    },
    {
      "source": "GpdO9r73xT",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8564
    },
    {
      "source": "GpdO9r73xT",
      "target": "This enables the network to adaptively reuse parameters across tasks",
      "similarity": 0.8533
    },
    {
      "source": "GpdO9r73xT",
      "target": "matched mask pairs between prediction and annotation respectively. Extensive",
      "similarity": 0.8396
    },
    {
      "source": "GpdO9r73xT",
      "target": "kbm6tsICar",
      "similarity": 0.8375
    },
    {
      "source": "GpdO9r73xT",
      "target": "C45YqeBDUM",
      "similarity": 0.8345
    },
    {
      "source": "yQcFniousM",
      "target": "To ensure this progress",
      "similarity": 0.8084
    },
    {
      "source": "yQcFniousM",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.8054
    },
    {
      "source": "yQcFniousM",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.7858
    },
    {
      "source": "yQcFniousM",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.7796
    },
    {
      "source": "yQcFniousM",
      "target": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "similarity": 0.7759
    },
    {
      "source": "named Pacmann",
      "target": "xiQNfYl33p",
      "similarity": 0.8807
    },
    {
      "source": "named Pacmann",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8634
    },
    {
      "source": "named Pacmann",
      "target": "To develop SoundCTM",
      "similarity": 0.8615
    },
    {
      "source": "named Pacmann",
      "target": "QowsEic1sc",
      "similarity": 0.8602
    },
    {
      "source": "named Pacmann",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8545
    },
    {
      "source": "that allows a client to perform ANN search",
      "target": "EEgYUccwsV",
      "similarity": 0.8599
    },
    {
      "source": "that allows a client to perform ANN search",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8568
    },
    {
      "source": "that allows a client to perform ANN search",
      "target": "Dl3MsjaIdp",
      "similarity": 0.853
    },
    {
      "source": "that allows a client to perform ANN search",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8486
    },
    {
      "source": "that allows a client to perform ANN search",
      "target": "suz4utPr9Y",
      "similarity": 0.8477
    },
    {
      "source": "in a vector database",
      "target": "QWunLKbBGF",
      "similarity": 0.9186
    },
    {
      "source": "in a vector database",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.9144
    },
    {
      "source": "in a vector database",
      "target": "odU59TxdiB",
      "similarity": 0.911
    },
    {
      "source": "in a vector database",
      "target": "Overall",
      "similarity": 0.9066
    },
    {
      "source": "in a vector database",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8986
    },
    {
      "source": "without revealing the query vector to the server.",
      "target": "0fJfVOSUra",
      "similarity": 0.8617
    },
    {
      "source": "without revealing the query vector to the server.",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8534
    },
    {
      "source": "without revealing the query vector to the server.",
      "target": "To this end",
      "similarity": 0.8446
    },
    {
      "source": "without revealing the query vector to the server.",
      "target": "J9FgrqOOni",
      "similarity": 0.838
    },
    {
      "source": "without revealing the query vector to the server.",
      "target": "se4vjm7h4E",
      "similarity": 0.8329
    },
    {
      "source": "Unlike prior constructions that run encrypted search on the server side",
      "target": "aXwukBD6M6",
      "similarity": 0.8356
    },
    {
      "source": "Unlike prior constructions that run encrypted search on the server side",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8331
    },
    {
      "source": "Unlike prior constructions that run encrypted search on the server side",
      "target": "attribution and dataset selection.\"",
      "similarity": 0.8298
    },
    {
      "source": "Unlike prior constructions that run encrypted search on the server side",
      "target": "fifXzmzeGy",
      "similarity": 0.8174
    },
    {
      "source": "Unlike prior constructions that run encrypted search on the server side",
      "target": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "similarity": 0.8162
    },
    {
      "source": "Pacmann carefully offloads limited computation and storage to the client",
      "target": "EEgYUccwsV",
      "similarity": 0.8706
    },
    {
      "source": "Pacmann carefully offloads limited computation and storage to the client",
      "target": "suz4utPr9Y",
      "similarity": 0.8475
    },
    {
      "source": "Pacmann carefully offloads limited computation and storage to the client",
      "target": "QYigQ6gXNw",
      "similarity": 0.8411
    },
    {
      "source": "Pacmann carefully offloads limited computation and storage to the client",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8366
    },
    {
      "source": "Pacmann carefully offloads limited computation and storage to the client",
      "target": "available at https://github.com/qiaoruiyt/GSR.\"",
      "similarity": 0.8311
    },
    {
      "source": "no longer requiring computationally-intensive cryptographic techniques.",
      "target": "In this paper",
      "similarity": 0.831
    },
    {
      "source": "no longer requiring computationally-intensive cryptographic techniques.",
      "target": "vQhn4wrQ6j",
      "similarity": 0.8255
    },
    {
      "source": "no longer requiring computationally-intensive cryptographic techniques.",
      "target": "Tkkrm3pA35",
      "similarity": 0.8154
    },
    {
      "source": "no longer requiring computationally-intensive cryptographic techniques.",
      "target": "1F8xTfv6ah",
      "similarity": 0.812
    },
    {
      "source": "no longer requiring computationally-intensive cryptographic techniques.",
      "target": "Second",
      "similarity": 0.8013
    },
    {
      "source": "Specifically",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8243
    },
    {
      "source": "Specifically",
      "target": "vRvVVb0NAz",
      "similarity": 0.81
    },
    {
      "source": "Specifically",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8057
    },
    {
      "source": "Specifically",
      "target": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "similarity": 0.8044
    },
    {
      "source": "Specifically",
      "target": "However",
      "similarity": 0.8021
    },
    {
      "source": "To make this efficient",
      "target": "PxlfzEePC0",
      "similarity": 0.8485
    },
    {
      "source": "To make this efficient",
      "target": "hgwGi81ndj",
      "similarity": 0.8463
    },
    {
      "source": "To make this efficient",
      "target": "cKlzKs3Nnb",
      "similarity": 0.8456
    },
    {
      "source": "To make this efficient",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.8391
    },
    {
      "source": "To make this efficient",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8348
    },
    {
      "source": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "target": "PstM8YfhvI",
      "similarity": 0.8502
    },
    {
      "source": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "target": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "similarity": 0.8458
    },
    {
      "source": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "target": "C45YqeBDUM",
      "similarity": 0.845
    },
    {
      "source": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "target": "bBoetBIN2R",
      "similarity": 0.8393
    },
    {
      "source": "(1) we adapt a leading graph-based ANN search algorithm to be compatible with private information retrieval (PIR) for subgraph retrieval;",
      "target": "ROpY0qRUXL",
      "similarity": 0.8345
    },
    {
      "source": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "target": "In this work",
      "similarity": 0.8132
    },
    {
      "source": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "target": "In parallel",
      "similarity": 0.7898
    },
    {
      "source": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "target": "Existing approaches fall short in addressing the temporal adaptability of knowledge",
      "similarity": 0.7891
    },
    {
      "source": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.7887
    },
    {
      "source": "(2) we use a recent class of PIR schemes that trade offline preprocessing for online computational efficiency.",
      "target": "connection component",
      "similarity": 0.7806
    },
    {
      "source": "Pacmann achieves significantly better search quality than",
      "target": "To explore real-time segmentation",
      "similarity": 0.8362
    },
    {
      "source": "Pacmann achieves significantly better search quality than",
      "target": "We release models",
      "similarity": 0.8268
    },
    {
      "source": "Pacmann achieves significantly better search quality than",
      "target": "FrFQpAgnGE",
      "similarity": 0.8238
    },
    {
      "source": "Pacmann achieves significantly better search quality than",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8226
    },
    {
      "source": "Pacmann achieves significantly better search quality than",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8194
    },
    {
      "source": "the state-of-the-art private ANN search schemes",
      "target": "uhaLuZcCjH",
      "similarity": 0.9057
    },
    {
      "source": "the state-of-the-art private ANN search schemes",
      "target": "To address these challenges",
      "similarity": 0.8387
    },
    {
      "source": "the state-of-the-art private ANN search schemes",
      "target": "INyi7qUdjZ",
      "similarity": 0.8333
    },
    {
      "source": "the state-of-the-art private ANN search schemes",
      "target": "findings stress the limitations of collective thought approaches and highlight the",
      "similarity": 0.8311
    },
    {
      "source": "the state-of-the-art private ANN search schemes",
      "target": "eGqQyTAbXC",
      "similarity": 0.8229
    },
    {
      "source": "showing up to 2.5$\\times$ better search accuracy on",
      "target": "Finally",
      "similarity": 0.8421
    },
    {
      "source": "showing up to 2.5$\\times$ better search accuracy on",
      "target": "MBBRHDuiwM",
      "similarity": 0.8393
    },
    {
      "source": "showing up to 2.5$\\times$ better search accuracy on",
      "target": "implementation",
      "similarity": 0.8344
    },
    {
      "source": "showing up to 2.5$\\times$ better search accuracy on",
      "target": "K4FAFNRpko",
      "similarity": 0.8339
    },
    {
      "source": "showing up to 2.5$\\times$ better search accuracy on",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.8283
    },
    {
      "source": "real-world datasets than prior work and",
      "target": "TKuYWeFE6S",
      "similarity": 0.9019
    },
    {
      "source": "real-world datasets than prior work and",
      "target": "oeP6OL7ouB",
      "similarity": 0.8784
    },
    {
      "source": "real-world datasets than prior work and",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8599
    },
    {
      "source": "real-world datasets than prior work and",
      "target": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "similarity": 0.859
    },
    {
      "source": "real-world datasets than prior work and",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8528
    },
    {
      "source": "reaching 90\\% quality of a state-of-the-art",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8578
    },
    {
      "source": "reaching 90\\% quality of a state-of-the-art",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8458
    },
    {
      "source": "reaching 90\\% quality of a state-of-the-art",
      "target": "wSkvf2WyYz",
      "similarity": 0.8444
    },
    {
      "source": "reaching 90\\% quality of a state-of-the-art",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8402
    },
    {
      "source": "reaching 90\\% quality of a state-of-the-art",
      "target": "hgwGi81ndj",
      "similarity": 0.8396
    },
    {
      "source": "non-private ANN algorithm.",
      "target": "fXJCqdUSVG",
      "similarity": 0.8282
    },
    {
      "source": "non-private ANN algorithm.",
      "target": "te2IdORabL",
      "similarity": 0.8215
    },
    {
      "source": "non-private ANN algorithm.",
      "target": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "similarity": 0.8128
    },
    {
      "source": "non-private ANN algorithm.",
      "target": "To ensure this progress",
      "similarity": 0.8101
    },
    {
      "source": "non-private ANN algorithm.",
      "target": "uhaLuZcCjH",
      "similarity": 0.8091
    },
    {
      "source": "Moreover on large datasets with up to 100 million vectors",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8674
    },
    {
      "source": "Moreover on large datasets with up to 100 million vectors",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8485
    },
    {
      "source": "Moreover on large datasets with up to 100 million vectors",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.8432
    },
    {
      "source": "Moreover on large datasets with up to 100 million vectors",
      "target": "tu3qwNjrtw",
      "similarity": 0.8365
    },
    {
      "source": "Moreover on large datasets with up to 100 million vectors",
      "target": "learning has exhibited impressive capacities across various healthcare domains",
      "similarity": 0.8364
    },
    {
      "source": "Pacmann shows better scalability",
      "target": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "similarity": 0.8506
    },
    {
      "source": "Pacmann shows better scalability",
      "target": "fL4qWkSmtM",
      "similarity": 0.8302
    },
    {
      "source": "Pacmann shows better scalability",
      "target": "n34taxF0TC",
      "similarity": 0.8264
    },
    {
      "source": "Pacmann shows better scalability",
      "target": "fGIqGfmgkW",
      "similarity": 0.8242
    },
    {
      "source": "Pacmann shows better scalability",
      "target": "QWunLKbBGF",
      "similarity": 0.8217
    },
    {
      "source": "than prior private ANN schemes",
      "target": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "similarity": 0.8737
    },
    {
      "source": "than prior private ANN schemes",
      "target": "HqjRlT65WX",
      "similarity": 0.8303
    },
    {
      "source": "than prior private ANN schemes",
      "target": "OuLgaHEmzi",
      "similarity": 0.8256
    },
    {
      "source": "than prior private ANN schemes",
      "target": "eHehzSDUFp",
      "similarity": 0.8227
    },
    {
      "source": "than prior private ANN schemes",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8226
    },
    {
      "source": "with up to 62\\% reduction in computation time",
      "target": "an upper bound of excess risk on downstream classification tasks of representations",
      "similarity": 0.8051
    },
    {
      "source": "with up to 62\\% reduction in computation time",
      "target": "PSiijdQjNU",
      "similarity": 0.7982
    },
    {
      "source": "with up to 62\\% reduction in computation time",
      "target": "ajSmXqgS24",
      "similarity": 0.7957
    },
    {
      "source": "with up to 62\\% reduction in computation time",
      "target": "cADpvQgnqg",
      "similarity": 0.7877
    },
    {
      "source": "with up to 62\\% reduction in computation time",
      "target": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "similarity": 0.786
    },
    {
      "source": "and 22\\% reduction in overall latency.\"",
      "target": "latent variables",
      "similarity": 0.8554
    },
    {
      "source": "and 22\\% reduction in overall latency.\"",
      "target": "depth-wise",
      "similarity": 0.852
    },
    {
      "source": "and 22\\% reduction in overall latency.\"",
      "target": "cADpvQgnqg",
      "similarity": 0.8473
    },
    {
      "source": "and 22\\% reduction in overall latency.\"",
      "target": "WJaUkwci9o",
      "similarity": 0.8472
    },
    {
      "source": "and 22\\% reduction in overall latency.\"",
      "target": "zxO4WuVGns",
      "similarity": 0.8442
    },
    {
      "source": "zZ8fgXHkXi",
      "target": "6VhDQP7WGX",
      "similarity": 0.8382
    },
    {
      "source": "zZ8fgXHkXi",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8364
    },
    {
      "source": "zZ8fgXHkXi",
      "target": "In experiments with GPT-4",
      "similarity": 0.8263
    },
    {
      "source": "zZ8fgXHkXi",
      "target": "yR47RmND1m",
      "similarity": 0.8256
    },
    {
      "source": "zZ8fgXHkXi",
      "target": "1durmugh3I",
      "similarity": 0.8223
    },
    {
      "source": "otW0TJOUYF",
      "target": "FrFQpAgnGE",
      "similarity": 0.8886
    },
    {
      "source": "otW0TJOUYF",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8841
    },
    {
      "source": "otW0TJOUYF",
      "target": "To this end",
      "similarity": 0.8683
    },
    {
      "source": "otW0TJOUYF",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8647
    },
    {
      "source": "otW0TJOUYF",
      "target": "4ktJJBvvUd",
      "similarity": 0.8612
    },
    {
      "source": "fXJCqdUSVG",
      "target": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "similarity": 0.8171
    },
    {
      "source": "fXJCqdUSVG",
      "target": "(b) Given these lower bounds",
      "similarity": 0.8158
    },
    {
      "source": "fXJCqdUSVG",
      "target": "INyi7qUdjZ",
      "similarity": 0.8107
    },
    {
      "source": "fXJCqdUSVG",
      "target": "4iFSBgxvIO",
      "similarity": 0.8074
    },
    {
      "source": "fXJCqdUSVG",
      "target": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "similarity": 0.8055
    },
    {
      "source": "DsIOUoZkVk",
      "target": "1DVgysiIt7",
      "similarity": 0.844
    },
    {
      "source": "DsIOUoZkVk",
      "target": "mzL19kKE3r",
      "similarity": 0.8021
    },
    {
      "source": "DsIOUoZkVk",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.7945
    },
    {
      "source": "DsIOUoZkVk",
      "target": "FPQzXME9NK",
      "similarity": 0.7835
    },
    {
      "source": "DsIOUoZkVk",
      "target": "leading proprietary models (e.g.",
      "similarity": 0.7819
    },
    {
      "source": "Tkkrm3pA35",
      "target": "slO3xTt4CG",
      "similarity": 0.8536
    },
    {
      "source": "Tkkrm3pA35",
      "target": "1F8xTfv6ah",
      "similarity": 0.8282
    },
    {
      "source": "Tkkrm3pA35",
      "target": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "similarity": 0.828
    },
    {
      "source": "Tkkrm3pA35",
      "target": "C45YqeBDUM",
      "similarity": 0.8196
    },
    {
      "source": "Tkkrm3pA35",
      "target": "Excitingly",
      "similarity": 0.8147
    },
    {
      "source": "Q0s6kgrUMr",
      "target": "p60Y6o85Cj",
      "similarity": 0.8102
    },
    {
      "source": "Q0s6kgrUMr",
      "target": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "similarity": 0.8026
    },
    {
      "source": "Q0s6kgrUMr",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8023
    },
    {
      "source": "Q0s6kgrUMr",
      "target": "U3PBITXNG6",
      "similarity": 0.7994
    },
    {
      "source": "Q0s6kgrUMr",
      "target": "owP2mymrTD",
      "similarity": 0.7948
    },
    {
      "source": "J4xLuCt2kg",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8384
    },
    {
      "source": "J4xLuCt2kg",
      "target": "compression has become increasingly crucial for reducing costs and improving",
      "similarity": 0.8326
    },
    {
      "source": "J4xLuCt2kg",
      "target": "AjXkRZIvjB",
      "similarity": 0.8258
    },
    {
      "source": "J4xLuCt2kg",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.825
    },
    {
      "source": "J4xLuCt2kg",
      "target": "yRKelogz5i",
      "similarity": 0.8225
    },
    {
      "source": "Essg9kb4yx",
      "target": "For example",
      "similarity": 0.8906
    },
    {
      "source": "Essg9kb4yx",
      "target": "jTEKTdI3K9",
      "similarity": 0.8834
    },
    {
      "source": "Essg9kb4yx",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8822
    },
    {
      "source": "Essg9kb4yx",
      "target": "se4vjm7h4E",
      "similarity": 0.8765
    },
    {
      "source": "Essg9kb4yx",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8762
    },
    {
      "source": "However",
      "target": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "similarity": 0.8526
    },
    {
      "source": "However",
      "target": "dgR6i4TSng",
      "similarity": 0.8518
    },
    {
      "source": "However",
      "target": "U42TkrEDzb",
      "similarity": 0.8463
    },
    {
      "source": "However",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8451
    },
    {
      "source": "However",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8447
    },
    {
      "source": "Moreover",
      "target": "4O0v4s3IzY",
      "similarity": 0.8758
    },
    {
      "source": "Moreover",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8663
    },
    {
      "source": "Moreover",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8566
    },
    {
      "source": "Moreover",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.8499
    },
    {
      "source": "Moreover",
      "target": "is often a non-linear function",
      "similarity": 0.8493
    },
    {
      "source": "To overcome these challenges",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8809
    },
    {
      "source": "To overcome these challenges",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8693
    },
    {
      "source": "To overcome these challenges",
      "target": "To this end",
      "similarity": 0.8646
    },
    {
      "source": "To overcome these challenges",
      "target": "yIlyHJdYV3",
      "similarity": 0.8623
    },
    {
      "source": "To overcome these challenges",
      "target": "FrFQpAgnGE",
      "similarity": 0.8561
    },
    {
      "source": "ssRdQimeUI",
      "target": "j1tSLYKwg8",
      "similarity": 0.8509
    },
    {
      "source": "ssRdQimeUI",
      "target": "In this paper",
      "similarity": 0.8452
    },
    {
      "source": "ssRdQimeUI",
      "target": "xJXq6FkqEw",
      "similarity": 0.8397
    },
    {
      "source": "ssRdQimeUI",
      "target": "kSdWcw5mkp",
      "similarity": 0.834
    },
    {
      "source": "ssRdQimeUI",
      "target": "Subsequently",
      "similarity": 0.834
    },
    {
      "source": "Gq7RDMeZi4",
      "target": "but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.\"",
      "similarity": 0.7542
    },
    {
      "source": "z0hUsPhwUN",
      "target": "X6y5CC44HM",
      "similarity": 0.8248
    },
    {
      "source": "z0hUsPhwUN",
      "target": "GpdO9r73xT",
      "similarity": 0.7925
    },
    {
      "source": "z0hUsPhwUN",
      "target": "ROpY0qRUXL",
      "similarity": 0.7921
    },
    {
      "source": "z0hUsPhwUN",
      "target": "YcUV5apdlq",
      "similarity": 0.7882
    },
    {
      "source": "z0hUsPhwUN",
      "target": "C45YqeBDUM",
      "similarity": 0.7879
    },
    {
      "source": "zd0iX5xBhA",
      "target": "E4LAVLXAHW",
      "similarity": 0.8603
    },
    {
      "source": "zd0iX5xBhA",
      "target": "phenomenon known as loss of plasticity.",
      "similarity": 0.8589
    },
    {
      "source": "zd0iX5xBhA",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.857
    },
    {
      "source": "zd0iX5xBhA",
      "target": "IuU0wcO0mo",
      "similarity": 0.8534
    },
    {
      "source": "zd0iX5xBhA",
      "target": "Finally",
      "similarity": 0.8533
    },
    {
      "source": "OwpLQrpdwE",
      "target": "U834XHJuqk",
      "similarity": 0.8088
    },
    {
      "source": "OwpLQrpdwE",
      "target": "sYNWqQYJhz",
      "similarity": 0.7988
    },
    {
      "source": "OwpLQrpdwE",
      "target": "In $\\texttt{ProAdvPrompter}$",
      "similarity": 0.7984
    },
    {
      "source": "OwpLQrpdwE",
      "target": "assessing and advancing topological methods",
      "similarity": 0.7984
    },
    {
      "source": "OwpLQrpdwE",
      "target": "Finally",
      "similarity": 0.7908
    },
    {
      "source": "tfO07iz0b9",
      "target": "VQwI055flA",
      "similarity": 0.8581
    },
    {
      "source": "tfO07iz0b9",
      "target": "bMC1t7eLRc",
      "similarity": 0.849
    },
    {
      "source": "tfO07iz0b9",
      "target": "To this end",
      "similarity": 0.8462
    },
    {
      "source": "tfO07iz0b9",
      "target": "Such models faced convergence issues due to vanishing gradient",
      "similarity": 0.8448
    },
    {
      "source": "tfO07iz0b9",
      "target": "2mqb8bPHeb",
      "similarity": 0.8421
    },
    {
      "source": "7HEMpBTb3R",
      "target": "phAlw3JPms",
      "similarity": 0.8643
    },
    {
      "source": "7HEMpBTb3R",
      "target": "certifies LLMs for counterfactual bias on distributions of prompts. A certificate",
      "similarity": 0.8631
    },
    {
      "source": "7HEMpBTb3R",
      "target": "we propose positive-unlabeled diffusion models",
      "similarity": 0.8489
    },
    {
      "source": "7HEMpBTb3R",
      "target": "In this paper",
      "similarity": 0.8422
    },
    {
      "source": "7HEMpBTb3R",
      "target": "is often a non-linear function",
      "similarity": 0.8407
    },
    {
      "source": "Prior methods improve accuracy using external semantic supervision",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.847
    },
    {
      "source": "Prior methods improve accuracy using external semantic supervision",
      "target": "7bAjVh3CG3",
      "similarity": 0.8343
    },
    {
      "source": "Prior methods improve accuracy using external semantic supervision",
      "target": "In this paper",
      "similarity": 0.8305
    },
    {
      "source": "Prior methods improve accuracy using external semantic supervision",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8302
    },
    {
      "source": "Prior methods improve accuracy using external semantic supervision",
      "target": "X1U74IwuxG",
      "similarity": 0.8295
    },
    {
      "source": "bEqI61iBue",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8125
    },
    {
      "source": "bEqI61iBue",
      "target": "p60Y6o85Cj",
      "similarity": 0.8115
    },
    {
      "source": "bEqI61iBue",
      "target": "Our Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%",
      "similarity": 0.8041
    },
    {
      "source": "bEqI61iBue",
      "target": "Aly68Y5Es0",
      "similarity": 0.8032
    },
    {
      "source": "bEqI61iBue",
      "target": "O6znYvxC1U",
      "similarity": 0.8025
    },
    {
      "source": "6Ai8SuDsh3",
      "target": "j1tSLYKwg8",
      "similarity": 0.825
    },
    {
      "source": "6Ai8SuDsh3",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8081
    },
    {
      "source": "6Ai8SuDsh3",
      "target": "sampling methods",
      "similarity": 0.8015
    },
    {
      "source": "6Ai8SuDsh3",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8014
    },
    {
      "source": "6Ai8SuDsh3",
      "target": "ymt4crbbXh",
      "similarity": 0.7979
    },
    {
      "source": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8346
    },
    {
      "source": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8344
    },
    {
      "source": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "target": "kxnoqaisCT",
      "similarity": 0.8304
    },
    {
      "source": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8271
    },
    {
      "source": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8265
    },
    {
      "source": "We provide theoretical justifications for our new objective",
      "target": "$$",
      "similarity": 0.8604
    },
    {
      "source": "We provide theoretical justifications for our new objective",
      "target": "works remains elusive. Current interpretability work can extract features from",
      "similarity": 0.8555
    },
    {
      "source": "We provide theoretical justifications for our new objective",
      "target": "(including gradient-based",
      "similarity": 0.8314
    },
    {
      "source": "We provide theoretical justifications for our new objective",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8193
    },
    {
      "source": "We provide theoretical justifications for our new objective",
      "target": "MT3aOfXIbY",
      "similarity": 0.8119
    },
    {
      "source": "nzjSvVZBIp",
      "target": "- In continuous image-based control (e.g.",
      "similarity": 0.8481
    },
    {
      "source": "nzjSvVZBIp",
      "target": "comprehensive experiments",
      "similarity": 0.8362
    },
    {
      "source": "nzjSvVZBIp",
      "target": "yR47RmND1m",
      "similarity": 0.832
    },
    {
      "source": "nzjSvVZBIp",
      "target": "xI71dsS3o4",
      "similarity": 0.8309
    },
    {
      "source": "nzjSvVZBIp",
      "target": "1durmugh3I",
      "similarity": 0.8257
    },
    {
      "source": "h1XoHOd19I",
      "target": "faceswaps",
      "similarity": 0.8491
    },
    {
      "source": "h1XoHOd19I",
      "target": "NJxCpMt0sf",
      "similarity": 0.846
    },
    {
      "source": "h1XoHOd19I",
      "target": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "similarity": 0.8459
    },
    {
      "source": "h1XoHOd19I",
      "target": "VoayJihXra",
      "similarity": 0.845
    },
    {
      "source": "h1XoHOd19I",
      "target": "FiyS0ecSm0",
      "similarity": 0.8447
    },
    {
      "source": "However",
      "target": "2PRpcmJecX",
      "similarity": 0.77
    },
    {
      "source": "However",
      "target": "integrates with modern graphics engines supporting downstream applications such as scene editing",
      "similarity": 0.7668
    },
    {
      "source": "However",
      "target": "1NprT9Kz0d",
      "similarity": 0.7643
    },
    {
      "source": "However",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.764
    },
    {
      "source": "However",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.7594
    },
    {
      "source": "To enhance the domain adaptation of LLMs",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8433
    },
    {
      "source": "To enhance the domain adaptation of LLMs",
      "target": "To address these challenges",
      "similarity": 0.8427
    },
    {
      "source": "To enhance the domain adaptation of LLMs",
      "target": "To address these issues",
      "similarity": 0.8395
    },
    {
      "source": "To enhance the domain adaptation of LLMs",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8377
    },
    {
      "source": "To enhance the domain adaptation of LLMs",
      "target": "For instance",
      "similarity": 0.8365
    },
    {
      "source": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "target": "In this paper",
      "similarity": 0.8465
    },
    {
      "source": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "target": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "similarity": 0.8036
    },
    {
      "source": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "target": "fjEZ2LPceZ",
      "similarity": 0.8023
    },
    {
      "source": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "target": "constraints and dynamics",
      "similarity": 0.7999
    },
    {
      "source": "Extensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains.\"",
      "target": "model may lack the ability to fully understand the content and may have inherent",
      "similarity": 0.7979
    },
    {
      "source": "cmfyMV45XO",
      "target": "Antib6Uovh",
      "similarity": 0.8563
    },
    {
      "source": "cmfyMV45XO",
      "target": "9EqQC2ct4H",
      "similarity": 0.8448
    },
    {
      "source": "cmfyMV45XO",
      "target": "To enable TTA for regression",
      "similarity": 0.8443
    },
    {
      "source": "cmfyMV45XO",
      "target": "pCj2sLNoJq",
      "similarity": 0.8317
    },
    {
      "source": "cmfyMV45XO",
      "target": "S1Bv3068Xt",
      "similarity": 0.8313
    },
    {
      "source": "Bpn8q40n1n",
      "target": "M5t0WvjfCg",
      "similarity": 0.8381
    },
    {
      "source": "Bpn8q40n1n",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8354
    },
    {
      "source": "Bpn8q40n1n",
      "target": "However",
      "similarity": 0.8258
    },
    {
      "source": "Bpn8q40n1n",
      "target": "UL2",
      "similarity": 0.8233
    },
    {
      "source": "Bpn8q40n1n",
      "target": "Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function",
      "similarity": 0.8216
    },
    {
      "source": "dImD2sgy86",
      "target": "Specifically",
      "similarity": 0.8348
    },
    {
      "source": "dImD2sgy86",
      "target": "tQyh0gnfqW",
      "similarity": 0.8119
    },
    {
      "source": "dImD2sgy86",
      "target": "4GT9uTsAJE",
      "similarity": 0.8073
    },
    {
      "source": "dImD2sgy86",
      "target": "Second",
      "similarity": 0.8039
    },
    {
      "source": "dImD2sgy86",
      "target": "iVMcYxTiVM",
      "similarity": 0.802
    },
    {
      "source": "sampling methods",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8504
    },
    {
      "source": "sampling methods",
      "target": "Moreover",
      "similarity": 0.8397
    },
    {
      "source": "sampling methods",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8386
    },
    {
      "source": "sampling methods",
      "target": "In addition",
      "similarity": 0.8381
    },
    {
      "source": "sampling methods",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8297
    },
    {
      "source": "RZwtbg3qYD",
      "target": "FPBce2P1er",
      "similarity": 0.8105
    },
    {
      "source": "RZwtbg3qYD",
      "target": "Real-world causal structures",
      "similarity": 0.8092
    },
    {
      "source": "RZwtbg3qYD",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.8091
    },
    {
      "source": "RZwtbg3qYD",
      "target": "Results show that  CogVideoX achieves state-of-the-art performance in both automated benchmarks and human evaluation.",
      "similarity": 0.8084
    },
    {
      "source": "RZwtbg3qYD",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8003
    },
    {
      "source": "xJXq6FkqEw",
      "target": "j1tSLYKwg8",
      "similarity": 0.8696
    },
    {
      "source": "xJXq6FkqEw",
      "target": "In this paper",
      "similarity": 0.8674
    },
    {
      "source": "xJXq6FkqEw",
      "target": "9KiE3t6CsL",
      "similarity": 0.8576
    },
    {
      "source": "xJXq6FkqEw",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.8515
    },
    {
      "source": "xJXq6FkqEw",
      "target": "ByCV9xWfNK",
      "similarity": 0.8484
    },
    {
      "source": "powerful expressiveness",
      "target": "the causal parents of the treatment or those of the outcome are observed",
      "similarity": 0.875
    },
    {
      "source": "powerful expressiveness",
      "target": "IQxBDLmVpT",
      "similarity": 0.872
    },
    {
      "source": "powerful expressiveness",
      "target": "To overcome this limitation",
      "similarity": 0.8604
    },
    {
      "source": "powerful expressiveness",
      "target": "RC5FPYVQaH",
      "similarity": 0.8411
    },
    {
      "source": "powerful expressiveness",
      "target": "bmrYu2Ekdz",
      "similarity": 0.8373
    },
    {
      "source": "uncertainty estimation. Concurrently",
      "target": "Yet",
      "similarity": 0.8515
    },
    {
      "source": "uncertainty estimation. Concurrently",
      "target": "tcsZt9ZNKD",
      "similarity": 0.8399
    },
    {
      "source": "uncertainty estimation. Concurrently",
      "target": "To overcome those challenges",
      "similarity": 0.8395
    },
    {
      "source": "uncertainty estimation. Concurrently",
      "target": "semTHoVGsJ",
      "similarity": 0.8393
    },
    {
      "source": "uncertainty estimation. Concurrently",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8369
    },
    {
      "source": "works leads to a multifaceted problem",
      "target": "9qS3HzSDNv",
      "similarity": 0.8563
    },
    {
      "source": "works leads to a multifaceted problem",
      "target": "FiyS0ecSm0",
      "similarity": 0.8434
    },
    {
      "source": "works leads to a multifaceted problem",
      "target": "K7xpl3LZQp",
      "similarity": 0.8406
    },
    {
      "source": "works leads to a multifaceted problem",
      "target": "In this work",
      "similarity": 0.8387
    },
    {
      "source": "works leads to a multifaceted problem",
      "target": "In particular",
      "similarity": 0.8367
    },
    {
      "source": "niques reveal that multiple unrelated features influence the decisions",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8702
    },
    {
      "source": "niques reveal that multiple unrelated features influence the decisions",
      "target": "Moreover",
      "similarity": 0.8573
    },
    {
      "source": "niques reveal that multiple unrelated features influence the decisions",
      "target": "vVxeFSR4fU",
      "similarity": 0.8485
    },
    {
      "source": "niques reveal that multiple unrelated features influence the decisions",
      "target": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "similarity": 0.8454
    },
    {
      "source": "niques reveal that multiple unrelated features influence the decisions",
      "target": "gsShHPxkUW",
      "similarity": 0.8422
    },
    {
      "source": "dermining interpretability. To address these challenges",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8269
    },
    {
      "source": "dermining interpretability. To address these challenges",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.8261
    },
    {
      "source": "dermining interpretability. To address these challenges",
      "target": "j1tSLYKwg8",
      "similarity": 0.8249
    },
    {
      "source": "dermining interpretability. To address these challenges",
      "target": "hOELrZfg0J",
      "similarity": 0.8212
    },
    {
      "source": "dermining interpretability. To address these challenges",
      "target": "samples. However",
      "similarity": 0.8161
    },
    {
      "source": "Nonnegative Decision Layer (BNDL)",
      "target": "jTEKTdI3K9",
      "similarity": 0.897
    },
    {
      "source": "Nonnegative Decision Layer (BNDL)",
      "target": "while ensuring safety during learning.\"",
      "similarity": 0.893
    },
    {
      "source": "Nonnegative Decision Layer (BNDL)",
      "target": "For example",
      "similarity": 0.8908
    },
    {
      "source": "Nonnegative Decision Layer (BNDL)",
      "target": "se4vjm7h4E",
      "similarity": 0.8871
    },
    {
      "source": "Nonnegative Decision Layer (BNDL)",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.87
    },
    {
      "source": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "target": "among textual and visual tokens using a Causal Graphical Model (CGM)",
      "similarity": 0.825
    },
    {
      "source": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "target": "prior to their applications to human patients. To facilitate its easy access and",
      "similarity": 0.8145
    },
    {
      "source": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "target": "then show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks",
      "similarity": 0.8137
    },
    {
      "source": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "target": "QaTBHSqmH9",
      "similarity": 0.8132
    },
    {
      "source": "as a conditional Bayesian non-negative factor analysis. By leveraging stochastic",
      "target": "identically. Therefore",
      "similarity": 0.8102
    },
    {
      "source": "latent variables",
      "target": "cADpvQgnqg",
      "similarity": 0.8448
    },
    {
      "source": "latent variables",
      "target": "WJaUkwci9o",
      "similarity": 0.8445
    },
    {
      "source": "latent variables",
      "target": "kbm6tsICar",
      "similarity": 0.8408
    },
    {
      "source": "latent variables",
      "target": "gcouwCx7dG",
      "similarity": 0.8364
    },
    {
      "source": "latent variables",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8348
    },
    {
      "source": "uncertainty estimation. Moreover",
      "target": "cC3LxGZasH",
      "similarity": 0.8831
    },
    {
      "source": "uncertainty estimation. Moreover",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8581
    },
    {
      "source": "uncertainty estimation. Moreover",
      "target": "4JK2XMGUc8",
      "similarity": 0.8533
    },
    {
      "source": "uncertainty estimation. Moreover",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8512
    },
    {
      "source": "uncertainty estimation. Moreover",
      "target": "increased their demand. However",
      "similarity": 0.8461
    },
    {
      "source": "variables encourage the model to learn disentangled representations and decision",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.8822
    },
    {
      "source": "variables encourage the model to learn disentangled representations and decision",
      "target": "9qS3HzSDNv",
      "similarity": 0.8413
    },
    {
      "source": "variables encourage the model to learn disentangled representations and decision",
      "target": "The experimental and theoretical results showcase the effectiveness and orthogonality of our proposed approach",
      "similarity": 0.8406
    },
    {
      "source": "variables encourage the model to learn disentangled representations and decision",
      "target": "VoayJihXra",
      "similarity": 0.838
    },
    {
      "source": "variables encourage the model to learn disentangled representations and decision",
      "target": "MyVC4X5B2X",
      "similarity": 0.8374
    },
    {
      "source": "layers",
      "target": "SMK0f8JoKF",
      "similarity": 0.8305
    },
    {
      "source": "layers",
      "target": "Bl3e8HV9xW",
      "similarity": 0.8242
    },
    {
      "source": "layers",
      "target": "wgDB1QuxIA",
      "similarity": 0.8181
    },
    {
      "source": "layers",
      "target": "D2hhkU5O48",
      "similarity": 0.8056
    },
    {
      "source": "layers",
      "target": "0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the",
      "similarity": 0.8026
    },
    {
      "source": "that BNDL can achieve effective disentangled learning. In addition",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8398
    },
    {
      "source": "that BNDL can achieve effective disentangled learning. In addition",
      "target": "DTatjJTDl1",
      "similarity": 0.8379
    },
    {
      "source": "that BNDL can achieve effective disentangled learning. In addition",
      "target": "introduce MANTRA",
      "similarity": 0.8367
    },
    {
      "source": "that BNDL can achieve effective disentangled learning. In addition",
      "target": "BOQpRtI4F5",
      "similarity": 0.8184
    },
    {
      "source": "that BNDL can achieve effective disentangled learning. In addition",
      "target": "A hybrid architecture with 1/3 full attention layers and 2/3 efficient ones achieves a balanced trade-off between efficiency and long-context performance.",
      "similarity": 0.8178
    },
    {
      "source": "a corresponding variational inference method utilizing a Weibull variational in-",
      "target": "To address this issue",
      "similarity": 0.822
    },
    {
      "source": "a corresponding variational inference method utilizing a Weibull variational in-",
      "target": "4JK2XMGUc8",
      "similarity": 0.818
    },
    {
      "source": "a corresponding variational inference method utilizing a Weibull variational in-",
      "target": "To enable TTA for regression",
      "similarity": 0.8125
    },
    {
      "source": "a corresponding variational inference method utilizing a Weibull variational in-",
      "target": "L0evcuybH5",
      "similarity": 0.8116
    },
    {
      "source": "a corresponding variational inference method utilizing a Weibull variational in-",
      "target": "kxnoqaisCT",
      "similarity": 0.8046
    },
    {
      "source": "ference network to approximate the posterior distribution of the latent variables.",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.8035
    },
    {
      "source": "ference network to approximate the posterior distribution of the latent variables.",
      "target": "IuU0wcO0mo",
      "similarity": 0.7996
    },
    {
      "source": "ference network to approximate the posterior distribution of the latent variables.",
      "target": "uHLgDEgiS5",
      "similarity": 0.7975
    },
    {
      "source": "ference network to approximate the posterior distribution of the latent variables.",
      "target": "Remarkably",
      "similarity": 0.7911
    },
    {
      "source": "ference network to approximate the posterior distribution of the latent variables.",
      "target": "space for $p > 1$",
      "similarity": 0.7906
    },
    {
      "source": "Our experimental results demonstrate that with enhanced disentanglement capa-",
      "target": "uL1H29dM0c",
      "similarity": 0.7844
    },
    {
      "source": "Our experimental results demonstrate that with enhanced disentanglement capa-",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.7842
    },
    {
      "source": "Our experimental results demonstrate that with enhanced disentanglement capa-",
      "target": "rCX9l4OTCT",
      "similarity": 0.7802
    },
    {
      "source": "Our experimental results demonstrate that with enhanced disentanglement capa-",
      "target": "novel decomposition approach. Our experiments show that MoDeGPT",
      "similarity": 0.7785
    },
    {
      "source": "Our experimental results demonstrate that with enhanced disentanglement capa-",
      "target": "fn36V5qsCw",
      "similarity": 0.775
    },
    {
      "source": "bilities",
      "target": "2ea5TNVR0c",
      "similarity": 0.8967
    },
    {
      "source": "bilities",
      "target": "To this end",
      "similarity": 0.8763
    },
    {
      "source": "bilities",
      "target": "Qja5s0K3VX",
      "similarity": 0.875
    },
    {
      "source": "bilities",
      "target": "pDDODPtpx9",
      "similarity": 0.8727
    },
    {
      "source": "bilities",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8702
    },
    {
      "source": "uncertainty estimation and improved interpretability.\"",
      "target": "structure encourages the decoder to learn only the main causal dependencies in",
      "similarity": 0.8371
    },
    {
      "source": "uncertainty estimation and improved interpretability.\"",
      "target": "mTCbq2QssD",
      "similarity": 0.8356
    },
    {
      "source": "uncertainty estimation and improved interpretability.\"",
      "target": "KAIqwkB3dT",
      "similarity": 0.8217
    },
    {
      "source": "uncertainty estimation and improved interpretability.\"",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8196
    },
    {
      "source": "uncertainty estimation and improved interpretability.\"",
      "target": "xI71dsS3o4",
      "similarity": 0.8189
    },
    {
      "source": "W2dR6rypBQ",
      "target": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "similarity": 0.8513
    },
    {
      "source": "W2dR6rypBQ",
      "target": "yORSk4Ycsa",
      "similarity": 0.8388
    },
    {
      "source": "W2dR6rypBQ",
      "target": "h8yg0hT96f",
      "similarity": 0.8363
    },
    {
      "source": "W2dR6rypBQ",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8331
    },
    {
      "source": "W2dR6rypBQ",
      "target": "frozen nonlinear manifolds",
      "similarity": 0.832
    },
    {
      "source": "GLWf2fq0bX",
      "target": "In this work",
      "similarity": 0.8751
    },
    {
      "source": "GLWf2fq0bX",
      "target": "To address this issue",
      "similarity": 0.8381
    },
    {
      "source": "GLWf2fq0bX",
      "target": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "similarity": 0.8321
    },
    {
      "source": "GLWf2fq0bX",
      "target": "03EkqSCKuO",
      "similarity": 0.8295
    },
    {
      "source": "GLWf2fq0bX",
      "target": "ajSmXqgS24",
      "similarity": 0.8261
    },
    {
      "source": "oeP6OL7ouB",
      "target": "TKuYWeFE6S",
      "similarity": 0.8731
    },
    {
      "source": "oeP6OL7ouB",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.8446
    },
    {
      "source": "oeP6OL7ouB",
      "target": "zpENPcQSj1",
      "similarity": 0.8413
    },
    {
      "source": "oeP6OL7ouB",
      "target": "These bounds apply to any estimator belonging to a class of Lipschitz continuous estimators",
      "similarity": 0.837
    },
    {
      "source": "oeP6OL7ouB",
      "target": "Specifically",
      "similarity": 0.8347
    },
    {
      "source": "QWunLKbBGF",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.9151
    },
    {
      "source": "QWunLKbBGF",
      "target": "odU59TxdiB",
      "similarity": 0.912
    },
    {
      "source": "QWunLKbBGF",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8975
    },
    {
      "source": "QWunLKbBGF",
      "target": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "similarity": 0.8971
    },
    {
      "source": "QWunLKbBGF",
      "target": "AsAy7CROLs",
      "similarity": 0.8939
    },
    {
      "source": "PrefEval comprises 3",
      "target": "5YbuOTUFQ4",
      "similarity": 0.8133
    },
    {
      "source": "PrefEval comprises 3",
      "target": "Code",
      "similarity": 0.8111
    },
    {
      "source": "PrefEval comprises 3",
      "target": "which",
      "similarity": 0.8077
    },
    {
      "source": "PrefEval comprises 3",
      "target": "8rbkePAapb",
      "similarity": 0.8015
    },
    {
      "source": "PrefEval comprises 3",
      "target": "TJo6aQb7mK",
      "similarity": 0.7911
    },
    {
      "source": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8364
    },
    {
      "source": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.834
    },
    {
      "source": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "target": "5IWJBStfU7",
      "similarity": 0.8264
    },
    {
      "source": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "target": "c61unr33XA",
      "similarity": 0.8209
    },
    {
      "source": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "target": "{Subsequently}",
      "similarity": 0.8202
    },
    {
      "source": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "target": "FS2nukC2jv",
      "similarity": 0.8157
    },
    {
      "source": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8148
    },
    {
      "source": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "target": "IXyfbaGlps",
      "similarity": 0.813
    },
    {
      "source": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8115
    },
    {
      "source": "Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular",
      "target": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "similarity": 0.8099
    },
    {
      "source": "Pnk7vMbznK",
      "target": "We propose RAMEN",
      "similarity": 0.8513
    },
    {
      "source": "Pnk7vMbznK",
      "target": "m8yby1JfbU",
      "similarity": 0.8466
    },
    {
      "source": "Pnk7vMbznK",
      "target": "fifXzmzeGy",
      "similarity": 0.8324
    },
    {
      "source": "Pnk7vMbznK",
      "target": "This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce",
      "similarity": 0.8237
    },
    {
      "source": "Pnk7vMbznK",
      "target": "Nevertheless",
      "similarity": 0.8203
    },
    {
      "source": "P7O1Vt1BdU",
      "target": "FPQzXME9NK",
      "similarity": 0.8238
    },
    {
      "source": "P7O1Vt1BdU",
      "target": "bc2H72hGxB",
      "similarity": 0.8132
    },
    {
      "source": "P7O1Vt1BdU",
      "target": "lence of good solutions in over-parameterized deep neural networks",
      "similarity": 0.7971
    },
    {
      "source": "P7O1Vt1BdU",
      "target": "c61unr33XA",
      "similarity": 0.7934
    },
    {
      "source": "P7O1Vt1BdU",
      "target": "RAyRXQjsFl",
      "similarity": 0.7886
    },
    {
      "source": "CahIEKCu5Q",
      "target": "Under these assumptions",
      "similarity": 0.8171
    },
    {
      "source": "CahIEKCu5Q",
      "target": "VMV8gefvq8",
      "similarity": 0.8168
    },
    {
      "source": "CahIEKCu5Q",
      "target": "eC2a2IndIt",
      "similarity": 0.8077
    },
    {
      "source": "CahIEKCu5Q",
      "target": "yORSk4Ycsa",
      "similarity": 0.8058
    },
    {
      "source": "CahIEKCu5Q",
      "target": "aBnVU5DL3I",
      "similarity": 0.8053
    },
    {
      "source": "dOAkHmsjRX",
      "target": "TljGdvzFq2",
      "similarity": 0.8694
    },
    {
      "source": "dOAkHmsjRX",
      "target": "Using this extension",
      "similarity": 0.8684
    },
    {
      "source": "dOAkHmsjRX",
      "target": "For TP",
      "similarity": 0.8683
    },
    {
      "source": "dOAkHmsjRX",
      "target": "BI2int5SAC",
      "similarity": 0.8615
    },
    {
      "source": "dOAkHmsjRX",
      "target": "To this end",
      "similarity": 0.861
    },
    {
      "source": "vue9P1Ypk6",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8732
    },
    {
      "source": "vue9P1Ypk6",
      "target": "NTHMw8S1Ow",
      "similarity": 0.8297
    },
    {
      "source": "vue9P1Ypk6",
      "target": "5xSRg3eYZz",
      "similarity": 0.8232
    },
    {
      "source": "vue9P1Ypk6",
      "target": "Additionally",
      "similarity": 0.8231
    },
    {
      "source": "vue9P1Ypk6",
      "target": "mTCbq2QssD",
      "similarity": 0.8212
    },
    {
      "source": "KAIqwkB3dT",
      "target": "5xSRg3eYZz",
      "similarity": 0.8552
    },
    {
      "source": "KAIqwkB3dT",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8523
    },
    {
      "source": "KAIqwkB3dT",
      "target": "iLUcsecZJp",
      "similarity": 0.8473
    },
    {
      "source": "KAIqwkB3dT",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8454
    },
    {
      "source": "KAIqwkB3dT",
      "target": "rTQNGQxm4K",
      "similarity": 0.8445
    },
    {
      "source": "n34taxF0TC",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8712
    },
    {
      "source": "n34taxF0TC",
      "target": "VQwI055flA",
      "similarity": 0.8692
    },
    {
      "source": "n34taxF0TC",
      "target": "To overcome these limitations",
      "similarity": 0.866
    },
    {
      "source": "n34taxF0TC",
      "target": "iOMnn1hSBO",
      "similarity": 0.8544
    },
    {
      "source": "n34taxF0TC",
      "target": "To this end",
      "similarity": 0.8517
    },
    {
      "source": "uCqxDfLYrB",
      "target": "Mamba",
      "similarity": 0.775
    },
    {
      "source": "uCqxDfLYrB",
      "target": "mb2ryuZ3wz",
      "similarity": 0.7722
    },
    {
      "source": "uCqxDfLYrB",
      "target": "We also study multiple effects of RAG setup on the extractability of data",
      "similarity": 0.7687
    },
    {
      "source": "uCqxDfLYrB",
      "target": "We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending the human world dynamics through the video modality.\"",
      "similarity": 0.7666
    },
    {
      "source": "uCqxDfLYrB",
      "target": "In this paper",
      "similarity": 0.7653
    },
    {
      "source": "Bl3e8HV9xW",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.8301
    },
    {
      "source": "Bl3e8HV9xW",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8103
    },
    {
      "source": "Bl3e8HV9xW",
      "target": "In this paper",
      "similarity": 0.8096
    },
    {
      "source": "Bl3e8HV9xW",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8049
    },
    {
      "source": "Bl3e8HV9xW",
      "target": "magnitudes in solutions preferred by SAEs.\"",
      "similarity": 0.8044
    },
    {
      "source": "fsDZwS49uY",
      "target": "HqjRlT65WX",
      "similarity": 0.8201
    },
    {
      "source": "fsDZwS49uY",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8191
    },
    {
      "source": "fsDZwS49uY",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8188
    },
    {
      "source": "fsDZwS49uY",
      "target": "vRvVVb0NAz",
      "similarity": 0.8185
    },
    {
      "source": "fsDZwS49uY",
      "target": "PwxYoMvmvy",
      "similarity": 0.8144
    },
    {
      "source": "Furthermore",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8273
    },
    {
      "source": "Furthermore",
      "target": "CS2JWaziYr",
      "similarity": 0.8196
    },
    {
      "source": "Furthermore",
      "target": "kOYnXVQCtA",
      "similarity": 0.8161
    },
    {
      "source": "Furthermore",
      "target": "When combined with Boltzmann exploration",
      "similarity": 0.8158
    },
    {
      "source": "Furthermore",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8154
    },
    {
      "source": "SXtl7NRyE5",
      "target": "Moreover",
      "similarity": 0.8612
    },
    {
      "source": "SXtl7NRyE5",
      "target": "Mjn53GtMxi",
      "similarity": 0.8569
    },
    {
      "source": "SXtl7NRyE5",
      "target": "instructions",
      "similarity": 0.8555
    },
    {
      "source": "SXtl7NRyE5",
      "target": "4D0f16Vwc3",
      "similarity": 0.852
    },
    {
      "source": "SXtl7NRyE5",
      "target": "INow59Vurm",
      "similarity": 0.8466
    },
    {
      "source": "Although regression is one of the fundamental tasks in machine learning",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8553
    },
    {
      "source": "Although regression is one of the fundamental tasks in machine learning",
      "target": "QOfswj7hij",
      "similarity": 0.847
    },
    {
      "source": "Although regression is one of the fundamental tasks in machine learning",
      "target": "named Pacmann",
      "similarity": 0.8391
    },
    {
      "source": "Although regression is one of the fundamental tasks in machine learning",
      "target": "This paper proposes",
      "similarity": 0.8317
    },
    {
      "source": "Although regression is one of the fundamental tasks in machine learning",
      "target": "Q150eWkQ4I",
      "similarity": 0.8316
    },
    {
      "source": "To enable TTA for regression",
      "target": "Antib6Uovh",
      "similarity": 0.8707
    },
    {
      "source": "To enable TTA for regression",
      "target": "To this end",
      "similarity": 0.8621
    },
    {
      "source": "To enable TTA for regression",
      "target": "ZS7UEI3vG5",
      "similarity": 0.8538
    },
    {
      "source": "To enable TTA for regression",
      "target": "AJpUZd8Clb",
      "similarity": 0.8441
    },
    {
      "source": "To enable TTA for regression",
      "target": "To address this",
      "similarity": 0.8436
    },
    {
      "source": "However",
      "target": "bBoetBIN2R",
      "similarity": 0.818
    },
    {
      "source": "However",
      "target": "Although existing curriculum generation approaches provide benefits in sample efficiency",
      "similarity": 0.8089
    },
    {
      "source": "However",
      "target": "2zmO1GVT0Y",
      "similarity": 0.804
    },
    {
      "source": "However",
      "target": "ByCV9xWfNK",
      "similarity": 0.8028
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.8022
    },
    {
      "source": "For an effective feature alignment in TTA for regression",
      "target": "In this paper",
      "similarity": 0.82
    },
    {
      "source": "For an effective feature alignment in TTA for regression",
      "target": "GhexuBLxbO",
      "similarity": 0.8182
    },
    {
      "source": "For an effective feature alignment in TTA for regression",
      "target": "e5mTvjXG9u",
      "similarity": 0.7864
    },
    {
      "source": "For an effective feature alignment in TTA for regression",
      "target": "R4h5PXzUuU",
      "similarity": 0.7859
    },
    {
      "source": "For an effective feature alignment in TTA for regression",
      "target": "Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically",
      "similarity": 0.782
    },
    {
      "source": "SSA consists of two components: subspace detection and dimension weighting.",
      "target": "prompts of 128K length",
      "similarity": 0.8432
    },
    {
      "source": "SSA consists of two components: subspace detection and dimension weighting.",
      "target": "xJXq6FkqEw",
      "similarity": 0.8363
    },
    {
      "source": "SSA consists of two components: subspace detection and dimension weighting.",
      "target": "ajxAJ8GUX4",
      "similarity": 0.8333
    },
    {
      "source": "SSA consists of two components: subspace detection and dimension weighting.",
      "target": "j1tSLYKwg8",
      "similarity": 0.8283
    },
    {
      "source": "SSA consists of two components: subspace detection and dimension weighting.",
      "target": "In addition",
      "similarity": 0.8235
    },
    {
      "source": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8439
    },
    {
      "source": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "target": "To overcome those challenges",
      "similarity": 0.8344
    },
    {
      "source": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.8308
    },
    {
      "source": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "target": "While this is the first precise characterization of the expected missing mass in terms of the sample",
      "similarity": 0.83
    },
    {
      "source": "Subspace detection finds the feature subspace that is representative and significant to the output.",
      "target": "4JK2XMGUc8",
      "similarity": 0.8287
    },
    {
      "source": "Then",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8608
    },
    {
      "source": "Then",
      "target": "In this paper",
      "similarity": 0.8538
    },
    {
      "source": "Then",
      "target": "Q6PAnqYVpo",
      "similarity": 0.8536
    },
    {
      "source": "Then",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8508
    },
    {
      "source": "Then",
      "target": "pDDODPtpx9",
      "similarity": 0.8474
    },
    {
      "source": "Meanwhile",
      "target": "Tn5B6Udq3E",
      "similarity": 0.849
    },
    {
      "source": "Meanwhile",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8474
    },
    {
      "source": "Meanwhile",
      "target": "bilities",
      "similarity": 0.845
    },
    {
      "source": "Meanwhile",
      "target": "tDIL7UXmSS",
      "similarity": 0.8437
    },
    {
      "source": "Meanwhile",
      "target": "BpyHIrpUOL",
      "similarity": 0.8426
    },
    {
      "source": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "target": "First",
      "similarity": 0.7981
    },
    {
      "source": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "target": "In StreamingQA",
      "similarity": 0.7968
    },
    {
      "source": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "target": "However",
      "similarity": 0.7895
    },
    {
      "source": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.7894
    },
    {
      "source": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "target": "5YbuOTUFQ4",
      "similarity": 0.7841
    },
    {
      "source": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "target": "In this paper",
      "similarity": 0.841
    },
    {
      "source": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8348
    },
    {
      "source": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8289
    },
    {
      "source": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "target": "L0evcuybH5",
      "similarity": 0.826
    },
    {
      "source": "The code is available at https://github.com/kzkadc/regression-tta.\"",
      "target": "tu3qwNjrtw",
      "similarity": 0.8257
    },
    {
      "source": "AsAy7CROLs",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.9127
    },
    {
      "source": "AsAy7CROLs",
      "target": "odU59TxdiB",
      "similarity": 0.9067
    },
    {
      "source": "AsAy7CROLs",
      "target": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "similarity": 0.8716
    },
    {
      "source": "AsAy7CROLs",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.871
    },
    {
      "source": "AsAy7CROLs",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8689
    },
    {
      "source": "2ea5TNVR0c",
      "target": "As a first step towards a better understanding",
      "similarity": 0.8665
    },
    {
      "source": "2ea5TNVR0c",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8589
    },
    {
      "source": "2ea5TNVR0c",
      "target": "ZadnlOHsHv",
      "similarity": 0.8553
    },
    {
      "source": "2ea5TNVR0c",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8543
    },
    {
      "source": "2ea5TNVR0c",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8532
    },
    {
      "source": "YOpa6dTrpt",
      "target": "EEgYUccwsV",
      "similarity": 0.7865
    },
    {
      "source": "YOpa6dTrpt",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.7862
    },
    {
      "source": "YOpa6dTrpt",
      "target": "YUYJsHOf3c",
      "similarity": 0.7861
    },
    {
      "source": "YOpa6dTrpt",
      "target": "hXm0Wu2U9K",
      "similarity": 0.7857
    },
    {
      "source": "YOpa6dTrpt",
      "target": "YcUV5apdlq",
      "similarity": 0.7846
    },
    {
      "source": "pPQPQ7Yd58",
      "target": "Ax0i933gtp",
      "similarity": 0.8822
    },
    {
      "source": "pPQPQ7Yd58",
      "target": "fXb9BbuyAD",
      "similarity": 0.8542
    },
    {
      "source": "pPQPQ7Yd58",
      "target": "jj7b3p5kLY",
      "similarity": 0.8356
    },
    {
      "source": "pPQPQ7Yd58",
      "target": "mnna9LUg7P",
      "similarity": 0.8327
    },
    {
      "source": "pPQPQ7Yd58",
      "target": "We propose the use of principal persistence measures",
      "similarity": 0.8314
    },
    {
      "source": "- In discrete image-based control (e.g.",
      "target": "se4vjm7h4E",
      "similarity": 0.8794
    },
    {
      "source": "- In discrete image-based control (e.g.",
      "target": "jTEKTdI3K9",
      "similarity": 0.8781
    },
    {
      "source": "- In discrete image-based control (e.g.",
      "target": "For example",
      "similarity": 0.8751
    },
    {
      "source": "- In discrete image-based control (e.g.",
      "target": "ue1Tt3h1VC",
      "similarity": 0.8698
    },
    {
      "source": "- In discrete image-based control (e.g.",
      "target": "To tackle this challenge",
      "similarity": 0.8698
    },
    {
      "source": "- In continuous image-based control (e.g.",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8366
    },
    {
      "source": "- In continuous image-based control (e.g.",
      "target": "xI71dsS3o4",
      "similarity": 0.8339
    },
    {
      "source": "- In continuous image-based control (e.g.",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8265
    },
    {
      "source": "- In continuous image-based control (e.g.",
      "target": "In particular",
      "similarity": 0.8254
    },
    {
      "source": "- In continuous image-based control (e.g.",
      "target": "PY56Wur7S0",
      "similarity": 0.8237
    },
    {
      "source": "Beyond empirical observation",
      "target": "bmbRCRiNDu",
      "similarity": 0.8418
    },
    {
      "source": "Beyond empirical observation",
      "target": "per subject over the entire disease development phases. The dataset consists of",
      "similarity": 0.8381
    },
    {
      "source": "Beyond empirical observation",
      "target": "eWocmTQn7H",
      "similarity": 0.8261
    },
    {
      "source": "Beyond empirical observation",
      "target": "Extending our study to production RAG models",
      "similarity": 0.8249
    },
    {
      "source": "Beyond empirical observation",
      "target": "SXtl7NRyE5",
      "similarity": 0.8191
    },
    {
      "source": "zpENPcQSj1",
      "target": "from computer vision to speech and natural language processing",
      "similarity": 0.8742
    },
    {
      "source": "zpENPcQSj1",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8627
    },
    {
      "source": "zpENPcQSj1",
      "target": "In this task",
      "similarity": 0.861
    },
    {
      "source": "zpENPcQSj1",
      "target": "rwqShzb9li",
      "similarity": 0.8604
    },
    {
      "source": "zpENPcQSj1",
      "target": "TKuYWeFE6S",
      "similarity": 0.8587
    },
    {
      "source": "kOYnXVQCtA",
      "target": "x33vSZUg0A",
      "similarity": 0.8312
    },
    {
      "source": "kOYnXVQCtA",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8046
    },
    {
      "source": "kOYnXVQCtA",
      "target": "To address this",
      "similarity": 0.8043
    },
    {
      "source": "kOYnXVQCtA",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.797
    },
    {
      "source": "kOYnXVQCtA",
      "target": "CS2JWaziYr",
      "similarity": 0.7969
    },
    {
      "source": "JY6P45sFDS",
      "target": "Reweighting (GSR)",
      "similarity": 0.8709
    },
    {
      "source": "JY6P45sFDS",
      "target": "R4q3cY3kQf",
      "similarity": 0.8622
    },
    {
      "source": "JY6P45sFDS",
      "target": "pDDODPtpx9",
      "similarity": 0.8609
    },
    {
      "source": "JY6P45sFDS",
      "target": "To this end",
      "similarity": 0.8608
    },
    {
      "source": "JY6P45sFDS",
      "target": "bilities",
      "similarity": 0.8595
    },
    {
      "source": "2mqb8bPHeb",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8934
    },
    {
      "source": "2mqb8bPHeb",
      "target": "stacking methods. Specifically",
      "similarity": 0.8896
    },
    {
      "source": "2mqb8bPHeb",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8881
    },
    {
      "source": "2mqb8bPHeb",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8785
    },
    {
      "source": "2mqb8bPHeb",
      "target": "yIlyHJdYV3",
      "similarity": 0.8773
    },
    {
      "source": "uQnvYP7yX9",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8437
    },
    {
      "source": "uQnvYP7yX9",
      "target": "K4FAFNRpko",
      "similarity": 0.8432
    },
    {
      "source": "uQnvYP7yX9",
      "target": "kxnoqaisCT",
      "similarity": 0.8417
    },
    {
      "source": "uQnvYP7yX9",
      "target": "To remedy this problem",
      "similarity": 0.8398
    },
    {
      "source": "uQnvYP7yX9",
      "target": "PwxYoMvmvy",
      "similarity": 0.837
    },
    {
      "source": "jqmptcSNVG",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8641
    },
    {
      "source": "jqmptcSNVG",
      "target": "U3PBITXNG6",
      "similarity": 0.8552
    },
    {
      "source": "jqmptcSNVG",
      "target": "Traditionally",
      "similarity": 0.8486
    },
    {
      "source": "jqmptcSNVG",
      "target": "8eNLKk5by4",
      "similarity": 0.8439
    },
    {
      "source": "jqmptcSNVG",
      "target": "More broadly",
      "similarity": 0.8402
    },
    {
      "source": "To address these challenges",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8399
    },
    {
      "source": "To address these challenges",
      "target": "l0fn10vSyM",
      "similarity": 0.8333
    },
    {
      "source": "To address these challenges",
      "target": "Aly68Y5Es0",
      "similarity": 0.8313
    },
    {
      "source": "To address these challenges",
      "target": "Second",
      "similarity": 0.8258
    },
    {
      "source": "To address these challenges",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8254
    },
    {
      "source": "By combining hot spot sampling with fragment-based extension",
      "target": "We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata.",
      "similarity": 0.8279
    },
    {
      "source": "By combining hot spot sampling with fragment-based extension",
      "target": "h1XoHOd19I",
      "similarity": 0.807
    },
    {
      "source": "By combining hot spot sampling with fragment-based extension",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.802
    },
    {
      "source": "By combining hot spot sampling with fragment-based extension",
      "target": "However",
      "similarity": 0.8
    },
    {
      "source": "By combining hot spot sampling with fragment-based extension",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.7995
    },
    {
      "source": "6qUUgw9bAZ",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.7942
    },
    {
      "source": "6qUUgw9bAZ",
      "target": "Our model achieves better accuracy and generalization than fully neural alternatives",
      "similarity": 0.7921
    },
    {
      "source": "6qUUgw9bAZ",
      "target": "bc3sUsS6ck",
      "similarity": 0.7897
    },
    {
      "source": "6qUUgw9bAZ",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.7821
    },
    {
      "source": "6qUUgw9bAZ",
      "target": "ANBuEJesgx",
      "similarity": 0.7759
    },
    {
      "source": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8353
    },
    {
      "source": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "target": "cation",
      "similarity": 0.8314
    },
    {
      "source": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8166
    },
    {
      "source": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "target": "D2hhkU5O48",
      "similarity": 0.8156
    },
    {
      "source": "Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively",
      "target": "objects to benchmark progress. Our findings show that CADCodeVerify improves",
      "similarity": 0.8138
    },
    {
      "source": "7LGmXXZXtP",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8605
    },
    {
      "source": "7LGmXXZXtP",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8587
    },
    {
      "source": "7LGmXXZXtP",
      "target": "Despite theoretically sound",
      "similarity": 0.8518
    },
    {
      "source": "7LGmXXZXtP",
      "target": "tu3qwNjrtw",
      "similarity": 0.8494
    },
    {
      "source": "7LGmXXZXtP",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8407
    },
    {
      "source": "Drawing on findings from cognitive science about representativeness heuristics",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8659
    },
    {
      "source": "Drawing on findings from cognitive science about representativeness heuristics",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8612
    },
    {
      "source": "Drawing on findings from cognitive science about representativeness heuristics",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8555
    },
    {
      "source": "Drawing on findings from cognitive science about representativeness heuristics",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8536
    },
    {
      "source": "Drawing on findings from cognitive science about representativeness heuristics",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8523
    },
    {
      "source": "N4rYbQowE3",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8468
    },
    {
      "source": "N4rYbQowE3",
      "target": "This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g.",
      "similarity": 0.8347
    },
    {
      "source": "N4rYbQowE3",
      "target": "KAIqwkB3dT",
      "similarity": 0.8343
    },
    {
      "source": "N4rYbQowE3",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8309
    },
    {
      "source": "N4rYbQowE3",
      "target": "By leveraging online data collection",
      "similarity": 0.8284
    },
    {
      "source": "TWnUgSAWNw",
      "target": "To this end",
      "similarity": 0.8576
    },
    {
      "source": "TWnUgSAWNw",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8469
    },
    {
      "source": "TWnUgSAWNw",
      "target": "VQwI055flA",
      "similarity": 0.8447
    },
    {
      "source": "TWnUgSAWNw",
      "target": "To overcome these limitations",
      "similarity": 0.8407
    },
    {
      "source": "TWnUgSAWNw",
      "target": "n34taxF0TC",
      "similarity": 0.8401
    },
    {
      "source": "x1An5a3U9I",
      "target": "MBBRHDuiwM",
      "similarity": 0.8459
    },
    {
      "source": "x1An5a3U9I",
      "target": "4es2oO9tw1",
      "similarity": 0.8459
    },
    {
      "source": "x1An5a3U9I",
      "target": "m8yby1JfbU",
      "similarity": 0.84
    },
    {
      "source": "x1An5a3U9I",
      "target": "uHLgDEgiS5",
      "similarity": 0.8391
    },
    {
      "source": "x1An5a3U9I",
      "target": "AoIKgHu9Si",
      "similarity": 0.8285
    },
    {
      "source": "bounded ranges",
      "target": "AD5yx2xq8R",
      "similarity": 0.8397
    },
    {
      "source": "bounded ranges",
      "target": "EditRoom-DB",
      "similarity": 0.8253
    },
    {
      "source": "bounded ranges",
      "target": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "similarity": 0.8237
    },
    {
      "source": "bounded ranges",
      "target": "FrFQpAgnGE",
      "similarity": 0.8232
    },
    {
      "source": "bounded ranges",
      "target": "2mqb8bPHeb",
      "similarity": 0.8214
    },
    {
      "source": "SWEqzy7IQB",
      "target": "semTHoVGsJ",
      "similarity": 0.8434
    },
    {
      "source": "SWEqzy7IQB",
      "target": "uZgK0tcPqd",
      "similarity": 0.833
    },
    {
      "source": "SWEqzy7IQB",
      "target": "To enhance the domain adaptation of LLMs",
      "similarity": 0.8319
    },
    {
      "source": "SWEqzy7IQB",
      "target": "prompts of 128K length",
      "similarity": 0.8281
    },
    {
      "source": "SWEqzy7IQB",
      "target": "of natural language. However",
      "similarity": 0.8274
    },
    {
      "source": "htDczodFN5",
      "target": "oP7arLOWix",
      "similarity": 0.8532
    },
    {
      "source": "htDczodFN5",
      "target": "6GATHdOi1x",
      "similarity": 0.8464
    },
    {
      "source": "htDczodFN5",
      "target": "Qja5s0K3VX",
      "similarity": 0.8454
    },
    {
      "source": "htDczodFN5",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8442
    },
    {
      "source": "htDczodFN5",
      "target": "u2QdCiOgwA",
      "similarity": 0.8435
    },
    {
      "source": "yj9lLwMjnE",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8404
    },
    {
      "source": "yj9lLwMjnE",
      "target": "To this end",
      "similarity": 0.8381
    },
    {
      "source": "yj9lLwMjnE",
      "target": "iOMnn1hSBO",
      "similarity": 0.8375
    },
    {
      "source": "yj9lLwMjnE",
      "target": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "similarity": 0.8315
    },
    {
      "source": "yj9lLwMjnE",
      "target": "VQwI055flA",
      "similarity": 0.8271
    },
    {
      "source": "9GsgCUJtic",
      "target": "GhexuBLxbO",
      "similarity": 0.7844
    },
    {
      "source": "9GsgCUJtic",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.7823
    },
    {
      "source": "9GsgCUJtic",
      "target": "lXRDQsiP2v",
      "similarity": 0.7706
    },
    {
      "source": "9GsgCUJtic",
      "target": "5btFIv2PNb",
      "similarity": 0.766
    },
    {
      "source": "9GsgCUJtic",
      "target": "1ExfUpmIW4",
      "similarity": 0.7611
    },
    {
      "source": "NDLmZZWATc",
      "target": "We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.\"",
      "similarity": 0.8805
    },
    {
      "source": "NDLmZZWATc",
      "target": "Moreover",
      "similarity": 0.8748
    },
    {
      "source": "NDLmZZWATc",
      "target": "With regards to improving Shampoo's computational efficiency",
      "similarity": 0.8628
    },
    {
      "source": "NDLmZZWATc",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.856
    },
    {
      "source": "NDLmZZWATc",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8554
    },
    {
      "source": "To supplement the text information in VLM trained on correlations with vision data",
      "target": "D2hhkU5O48",
      "similarity": 0.8135
    },
    {
      "source": "To supplement the text information in VLM trained on correlations with vision data",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8033
    },
    {
      "source": "To supplement the text information in VLM trained on correlations with vision data",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8024
    },
    {
      "source": "To supplement the text information in VLM trained on correlations with vision data",
      "target": "The code supporting this library is a public",
      "similarity": 0.7975
    },
    {
      "source": "To supplement the text information in VLM trained on correlations with vision data",
      "target": "wgDB1QuxIA",
      "similarity": 0.7937
    },
    {
      "source": "Existing methods typically extract text-based responses (i.e.",
      "target": "YcUV5apdlq",
      "similarity": 0.8653
    },
    {
      "source": "Existing methods typically extract text-based responses (i.e.",
      "target": "nrvoWOWcyg",
      "similarity": 0.822
    },
    {
      "source": "Existing methods typically extract text-based responses (i.e.",
      "target": "ULGbw2URE3",
      "similarity": 0.8192
    },
    {
      "source": "Existing methods typically extract text-based responses (i.e.",
      "target": "WJaUkwci9o",
      "similarity": 0.8192
    },
    {
      "source": "Existing methods typically extract text-based responses (i.e.",
      "target": "In this work",
      "similarity": 0.8163
    },
    {
      "source": "In this work",
      "target": "J9FgrqOOni",
      "similarity": 0.8904
    },
    {
      "source": "In this work",
      "target": "LqTz13JS2P",
      "similarity": 0.8651
    },
    {
      "source": "In this work",
      "target": "PQpvhUrA1C",
      "similarity": 0.8574
    },
    {
      "source": "In this work",
      "target": "To this end",
      "similarity": 0.8553
    },
    {
      "source": "In this work",
      "target": "oYemKnlIrO",
      "similarity": 0.8535
    },
    {
      "source": "By adopting a description-free approach",
      "target": "1qGkuxI9UX",
      "similarity": 0.8493
    },
    {
      "source": "By adopting a description-free approach",
      "target": "Our method not only corrects this issue but also improves the results for privately finding an SOSP",
      "similarity": 0.8384
    },
    {
      "source": "By adopting a description-free approach",
      "target": "46xYl55hdc",
      "similarity": 0.8363
    },
    {
      "source": "By adopting a description-free approach",
      "target": "and a 10.3% decrease in VisualWebArena tasks. Our work highlights performance",
      "similarity": 0.8286
    },
    {
      "source": "By adopting a description-free approach",
      "target": "d7pr2doXn3",
      "similarity": 0.828
    },
    {
      "source": "Additionally",
      "target": "we address this problem by using a small amount of labeled sensitive data.",
      "similarity": 0.7751
    },
    {
      "source": "Additionally",
      "target": "ii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks",
      "similarity": 0.7648
    },
    {
      "source": "Additionally",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.7576
    },
    {
      "source": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "target": "purpose optimization algorithm with minimal assumptions.\"",
      "similarity": 0.8285
    },
    {
      "source": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "target": "sivity and potential training instabilities due to vanishing gradients. Empirical ev-",
      "similarity": 0.817
    },
    {
      "source": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "target": "component of real-world software development.\"",
      "similarity": 0.8086
    },
    {
      "source": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "target": "To address this",
      "similarity": 0.8065
    },
    {
      "source": "Experimental results show that our approach achieves superior performance across 11 recognition datasets.\"",
      "target": "tnB94WQGrn",
      "similarity": 0.8048
    },
    {
      "source": "ue1Tt3h1VC",
      "target": "jTEKTdI3K9",
      "similarity": 0.881
    },
    {
      "source": "ue1Tt3h1VC",
      "target": "JSB171dSUU",
      "similarity": 0.8731
    },
    {
      "source": "ue1Tt3h1VC",
      "target": "Nonnegative Decision Layer (BNDL)",
      "similarity": 0.8698
    },
    {
      "source": "ue1Tt3h1VC",
      "target": "Essg9kb4yx",
      "similarity": 0.8677
    },
    {
      "source": "ue1Tt3h1VC",
      "target": "se4vjm7h4E",
      "similarity": 0.8639
    },
    {
      "source": "XRtyVELwr6",
      "target": "oYemKnlIrO",
      "similarity": 0.8432
    },
    {
      "source": "XRtyVELwr6",
      "target": "To this end",
      "similarity": 0.8342
    },
    {
      "source": "XRtyVELwr6",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8308
    },
    {
      "source": "XRtyVELwr6",
      "target": "XmProj9cPs",
      "similarity": 0.8302
    },
    {
      "source": "XRtyVELwr6",
      "target": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "similarity": 0.8291
    },
    {
      "source": "slO3xTt4CG",
      "target": "60GeEoG5kD",
      "similarity": 0.834
    },
    {
      "source": "slO3xTt4CG",
      "target": "GTcEe5fayC",
      "similarity": 0.8306
    },
    {
      "source": "slO3xTt4CG",
      "target": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "similarity": 0.8219
    },
    {
      "source": "slO3xTt4CG",
      "target": "We believe this demonstrates the feasibility of large scale",
      "similarity": 0.8194
    },
    {
      "source": "slO3xTt4CG",
      "target": "wkbx7BRAsM",
      "similarity": 0.812
    },
    {
      "source": "aTYexOYlLb",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8632
    },
    {
      "source": "aTYexOYlLb",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.8348
    },
    {
      "source": "aTYexOYlLb",
      "target": "GySIAKEwtZ",
      "similarity": 0.8282
    },
    {
      "source": "aTYexOYlLb",
      "target": "However",
      "similarity": 0.8272
    },
    {
      "source": "aTYexOYlLb",
      "target": "Our novel resource",
      "similarity": 0.8243
    },
    {
      "source": "jTEKTdI3K9",
      "target": "se4vjm7h4E",
      "similarity": 0.9
    },
    {
      "source": "jTEKTdI3K9",
      "target": "while ensuring safety during learning.\"",
      "similarity": 0.8769
    },
    {
      "source": "jTEKTdI3K9",
      "target": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "similarity": 0.8677
    },
    {
      "source": "jTEKTdI3K9",
      "target": "To tackle this challenge",
      "similarity": 0.8663
    },
    {
      "source": "jTEKTdI3K9",
      "target": "09FiNmvNMw",
      "similarity": 0.8491
    },
    {
      "source": "as well as the cross-modal matching and reasoning abilities of these models. Our results reveal that most existing audio-visual LLMs struggle with hallucinations caused by cross-interactions between modalities",
      "target": "We found that long distance referrals",
      "similarity": 0.8526
    },
    {
      "source": "as well as the cross-modal matching and reasoning abilities of these models. Our results reveal that most existing audio-visual LLMs struggle with hallucinations caused by cross-interactions between modalities",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8282
    },
    {
      "source": "as well as the cross-modal matching and reasoning abilities of these models. Our results reveal that most existing audio-visual LLMs struggle with hallucinations caused by cross-interactions between modalities",
      "target": "However",
      "similarity": 0.8265
    },
    {
      "source": "as well as the cross-modal matching and reasoning abilities of these models. Our results reveal that most existing audio-visual LLMs struggle with hallucinations caused by cross-interactions between modalities",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8134
    },
    {
      "source": "as well as the cross-modal matching and reasoning abilities of these models. Our results reveal that most existing audio-visual LLMs struggle with hallucinations caused by cross-interactions between modalities",
      "target": "JbRM5QKRDd",
      "similarity": 0.8106
    },
    {
      "source": "eb5pkwIB5i",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8362
    },
    {
      "source": "eb5pkwIB5i",
      "target": "AoIKgHu9Si",
      "similarity": 0.8329
    },
    {
      "source": "eb5pkwIB5i",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.8285
    },
    {
      "source": "eb5pkwIB5i",
      "target": "To address this limitation",
      "similarity": 0.8201
    },
    {
      "source": "eb5pkwIB5i",
      "target": "However",
      "similarity": 0.8004
    },
    {
      "source": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "target": "Ultimately",
      "similarity": 0.8795
    },
    {
      "source": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "target": "Es4RPNDtmq",
      "similarity": 0.8744
    },
    {
      "source": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.866
    },
    {
      "source": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "target": "LNL7zKvm7e",
      "similarity": 0.8635
    },
    {
      "source": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "target": "potential algorithms to solve one task",
      "similarity": 0.8622
    },
    {
      "source": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8786
    },
    {
      "source": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "target": "VQwI055flA",
      "similarity": 0.8726
    },
    {
      "source": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "target": "uxVBbSlKQ4",
      "similarity": 0.872
    },
    {
      "source": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "target": "WCRQFlji2q",
      "similarity": 0.8717
    },
    {
      "source": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8716
    },
    {
      "source": "In experiments with GPT-4",
      "target": "nibeaHUEJx",
      "similarity": 0.8499
    },
    {
      "source": "In experiments with GPT-4",
      "target": "S1Bv3068Xt",
      "similarity": 0.8467
    },
    {
      "source": "In experiments with GPT-4",
      "target": "To this end",
      "similarity": 0.8415
    },
    {
      "source": "In experiments with GPT-4",
      "target": "zg3ec1TdAP",
      "similarity": 0.8395
    },
    {
      "source": "In experiments with GPT-4",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8382
    },
    {
      "source": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8703
    },
    {
      "source": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "target": "EyaH1wzmao",
      "similarity": 0.8571
    },
    {
      "source": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "target": "Second",
      "similarity": 0.8527
    },
    {
      "source": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "target": "VoayJihXra",
      "similarity": 0.8519
    },
    {
      "source": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "target": "In this paper",
      "similarity": 0.8508
    },
    {
      "source": "IDJUscOjM3",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8704
    },
    {
      "source": "IDJUscOjM3",
      "target": "Pujt3ADZgI",
      "similarity": 0.8639
    },
    {
      "source": "IDJUscOjM3",
      "target": "pDDODPtpx9",
      "similarity": 0.8635
    },
    {
      "source": "IDJUscOjM3",
      "target": "instructions",
      "similarity": 0.8609
    },
    {
      "source": "IDJUscOjM3",
      "target": "The databases in Spider 2.0 are sourced from real data applications",
      "similarity": 0.8599
    },
    {
      "source": "jckKNzYYA6",
      "target": "However",
      "similarity": 0.8397
    },
    {
      "source": "jckKNzYYA6",
      "target": "Our extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.",
      "similarity": 0.8187
    },
    {
      "source": "jckKNzYYA6",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8167
    },
    {
      "source": "jckKNzYYA6",
      "target": "ykuc5q381b",
      "similarity": 0.8164
    },
    {
      "source": "jckKNzYYA6",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8144
    },
    {
      "source": "FrFQpAgnGE",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.93
    },
    {
      "source": "FrFQpAgnGE",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8896
    },
    {
      "source": "FrFQpAgnGE",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8866
    },
    {
      "source": "FrFQpAgnGE",
      "target": "Oxpkn0YLG1",
      "similarity": 0.886
    },
    {
      "source": "FrFQpAgnGE",
      "target": "Furthermore",
      "similarity": 0.8806
    },
    {
      "source": "hOELrZfg0J",
      "target": "instances compared to 6% for the next best system.\"",
      "similarity": 0.8333
    },
    {
      "source": "hOELrZfg0J",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.832
    },
    {
      "source": "hOELrZfg0J",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8162
    },
    {
      "source": "hOELrZfg0J",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8153
    },
    {
      "source": "hOELrZfg0J",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.8123
    },
    {
      "source": "1DVgysiIt7",
      "target": "To bridge this gap",
      "similarity": 0.8085
    },
    {
      "source": "1DVgysiIt7",
      "target": "FPQzXME9NK",
      "similarity": 0.7936
    },
    {
      "source": "1DVgysiIt7",
      "target": "Taking sparse RGB images as input",
      "similarity": 0.7903
    },
    {
      "source": "1DVgysiIt7",
      "target": "1yJP5TVWih",
      "similarity": 0.7892
    },
    {
      "source": "1DVgysiIt7",
      "target": "HZgZrtIreg",
      "similarity": 0.7886
    },
    {
      "source": "ZSdubdbOoi",
      "target": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "similarity": 0.8159
    },
    {
      "source": "ZSdubdbOoi",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8026
    },
    {
      "source": "ZSdubdbOoi",
      "target": "rakhNY32vw",
      "similarity": 0.8002
    },
    {
      "source": "ZSdubdbOoi",
      "target": "JytL2MrlLT",
      "similarity": 0.7996
    },
    {
      "source": "ZSdubdbOoi",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.796
    },
    {
      "source": "PxlfzEePC0",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8629
    },
    {
      "source": "PxlfzEePC0",
      "target": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "similarity": 0.8489
    },
    {
      "source": "PxlfzEePC0",
      "target": "However",
      "similarity": 0.8414
    },
    {
      "source": "PxlfzEePC0",
      "target": "We start by showing numerically that several variants used in practice",
      "similarity": 0.8383
    },
    {
      "source": "PxlfzEePC0",
      "target": "Thus",
      "similarity": 0.8371
    },
    {
      "source": "CkgKSqZbuC",
      "target": "nfKfAzkiez",
      "similarity": 0.8345
    },
    {
      "source": "CkgKSqZbuC",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8268
    },
    {
      "source": "CkgKSqZbuC",
      "target": "P6IVIoGRRg",
      "similarity": 0.8143
    },
    {
      "source": "CkgKSqZbuC",
      "target": "NKotdPUc3L",
      "similarity": 0.8035
    },
    {
      "source": "CkgKSqZbuC",
      "target": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "similarity": 0.802
    },
    {
      "source": "To address these limitations",
      "target": "AnL6BuWzxa",
      "similarity": 0.8491
    },
    {
      "source": "To address these limitations",
      "target": "To address this issue",
      "similarity": 0.8163
    },
    {
      "source": "To address these limitations",
      "target": "1H90Gb9rJ9",
      "similarity": 0.8106
    },
    {
      "source": "To address these limitations",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8102
    },
    {
      "source": "To address these limitations",
      "target": "qZEdmyqCHF",
      "similarity": 0.8091
    },
    {
      "source": "We then encode safety knowledge among different categories as first-order logical rules and embed them into a probabilistic graphic model (PGM) based reasoning component. The unsafety probabilities of different categories from data-driven guardrail models are sent to the reasoning component for final inference. We employ two types of PGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs)",
      "target": "spDUv05cEq",
      "similarity": 0.8122
    },
    {
      "source": "We then encode safety knowledge among different categories as first-order logical rules and embed them into a probabilistic graphic model (PGM) based reasoning component. The unsafety probabilities of different categories from data-driven guardrail models are sent to the reasoning component for final inference. We employ two types of PGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs)",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8002
    },
    {
      "source": "We then encode safety knowledge among different categories as first-order logical rules and embed them into a probabilistic graphic model (PGM) based reasoning component. The unsafety probabilities of different categories from data-driven guardrail models are sent to the reasoning component for final inference. We employ two types of PGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs)",
      "target": "zXCnIyX9MG",
      "similarity": 0.7955
    },
    {
      "source": "We then encode safety knowledge among different categories as first-order logical rules and embed them into a probabilistic graphic model (PGM) based reasoning component. The unsafety probabilities of different categories from data-driven guardrail models are sent to the reasoning component for final inference. We employ two types of PGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs)",
      "target": "Code",
      "similarity": 0.7894
    },
    {
      "source": "We then encode safety knowledge among different categories as first-order logical rules and embed them into a probabilistic graphic model (PGM) based reasoning component. The unsafety probabilities of different categories from data-driven guardrail models are sent to the reasoning component for final inference. We employ two types of PGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs)",
      "target": "Building on these insights",
      "similarity": 0.7865
    },
    {
      "source": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8348
    },
    {
      "source": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "target": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "similarity": 0.8337
    },
    {
      "source": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "target": "Instruct",
      "similarity": 0.8322
    },
    {
      "source": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8318
    },
    {
      "source": "We further reveal that $R^2$-Guard can effectively adapt to safety category updates by simply editing the PGM reasoning graph.\"",
      "target": "Second",
      "similarity": 0.8304
    },
    {
      "source": "G328D1xt4W",
      "target": "reZKq6hjOZ",
      "similarity": 0.8939
    },
    {
      "source": "G328D1xt4W",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.841
    },
    {
      "source": "G328D1xt4W",
      "target": "Subsequently",
      "similarity": 0.8401
    },
    {
      "source": "G328D1xt4W",
      "target": "A1HhtITVEi",
      "similarity": 0.8392
    },
    {
      "source": "G328D1xt4W",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8379
    },
    {
      "source": "tijmpS9Vy2",
      "target": "To overcome such limitations",
      "similarity": 0.8485
    },
    {
      "source": "tijmpS9Vy2",
      "target": "TYSQYx9vwd",
      "similarity": 0.8453
    },
    {
      "source": "tijmpS9Vy2",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8449
    },
    {
      "source": "tijmpS9Vy2",
      "target": "Discoveries of such relations",
      "similarity": 0.841
    },
    {
      "source": "tijmpS9Vy2",
      "target": "rCX9l4OTCT",
      "similarity": 0.8376
    },
    {
      "source": "oP7arLOWix",
      "target": "Using this extension",
      "similarity": 0.9076
    },
    {
      "source": "oP7arLOWix",
      "target": "previous results.\"",
      "similarity": 0.8679
    },
    {
      "source": "oP7arLOWix",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8643
    },
    {
      "source": "oP7arLOWix",
      "target": "To this end",
      "similarity": 0.8626
    },
    {
      "source": "oP7arLOWix",
      "target": "training data. Equipped with these findings",
      "similarity": 0.8626
    },
    {
      "source": "Aye5wL6TCn",
      "target": "1F8xTfv6ah",
      "similarity": 0.8487
    },
    {
      "source": "Aye5wL6TCn",
      "target": "aKkDY1Wca0",
      "similarity": 0.8462
    },
    {
      "source": "Aye5wL6TCn",
      "target": "Beyond performance evaluations",
      "similarity": 0.8423
    },
    {
      "source": "Aye5wL6TCn",
      "target": "P6IVIoGRRg",
      "similarity": 0.8355
    },
    {
      "source": "Aye5wL6TCn",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8324
    },
    {
      "source": "frsg32u0rO",
      "target": "Q150eWkQ4I",
      "similarity": 0.841
    },
    {
      "source": "frsg32u0rO",
      "target": "This paper proposes",
      "similarity": 0.8404
    },
    {
      "source": "frsg32u0rO",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8248
    },
    {
      "source": "frsg32u0rO",
      "target": "ples. To our knowledge",
      "similarity": 0.8246
    },
    {
      "source": "frsg32u0rO",
      "target": "qykpnEWf2J",
      "similarity": 0.8182
    },
    {
      "source": "Empirically",
      "target": "This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries.",
      "similarity": 0.7833
    },
    {
      "source": "Empirically",
      "target": "Ij9ilPh36h",
      "similarity": 0.7817
    },
    {
      "source": "Empirically",
      "target": "Although this approach simplifies data acquisition compared to supervised methods",
      "similarity": 0.7804
    },
    {
      "source": "Empirically",
      "target": "x$",
      "similarity": 0.7787
    },
    {
      "source": "Empirically",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.777
    },
    {
      "source": "Given that block verification does not increase code complexity",
      "target": "To meet real-time requirements and balance multi-task learning",
      "similarity": 0.7941
    },
    {
      "source": "Given that block verification does not increase code complexity",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.7882
    },
    {
      "source": "Given that block verification does not increase code complexity",
      "target": "For example",
      "similarity": 0.7858
    },
    {
      "source": "Given that block verification does not increase code complexity",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.7823
    },
    {
      "source": "Given that block verification does not increase code complexity",
      "target": "txV4dNeusx",
      "similarity": 0.7771
    },
    {
      "source": "bcTjW5kS4W",
      "target": "4A9IdSa1ul",
      "similarity": 0.8534
    },
    {
      "source": "bcTjW5kS4W",
      "target": "msEr27EejF",
      "similarity": 0.8434
    },
    {
      "source": "bcTjW5kS4W",
      "target": "https://github.com/OceannTwT/Tool-Planner.\"",
      "similarity": 0.8417
    },
    {
      "source": "bcTjW5kS4W",
      "target": "oYemKnlIrO",
      "similarity": 0.8367
    },
    {
      "source": "bcTjW5kS4W",
      "target": "Jyh0DR4fFE",
      "similarity": 0.8361
    },
    {
      "source": "nx9Z5Kva96",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8844
    },
    {
      "source": "nx9Z5Kva96",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8812
    },
    {
      "source": "nx9Z5Kva96",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8709
    },
    {
      "source": "nx9Z5Kva96",
      "target": "2mqb8bPHeb",
      "similarity": 0.8677
    },
    {
      "source": "nx9Z5Kva96",
      "target": "yIlyHJdYV3",
      "similarity": 0.8652
    },
    {
      "source": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "target": "pRCOZllZdT",
      "similarity": 0.8576
    },
    {
      "source": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "target": "v1rFkElnIn",
      "similarity": 0.8558
    },
    {
      "source": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "target": "Existing techniques for solving such inverse problems rely on traditional optimization methods",
      "similarity": 0.8548
    },
    {
      "source": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "target": "This approximation may be undesirable as all information from the vector quantization operation is lost.",
      "similarity": 0.8544
    },
    {
      "source": "This work offers new insights into understanding and advancing SFDA performance.\"",
      "target": "while ensuring safety during learning.\"",
      "similarity": 0.8532
    },
    {
      "source": "UYcUpiULmT",
      "target": "ULorFBST6X",
      "similarity": 0.8775
    },
    {
      "source": "UYcUpiULmT",
      "target": "Ian00SaFHg",
      "similarity": 0.8466
    },
    {
      "source": "UYcUpiULmT",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.842
    },
    {
      "source": "UYcUpiULmT",
      "target": "fXb9BbuyAD",
      "similarity": 0.8402
    },
    {
      "source": "UYcUpiULmT",
      "target": "mnna9LUg7P",
      "similarity": 0.8388
    },
    {
      "source": "space",
      "target": "uSz2K30RRd",
      "similarity": 0.8443
    },
    {
      "source": "space",
      "target": "ptjrpEGrGg",
      "similarity": 0.8405
    },
    {
      "source": "space",
      "target": "F5R0lG74Tu",
      "similarity": 0.838
    },
    {
      "source": "space",
      "target": "tQ1PmLfPBL",
      "similarity": 0.834
    },
    {
      "source": "space",
      "target": "In this paper",
      "similarity": 0.8294
    },
    {
      "source": "function predictors on 3D scenes from the iGibson building dataset and showcase optimal planning with 4-joint robotic manipulators. Lastly",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8277
    },
    {
      "source": "function predictors on 3D scenes from the iGibson building dataset and showcase optimal planning with 4-joint robotic manipulators. Lastly",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.825
    },
    {
      "source": "function predictors on 3D scenes from the iGibson building dataset and showcase optimal planning with 4-joint robotic manipulators. Lastly",
      "target": "5xwx1Myosu",
      "similarity": 0.8225
    },
    {
      "source": "function predictors on 3D scenes from the iGibson building dataset and showcase optimal planning with 4-joint robotic manipulators. Lastly",
      "target": "KlV5CkNQkl",
      "similarity": 0.8183
    },
    {
      "source": "function predictors on 3D scenes from the iGibson building dataset and showcase optimal planning with 4-joint robotic manipulators. Lastly",
      "target": "28abpUEICJ",
      "similarity": 0.8175
    },
    {
      "source": "XMgpnZ2ET7",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8572
    },
    {
      "source": "XMgpnZ2ET7",
      "target": "5pd78GmXC6",
      "similarity": 0.8383
    },
    {
      "source": "XMgpnZ2ET7",
      "target": "the costliness of the labels",
      "similarity": 0.8343
    },
    {
      "source": "XMgpnZ2ET7",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8333
    },
    {
      "source": "XMgpnZ2ET7",
      "target": "Aye5wL6TCn",
      "similarity": 0.8287
    },
    {
      "source": "SG1R2H3fa1",
      "target": "FrFQpAgnGE",
      "similarity": 0.8339
    },
    {
      "source": "SG1R2H3fa1",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8323
    },
    {
      "source": "SG1R2H3fa1",
      "target": "Second",
      "similarity": 0.8321
    },
    {
      "source": "SG1R2H3fa1",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8315
    },
    {
      "source": "SG1R2H3fa1",
      "target": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "similarity": 0.8309
    },
    {
      "source": "9vTAkJ9Tik",
      "target": "6DHIkLv5i3",
      "similarity": 0.7854
    },
    {
      "source": "9vTAkJ9Tik",
      "target": "ANBuEJesgx",
      "similarity": 0.7831
    },
    {
      "source": "9vTAkJ9Tik",
      "target": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "similarity": 0.7777
    },
    {
      "source": "9vTAkJ9Tik",
      "target": "logical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence",
      "similarity": 0.7774
    },
    {
      "source": "9vTAkJ9Tik",
      "target": "samples. However",
      "similarity": 0.7752
    },
    {
      "source": "While it is possible to correct for biases if the underlying causal graph is known",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8585
    },
    {
      "source": "While it is possible to correct for biases if the underlying causal graph is known",
      "target": "meKEKDhdnx",
      "similarity": 0.8567
    },
    {
      "source": "While it is possible to correct for biases if the underlying causal graph is known",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8551
    },
    {
      "source": "While it is possible to correct for biases if the underlying causal graph is known",
      "target": "To tackle this challenge",
      "similarity": 0.8525
    },
    {
      "source": "While it is possible to correct for biases if the underlying causal graph is known",
      "target": "tu3qwNjrtw",
      "similarity": 0.8517
    },
    {
      "source": "We propose RAMEN",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8524
    },
    {
      "source": "We propose RAMEN",
      "target": "IuU0wcO0mo",
      "similarity": 0.8386
    },
    {
      "source": "We propose RAMEN",
      "target": "For TP",
      "similarity": 0.8377
    },
    {
      "source": "We propose RAMEN",
      "target": "Using this approach",
      "similarity": 0.8353
    },
    {
      "source": "We propose RAMEN",
      "target": "LLMs. Interestingly",
      "similarity": 0.8317
    },
    {
      "source": "by leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably",
      "target": "HqjRlT65WX",
      "similarity": 0.8231
    },
    {
      "source": "by leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably",
      "target": "OuLgaHEmzi",
      "similarity": 0.8049
    },
    {
      "source": "by leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably",
      "target": "rTQNGQxm4K",
      "similarity": 0.8048
    },
    {
      "source": "by leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably",
      "target": "8y5Uf6oEiB",
      "similarity": 0.8019
    },
    {
      "source": "by leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably",
      "target": "cPD2hU35x3",
      "similarity": 0.8013
    },
    {
      "source": "the causal parents of the treatment or those of the outcome are observed",
      "target": "IQxBDLmVpT",
      "similarity": 0.8551
    },
    {
      "source": "the causal parents of the treatment or those of the outcome are observed",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8499
    },
    {
      "source": "the causal parents of the treatment or those of the outcome are observed",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8487
    },
    {
      "source": "the causal parents of the treatment or those of the outcome are observed",
      "target": "dEg5SdGaiq",
      "similarity": 0.8436
    },
    {
      "source": "the causal parents of the treatment or those of the outcome are observed",
      "target": "1Njl73JKjB",
      "similarity": 0.8401
    },
    {
      "source": "1vrpdV9U3i",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8697
    },
    {
      "source": "1vrpdV9U3i",
      "target": "IuU0wcO0mo",
      "similarity": 0.8486
    },
    {
      "source": "1vrpdV9U3i",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8472
    },
    {
      "source": "1vrpdV9U3i",
      "target": "dAeET8gxqg",
      "similarity": 0.847
    },
    {
      "source": "1vrpdV9U3i",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8444
    },
    {
      "source": "2c7pfOqu9k",
      "target": "PwxYoMvmvy",
      "similarity": 0.8374
    },
    {
      "source": "2c7pfOqu9k",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8364
    },
    {
      "source": "2c7pfOqu9k",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8285
    },
    {
      "source": "2c7pfOqu9k",
      "target": "OuLgaHEmzi",
      "similarity": 0.8266
    },
    {
      "source": "2c7pfOqu9k",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8248
    },
    {
      "source": "77gQUdQhE7",
      "target": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "similarity": 0.7971
    },
    {
      "source": "77gQUdQhE7",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.7859
    },
    {
      "source": "77gQUdQhE7",
      "target": "Stick-breaking also performs well at length generalisation",
      "similarity": 0.7837
    },
    {
      "source": "77gQUdQhE7",
      "target": "To systematically evaluate MLLMs' oversensitivity to these stimuli",
      "similarity": 0.7773
    },
    {
      "source": "77gQUdQhE7",
      "target": "Then",
      "similarity": 0.7763
    },
    {
      "source": "skGSOcrIj7",
      "target": "Existing training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions",
      "similarity": 0.8476
    },
    {
      "source": "skGSOcrIj7",
      "target": "HqjRlT65WX",
      "similarity": 0.8437
    },
    {
      "source": "skGSOcrIj7",
      "target": "YvKJGYL4j7",
      "similarity": 0.8387
    },
    {
      "source": "skGSOcrIj7",
      "target": "rTQNGQxm4K",
      "similarity": 0.8372
    },
    {
      "source": "skGSOcrIj7",
      "target": "We then propose deep Fourier features",
      "similarity": 0.8328
    },
    {
      "source": "S4dItvpvAv",
      "target": "implementation",
      "similarity": 0.8261
    },
    {
      "source": "S4dItvpvAv",
      "target": "In addition",
      "similarity": 0.8129
    },
    {
      "source": "S4dItvpvAv",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.8046
    },
    {
      "source": "S4dItvpvAv",
      "target": "This corresponds to",
      "similarity": 0.8001
    },
    {
      "source": "S4dItvpvAv",
      "target": "gsShHPxkUW",
      "similarity": 0.7985
    },
    {
      "source": "The Pareto front identifies the set of policies that cannot be dominated",
      "target": "bMC1t7eLRc",
      "similarity": 0.8741
    },
    {
      "source": "The Pareto front identifies the set of policies that cannot be dominated",
      "target": "4ktJJBvvUd",
      "similarity": 0.846
    },
    {
      "source": "The Pareto front identifies the set of policies that cannot be dominated",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8415
    },
    {
      "source": "The Pareto front identifies the set of policies that cannot be dominated",
      "target": "Ahlrf2HGJR",
      "similarity": 0.8414
    },
    {
      "source": "The Pareto front identifies the set of policies that cannot be dominated",
      "target": "Furthermore",
      "similarity": 0.8373
    },
    {
      "source": "However",
      "target": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "similarity": 0.8226
    },
    {
      "source": "However",
      "target": "eNQp79A5Oz",
      "similarity": 0.8169
    },
    {
      "source": "However",
      "target": "ZNnmcddaB3",
      "similarity": 0.8168
    },
    {
      "source": "However",
      "target": "PDnEDS244P",
      "similarity": 0.816
    },
    {
      "source": "However",
      "target": "Based on this concept",
      "similarity": 0.8159
    },
    {
      "source": "In this work",
      "target": "gfI9v7AbFg",
      "similarity": 0.8422
    },
    {
      "source": "In this work",
      "target": "In this work",
      "similarity": 0.8409
    },
    {
      "source": "In this work",
      "target": "Second",
      "similarity": 0.8256
    },
    {
      "source": "In this work",
      "target": "U3PBITXNG6",
      "similarity": 0.8242
    },
    {
      "source": "In this work",
      "target": "ERv8ptegFi",
      "similarity": 0.8233
    },
    {
      "source": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "target": "eiqrnVaeIw",
      "similarity": 0.8573
    },
    {
      "source": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "target": "254NJe9JEw",
      "similarity": 0.853
    },
    {
      "source": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "target": "IuU0wcO0mo",
      "similarity": 0.8511
    },
    {
      "source": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "target": "Moreover",
      "similarity": 0.8481
    },
    {
      "source": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "target": "JAMxRSXLFz",
      "similarity": 0.8477
    },
    {
      "source": "This insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair",
      "target": "78tc3EiUrN",
      "similarity": 0.8457
    },
    {
      "source": "This insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair",
      "target": "To overcome those challenges",
      "similarity": 0.84
    },
    {
      "source": "This insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair",
      "target": "We also thoroughly analyzed our pre-training dataset",
      "similarity": 0.8311
    },
    {
      "source": "This insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair",
      "target": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "similarity": 0.8232
    },
    {
      "source": "This insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair",
      "target": "hyfe5q5TD0",
      "similarity": 0.8149
    },
    {
      "source": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "target": "gWgaypDBs8",
      "similarity": 0.7953
    },
    {
      "source": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "target": "L5godAOC2z",
      "similarity": 0.7907
    },
    {
      "source": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "target": "Our non-adversarial method does not require learning an explicit reward function and can be solved seamlessly with existing RL algorithms.",
      "similarity": 0.785
    },
    {
      "source": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.7843
    },
    {
      "source": "We develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front",
      "target": "ZooProbe generates high-quality data that accelerates MLLM training and enhances performance",
      "similarity": 0.7828
    },
    {
      "source": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "target": "9EqQC2ct4H",
      "similarity": 0.8443
    },
    {
      "source": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "target": "pCj2sLNoJq",
      "similarity": 0.8222
    },
    {
      "source": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "target": "SEARCH (SFS)**",
      "similarity": 0.815
    },
    {
      "source": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "target": "aWXnKanInf",
      "similarity": 0.8069
    },
    {
      "source": "Our empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.\"",
      "target": "of natural language. However",
      "similarity": 0.8051
    },
    {
      "source": "sVNfWhtaJC",
      "target": "1xzqz73hvL",
      "similarity": 0.8473
    },
    {
      "source": "sVNfWhtaJC",
      "target": "exgLs4snap",
      "similarity": 0.8326
    },
    {
      "source": "sVNfWhtaJC",
      "target": "fL4qWkSmtM",
      "similarity": 0.8299
    },
    {
      "source": "sVNfWhtaJC",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8297
    },
    {
      "source": "sVNfWhtaJC",
      "target": "imT03YXlG2",
      "similarity": 0.8183
    },
    {
      "source": "IwPXYk6BV9",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8291
    },
    {
      "source": "IwPXYk6BV9",
      "target": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "similarity": 0.828
    },
    {
      "source": "IwPXYk6BV9",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8154
    },
    {
      "source": "IwPXYk6BV9",
      "target": "R4h5PXzUuU",
      "similarity": 0.8142
    },
    {
      "source": "IwPXYk6BV9",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8138
    },
    {
      "source": "QOfswj7hij",
      "target": "QCDdI7X3f9",
      "similarity": 0.8455
    },
    {
      "source": "QOfswj7hij",
      "target": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "similarity": 0.841
    },
    {
      "source": "QOfswj7hij",
      "target": "VoayJihXra",
      "similarity": 0.8409
    },
    {
      "source": "QOfswj7hij",
      "target": "ples. To our knowledge",
      "similarity": 0.8404
    },
    {
      "source": "QOfswj7hij",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8398
    },
    {
      "source": "BOQpRtI4F5",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8441
    },
    {
      "source": "BOQpRtI4F5",
      "target": "QaTBHSqmH9",
      "similarity": 0.8334
    },
    {
      "source": "BOQpRtI4F5",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8331
    },
    {
      "source": "BOQpRtI4F5",
      "target": "7EhS3YBxjY",
      "similarity": 0.8313
    },
    {
      "source": "BOQpRtI4F5",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.827
    },
    {
      "source": "In this work",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8295
    },
    {
      "source": "In this work",
      "target": "This paper proposes Preble",
      "similarity": 0.8293
    },
    {
      "source": "In this work",
      "target": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "similarity": 0.8279
    },
    {
      "source": "In this work",
      "target": "2o58Mbqkd2",
      "similarity": 0.8265
    },
    {
      "source": "In this work",
      "target": "41uZB8bDFh",
      "similarity": 0.8246
    },
    {
      "source": "ByCV9xWfNK",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.839
    },
    {
      "source": "ByCV9xWfNK",
      "target": "ajxAJ8GUX4",
      "similarity": 0.8378
    },
    {
      "source": "ByCV9xWfNK",
      "target": "Subsequently",
      "similarity": 0.8313
    },
    {
      "source": "ByCV9xWfNK",
      "target": "bBoetBIN2R",
      "similarity": 0.83
    },
    {
      "source": "ByCV9xWfNK",
      "target": "j1tSLYKwg8",
      "similarity": 0.83
    },
    {
      "source": "PbheqxnO1e",
      "target": "Beyond performance evaluations",
      "similarity": 0.8444
    },
    {
      "source": "PbheqxnO1e",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8307
    },
    {
      "source": "PbheqxnO1e",
      "target": "SyVPiehSbg",
      "similarity": 0.8289
    },
    {
      "source": "PbheqxnO1e",
      "target": "1F8xTfv6ah",
      "similarity": 0.8287
    },
    {
      "source": "PbheqxnO1e",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8282
    },
    {
      "source": "In this work",
      "target": "GtvuNrk58a",
      "similarity": 0.7991
    },
    {
      "source": "In this work",
      "target": "For example",
      "similarity": 0.7973
    },
    {
      "source": "In this work",
      "target": "q87GUkdQBm",
      "similarity": 0.7954
    },
    {
      "source": "In this work",
      "target": "From this perspective",
      "similarity": 0.7929
    },
    {
      "source": "In this work",
      "target": "In this work",
      "similarity": 0.7899
    },
    {
      "source": "XoulHHQGFi",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8263
    },
    {
      "source": "XoulHHQGFi",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8251
    },
    {
      "source": "XoulHHQGFi",
      "target": "For that purpose",
      "similarity": 0.8157
    },
    {
      "source": "XoulHHQGFi",
      "target": "kmgrlG9TR0",
      "similarity": 0.8143
    },
    {
      "source": "XoulHHQGFi",
      "target": "However",
      "similarity": 0.8141
    },
    {
      "source": "CoQw1dXtGb",
      "target": "OL44KtasKc",
      "similarity": 0.8268
    },
    {
      "source": "CoQw1dXtGb",
      "target": "In this task",
      "similarity": 0.8126
    },
    {
      "source": "CoQw1dXtGb",
      "target": "Our experiments demonstrate the superiority of our method finding the most influential neuron path along which the information flows",
      "similarity": 0.8087
    },
    {
      "source": "CoQw1dXtGb",
      "target": "FZv3kPHTtB",
      "similarity": 0.8064
    },
    {
      "source": "CoQw1dXtGb",
      "target": "xvhV3LvYTc",
      "similarity": 0.8038
    },
    {
      "source": "Without labeled calibration data for target domains",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8473
    },
    {
      "source": "Without labeled calibration data for target domains",
      "target": "its relevance in machine learning.",
      "similarity": 0.8379
    },
    {
      "source": "Without labeled calibration data for target domains",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8342
    },
    {
      "source": "Without labeled calibration data for target domains",
      "target": "TlAdgeoDTo",
      "similarity": 0.8323
    },
    {
      "source": "Without labeled calibration data for target domains",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8318
    },
    {
      "source": "For scenarios with constant label distribution",
      "target": "5pd78GmXC6",
      "similarity": 0.8074
    },
    {
      "source": "For scenarios with constant label distribution",
      "target": "Second",
      "similarity": 0.8038
    },
    {
      "source": "For scenarios with constant label distribution",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.8004
    },
    {
      "source": "For scenarios with constant label distribution",
      "target": "oDbiL9CLoS",
      "similarity": 0.796
    },
    {
      "source": "For scenarios with constant label distribution",
      "target": "HsHxSN23rM",
      "similarity": 0.7955
    },
    {
      "source": "However",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.8237
    },
    {
      "source": "However",
      "target": "In a client-server setting",
      "similarity": 0.8193
    },
    {
      "source": "However",
      "target": "vRvVVb0NAz",
      "similarity": 0.811
    },
    {
      "source": "However",
      "target": "domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions",
      "similarity": 0.81
    },
    {
      "source": "However",
      "target": "We discover the neural ensembles underlying non-simultaneous observations",
      "similarity": 0.8043
    },
    {
      "source": "Here",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8791
    },
    {
      "source": "Here",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8746
    },
    {
      "source": "Here",
      "target": "VQwI055flA",
      "similarity": 0.8701
    },
    {
      "source": "Here",
      "target": "Furthermore",
      "similarity": 0.8656
    },
    {
      "source": "Here",
      "target": "To this end",
      "similarity": 0.8653
    },
    {
      "source": "We introduce a novel",
      "target": "wmV4cIbgl6",
      "similarity": 0.8353
    },
    {
      "source": "We introduce a novel",
      "target": "GySIAKEwtZ",
      "similarity": 0.8319
    },
    {
      "source": "We introduce a novel",
      "target": "xP1radUi32",
      "similarity": 0.8234
    },
    {
      "source": "We introduce a novel",
      "target": "g3VCIM94ke",
      "similarity": 0.8198
    },
    {
      "source": "We introduce a novel",
      "target": "4NTrco82W0",
      "similarity": 0.819
    },
    {
      "source": "As a remedy",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8235
    },
    {
      "source": "As a remedy",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8168
    },
    {
      "source": "As a remedy",
      "target": "This paper introduces PANGEA",
      "similarity": 0.8142
    },
    {
      "source": "As a remedy",
      "target": "We release models",
      "similarity": 0.8104
    },
    {
      "source": "As a remedy",
      "target": "To the best of our knowledge",
      "similarity": 0.8094
    },
    {
      "source": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "target": "txD9llAYn9",
      "similarity": 0.8663
    },
    {
      "source": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8625
    },
    {
      "source": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "target": "FrFQpAgnGE",
      "similarity": 0.8601
    },
    {
      "source": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "target": "WCRQFlji2q",
      "similarity": 0.8592
    },
    {
      "source": "SPDIM uses the information maximization principle to learn a single SPD-manifold-constrained parameter per target domain.",
      "target": "Furthermore",
      "similarity": 0.8566
    },
    {
      "source": "In simulations",
      "target": "j1tSLYKwg8",
      "similarity": 0.8614
    },
    {
      "source": "In simulations",
      "target": "qZEdmyqCHF",
      "similarity": 0.8559
    },
    {
      "source": "In simulations",
      "target": "Subsequently",
      "similarity": 0.8503
    },
    {
      "source": "In simulations",
      "target": "In this paper",
      "similarity": 0.8468
    },
    {
      "source": "In simulations",
      "target": "in a vector database",
      "similarity": 0.8425
    },
    {
      "source": "Moreover",
      "target": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "similarity": 0.8247
    },
    {
      "source": "Moreover",
      "target": "In this paper",
      "similarity": 0.8148
    },
    {
      "source": "Moreover",
      "target": "D2hhkU5O48",
      "similarity": 0.8148
    },
    {
      "source": "Moreover",
      "target": "From these insights",
      "similarity": 0.8117
    },
    {
      "source": "Moreover",
      "target": "wLmJIs1uqG",
      "similarity": 0.8002
    },
    {
      "source": "bRa4JLPzii",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8995
    },
    {
      "source": "bRa4JLPzii",
      "target": "Oxpkn0YLG1",
      "similarity": 0.897
    },
    {
      "source": "bRa4JLPzii",
      "target": "FrFQpAgnGE",
      "similarity": 0.8767
    },
    {
      "source": "bRa4JLPzii",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8692
    },
    {
      "source": "bRa4JLPzii",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8649
    },
    {
      "source": "N1L5TgtkAw",
      "target": "54XlM8Clkg",
      "similarity": 0.8031
    },
    {
      "source": "N1L5TgtkAw",
      "target": "As a flexible experimental test bed",
      "similarity": 0.7767
    },
    {
      "source": "N1L5TgtkAw",
      "target": "hyfe5q5TD0",
      "similarity": 0.7766
    },
    {
      "source": "N1L5TgtkAw",
      "target": "We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation.",
      "similarity": 0.7764
    },
    {
      "source": "N1L5TgtkAw",
      "target": "zGzs5SIwT8",
      "similarity": 0.7675
    },
    {
      "source": "kvLenbZZgg",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8584
    },
    {
      "source": "kvLenbZZgg",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.8488
    },
    {
      "source": "kvLenbZZgg",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8411
    },
    {
      "source": "kvLenbZZgg",
      "target": "memorization.",
      "similarity": 0.8377
    },
    {
      "source": "kvLenbZZgg",
      "target": "Furthermore",
      "similarity": 0.8373
    },
    {
      "source": "uy4EavBEwl",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8232
    },
    {
      "source": "uy4EavBEwl",
      "target": "n2NidsYDop",
      "similarity": 0.8015
    },
    {
      "source": "uy4EavBEwl",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.7995
    },
    {
      "source": "uy4EavBEwl",
      "target": "INqLJwqUmc",
      "similarity": 0.7989
    },
    {
      "source": "uy4EavBEwl",
      "target": "To address this limitation",
      "similarity": 0.7982
    },
    {
      "source": "ZNnmcddaB3",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.82
    },
    {
      "source": "ZNnmcddaB3",
      "target": "Finally",
      "similarity": 0.818
    },
    {
      "source": "ZNnmcddaB3",
      "target": "Moreover",
      "similarity": 0.8124
    },
    {
      "source": "ZNnmcddaB3",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8108
    },
    {
      "source": "ZNnmcddaB3",
      "target": "eUEMjwh5wK",
      "similarity": 0.808
    },
    {
      "source": "cR5GTis5II",
      "target": "TvGPP8i18S",
      "similarity": 0.835
    },
    {
      "source": "cR5GTis5II",
      "target": "Moreover",
      "similarity": 0.834
    },
    {
      "source": "cR5GTis5II",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8168
    },
    {
      "source": "cR5GTis5II",
      "target": "To tackle this problem",
      "similarity": 0.8138
    },
    {
      "source": "cR5GTis5II",
      "target": "We find that initiating pruning at 25\\% of total training compute and concluding at 75\\% achieves near-optimal final evaluation loss.",
      "similarity": 0.8136
    },
    {
      "source": "Ax3uliEBVR",
      "target": "bc2H72hGxB",
      "similarity": 0.8406
    },
    {
      "source": "Ax3uliEBVR",
      "target": "Therefore",
      "similarity": 0.832
    },
    {
      "source": "Ax3uliEBVR",
      "target": "memorization.",
      "similarity": 0.8247
    },
    {
      "source": "Ax3uliEBVR",
      "target": "03EkqSCKuO",
      "similarity": 0.8228
    },
    {
      "source": "Ax3uliEBVR",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8218
    },
    {
      "source": "4FIjRodbW6",
      "target": "mkDam1xIzW",
      "similarity": 0.8705
    },
    {
      "source": "4FIjRodbW6",
      "target": "4GT9uTsAJE",
      "similarity": 0.8588
    },
    {
      "source": "4FIjRodbW6",
      "target": "{Subsequently}",
      "similarity": 0.8566
    },
    {
      "source": "4FIjRodbW6",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8365
    },
    {
      "source": "4FIjRodbW6",
      "target": "RAyRXQjsFl",
      "similarity": 0.8364
    },
    {
      "source": "TlAdgeoDTo",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.857
    },
    {
      "source": "TlAdgeoDTo",
      "target": "EcrdmRT99M",
      "similarity": 0.8416
    },
    {
      "source": "TlAdgeoDTo",
      "target": "To overcome those challenges",
      "similarity": 0.8413
    },
    {
      "source": "TlAdgeoDTo",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8386
    },
    {
      "source": "TlAdgeoDTo",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8355
    },
    {
      "source": "e8qXTxMgPg",
      "target": "gFvRRCnQvX",
      "similarity": 0.8287
    },
    {
      "source": "e8qXTxMgPg",
      "target": "FBhKUXK7od",
      "similarity": 0.8222
    },
    {
      "source": "e8qXTxMgPg",
      "target": "Our architecture combines this efficient scaling with noise-conditioned self-attention mechanism",
      "similarity": 0.8148
    },
    {
      "source": "e8qXTxMgPg",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.8114
    },
    {
      "source": "e8qXTxMgPg",
      "target": "However",
      "similarity": 0.8074
    },
    {
      "source": "\\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here",
      "target": "depth-wise",
      "similarity": 0.8511
    },
    {
      "source": "\\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here",
      "target": "lydPkW4lfz",
      "similarity": 0.8003
    },
    {
      "source": "\\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here",
      "target": "e0X9l4kecx",
      "similarity": 0.7941
    },
    {
      "source": "\\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here",
      "target": "rWQDzq3O5c",
      "similarity": 0.792
    },
    {
      "source": "\\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.7904
    },
    {
      "source": "(b) Given these lower bounds",
      "target": "kxnoqaisCT",
      "similarity": 0.8287
    },
    {
      "source": "(b) Given these lower bounds",
      "target": "We instead consider the inverted situation",
      "similarity": 0.821
    },
    {
      "source": "(b) Given these lower bounds",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8185
    },
    {
      "source": "(b) Given these lower bounds",
      "target": "This additional weighting reflects the significance of each state-action pair's contribution to learning the style",
      "similarity": 0.818
    },
    {
      "source": "(b) Given these lower bounds",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8132
    },
    {
      "source": "Yk87CwhBDx",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8539
    },
    {
      "source": "Yk87CwhBDx",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8506
    },
    {
      "source": "Yk87CwhBDx",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.849
    },
    {
      "source": "Yk87CwhBDx",
      "target": "is often a non-linear function",
      "similarity": 0.8475
    },
    {
      "source": "Yk87CwhBDx",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.847
    },
    {
      "source": "5X5Z7Ffrjb",
      "target": "unlimited streaming.\"",
      "similarity": 0.8349
    },
    {
      "source": "5X5Z7Ffrjb",
      "target": "In this work",
      "similarity": 0.82
    },
    {
      "source": "5X5Z7Ffrjb",
      "target": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "similarity": 0.8129
    },
    {
      "source": "5X5Z7Ffrjb",
      "target": "task.",
      "similarity": 0.802
    },
    {
      "source": "5X5Z7Ffrjb",
      "target": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "similarity": 0.7933
    },
    {
      "source": "nIEjY4a2Lf",
      "target": "To develop SoundCTM",
      "similarity": 0.8248
    },
    {
      "source": "nIEjY4a2Lf",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8243
    },
    {
      "source": "nIEjY4a2Lf",
      "target": "named Pacmann",
      "similarity": 0.8239
    },
    {
      "source": "nIEjY4a2Lf",
      "target": "https://github.com/Infini-AI-Lab/APE.\"",
      "similarity": 0.8219
    },
    {
      "source": "nIEjY4a2Lf",
      "target": "HD6bWcj87Y",
      "similarity": 0.8211
    },
    {
      "source": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "target": "Next",
      "similarity": 0.7954
    },
    {
      "source": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "target": "roNSXZpUDN",
      "similarity": 0.7936
    },
    {
      "source": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.7893
    },
    {
      "source": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "target": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "similarity": 0.7857
    },
    {
      "source": "$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly",
      "target": "uREg3OHjLL",
      "similarity": 0.7831
    },
    {
      "source": "4011PUI9vm",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8547
    },
    {
      "source": "4011PUI9vm",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8536
    },
    {
      "source": "4011PUI9vm",
      "target": "samples. However",
      "similarity": 0.8522
    },
    {
      "source": "4011PUI9vm",
      "target": "9ca9eHNrdH",
      "similarity": 0.8519
    },
    {
      "source": "4011PUI9vm",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8512
    },
    {
      "source": "HaX48yksVL",
      "target": "In this paper",
      "similarity": 0.8611
    },
    {
      "source": "HaX48yksVL",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8576
    },
    {
      "source": "HaX48yksVL",
      "target": "iOMnn1hSBO",
      "similarity": 0.8574
    },
    {
      "source": "HaX48yksVL",
      "target": "l6QnSQizmN",
      "similarity": 0.8543
    },
    {
      "source": "HaX48yksVL",
      "target": "ff2V3UR9sC",
      "similarity": 0.8531
    },
    {
      "source": "gVnJFY8nCM",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8292
    },
    {
      "source": "gVnJFY8nCM",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8233
    },
    {
      "source": "gVnJFY8nCM",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8232
    },
    {
      "source": "gVnJFY8nCM",
      "target": "m8yby1JfbU",
      "similarity": 0.8223
    },
    {
      "source": "gVnJFY8nCM",
      "target": "PY56Wur7S0",
      "similarity": 0.8207
    },
    {
      "source": "In contrast",
      "target": "WoPovNkM5h",
      "similarity": 0.8231
    },
    {
      "source": "In contrast",
      "target": "5IWJBStfU7",
      "similarity": 0.818
    },
    {
      "source": "In contrast",
      "target": "zBbZ2vdLzH",
      "similarity": 0.8069
    },
    {
      "source": "In contrast",
      "target": "Inspired by MuZero",
      "similarity": 0.8059
    },
    {
      "source": "In contrast",
      "target": "4v4RcAODj9",
      "similarity": 0.805
    },
    {
      "source": "VMV8gefvq8",
      "target": "Under these assumptions",
      "similarity": 0.8359
    },
    {
      "source": "VMV8gefvq8",
      "target": "nYjAzwor9R",
      "similarity": 0.8211
    },
    {
      "source": "VMV8gefvq8",
      "target": "C45YqeBDUM",
      "similarity": 0.8189
    },
    {
      "source": "VMV8gefvq8",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8113
    },
    {
      "source": "VMV8gefvq8",
      "target": "K5yeB4dTtS",
      "similarity": 0.8036
    },
    {
      "source": "from computer vision to speech and natural language processing",
      "target": "Specifically",
      "similarity": 0.8546
    },
    {
      "source": "from computer vision to speech and natural language processing",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8456
    },
    {
      "source": "from computer vision to speech and natural language processing",
      "target": "CAKE also employs a new eviction indicator that considers the shifting importance of tokens over time",
      "similarity": 0.8414
    },
    {
      "source": "from computer vision to speech and natural language processing",
      "target": "To this end",
      "similarity": 0.841
    },
    {
      "source": "from computer vision to speech and natural language processing",
      "target": "This paper introduces **TORCHTITAN**$^1$",
      "similarity": 0.8402
    },
    {
      "source": "increased their demand. However",
      "target": "However",
      "similarity": 0.9289
    },
    {
      "source": "increased their demand. However",
      "target": "PHg4rAXFVH",
      "similarity": 0.87
    },
    {
      "source": "increased their demand. However",
      "target": "cC3LxGZasH",
      "similarity": 0.866
    },
    {
      "source": "increased their demand. However",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8541
    },
    {
      "source": "increased their demand. However",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8534
    },
    {
      "source": "significant challenges due to their massive size (e.g.",
      "target": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "similarity": 0.8485
    },
    {
      "source": "significant challenges due to their massive size (e.g.",
      "target": "gfI9v7AbFg",
      "similarity": 0.8414
    },
    {
      "source": "significant challenges due to their massive size (e.g.",
      "target": "U3PBITXNG6",
      "similarity": 0.8411
    },
    {
      "source": "significant challenges due to their massive size (e.g.",
      "target": "ERv8ptegFi",
      "similarity": 0.8331
    },
    {
      "source": "significant challenges due to their massive size (e.g.",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8331
    },
    {
      "source": "Recent literature has focused on compressing the original weights or reducing the",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8546
    },
    {
      "source": "Recent literature has focused on compressing the original weights or reducing the",
      "target": "9qS3HzSDNv",
      "similarity": 0.8524
    },
    {
      "source": "Recent literature has focused on compressing the original weights or reducing the",
      "target": "To address these challenges",
      "similarity": 0.8512
    },
    {
      "source": "Recent literature has focused on compressing the original weights or reducing the",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8495
    },
    {
      "source": "Recent literature has focused on compressing the original weights or reducing the",
      "target": "Here",
      "similarity": 0.8481
    },
    {
      "source": "number of parameters required for fine-tuning these models. These compression",
      "target": "Moreover",
      "similarity": 0.8244
    },
    {
      "source": "number of parameters required for fine-tuning these models. These compression",
      "target": "is usually inaccessible for advanced LLMs",
      "similarity": 0.822
    },
    {
      "source": "number of parameters required for fine-tuning these models. These compression",
      "target": "9cQB1Hwrtw",
      "similarity": 0.8125
    },
    {
      "source": "number of parameters required for fine-tuning these models. These compression",
      "target": "that more recent SAE variants such as Gated SAEs and Top-K SAEs are competitive",
      "similarity": 0.8049
    },
    {
      "source": "number of parameters required for fine-tuning these models. These compression",
      "target": "gLa96FlWwn",
      "similarity": 0.8037
    },
    {
      "source": "methods generally constrain the parameter space",
      "target": "INqLJwqUmc",
      "similarity": 0.8181
    },
    {
      "source": "methods generally constrain the parameter space",
      "target": "UIFAJZ22ZF",
      "similarity": 0.8151
    },
    {
      "source": "methods generally constrain the parameter space",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.7995
    },
    {
      "source": "methods generally constrain the parameter space",
      "target": "DpLFmc09pC",
      "similarity": 0.7937
    },
    {
      "source": "methods generally constrain the parameter space",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.7905
    },
    {
      "source": "reparametrization (e.g.",
      "target": "1F8xTfv6ah",
      "similarity": 0.8418
    },
    {
      "source": "reparametrization (e.g.",
      "target": "In this paper",
      "similarity": 0.8359
    },
    {
      "source": "reparametrization (e.g.",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8347
    },
    {
      "source": "reparametrization (e.g.",
      "target": "Beyond performance evaluations",
      "similarity": 0.8291
    },
    {
      "source": "reparametrization (e.g.",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8123
    },
    {
      "source": "or after the model training. In this paper",
      "target": "F57HPKZ6KD",
      "similarity": 0.8179
    },
    {
      "source": "or after the model training. In this paper",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8047
    },
    {
      "source": "or after the model training. In this paper",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8043
    },
    {
      "source": "or after the model training. In this paper",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8027
    },
    {
      "source": "or after the model training. In this paper",
      "target": "jlhBFm7T2J",
      "similarity": 0.8004
    },
    {
      "source": "sion method",
      "target": "WCRQFlji2q",
      "similarity": 0.8742
    },
    {
      "source": "sion method",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8614
    },
    {
      "source": "sion method",
      "target": "VQwI055flA",
      "similarity": 0.8582
    },
    {
      "source": "sion method",
      "target": "txD9llAYn9",
      "similarity": 0.858
    },
    {
      "source": "sion method",
      "target": "ensuring the generation of only normal data.",
      "similarity": 0.8559
    },
    {
      "source": "This method constrains the parameter space to low-dimensional pre-defined and",
      "target": "With regards to improving Shampoo's computational efficiency",
      "similarity": 0.8472
    },
    {
      "source": "This method constrains the parameter space to low-dimensional pre-defined and",
      "target": "wHebuIb6IH",
      "similarity": 0.8375
    },
    {
      "source": "This method constrains the parameter space to low-dimensional pre-defined and",
      "target": "dgR6i4TSng",
      "similarity": 0.837
    },
    {
      "source": "This method constrains the parameter space to low-dimensional pre-defined and",
      "target": "r0pLGGcuY6",
      "similarity": 0.8359
    },
    {
      "source": "This method constrains the parameter space to low-dimensional pre-defined and",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8358
    },
    {
      "source": "frozen nonlinear manifolds",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8675
    },
    {
      "source": "frozen nonlinear manifolds",
      "target": "h8yg0hT96f",
      "similarity": 0.8504
    },
    {
      "source": "frozen nonlinear manifolds",
      "target": "P4XmKjXTrM",
      "similarity": 0.847
    },
    {
      "source": "frozen nonlinear manifolds",
      "target": "yORSk4Ycsa",
      "similarity": 0.8455
    },
    {
      "source": "frozen nonlinear manifolds",
      "target": "mnna9LUg7P",
      "similarity": 0.8433
    },
    {
      "source": "lence of good solutions in over-parameterized deep neural networks",
      "target": "{Subsequently}",
      "similarity": 0.8555
    },
    {
      "source": "lence of good solutions in over-parameterized deep neural networks",
      "target": "c61unr33XA",
      "similarity": 0.8552
    },
    {
      "source": "lence of good solutions in over-parameterized deep neural networks",
      "target": "nDTvP6tBMd",
      "similarity": 0.8427
    },
    {
      "source": "lence of good solutions in over-parameterized deep neural networks",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8339
    },
    {
      "source": "lence of good solutions in over-parameterized deep neural networks",
      "target": "fNMKqyvuZT",
      "similarity": 0.8335
    },
    {
      "source": "by constraining the parameter space to our proposed manifold",
      "target": "5Y9NT6lW21",
      "similarity": 0.8361
    },
    {
      "source": "by constraining the parameter space to our proposed manifold",
      "target": "YzxMu1asQi",
      "similarity": 0.8348
    },
    {
      "source": "by constraining the parameter space to our proposed manifold",
      "target": "Reweighting (GSR)",
      "similarity": 0.833
    },
    {
      "source": "by constraining the parameter space to our proposed manifold",
      "target": "First",
      "similarity": 0.8273
    },
    {
      "source": "by constraining the parameter space to our proposed manifold",
      "target": "Usklli4gMc",
      "similarity": 0.8243
    },
    {
      "source": "high-quality solutions while achieving unprecedented compression rates across",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8911
    },
    {
      "source": "high-quality solutions while achieving unprecedented compression rates across",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8721
    },
    {
      "source": "high-quality solutions while achieving unprecedented compression rates across",
      "target": "nx9Z5Kva96",
      "similarity": 0.8606
    },
    {
      "source": "high-quality solutions while achieving unprecedented compression rates across",
      "target": "Vz0CWFMPUe",
      "similarity": 0.8572
    },
    {
      "source": "high-quality solutions while achieving unprecedented compression rates across",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8539
    },
    {
      "source": "a wide variety of tasks and architectures. Through extensive experiments in",
      "target": "AJpUZd8Clb",
      "similarity": 0.8754
    },
    {
      "source": "a wide variety of tasks and architectures. Through extensive experiments in",
      "target": "jxMAPMqNr5",
      "similarity": 0.8597
    },
    {
      "source": "a wide variety of tasks and architectures. Through extensive experiments in",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8474
    },
    {
      "source": "a wide variety of tasks and architectures. Through extensive experiments in",
      "target": "Using this extension",
      "similarity": 0.8429
    },
    {
      "source": "a wide variety of tasks and architectures. Through extensive experiments in",
      "target": "To this end",
      "similarity": 0.8398
    },
    {
      "source": "computer vision and natural language processing tasks",
      "target": "We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.",
      "similarity": 0.7898
    },
    {
      "source": "computer vision and natural language processing tasks",
      "target": "To improve prompt quality",
      "similarity": 0.7865
    },
    {
      "source": "computer vision and natural language processing tasks",
      "target": "By applying this variational estimation framework to $f$-GANs",
      "similarity": 0.7776
    },
    {
      "source": "computer vision and natural language processing tasks",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.7761
    },
    {
      "source": "computer vision and natural language processing tasks",
      "target": "In $\\texttt{ProAdvPrompter}$",
      "similarity": 0.7721
    },
    {
      "source": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8531
    },
    {
      "source": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "target": "JYTQ6ELUVO",
      "similarity": 0.8419
    },
    {
      "source": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8412
    },
    {
      "source": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "target": "$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.",
      "similarity": 0.8406
    },
    {
      "source": "method significantly outperforms state-of-the-art baselines in terms of compres-",
      "target": "In this paper",
      "similarity": 0.8392
    },
    {
      "source": "sion",
      "target": "The standard composition-based privacy analysis of DP-SGD effectively assumes that the adversary has access to all intermediate iterates",
      "similarity": 0.8461
    },
    {
      "source": "sion",
      "target": "For that purpose",
      "similarity": 0.8427
    },
    {
      "source": "sion",
      "target": "EyaH1wzmao",
      "similarity": 0.8419
    },
    {
      "source": "sion",
      "target": "BI2int5SAC",
      "similarity": 0.8383
    },
    {
      "source": "sion",
      "target": "90DC0IvlSs",
      "similarity": 0.8375
    },
    {
      "source": "https://github.com/mint-vu/MCNC.\"",
      "target": "Uo4EHT4ZZ8",
      "similarity": 0.8601
    },
    {
      "source": "https://github.com/mint-vu/MCNC.\"",
      "target": "pDDODPtpx9",
      "similarity": 0.8542
    },
    {
      "source": "https://github.com/mint-vu/MCNC.\"",
      "target": "FyMjfDQ9RO",
      "similarity": 0.8522
    },
    {
      "source": "https://github.com/mint-vu/MCNC.\"",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.848
    },
    {
      "source": "https://github.com/mint-vu/MCNC.\"",
      "target": "JY6P45sFDS",
      "similarity": 0.8463
    },
    {
      "source": "mZptYYttFj",
      "target": "nrvoWOWcyg",
      "similarity": 0.8347
    },
    {
      "source": "mZptYYttFj",
      "target": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "similarity": 0.8314
    },
    {
      "source": "mZptYYttFj",
      "target": "Additionally",
      "similarity": 0.8312
    },
    {
      "source": "mZptYYttFj",
      "target": "latent variables",
      "similarity": 0.8289
    },
    {
      "source": "mZptYYttFj",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8262
    },
    {
      "source": "LWeVVPuIx0",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8805
    },
    {
      "source": "LWeVVPuIx0",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.871
    },
    {
      "source": "LWeVVPuIx0",
      "target": "wHebuIb6IH",
      "similarity": 0.8521
    },
    {
      "source": "LWeVVPuIx0",
      "target": "JytL2MrlLT",
      "similarity": 0.8495
    },
    {
      "source": "LWeVVPuIx0",
      "target": "EzrZX9bd4G",
      "similarity": 0.8489
    },
    {
      "source": "We start by showing numerically that several variants used in practice",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8655
    },
    {
      "source": "We start by showing numerically that several variants used in practice",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8597
    },
    {
      "source": "We start by showing numerically that several variants used in practice",
      "target": "cKlzKs3Nnb",
      "similarity": 0.8352
    },
    {
      "source": "We start by showing numerically that several variants used in practice",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8307
    },
    {
      "source": "We start by showing numerically that several variants used in practice",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.829
    },
    {
      "source": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8259
    },
    {
      "source": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "target": "fXb9BbuyAD",
      "similarity": 0.8241
    },
    {
      "source": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "target": "4es2oO9tw1",
      "similarity": 0.8217
    },
    {
      "source": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "target": "gsShHPxkUW",
      "similarity": 0.8196
    },
    {
      "source": "We then prove that recent variants of these algorithms based on a smoothing technique",
      "target": "Ian00SaFHg",
      "similarity": 0.8194
    },
    {
      "source": "HsHxSN23rM",
      "target": "5pd78GmXC6",
      "similarity": 0.8366
    },
    {
      "source": "HsHxSN23rM",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8354
    },
    {
      "source": "HsHxSN23rM",
      "target": "xnF2U0ro7b",
      "similarity": 0.834
    },
    {
      "source": "HsHxSN23rM",
      "target": "aKkDY1Wca0",
      "similarity": 0.8297
    },
    {
      "source": "HsHxSN23rM",
      "target": "However",
      "similarity": 0.8296
    },
    {
      "source": "nDTvP6tBMd",
      "target": "{Subsequently}",
      "similarity": 0.8754
    },
    {
      "source": "nDTvP6tBMd",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8731
    },
    {
      "source": "nDTvP6tBMd",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8674
    },
    {
      "source": "nDTvP6tBMd",
      "target": "yLhJYvkKA0",
      "similarity": 0.8643
    },
    {
      "source": "nDTvP6tBMd",
      "target": "fNMKqyvuZT",
      "similarity": 0.8618
    },
    {
      "source": "4vzGQcVUG8",
      "target": "mobile devices.\"",
      "similarity": 0.8237
    },
    {
      "source": "4vzGQcVUG8",
      "target": "exgLs4snap",
      "similarity": 0.8125
    },
    {
      "source": "4vzGQcVUG8",
      "target": "rfdblE10qm",
      "similarity": 0.8077
    },
    {
      "source": "4vzGQcVUG8",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8068
    },
    {
      "source": "4vzGQcVUG8",
      "target": "7d2JwGbxhA",
      "similarity": 0.8042
    },
    {
      "source": "We instead consider the inverted situation",
      "target": "ptjrpEGrGg",
      "similarity": 0.8548
    },
    {
      "source": "We instead consider the inverted situation",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8503
    },
    {
      "source": "We instead consider the inverted situation",
      "target": "named Pacmann",
      "similarity": 0.8446
    },
    {
      "source": "We instead consider the inverted situation",
      "target": "To develop SoundCTM",
      "similarity": 0.8425
    },
    {
      "source": "We instead consider the inverted situation",
      "target": "Q150eWkQ4I",
      "similarity": 0.838
    },
    {
      "source": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "target": "llSiIJosDj",
      "similarity": 0.889
    },
    {
      "source": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "target": "pDDODPtpx9",
      "similarity": 0.8673
    },
    {
      "source": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "target": "To this end",
      "similarity": 0.8638
    },
    {
      "source": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "target": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "similarity": 0.8546
    },
    {
      "source": "This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}.",
      "target": "First",
      "similarity": 0.8513
    },
    {
      "source": "We theoretically investigate weak-to-strong generalization for binary and multilabel classification in a stylized overparameterized spiked covariance model with Gaussian covariates where the weak teacher's pseudolabels are asymptotically like random guessing.",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8453
    },
    {
      "source": "We theoretically investigate weak-to-strong generalization for binary and multilabel classification in a stylized overparameterized spiked covariance model with Gaussian covariates where the weak teacher's pseudolabels are asymptotically like random guessing.",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.8416
    },
    {
      "source": "We theoretically investigate weak-to-strong generalization for binary and multilabel classification in a stylized overparameterized spiked covariance model with Gaussian covariates where the weak teacher's pseudolabels are asymptotically like random guessing.",
      "target": "Furthermore",
      "similarity": 0.8374
    },
    {
      "source": "We theoretically investigate weak-to-strong generalization for binary and multilabel classification in a stylized overparameterized spiked covariance model with Gaussian covariates where the weak teacher's pseudolabels are asymptotically like random guessing.",
      "target": "memorization.",
      "similarity": 0.8354
    },
    {
      "source": "We theoretically investigate weak-to-strong generalization for binary and multilabel classification in a stylized overparameterized spiked covariance model with Gaussian covariates where the weak teacher's pseudolabels are asymptotically like random guessing.",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8288
    },
    {
      "source": "Under these assumptions",
      "target": "Pj06mxCXPl",
      "similarity": 0.8088
    },
    {
      "source": "Under these assumptions",
      "target": "C45YqeBDUM",
      "similarity": 0.8025
    },
    {
      "source": "Under these assumptions",
      "target": "GhexuBLxbO",
      "similarity": 0.7932
    },
    {
      "source": "Under these assumptions",
      "target": "K5yeB4dTtS",
      "similarity": 0.7924
    },
    {
      "source": "Under these assumptions",
      "target": "4X9RpKH4Ls",
      "similarity": 0.7877
    },
    {
      "source": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "target": "04qx93Viwj",
      "similarity": 0.8411
    },
    {
      "source": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "target": "of our approaches.",
      "similarity": 0.8374
    },
    {
      "source": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "target": "DPzQ5n3mNm",
      "similarity": 0.8349
    },
    {
      "source": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "target": "MxbEiFRf39",
      "similarity": 0.8324
    },
    {
      "source": "Our techniques should eventually extend to weak-to-strong multiclass classification.",
      "target": "H9UnNgdq0g",
      "similarity": 0.8303
    },
    {
      "source": "Towards doing so",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8781
    },
    {
      "source": "Towards doing so",
      "target": "To this end",
      "similarity": 0.8746
    },
    {
      "source": "Towards doing so",
      "target": "VQwI055flA",
      "similarity": 0.8697
    },
    {
      "source": "Towards doing so",
      "target": "bMC1t7eLRc",
      "similarity": 0.8631
    },
    {
      "source": "Towards doing so",
      "target": "FrFQpAgnGE",
      "similarity": 0.8588
    },
    {
      "source": "Understanding the multilabel setting reinforces the value of using logits for weak supervision when they are available.\"",
      "target": "l6QnSQizmN",
      "similarity": 0.8476
    },
    {
      "source": "Understanding the multilabel setting reinforces the value of using logits for weak supervision when they are available.\"",
      "target": "2024. Our BoneMet dataset is well-organized into six components",
      "similarity": 0.8387
    },
    {
      "source": "Understanding the multilabel setting reinforces the value of using logits for weak supervision when they are available.\"",
      "target": "calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g.",
      "similarity": 0.8383
    },
    {
      "source": "Understanding the multilabel setting reinforces the value of using logits for weak supervision when they are available.\"",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8359
    },
    {
      "source": "Understanding the multilabel setting reinforces the value of using logits for weak supervision when they are available.\"",
      "target": "4S2L519nIX",
      "similarity": 0.8291
    },
    {
      "source": "WCRQFlji2q",
      "target": "VQwI055flA",
      "similarity": 0.8753
    },
    {
      "source": "WCRQFlji2q",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8751
    },
    {
      "source": "WCRQFlji2q",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8726
    },
    {
      "source": "WCRQFlji2q",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8707
    },
    {
      "source": "WCRQFlji2q",
      "target": "uxVBbSlKQ4",
      "similarity": 0.866
    },
    {
      "source": "YvKJGYL4j7",
      "target": "PwxYoMvmvy",
      "similarity": 0.841
    },
    {
      "source": "YvKJGYL4j7",
      "target": "S1Bv3068Xt",
      "similarity": 0.8407
    },
    {
      "source": "YvKJGYL4j7",
      "target": "5xSRg3eYZz",
      "similarity": 0.8369
    },
    {
      "source": "YvKJGYL4j7",
      "target": "zY37C8d6bS",
      "similarity": 0.8343
    },
    {
      "source": "YvKJGYL4j7",
      "target": "We then propose deep Fourier features",
      "similarity": 0.8326
    },
    {
      "source": "lXRDQsiP2v",
      "target": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "similarity": 0.8005
    },
    {
      "source": "lXRDQsiP2v",
      "target": "5btFIv2PNb",
      "similarity": 0.7995
    },
    {
      "source": "lXRDQsiP2v",
      "target": "ajSmXqgS24",
      "similarity": 0.7944
    },
    {
      "source": "lXRDQsiP2v",
      "target": "dmCGjPFVhF",
      "similarity": 0.7943
    },
    {
      "source": "lXRDQsiP2v",
      "target": "In this work",
      "similarity": 0.7939
    },
    {
      "source": "TljGdvzFq2",
      "target": "Pujt3ADZgI",
      "similarity": 0.8682
    },
    {
      "source": "TljGdvzFq2",
      "target": "3E8YNv1HjU",
      "similarity": 0.8637
    },
    {
      "source": "TljGdvzFq2",
      "target": "254NJe9JEw",
      "similarity": 0.8609
    },
    {
      "source": "TljGdvzFq2",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8593
    },
    {
      "source": "TljGdvzFq2",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8584
    },
    {
      "source": "ki7b0qD11r",
      "target": "odU59TxdiB",
      "similarity": 0.8847
    },
    {
      "source": "ki7b0qD11r",
      "target": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "similarity": 0.8823
    },
    {
      "source": "ki7b0qD11r",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8766
    },
    {
      "source": "ki7b0qD11r",
      "target": "3cvwO5DBZn",
      "similarity": 0.8664
    },
    {
      "source": "ki7b0qD11r",
      "target": "in a vector database",
      "similarity": 0.8651
    },
    {
      "source": "GtvuNrk58a",
      "target": "FEpAUnS7f7",
      "similarity": 0.8263
    },
    {
      "source": "GtvuNrk58a",
      "target": "oYSsbY3G4o",
      "similarity": 0.8061
    },
    {
      "source": "GtvuNrk58a",
      "target": "AZR4R3lw7y",
      "similarity": 0.792
    },
    {
      "source": "GtvuNrk58a",
      "target": "VYWBMq1L7H",
      "similarity": 0.7918
    },
    {
      "source": "GtvuNrk58a",
      "target": "m5qpn0KTMZ",
      "similarity": 0.7888
    },
    {
      "source": "4O0v4s3IzY",
      "target": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "similarity": 0.8762
    },
    {
      "source": "4O0v4s3IzY",
      "target": "phAlw3JPms",
      "similarity": 0.8591
    },
    {
      "source": "4O0v4s3IzY",
      "target": "NHhjczmJjo",
      "similarity": 0.8588
    },
    {
      "source": "4O0v4s3IzY",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8548
    },
    {
      "source": "4O0v4s3IzY",
      "target": "2024. Our BoneMet dataset is well-organized into six components",
      "similarity": 0.8471
    },
    {
      "source": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "target": "gI0kPklUKS",
      "similarity": 0.8522
    },
    {
      "source": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "target": "tu3qwNjrtw",
      "similarity": 0.8472
    },
    {
      "source": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "target": "Despite theoretically sound",
      "similarity": 0.8471
    },
    {
      "source": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8458
    },
    {
      "source": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "target": "In this paper",
      "similarity": 0.8426
    },
    {
      "source": "This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval.",
      "target": "dmCGjPFVhF",
      "similarity": 0.8431
    },
    {
      "source": "This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval.",
      "target": "SqZ0KY4qBD",
      "similarity": 0.8197
    },
    {
      "source": "This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval.",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8123
    },
    {
      "source": "This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval.",
      "target": "tention in the deep learning literature. This phenomenon leads to reduced expres-",
      "similarity": 0.805
    },
    {
      "source": "This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval.",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8026
    },
    {
      "source": "In this paper",
      "target": "that",
      "similarity": 0.8698
    },
    {
      "source": "In this paper",
      "target": "It contains three fundamental sub-tasks: interactive segmentation",
      "similarity": 0.8377
    },
    {
      "source": "In this paper",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8332
    },
    {
      "source": "In this paper",
      "target": "To address these issues",
      "similarity": 0.8324
    },
    {
      "source": "In this paper",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.832
    },
    {
      "source": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "target": "NEu8wgPctU",
      "similarity": 0.81
    },
    {
      "source": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8092
    },
    {
      "source": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "target": "MoDE surpasses current state-of-the-art Transformer-based Diffusion Policies while enabling parameter-efficient scaling through sparse experts and noise-conditioned routing",
      "similarity": 0.8028
    },
    {
      "source": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.8002
    },
    {
      "source": "We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24",
      "target": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "similarity": 0.7968
    },
    {
      "source": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "target": "In this work",
      "similarity": 0.8435
    },
    {
      "source": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "target": "Subsequently",
      "similarity": 0.8401
    },
    {
      "source": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "target": "Additionally",
      "similarity": 0.8359
    },
    {
      "source": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "target": "vQhn4wrQ6j",
      "similarity": 0.835
    },
    {
      "source": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "target": "GBIUbwW9D8",
      "similarity": 0.8335
    },
    {
      "source": "In each case",
      "target": "zXCnIyX9MG",
      "similarity": 0.8121
    },
    {
      "source": "In each case",
      "target": "Building on these insights",
      "similarity": 0.8006
    },
    {
      "source": "In each case",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.7821
    },
    {
      "source": "In each case",
      "target": "huuKoVQnB0",
      "similarity": 0.7733
    },
    {
      "source": "In each case",
      "target": "CjXaMI2kUH",
      "similarity": 0.768
    },
    {
      "source": "with self-critique and significant performance gains with sound external verification.",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8894
    },
    {
      "source": "with self-critique and significant performance gains with sound external verification.",
      "target": "2kGKsyhtvh",
      "similarity": 0.8802
    },
    {
      "source": "with self-critique and significant performance gains with sound external verification.",
      "target": "VQwI055flA",
      "similarity": 0.8743
    },
    {
      "source": "with self-critique and significant performance gains with sound external verification.",
      "target": "78tc3EiUrN",
      "similarity": 0.8636
    },
    {
      "source": "with self-critique and significant performance gains with sound external verification.",
      "target": "bMC1t7eLRc",
      "similarity": 0.8634
    },
    {
      "source": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8332
    },
    {
      "source": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "target": "FCBbh0HCrF",
      "similarity": 0.8248
    },
    {
      "source": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "target": "tQyh0gnfqW",
      "similarity": 0.8235
    },
    {
      "source": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "target": "(1) Calculating the accurate influence of all available data is time-consuming.",
      "similarity": 0.8153
    },
    {
      "source": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "target": "Our approach addresses key challenges in this domain",
      "similarity": 0.8142
    },
    {
      "source": "reZKq6hjOZ",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8513
    },
    {
      "source": "reZKq6hjOZ",
      "target": "ymt4crbbXh",
      "similarity": 0.8421
    },
    {
      "source": "reZKq6hjOZ",
      "target": "of the NTK",
      "similarity": 0.8376
    },
    {
      "source": "reZKq6hjOZ",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8357
    },
    {
      "source": "reZKq6hjOZ",
      "target": "n34taxF0TC",
      "similarity": 0.8332
    },
    {
      "source": "U834XHJuqk",
      "target": "03OkC0LKDD",
      "similarity": 0.8349
    },
    {
      "source": "U834XHJuqk",
      "target": "such density estimation (DE) is a fundamental task underlying many probabilistic modeling problems.",
      "similarity": 0.8213
    },
    {
      "source": "U834XHJuqk",
      "target": "To bridge this gap",
      "similarity": 0.8084
    },
    {
      "source": "U834XHJuqk",
      "target": "Moreover",
      "similarity": 0.8036
    },
    {
      "source": "U834XHJuqk",
      "target": "f7O3hITh5s",
      "similarity": 0.798
    },
    {
      "source": "46xYl55hdc",
      "target": "Usklli4gMc",
      "similarity": 0.8579
    },
    {
      "source": "46xYl55hdc",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8402
    },
    {
      "source": "46xYl55hdc",
      "target": "1eQT9OzfNQ",
      "similarity": 0.8366
    },
    {
      "source": "46xYl55hdc",
      "target": "oYemKnlIrO",
      "similarity": 0.8322
    },
    {
      "source": "46xYl55hdc",
      "target": "Here $\\zeta$ is the aspect ratio ( i.e.",
      "similarity": 0.8308
    },
    {
      "source": "huuKoVQnB0",
      "target": "model and progressively increases the size of subnetworks during training",
      "similarity": 0.8188
    },
    {
      "source": "huuKoVQnB0",
      "target": "NCrFA7dq8T",
      "similarity": 0.8116
    },
    {
      "source": "huuKoVQnB0",
      "target": "such as employing VLMs to evaluate VLMs. However",
      "similarity": 0.8093
    },
    {
      "source": "huuKoVQnB0",
      "target": "B8akWa62Da",
      "similarity": 0.8069
    },
    {
      "source": "huuKoVQnB0",
      "target": "finetuned on 4K-length sequences",
      "similarity": 0.8051
    },
    {
      "source": "a3PmRgAB5T",
      "target": "To address this issue",
      "similarity": 0.8443
    },
    {
      "source": "a3PmRgAB5T",
      "target": "L0evcuybH5",
      "similarity": 0.8416
    },
    {
      "source": "a3PmRgAB5T",
      "target": "these pre-trained models still struggle to generalize to many challenging circumstances",
      "similarity": 0.8365
    },
    {
      "source": "a3PmRgAB5T",
      "target": "gFvRRCnQvX",
      "similarity": 0.8321
    },
    {
      "source": "a3PmRgAB5T",
      "target": "cC3LxGZasH",
      "similarity": 0.8299
    },
    {
      "source": "Additionally",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8152
    },
    {
      "source": "Additionally",
      "target": "lgsyLSsDRe",
      "similarity": 0.8034
    },
    {
      "source": "Additionally",
      "target": "mXHTifc1Fn",
      "similarity": 0.8022
    },
    {
      "source": "Additionally",
      "target": "We instead consider the inverted situation",
      "similarity": 0.796
    },
    {
      "source": "Additionally",
      "target": "Ij9ilPh36h",
      "similarity": 0.7958
    },
    {
      "source": "In our experiments",
      "target": "kxnoqaisCT",
      "similarity": 0.8316
    },
    {
      "source": "In our experiments",
      "target": "However",
      "similarity": 0.8224
    },
    {
      "source": "In our experiments",
      "target": "Recent research demonstrates the great impact of LLMs on sequential recommendation systems",
      "similarity": 0.8175
    },
    {
      "source": "In our experiments",
      "target": "PY56Wur7S0",
      "similarity": 0.8117
    },
    {
      "source": "In our experiments",
      "target": "stacking methods. Specifically",
      "similarity": 0.8072
    },
    {
      "source": "Starting from a stronger base model Llama-3-8B-Instruct",
      "target": "ensuring the generation of only normal data.",
      "similarity": 0.8559
    },
    {
      "source": "Starting from a stronger base model Llama-3-8B-Instruct",
      "target": "Usklli4gMc",
      "similarity": 0.8496
    },
    {
      "source": "Starting from a stronger base model Llama-3-8B-Instruct",
      "target": "J9FgrqOOni",
      "similarity": 0.8453
    },
    {
      "source": "Starting from a stronger base model Llama-3-8B-Instruct",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.837
    },
    {
      "source": "Starting from a stronger base model Llama-3-8B-Instruct",
      "target": "DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators",
      "similarity": 0.8349
    },
    {
      "source": "Notably",
      "target": "In the more general context",
      "similarity": 0.8769
    },
    {
      "source": "Notably",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8498
    },
    {
      "source": "Notably",
      "target": "cADpvQgnqg",
      "similarity": 0.8476
    },
    {
      "source": "Notably",
      "target": "However",
      "similarity": 0.8431
    },
    {
      "source": "Notably",
      "target": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "similarity": 0.8353
    },
    {
      "source": "UvPdpa4LuV",
      "target": "In this paper",
      "similarity": 0.8296
    },
    {
      "source": "UvPdpa4LuV",
      "target": "ny8T8OuNHe",
      "similarity": 0.8289
    },
    {
      "source": "UvPdpa4LuV",
      "target": "dCcY2pyNIO",
      "similarity": 0.8255
    },
    {
      "source": "UvPdpa4LuV",
      "target": "gsShHPxkUW",
      "similarity": 0.82
    },
    {
      "source": "UvPdpa4LuV",
      "target": "fXb9BbuyAD",
      "similarity": 0.8188
    },
    {
      "source": "8VtGeyJyx9",
      "target": "In this paper",
      "similarity": 0.864
    },
    {
      "source": "8VtGeyJyx9",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8556
    },
    {
      "source": "8VtGeyJyx9",
      "target": "Conversely",
      "similarity": 0.8529
    },
    {
      "source": "8VtGeyJyx9",
      "target": "riieAeQBJm",
      "similarity": 0.8523
    },
    {
      "source": "8VtGeyJyx9",
      "target": "we obtain the first",
      "similarity": 0.8469
    },
    {
      "source": "uxVBbSlKQ4",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8934
    },
    {
      "source": "uxVBbSlKQ4",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8719
    },
    {
      "source": "uxVBbSlKQ4",
      "target": "9qpdDiDQ2H",
      "similarity": 0.864
    },
    {
      "source": "uxVBbSlKQ4",
      "target": "bMC1t7eLRc",
      "similarity": 0.8634
    },
    {
      "source": "uxVBbSlKQ4",
      "target": "FvQsk3la17",
      "similarity": 0.8613
    },
    {
      "source": "aKkDY1Wca0",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.8476
    },
    {
      "source": "aKkDY1Wca0",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8411
    },
    {
      "source": "aKkDY1Wca0",
      "target": "Finally",
      "similarity": 0.8381
    },
    {
      "source": "aKkDY1Wca0",
      "target": "xnF2U0ro7b",
      "similarity": 0.8328
    },
    {
      "source": "aKkDY1Wca0",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8321
    },
    {
      "source": "M5t0WvjfCg",
      "target": "W0nydevOlG",
      "similarity": 0.8343
    },
    {
      "source": "M5t0WvjfCg",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.8214
    },
    {
      "source": "M5t0WvjfCg",
      "target": "sZQRUrvLn4",
      "similarity": 0.8205
    },
    {
      "source": "M5t0WvjfCg",
      "target": "sgbI8Pxwie",
      "similarity": 0.8187
    },
    {
      "source": "M5t0WvjfCg",
      "target": "upper bound of LLMs' generalization capabilities.",
      "similarity": 0.8167
    },
    {
      "source": "J9FgrqOOni",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8698
    },
    {
      "source": "J9FgrqOOni",
      "target": "LqTz13JS2P",
      "similarity": 0.8614
    },
    {
      "source": "J9FgrqOOni",
      "target": "pDDODPtpx9",
      "similarity": 0.8564
    },
    {
      "source": "J9FgrqOOni",
      "target": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "similarity": 0.8545
    },
    {
      "source": "J9FgrqOOni",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8527
    },
    {
      "source": "However",
      "target": "wgDB1QuxIA",
      "similarity": 0.8497
    },
    {
      "source": "However",
      "target": "U49N5V51rU",
      "similarity": 0.8219
    },
    {
      "source": "However",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8179
    },
    {
      "source": "However",
      "target": "As the initial step in investigating this behavior",
      "similarity": 0.8147
    },
    {
      "source": "However",
      "target": "In parallel",
      "similarity": 0.8139
    },
    {
      "source": "xI71dsS3o4",
      "target": "mTCbq2QssD",
      "similarity": 0.8503
    },
    {
      "source": "xI71dsS3o4",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8351
    },
    {
      "source": "xI71dsS3o4",
      "target": "nibeaHUEJx",
      "similarity": 0.8351
    },
    {
      "source": "xI71dsS3o4",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8306
    },
    {
      "source": "xI71dsS3o4",
      "target": "than existing search techniques",
      "similarity": 0.8293
    },
    {
      "source": "WwwJfkGq0G",
      "target": "Our experiments demonstrate that the proposed method",
      "similarity": 0.8554
    },
    {
      "source": "WwwJfkGq0G",
      "target": "gfI9v7AbFg",
      "similarity": 0.8429
    },
    {
      "source": "WwwJfkGq0G",
      "target": "position reveals interpretable low-rank structure across toy tasks",
      "similarity": 0.8322
    },
    {
      "source": "WwwJfkGq0G",
      "target": "JbRM5QKRDd",
      "similarity": 0.8321
    },
    {
      "source": "WwwJfkGq0G",
      "target": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "similarity": 0.8312
    },
    {
      "source": "G8U2nGP3Vi",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8214
    },
    {
      "source": "G8U2nGP3Vi",
      "target": "FCBbh0HCrF",
      "similarity": 0.8157
    },
    {
      "source": "G8U2nGP3Vi",
      "target": "INyi7qUdjZ",
      "similarity": 0.8149
    },
    {
      "source": "G8U2nGP3Vi",
      "target": "vQhn4wrQ6j",
      "similarity": 0.8102
    },
    {
      "source": "G8U2nGP3Vi",
      "target": "tQyh0gnfqW",
      "similarity": 0.8073
    },
    {
      "source": "Uo4EHT4ZZ8",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8693
    },
    {
      "source": "Uo4EHT4ZZ8",
      "target": "Finally",
      "similarity": 0.8617
    },
    {
      "source": "Uo4EHT4ZZ8",
      "target": "We undertake the first comprehensive exploration of this space",
      "similarity": 0.8583
    },
    {
      "source": "Uo4EHT4ZZ8",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8528
    },
    {
      "source": "Uo4EHT4ZZ8",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8495
    },
    {
      "source": "YcUV5apdlq",
      "target": "nrvoWOWcyg",
      "similarity": 0.8515
    },
    {
      "source": "YcUV5apdlq",
      "target": "cADpvQgnqg",
      "similarity": 0.85
    },
    {
      "source": "YcUV5apdlq",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8471
    },
    {
      "source": "YcUV5apdlq",
      "target": "depth-wise",
      "similarity": 0.8465
    },
    {
      "source": "YcUV5apdlq",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8447
    },
    {
      "source": "HQHnhVQznF",
      "target": "y9A2TpaGsE",
      "similarity": 0.8232
    },
    {
      "source": "HQHnhVQznF",
      "target": "However",
      "similarity": 0.815
    },
    {
      "source": "HQHnhVQznF",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8078
    },
    {
      "source": "HQHnhVQznF",
      "target": "FBkpCyujtS",
      "similarity": 0.8006
    },
    {
      "source": "HQHnhVQznF",
      "target": "RoN6M3i7gJ",
      "similarity": 0.8005
    },
    {
      "source": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "target": "h8yg0hT96f",
      "similarity": 0.8678
    },
    {
      "source": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8553
    },
    {
      "source": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "target": "cADpvQgnqg",
      "similarity": 0.8542
    },
    {
      "source": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "target": "nrvoWOWcyg",
      "similarity": 0.8485
    },
    {
      "source": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "target": "ny8T8OuNHe",
      "similarity": 0.845
    },
    {
      "source": "counterfactual bias)",
      "target": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "similarity": 0.8865
    },
    {
      "source": "counterfactual bias)",
      "target": "in a vector database",
      "similarity": 0.8826
    },
    {
      "source": "counterfactual bias)",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8825
    },
    {
      "source": "counterfactual bias)",
      "target": "odU59TxdiB",
      "similarity": 0.8819
    },
    {
      "source": "counterfactual bias)",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8796
    },
    {
      "source": "provide guarantees. Therefore",
      "target": "Additionally",
      "similarity": 0.8516
    },
    {
      "source": "provide guarantees. Therefore",
      "target": "xnF2U0ro7b",
      "similarity": 0.8362
    },
    {
      "source": "provide guarantees. Therefore",
      "target": "We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions.",
      "similarity": 0.8316
    },
    {
      "source": "provide guarantees. Therefore",
      "target": "gcouwCx7dG",
      "similarity": 0.8257
    },
    {
      "source": "provide guarantees. Therefore",
      "target": "depth-wise",
      "similarity": 0.8248
    },
    {
      "source": "certifies LLMs for counterfactual bias on distributions of prompts. A certificate",
      "target": "is often a non-linear function",
      "similarity": 0.8458
    },
    {
      "source": "certifies LLMs for counterfactual bias on distributions of prompts. A certificate",
      "target": "phAlw3JPms",
      "similarity": 0.8333
    },
    {
      "source": "certifies LLMs for counterfactual bias on distributions of prompts. A certificate",
      "target": "As a case study",
      "similarity": 0.8303
    },
    {
      "source": "certifies LLMs for counterfactual bias on distributions of prompts. A certificate",
      "target": "4O0v4s3IzY",
      "similarity": 0.8294
    },
    {
      "source": "certifies LLMs for counterfactual bias on distributions of prompts. A certificate",
      "target": "PIpGN5Ko3v",
      "similarity": 0.8274
    },
    {
      "source": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8322
    },
    {
      "source": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "target": "DTatjJTDl1",
      "similarity": 0.8303
    },
    {
      "source": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "target": "7EhS3YBxjY",
      "similarity": 0.8302
    },
    {
      "source": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.826
    },
    {
      "source": "consists of high-confidence bounds on the probability of unbiased LLM responses",
      "target": "Through a step-by-step rotary position embedding (RoPE) scaling training strategy",
      "similarity": 0.8254
    },
    {
      "source": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "target": "To address this",
      "similarity": 0.8039
    },
    {
      "source": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "target": "UqrFPhcmFp",
      "similarity": 0.7989
    },
    {
      "source": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "target": "To fill this gap",
      "similarity": 0.7873
    },
    {
      "source": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.781
    },
    {
      "source": "for any set of counterfactual prompts - prompts differing by demographic groups",
      "target": "vue9P1Ypk6",
      "similarity": 0.7704
    },
    {
      "source": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "target": "tu3qwNjrtw",
      "similarity": 0.8664
    },
    {
      "source": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "target": "Despite theoretically sound",
      "similarity": 0.8642
    },
    {
      "source": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8626
    },
    {
      "source": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "target": "To address these challenges",
      "similarity": 0.8522
    },
    {
      "source": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8514
    },
    {
      "source": "distributions of counterfactual prompts created by applying prefixes sampled from",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.7854
    },
    {
      "source": "distributions of counterfactual prompts created by applying prefixes sampled from",
      "target": "wLmJIs1uqG",
      "similarity": 0.7834
    },
    {
      "source": "distributions of counterfactual prompts created by applying prefixes sampled from",
      "target": "3ep9ZYMZS3",
      "similarity": 0.7832
    },
    {
      "source": "distributions of counterfactual prompts created by applying prefixes sampled from",
      "target": "1tBvzOYTLF",
      "similarity": 0.7812
    },
    {
      "source": "distributions of counterfactual prompts created by applying prefixes sampled from",
      "target": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "similarity": 0.777
    },
    {
      "source": "prefix distributions",
      "target": "pre-training data",
      "similarity": 0.8734
    },
    {
      "source": "prefix distributions",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8638
    },
    {
      "source": "prefix distributions",
      "target": "In addition",
      "similarity": 0.8527
    },
    {
      "source": "prefix distributions",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8468
    },
    {
      "source": "prefix distributions",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8466
    },
    {
      "source": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8355
    },
    {
      "source": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "target": "Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks.",
      "similarity": 0.8112
    },
    {
      "source": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "target": "Among these",
      "similarity": 0.8104
    },
    {
      "source": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "target": "owP2mymrTD",
      "similarity": 0.8044
    },
    {
      "source": "of jailbreaks in LLM\u2019s embedding space. We generate non-trivial certificates for",
      "target": "gfI9v7AbFg",
      "similarity": 0.8038
    },
    {
      "source": "SOTA LLMs",
      "target": "U3PBITXNG6",
      "similarity": 0.8647
    },
    {
      "source": "SOTA LLMs",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.855
    },
    {
      "source": "SOTA LLMs",
      "target": "AcVpLS86RT",
      "similarity": 0.8549
    },
    {
      "source": "SOTA LLMs",
      "target": "In this task",
      "similarity": 0.8523
    },
    {
      "source": "SOTA LLMs",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8519
    },
    {
      "source": "from computationally inexpensive prefix distributions.\"",
      "target": "ROpY0qRUXL",
      "similarity": 0.8724
    },
    {
      "source": "from computationally inexpensive prefix distributions.\"",
      "target": "bBoetBIN2R",
      "similarity": 0.8575
    },
    {
      "source": "from computationally inexpensive prefix distributions.\"",
      "target": "kbm6tsICar",
      "similarity": 0.8325
    },
    {
      "source": "from computationally inexpensive prefix distributions.\"",
      "target": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "similarity": 0.8321
    },
    {
      "source": "from computationally inexpensive prefix distributions.\"",
      "target": "2zmO1GVT0Y",
      "similarity": 0.8278
    },
    {
      "source": "AP0ndQloqR",
      "target": "potential algorithms to solve one task",
      "similarity": 0.8636
    },
    {
      "source": "AP0ndQloqR",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8611
    },
    {
      "source": "AP0ndQloqR",
      "target": "KD5nJUgeW4",
      "similarity": 0.8448
    },
    {
      "source": "AP0ndQloqR",
      "target": "MyVC4X5B2X",
      "similarity": 0.8408
    },
    {
      "source": "AP0ndQloqR",
      "target": "2ET561DyPe",
      "similarity": 0.8391
    },
    {
      "source": "FJFVmeXusW",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8505
    },
    {
      "source": "FJFVmeXusW",
      "target": "cADpvQgnqg",
      "similarity": 0.834
    },
    {
      "source": "FJFVmeXusW",
      "target": "WJaUkwci9o",
      "similarity": 0.8307
    },
    {
      "source": "FJFVmeXusW",
      "target": "uL1H29dM0c",
      "similarity": 0.8262
    },
    {
      "source": "FJFVmeXusW",
      "target": "Furthermore",
      "similarity": 0.8245
    },
    {
      "source": "meKEKDhdnx",
      "target": "In addition",
      "similarity": 0.8369
    },
    {
      "source": "meKEKDhdnx",
      "target": "In particular",
      "similarity": 0.8315
    },
    {
      "source": "meKEKDhdnx",
      "target": "tu3qwNjrtw",
      "similarity": 0.8301
    },
    {
      "source": "meKEKDhdnx",
      "target": "il5yUQsrjC",
      "similarity": 0.8264
    },
    {
      "source": "meKEKDhdnx",
      "target": "In this paper",
      "similarity": 0.8264
    },
    {
      "source": "For LLMs to solve complex problems",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.853
    },
    {
      "source": "For LLMs to solve complex problems",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8495
    },
    {
      "source": "For LLMs to solve complex problems",
      "target": "However",
      "similarity": 0.8413
    },
    {
      "source": "For LLMs to solve complex problems",
      "target": "K4FAFNRpko",
      "similarity": 0.8399
    },
    {
      "source": "For LLMs to solve complex problems",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8373
    },
    {
      "source": "instructions",
      "target": "To this end",
      "similarity": 0.8819
    },
    {
      "source": "instructions",
      "target": "pDDODPtpx9",
      "similarity": 0.871
    },
    {
      "source": "instructions",
      "target": "IuU0wcO0mo",
      "similarity": 0.8709
    },
    {
      "source": "instructions",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8688
    },
    {
      "source": "instructions",
      "target": "Using this extension",
      "similarity": 0.8688
    },
    {
      "source": "prompts. As such",
      "target": "In experimental validation across a variety of active learning tasks",
      "similarity": 0.8275
    },
    {
      "source": "prompts. As such",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8255
    },
    {
      "source": "prompts. As such",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.8244
    },
    {
      "source": "prompts. As such",
      "target": "JbRM5QKRDd",
      "similarity": 0.821
    },
    {
      "source": "prompts. As such",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8178
    },
    {
      "source": "propose to cache and reuse KV state of prompts. However",
      "target": "In particular",
      "similarity": 0.8286
    },
    {
      "source": "propose to cache and reuse KV state of prompts. However",
      "target": "FSjIrOm1vz",
      "similarity": 0.8282
    },
    {
      "source": "propose to cache and reuse KV state of prompts. However",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.8205
    },
    {
      "source": "propose to cache and reuse KV state of prompts. However",
      "target": "to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.\"",
      "similarity": 0.8131
    },
    {
      "source": "propose to cache and reuse KV state of prompts. However",
      "target": "Overall",
      "similarity": 0.813
    },
    {
      "source": "GPU optimization",
      "target": "Moreover",
      "similarity": 0.8216
    },
    {
      "source": "GPU optimization",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.819
    },
    {
      "source": "GPU optimization",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.818
    },
    {
      "source": "GPU optimization",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8142
    },
    {
      "source": "GPU optimization",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8138
    },
    {
      "source": "This paper proposes Preble",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8334
    },
    {
      "source": "This paper proposes Preble",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8284
    },
    {
      "source": "This paper proposes Preble",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8232
    },
    {
      "source": "This paper proposes Preble",
      "target": "l0fn10vSyM",
      "similarity": 0.8215
    },
    {
      "source": "This paper proposes Preble",
      "target": "tU074jg2vS",
      "similarity": 0.8201
    },
    {
      "source": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "target": "Moreover",
      "similarity": 0.895
    },
    {
      "source": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "target": "traditional energy-based models",
      "similarity": 0.8567
    },
    {
      "source": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "target": "fXb9BbuyAD",
      "similarity": 0.8545
    },
    {
      "source": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "target": "kRBQwlkFSP",
      "similarity": 0.8312
    },
    {
      "source": "timizes for prompt sharing. We designed a distributed scheduling system that co-optimizes",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8286
    },
    {
      "source": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "target": "rakhNY32vw",
      "similarity": 0.8464
    },
    {
      "source": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "target": "MxbEiFRf39",
      "similarity": 0.8427
    },
    {
      "source": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "target": "owP2mymrTD",
      "similarity": 0.8301
    },
    {
      "source": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "target": "CvGqMD5OtX",
      "similarity": 0.8218
    },
    {
      "source": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8201
    },
    {
      "source": "hierarchical scheduling mechanism. Our evaluation of Preble with real workloads and re-",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8164
    },
    {
      "source": "hierarchical scheduling mechanism. Our evaluation of Preble with real workloads and re-",
      "target": "Jjr2Odj8DJ",
      "similarity": 0.8154
    },
    {
      "source": "hierarchical scheduling mechanism. Our evaluation of Preble with real workloads and re-",
      "target": "zigzag spaghetti (ZS)",
      "similarity": 0.8135
    },
    {
      "source": "hierarchical scheduling mechanism. Our evaluation of Preble with real workloads and re-",
      "target": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "similarity": 0.8116
    },
    {
      "source": "hierarchical scheduling mechanism. Our evaluation of Preble with real workloads and re-",
      "target": "This paper proposes Preble",
      "similarity": 0.8102
    },
    {
      "source": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "target": "m8yby1JfbU",
      "similarity": 0.8426
    },
    {
      "source": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "target": "By incorporating generative models into the BOED framework",
      "similarity": 0.8309
    },
    {
      "source": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "target": "uL1H29dM0c",
      "similarity": 0.8295
    },
    {
      "source": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "target": "Inspired by M\u00e1t\u00e9 and Fleuret",
      "similarity": 0.8273
    },
    {
      "source": "quest arrival patterns on two open-source LLMs shows that Preble outperforms the SOTA",
      "target": "it hard to decide on a proper causal discovery strategy.",
      "similarity": 0.8149
    },
    {
      "source": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "target": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "similarity": 0.8308
    },
    {
      "source": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8195
    },
    {
      "source": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "target": "Interestingly",
      "similarity": 0.8191
    },
    {
      "source": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "target": "NHMuM84tRT",
      "similarity": 0.8032
    },
    {
      "source": "serving systems by 1.5\u00d7 to 14.5\u00d7 on average latency and 2\u00d7 to 10\u00d7 on p99 latency.\"",
      "target": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "similarity": 0.803
    },
    {
      "source": "Jjr2Odj8DJ",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8411
    },
    {
      "source": "Jjr2Odj8DJ",
      "target": "introduce",
      "similarity": 0.8178
    },
    {
      "source": "Jjr2Odj8DJ",
      "target": "SyVPiehSbg",
      "similarity": 0.8113
    },
    {
      "source": "Jjr2Odj8DJ",
      "target": "GhexuBLxbO",
      "similarity": 0.81
    },
    {
      "source": "Jjr2Odj8DJ",
      "target": "Existing approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work",
      "similarity": 0.8058
    },
    {
      "source": "QYigQ6gXNw",
      "target": "Dl3MsjaIdp",
      "similarity": 0.8534
    },
    {
      "source": "QYigQ6gXNw",
      "target": "suz4utPr9Y",
      "similarity": 0.8484
    },
    {
      "source": "QYigQ6gXNw",
      "target": "EEgYUccwsV",
      "similarity": 0.8469
    },
    {
      "source": "QYigQ6gXNw",
      "target": "Theoretically",
      "similarity": 0.8371
    },
    {
      "source": "QYigQ6gXNw",
      "target": "available at https://github.com/qiaoruiyt/GSR.\"",
      "similarity": 0.8303
    },
    {
      "source": "rWui9vLhOc",
      "target": "However",
      "similarity": 0.8175
    },
    {
      "source": "rWui9vLhOc",
      "target": "An ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).\"",
      "similarity": 0.8125
    },
    {
      "source": "rWui9vLhOc",
      "target": "TId1SHe8JG",
      "similarity": 0.8111
    },
    {
      "source": "rWui9vLhOc",
      "target": "We demonstrate the effectiveness of this method on language modeling and computer vision tasks.",
      "similarity": 0.8043
    },
    {
      "source": "rWui9vLhOc",
      "target": "BI2int5SAC",
      "similarity": 0.8003
    },
    {
      "source": "MT3aOfXIbY",
      "target": "$$",
      "similarity": 0.8188
    },
    {
      "source": "MT3aOfXIbY",
      "target": "\u2777 Requiring high time overhead during coreset selection to fine-tune and evaluate the target LLM. In this paper",
      "similarity": 0.8127
    },
    {
      "source": "MT3aOfXIbY",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8101
    },
    {
      "source": "MT3aOfXIbY",
      "target": "models to generalize when the proportions of the groups shift during deployment.",
      "similarity": 0.7985
    },
    {
      "source": "MT3aOfXIbY",
      "target": "resource",
      "similarity": 0.7896
    },
    {
      "source": "In this work",
      "target": "5pd78GmXC6",
      "similarity": 0.8178
    },
    {
      "source": "In this work",
      "target": "significant challenges due to their massive size (e.g.",
      "similarity": 0.8175
    },
    {
      "source": "In this work",
      "target": "gfI9v7AbFg",
      "similarity": 0.817
    },
    {
      "source": "In this work",
      "target": "For the diversity",
      "similarity": 0.8133
    },
    {
      "source": "In this work",
      "target": "ERv8ptegFi",
      "similarity": 0.8111
    },
    {
      "source": "As a byproduct of our methods",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.8237
    },
    {
      "source": "As a byproduct of our methods",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8203
    },
    {
      "source": "As a byproduct of our methods",
      "target": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "similarity": 0.8196
    },
    {
      "source": "As a byproduct of our methods",
      "target": "Theoretically",
      "similarity": 0.818
    },
    {
      "source": "As a byproduct of our methods",
      "target": "GTcEe5fayC",
      "similarity": 0.8179
    },
    {
      "source": "csbf1p8xUq",
      "target": "txV4dNeusx",
      "similarity": 0.8686
    },
    {
      "source": "csbf1p8xUq",
      "target": "{Subsequently}",
      "similarity": 0.8344
    },
    {
      "source": "csbf1p8xUq",
      "target": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "similarity": 0.8208
    },
    {
      "source": "csbf1p8xUq",
      "target": "5IWJBStfU7",
      "similarity": 0.8177
    },
    {
      "source": "csbf1p8xUq",
      "target": "yLhJYvkKA0",
      "similarity": 0.8154
    },
    {
      "source": "while some multilingual LLMs claim to support for hundreds of languages",
      "target": "YFxfcQMLWX",
      "similarity": 0.8691
    },
    {
      "source": "while some multilingual LLMs claim to support for hundreds of languages",
      "target": "lOi6FtIwR8",
      "similarity": 0.865
    },
    {
      "source": "while some multilingual LLMs claim to support for hundreds of languages",
      "target": "vbmSSIhKAM",
      "similarity": 0.863
    },
    {
      "source": "while some multilingual LLMs claim to support for hundreds of languages",
      "target": "bMC1t7eLRc",
      "similarity": 0.8607
    },
    {
      "source": "while some multilingual LLMs claim to support for hundreds of languages",
      "target": "However",
      "similarity": 0.8588
    },
    {
      "source": "se4vjm7h4E",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8789
    },
    {
      "source": "se4vjm7h4E",
      "target": "JSB171dSUU",
      "similarity": 0.8765
    },
    {
      "source": "se4vjm7h4E",
      "target": "To tackle this challenge",
      "similarity": 0.8702
    },
    {
      "source": "se4vjm7h4E",
      "target": "while ensuring safety during learning.\"",
      "similarity": 0.8612
    },
    {
      "source": "se4vjm7h4E",
      "target": "To this end",
      "similarity": 0.8588
    },
    {
      "source": "4S2L519nIX",
      "target": "is often a non-linear function",
      "similarity": 0.8548
    },
    {
      "source": "4S2L519nIX",
      "target": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "similarity": 0.8541
    },
    {
      "source": "4S2L519nIX",
      "target": "shown that GraphRouter substantially surpasses existing routers",
      "similarity": 0.8507
    },
    {
      "source": "4S2L519nIX",
      "target": "both open-sourced models such as LLaMA and Qwen families",
      "similarity": 0.8461
    },
    {
      "source": "4S2L519nIX",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8382
    },
    {
      "source": "iAK9oHp4Zz",
      "target": "is often a non-linear function",
      "similarity": 0.8579
    },
    {
      "source": "iAK9oHp4Zz",
      "target": "As a case study",
      "similarity": 0.8505
    },
    {
      "source": "iAK9oHp4Zz",
      "target": "PIpGN5Ko3v",
      "similarity": 0.8478
    },
    {
      "source": "iAK9oHp4Zz",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8429
    },
    {
      "source": "iAK9oHp4Zz",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8406
    },
    {
      "source": "To address the challenges associated with misaligned measures from different tracks during generation",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.796
    },
    {
      "source": "To address the challenges associated with misaligned measures from different tracks during generation",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.789
    },
    {
      "source": "To address the challenges associated with misaligned measures from different tracks during generation",
      "target": "We also note that merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.\"",
      "similarity": 0.7862
    },
    {
      "source": "To address the challenges associated with misaligned measures from different tracks during generation",
      "target": "a novel unsupervised neural framework that combines exploration and exploitation for combinatorial search optimization:",
      "similarity": 0.7835
    },
    {
      "source": "To address the challenges associated with misaligned measures from different tracks during generation",
      "target": "LLaMA-3-8B-based SFT model",
      "similarity": 0.7723
    },
    {
      "source": "Our contributions include a series of models capable of handling up to 8192 tokens",
      "target": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "similarity": 0.8099
    },
    {
      "source": "Our contributions include a series of models capable of handling up to 8192 tokens",
      "target": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "similarity": 0.8075
    },
    {
      "source": "Our contributions include a series of models capable of handling up to 8192 tokens",
      "target": "TrVYEZtSQH",
      "similarity": 0.7985
    },
    {
      "source": "Our contributions include a series of models capable of handling up to 8192 tokens",
      "target": "wozhdnRCtw",
      "similarity": 0.7964
    },
    {
      "source": "Our contributions include a series of models capable of handling up to 8192 tokens",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.7963
    },
    {
      "source": "wozhdnRCtw",
      "target": "YvKJGYL4j7",
      "similarity": 0.7803
    },
    {
      "source": "wozhdnRCtw",
      "target": "aVfDrl7xDV",
      "similarity": 0.7678
    },
    {
      "source": "wozhdnRCtw",
      "target": "8TBGdH3t6a",
      "similarity": 0.7649
    },
    {
      "source": "wozhdnRCtw",
      "target": "sZQRUrvLn4",
      "similarity": 0.7638
    },
    {
      "source": "wozhdnRCtw",
      "target": "ogXkmugNZw",
      "similarity": 0.7623
    },
    {
      "source": "uhaLuZcCjH",
      "target": "To address these challenges",
      "similarity": 0.8678
    },
    {
      "source": "uhaLuZcCjH",
      "target": "INyi7qUdjZ",
      "similarity": 0.8136
    },
    {
      "source": "uhaLuZcCjH",
      "target": "te2IdORabL",
      "similarity": 0.8084
    },
    {
      "source": "uhaLuZcCjH",
      "target": "HumanEval+** and **87.2% on HumanEval with GPT-3.5**",
      "similarity": 0.7994
    },
    {
      "source": "uhaLuZcCjH",
      "target": "SWEqzy7IQB",
      "similarity": 0.7931
    },
    {
      "source": "7XNgVPxCiA",
      "target": "Moreover",
      "similarity": 0.832
    },
    {
      "source": "7XNgVPxCiA",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.7707
    },
    {
      "source": "7XNgVPxCiA",
      "target": "pHe4P1IVnb",
      "similarity": 0.7647
    },
    {
      "source": "7XNgVPxCiA",
      "target": "To tackle this challenge",
      "similarity": 0.762
    },
    {
      "source": "7XNgVPxCiA",
      "target": "eNbA8Fqir4",
      "similarity": 0.7612
    },
    {
      "source": "bBoetBIN2R",
      "target": "ROpY0qRUXL",
      "similarity": 0.899
    },
    {
      "source": "bBoetBIN2R",
      "target": "4dAgG8ma3B",
      "similarity": 0.8312
    },
    {
      "source": "bBoetBIN2R",
      "target": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "similarity": 0.8294
    },
    {
      "source": "bBoetBIN2R",
      "target": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "similarity": 0.827
    },
    {
      "source": "bBoetBIN2R",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8255
    },
    {
      "source": "dh78yRFVK9",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8178
    },
    {
      "source": "dh78yRFVK9",
      "target": "kxnoqaisCT",
      "similarity": 0.8175
    },
    {
      "source": "dh78yRFVK9",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8167
    },
    {
      "source": "dh78yRFVK9",
      "target": "However",
      "similarity": 0.8118
    },
    {
      "source": "dh78yRFVK9",
      "target": "Existing safety constraints are then integrated into the COP",
      "similarity": 0.8076
    },
    {
      "source": "llSiIJosDj",
      "target": "pDDODPtpx9",
      "similarity": 0.8756
    },
    {
      "source": "llSiIJosDj",
      "target": "Reweighting (GSR)",
      "similarity": 0.8685
    },
    {
      "source": "llSiIJosDj",
      "target": "254NJe9JEw",
      "similarity": 0.8463
    },
    {
      "source": "llSiIJosDj",
      "target": "First",
      "similarity": 0.8463
    },
    {
      "source": "llSiIJosDj",
      "target": "JY6P45sFDS",
      "similarity": 0.8443
    },
    {
      "source": "dmCGjPFVhF",
      "target": "In this work",
      "similarity": 0.8344
    },
    {
      "source": "dmCGjPFVhF",
      "target": "suz4utPr9Y",
      "similarity": 0.8316
    },
    {
      "source": "dmCGjPFVhF",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8286
    },
    {
      "source": "dmCGjPFVhF",
      "target": "cADpvQgnqg",
      "similarity": 0.8222
    },
    {
      "source": "dmCGjPFVhF",
      "target": "GhexuBLxbO",
      "similarity": 0.8206
    },
    {
      "source": "1CIUkpoata",
      "target": "Moreover",
      "similarity": 0.8689
    },
    {
      "source": "1CIUkpoata",
      "target": "Furthermore",
      "similarity": 0.8684
    },
    {
      "source": "1CIUkpoata",
      "target": "FAfxvdv1Dy",
      "similarity": 0.8667
    },
    {
      "source": "1CIUkpoata",
      "target": "3bcN6xlO6f",
      "similarity": 0.8663
    },
    {
      "source": "1CIUkpoata",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8594
    },
    {
      "source": "6yENDA7J4G",
      "target": "First",
      "similarity": 0.8323
    },
    {
      "source": "6yENDA7J4G",
      "target": "j1tSLYKwg8",
      "similarity": 0.8311
    },
    {
      "source": "6yENDA7J4G",
      "target": "A1HhtITVEi",
      "similarity": 0.8305
    },
    {
      "source": "6yENDA7J4G",
      "target": "In simulations",
      "similarity": 0.8303
    },
    {
      "source": "6yENDA7J4G",
      "target": "hoYFLRNbhc",
      "similarity": 0.8243
    },
    {
      "source": "xiQNfYl33p",
      "target": "QowsEic1sc",
      "similarity": 0.8977
    },
    {
      "source": "xiQNfYl33p",
      "target": "stacking methods. Specifically",
      "similarity": 0.893
    },
    {
      "source": "xiQNfYl33p",
      "target": "2mqb8bPHeb",
      "similarity": 0.8725
    },
    {
      "source": "xiQNfYl33p",
      "target": "inference efficiency. Post-training pruning is a promising method that does not",
      "similarity": 0.8716
    },
    {
      "source": "xiQNfYl33p",
      "target": "wide dissemination",
      "similarity": 0.8678
    },
    {
      "source": "RC5FPYVQaH",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8594
    },
    {
      "source": "RC5FPYVQaH",
      "target": "In this paper",
      "similarity": 0.8583
    },
    {
      "source": "RC5FPYVQaH",
      "target": "However",
      "similarity": 0.8502
    },
    {
      "source": "RC5FPYVQaH",
      "target": "other baselines across all metrics",
      "similarity": 0.8487
    },
    {
      "source": "RC5FPYVQaH",
      "target": "J9FgrqOOni",
      "similarity": 0.8464
    },
    {
      "source": "jDsmB4o5S0",
      "target": "However",
      "similarity": 0.8903
    },
    {
      "source": "jDsmB4o5S0",
      "target": "uHLgDEgiS5",
      "similarity": 0.8519
    },
    {
      "source": "jDsmB4o5S0",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8503
    },
    {
      "source": "jDsmB4o5S0",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8477
    },
    {
      "source": "jDsmB4o5S0",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8393
    },
    {
      "source": "txV4dNeusx",
      "target": "4GT9uTsAJE",
      "similarity": 0.8552
    },
    {
      "source": "txV4dNeusx",
      "target": "iVMcYxTiVM",
      "similarity": 0.8544
    },
    {
      "source": "txV4dNeusx",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8447
    },
    {
      "source": "txV4dNeusx",
      "target": "Finally",
      "similarity": 0.8366
    },
    {
      "source": "txV4dNeusx",
      "target": "{Subsequently}",
      "similarity": 0.8364
    },
    {
      "source": "oI5tZaWkF9",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8194
    },
    {
      "source": "oI5tZaWkF9",
      "target": "To address the lack of annotations on levels of severity",
      "similarity": 0.8162
    },
    {
      "source": "oI5tZaWkF9",
      "target": "zigzag spaghetti (ZS)",
      "similarity": 0.8118
    },
    {
      "source": "oI5tZaWkF9",
      "target": "41uZB8bDFh",
      "similarity": 0.8105
    },
    {
      "source": "oI5tZaWkF9",
      "target": "GhexuBLxbO",
      "similarity": 0.8098
    },
    {
      "source": "KL8Sm4xRn7",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8278
    },
    {
      "source": "KL8Sm4xRn7",
      "target": "70B-base from 8K to 128K tokens",
      "similarity": 0.8086
    },
    {
      "source": "KL8Sm4xRn7",
      "target": "2c7pfOqu9k",
      "similarity": 0.8009
    },
    {
      "source": "KL8Sm4xRn7",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.7994
    },
    {
      "source": "KL8Sm4xRn7",
      "target": "vaJ4FObpXN",
      "similarity": 0.7934
    },
    {
      "source": "lBntjGbyv0",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8228
    },
    {
      "source": "lBntjGbyv0",
      "target": "Without labeled calibration data for target domains",
      "similarity": 0.8155
    },
    {
      "source": "lBntjGbyv0",
      "target": "edge insertion graph stream",
      "similarity": 0.8081
    },
    {
      "source": "lBntjGbyv0",
      "target": "Subsequently",
      "similarity": 0.8062
    },
    {
      "source": "lBntjGbyv0",
      "target": "TlAdgeoDTo",
      "similarity": 0.8052
    },
    {
      "source": "P4XmKjXTrM",
      "target": "97rOQDPmk2",
      "similarity": 0.8387
    },
    {
      "source": "P4XmKjXTrM",
      "target": "gsShHPxkUW",
      "similarity": 0.8331
    },
    {
      "source": "P4XmKjXTrM",
      "target": "This corresponds to",
      "similarity": 0.8314
    },
    {
      "source": "P4XmKjXTrM",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.831
    },
    {
      "source": "P4XmKjXTrM",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.8295
    },
    {
      "source": "rakhNY32vw",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8505
    },
    {
      "source": "rakhNY32vw",
      "target": "This paper introduces WebRL",
      "similarity": 0.8314
    },
    {
      "source": "rakhNY32vw",
      "target": "and (iii) can be effectively applied to corpus-linguistic analyses of Latin",
      "similarity": 0.8273
    },
    {
      "source": "rakhNY32vw",
      "target": "04qx93Viwj",
      "similarity": 0.8243
    },
    {
      "source": "rakhNY32vw",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.8239
    },
    {
      "source": "Along our analysis",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8474
    },
    {
      "source": "Along our analysis",
      "target": "However",
      "similarity": 0.8267
    },
    {
      "source": "Along our analysis",
      "target": "u3TL0qxLWf",
      "similarity": 0.8258
    },
    {
      "source": "Along our analysis",
      "target": "Following these principles",
      "similarity": 0.8254
    },
    {
      "source": "Along our analysis",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.8232
    },
    {
      "source": "J9VogDTa1W",
      "target": "we obtain the first",
      "similarity": 0.8819
    },
    {
      "source": "J9VogDTa1W",
      "target": "We also observe that the abstracted high-order actions are potentially interpretable",
      "similarity": 0.8744
    },
    {
      "source": "J9VogDTa1W",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8692
    },
    {
      "source": "J9VogDTa1W",
      "target": "In support of the probabilistic perspective",
      "similarity": 0.8675
    },
    {
      "source": "J9VogDTa1W",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8667
    },
    {
      "source": "vRvVVb0NAz",
      "target": "AmEgWDhmTr",
      "similarity": 0.8243
    },
    {
      "source": "vRvVVb0NAz",
      "target": "HqjRlT65WX",
      "similarity": 0.8161
    },
    {
      "source": "vRvVVb0NAz",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.8045
    },
    {
      "source": "vRvVVb0NAz",
      "target": "2c7pfOqu9k",
      "similarity": 0.801
    },
    {
      "source": "vRvVVb0NAz",
      "target": "PwxYoMvmvy",
      "similarity": 0.7987
    },
    {
      "source": "iVMcYxTiVM",
      "target": "RAyRXQjsFl",
      "similarity": 0.8553
    },
    {
      "source": "iVMcYxTiVM",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8519
    },
    {
      "source": "iVMcYxTiVM",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8448
    },
    {
      "source": "iVMcYxTiVM",
      "target": "In this paper",
      "similarity": 0.8444
    },
    {
      "source": "iVMcYxTiVM",
      "target": "uSz2K30RRd",
      "similarity": 0.8435
    },
    {
      "source": "As a first step towards a better understanding",
      "target": "bilities",
      "similarity": 0.8644
    },
    {
      "source": "As a first step towards a better understanding",
      "target": "TDy5Ih78b4",
      "similarity": 0.8614
    },
    {
      "source": "As a first step towards a better understanding",
      "target": "**8.6%** and **4.3%** over the state-of-the-art",
      "similarity": 0.8603
    },
    {
      "source": "As a first step towards a better understanding",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8579
    },
    {
      "source": "As a first step towards a better understanding",
      "target": "However",
      "similarity": 0.8549
    },
    {
      "source": "As expected",
      "target": "sLKDbuyq99",
      "similarity": 0.8382
    },
    {
      "source": "As expected",
      "target": "Second",
      "similarity": 0.8305
    },
    {
      "source": "As expected",
      "target": "In this paper",
      "similarity": 0.8299
    },
    {
      "source": "As expected",
      "target": "the weights of other group-unlabeled data. We introduce Group-robust Sample",
      "similarity": 0.8276
    },
    {
      "source": "As expected",
      "target": "For the diversity",
      "similarity": 0.8263
    },
    {
      "source": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "target": "First",
      "similarity": 0.8529
    },
    {
      "source": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "target": "achieving up to **88\\% performance improvement** on 3D reconstruction",
      "similarity": 0.8508
    },
    {
      "source": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "target": "pDDODPtpx9",
      "similarity": 0.8459
    },
    {
      "source": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.8448
    },
    {
      "source": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "target": "From these insights",
      "similarity": 0.8442
    },
    {
      "source": "Interestingly",
      "target": "FrFQpAgnGE",
      "similarity": 0.8739
    },
    {
      "source": "Interestingly",
      "target": "Furthermore",
      "similarity": 0.8624
    },
    {
      "source": "Interestingly",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8619
    },
    {
      "source": "Interestingly",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8613
    },
    {
      "source": "Interestingly",
      "target": "otW0TJOUYF",
      "similarity": 0.8602
    },
    {
      "source": "emMMa4q0qw",
      "target": "4GT9uTsAJE",
      "similarity": 0.7774
    },
    {
      "source": "emMMa4q0qw",
      "target": "We first propose a joint influence measure to assess the contribution of a set of neurons to the model outcome.",
      "similarity": 0.7717
    },
    {
      "source": "emMMa4q0qw",
      "target": "As a byproduct of our methods",
      "similarity": 0.7711
    },
    {
      "source": "emMMa4q0qw",
      "target": "up training of standard benchmarks like BERT and UL2",
      "similarity": 0.771
    },
    {
      "source": "emMMa4q0qw",
      "target": "4iFSBgxvIO",
      "similarity": 0.7667
    },
    {
      "source": "LrmPGtnros",
      "target": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "similarity": 0.8241
    },
    {
      "source": "LrmPGtnros",
      "target": "we address this problem by using a small amount of labeled sensitive data.",
      "similarity": 0.8168
    },
    {
      "source": "LrmPGtnros",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8147
    },
    {
      "source": "LrmPGtnros",
      "target": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "similarity": 0.8084
    },
    {
      "source": "LrmPGtnros",
      "target": "INyi7qUdjZ",
      "similarity": 0.8066
    },
    {
      "source": "6VhDQP7WGX",
      "target": "rJ5g8ueQaI",
      "similarity": 0.8277
    },
    {
      "source": "6VhDQP7WGX",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8223
    },
    {
      "source": "6VhDQP7WGX",
      "target": "We5z3UEnUY",
      "similarity": 0.8171
    },
    {
      "source": "6VhDQP7WGX",
      "target": "KxQRHOre9D",
      "similarity": 0.8168
    },
    {
      "source": "6VhDQP7WGX",
      "target": "We apply WebRL to transform Llama-3.1 models into proficient web agents",
      "similarity": 0.8154
    },
    {
      "source": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8478
    },
    {
      "source": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "target": "In this paper",
      "similarity": 0.8363
    },
    {
      "source": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "target": "ssRdQimeUI",
      "similarity": 0.8325
    },
    {
      "source": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "target": "imT03YXlG2",
      "similarity": 0.8323
    },
    {
      "source": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "target": "kxnoqaisCT",
      "similarity": 0.8249
    },
    {
      "source": "EkfLaCJ7bk",
      "target": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "similarity": 0.871
    },
    {
      "source": "EkfLaCJ7bk",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8624
    },
    {
      "source": "EkfLaCJ7bk",
      "target": "{Subsequently}",
      "similarity": 0.8617
    },
    {
      "source": "EkfLaCJ7bk",
      "target": "wSkvf2WyYz",
      "similarity": 0.8571
    },
    {
      "source": "EkfLaCJ7bk",
      "target": "5IWJBStfU7",
      "similarity": 0.857
    },
    {
      "source": "H9UnNgdq0g",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8394
    },
    {
      "source": "H9UnNgdq0g",
      "target": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "similarity": 0.8386
    },
    {
      "source": "H9UnNgdq0g",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8384
    },
    {
      "source": "H9UnNgdq0g",
      "target": "Second",
      "similarity": 0.8322
    },
    {
      "source": "H9UnNgdq0g",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8312
    },
    {
      "source": "kbjJ9ZOakb",
      "target": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "similarity": 0.8078
    },
    {
      "source": "kbjJ9ZOakb",
      "target": "(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences;",
      "similarity": 0.7948
    },
    {
      "source": "kbjJ9ZOakb",
      "target": "Through empirical and theoretical validation",
      "similarity": 0.791
    },
    {
      "source": "kbjJ9ZOakb",
      "target": "ptjrpEGrGg",
      "similarity": 0.7892
    },
    {
      "source": "kbjJ9ZOakb",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.7882
    },
    {
      "source": "GTcEe5fayC",
      "target": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "similarity": 0.8419
    },
    {
      "source": "GTcEe5fayC",
      "target": "60GeEoG5kD",
      "similarity": 0.8288
    },
    {
      "source": "GTcEe5fayC",
      "target": "AC5n7xHuR1",
      "similarity": 0.8259
    },
    {
      "source": "GTcEe5fayC",
      "target": "mFY0tPDWK8",
      "similarity": 0.8252
    },
    {
      "source": "GTcEe5fayC",
      "target": "cADpvQgnqg",
      "similarity": 0.823
    },
    {
      "source": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "target": "9KiE3t6CsL",
      "similarity": 0.8273
    },
    {
      "source": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "target": "Our code is available at https://github.com/XuandongZhao/PRC-Watermark.\"",
      "similarity": 0.8269
    },
    {
      "source": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "target": "that train models or perform hyperparameter tuning using the group-labeled data",
      "similarity": 0.8265
    },
    {
      "source": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "target": "8TBGdH3t6a",
      "similarity": 0.8238
    },
    {
      "source": "With the proven success of Vision Transformers (ViTs) in supervised tasks",
      "target": "Subsequently",
      "similarity": 0.8128
    },
    {
      "source": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "target": "BCP5nAHXqs",
      "similarity": 0.8331
    },
    {
      "source": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "target": "To be specific",
      "similarity": 0.8321
    },
    {
      "source": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "target": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "similarity": 0.8291
    },
    {
      "source": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "target": "XdRIno98gG",
      "similarity": 0.8286
    },
    {
      "source": "Recent studies in supervised learning have shown that token pruning can reduce training costs by removing less informative tokens without compromising accuracy. However",
      "target": "5pd78GmXC6",
      "similarity": 0.8286
    },
    {
      "source": "To this end",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8395
    },
    {
      "source": "To this end",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8376
    },
    {
      "source": "To this end",
      "target": "yLhJYvkKA0",
      "similarity": 0.8325
    },
    {
      "source": "To this end",
      "target": "{Subsequently}",
      "similarity": 0.8323
    },
    {
      "source": "To this end",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8305
    },
    {
      "source": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8247
    },
    {
      "source": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "target": "seriously affected even it contains a set of independently trained sub-models. To address this issue",
      "similarity": 0.8238
    },
    {
      "source": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "target": "Our work formally extends Transformers to capture the nuances of time and space continuity in both input and output space.",
      "similarity": 0.8117
    },
    {
      "source": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "target": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "similarity": 0.8093
    },
    {
      "source": "Experimental results show that our proposed approach effectively reduces training computation while maintaining accuracy. Specifically",
      "target": "4BFzTrIjPN",
      "similarity": 0.8039
    },
    {
      "source": "GpUv1FvZi1",
      "target": "TDy5Ih78b4",
      "similarity": 0.861
    },
    {
      "source": "GpUv1FvZi1",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.8606
    },
    {
      "source": "GpUv1FvZi1",
      "target": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "similarity": 0.8544
    },
    {
      "source": "GpUv1FvZi1",
      "target": "FrFQpAgnGE",
      "similarity": 0.8411
    },
    {
      "source": "GpUv1FvZi1",
      "target": "Ax0i933gtp",
      "similarity": 0.8406
    },
    {
      "source": "However",
      "target": "k3tbMMW8rH",
      "similarity": 0.8821
    },
    {
      "source": "However",
      "target": "g6v09VxgFw",
      "similarity": 0.8449
    },
    {
      "source": "However",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8309
    },
    {
      "source": "However",
      "target": "yaQbTAD2JJ",
      "similarity": 0.8228
    },
    {
      "source": "However",
      "target": "Our evaluations indicate that based on o1-preview",
      "similarity": 0.8213
    },
    {
      "source": "k3tbMMW8rH",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8272
    },
    {
      "source": "k3tbMMW8rH",
      "target": "g6v09VxgFw",
      "similarity": 0.8234
    },
    {
      "source": "k3tbMMW8rH",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.8202
    },
    {
      "source": "k3tbMMW8rH",
      "target": "gfI9v7AbFg",
      "similarity": 0.8198
    },
    {
      "source": "k3tbMMW8rH",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.817
    },
    {
      "source": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "target": "x83w6yGIWb",
      "similarity": 0.8186
    },
    {
      "source": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "target": "exgLs4snap",
      "similarity": 0.8166
    },
    {
      "source": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "target": "sVNfWhtaJC",
      "similarity": 0.8131
    },
    {
      "source": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "target": "GBIUbwW9D8",
      "similarity": 0.8106
    },
    {
      "source": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "target": "will be available at https://github.com/Eric-qi/NeuroQuant.\"",
      "similarity": 0.8073
    },
    {
      "source": "To strike a balance between scalability and minimal supervision",
      "target": "7mlvOHL6qJ",
      "similarity": 0.8684
    },
    {
      "source": "To strike a balance between scalability and minimal supervision",
      "target": "Ultimately",
      "similarity": 0.8638
    },
    {
      "source": "To strike a balance between scalability and minimal supervision",
      "target": "i1NNCrRxdM",
      "similarity": 0.8577
    },
    {
      "source": "To strike a balance between scalability and minimal supervision",
      "target": "6ycX677p2l",
      "similarity": 0.8544
    },
    {
      "source": "To strike a balance between scalability and minimal supervision",
      "target": "We investigate LLMs predicting properties of their own behavior in hypothetical situations. If a model M1 has this capability",
      "similarity": 0.8534
    },
    {
      "source": "PgXpOOqtyd",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.8359
    },
    {
      "source": "PgXpOOqtyd",
      "target": "wCOJpXm0Me",
      "similarity": 0.8317
    },
    {
      "source": "PgXpOOqtyd",
      "target": "spDUv05cEq",
      "similarity": 0.8215
    },
    {
      "source": "PgXpOOqtyd",
      "target": "that we can output a $\\kappa$-approximation using space only",
      "similarity": 0.8091
    },
    {
      "source": "PgXpOOqtyd",
      "target": "DTqx3iqjkz",
      "similarity": 0.8061
    },
    {
      "source": "Ym2RNPX6la",
      "target": "as representations of instances. In this work",
      "similarity": 0.8383
    },
    {
      "source": "Ym2RNPX6la",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.8191
    },
    {
      "source": "Ym2RNPX6la",
      "target": "tijmpS9Vy2",
      "similarity": 0.8167
    },
    {
      "source": "Ym2RNPX6la",
      "target": "To tackle this challenge",
      "similarity": 0.8132
    },
    {
      "source": "Ym2RNPX6la",
      "target": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "similarity": 0.8102
    },
    {
      "source": "VOoJEQlLW5",
      "target": "that enable researchers to (i) flexibly process and download the BoneMet data",
      "similarity": 0.8236
    },
    {
      "source": "VOoJEQlLW5",
      "target": "a corresponding variational inference method utilizing a Weibull variational in-",
      "similarity": 0.7968
    },
    {
      "source": "VOoJEQlLW5",
      "target": "However",
      "similarity": 0.774
    },
    {
      "source": "VOoJEQlLW5",
      "target": "lvw3UgeVxS",
      "similarity": 0.7675
    },
    {
      "source": "VOoJEQlLW5",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.7592
    },
    {
      "source": "7VkHffT5X2",
      "target": "tectural components in preventing rank collapse.\"",
      "similarity": 0.819
    },
    {
      "source": "7VkHffT5X2",
      "target": "However",
      "similarity": 0.8078
    },
    {
      "source": "7VkHffT5X2",
      "target": "Consequently",
      "similarity": 0.8069
    },
    {
      "source": "7VkHffT5X2",
      "target": "of extreme weather events",
      "similarity": 0.8063
    },
    {
      "source": "7VkHffT5X2",
      "target": "KV state reuse and computation load-balancing with a new scheduling algorithm and a",
      "similarity": 0.8056
    },
    {
      "source": "U0SijGsCHJ",
      "target": "This paper introduces PANGEA",
      "similarity": 0.8137
    },
    {
      "source": "U0SijGsCHJ",
      "target": "In this paper",
      "similarity": 0.7974
    },
    {
      "source": "U0SijGsCHJ",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.7943
    },
    {
      "source": "U0SijGsCHJ",
      "target": "vbmSSIhKAM",
      "similarity": 0.7843
    },
    {
      "source": "U0SijGsCHJ",
      "target": "x1yOHtFfDh",
      "similarity": 0.7796
    },
    {
      "source": "oYSsbY3G4o",
      "target": "FEpAUnS7f7",
      "similarity": 0.8289
    },
    {
      "source": "oYSsbY3G4o",
      "target": "1jcnvghayD",
      "similarity": 0.8052
    },
    {
      "source": "oYSsbY3G4o",
      "target": "vue9P1Ypk6",
      "similarity": 0.8052
    },
    {
      "source": "oYSsbY3G4o",
      "target": "heuristic algorithms. Recent advancements in deep learning have led to the development of learning-based heuristics",
      "similarity": 0.8048
    },
    {
      "source": "oYSsbY3G4o",
      "target": "m5qpn0KTMZ",
      "similarity": 0.8034
    },
    {
      "source": "m5qpn0KTMZ",
      "target": "Prior work developed UCB-style",
      "similarity": 0.7922
    },
    {
      "source": "m5qpn0KTMZ",
      "target": "nt8gBX58Kh",
      "similarity": 0.784
    },
    {
      "source": "m5qpn0KTMZ",
      "target": "In this work",
      "similarity": 0.781
    },
    {
      "source": "m5qpn0KTMZ",
      "target": "AZR4R3lw7y",
      "similarity": 0.7771
    },
    {
      "source": "m5qpn0KTMZ",
      "target": "Our novel resource",
      "similarity": 0.7729
    },
    {
      "source": "Using this extension",
      "target": "Qja5s0K3VX",
      "similarity": 0.8764
    },
    {
      "source": "Using this extension",
      "target": "Previous studies have developed LLM assistants",
      "similarity": 0.8674
    },
    {
      "source": "Using this extension",
      "target": "previous results.\"",
      "similarity": 0.8646
    },
    {
      "source": "Using this extension",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8637
    },
    {
      "source": "Using this extension",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8633
    },
    {
      "source": "Among these",
      "target": "E2PFv7ad3p",
      "similarity": 0.8582
    },
    {
      "source": "Among these",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8348
    },
    {
      "source": "Among these",
      "target": "Second",
      "similarity": 0.8295
    },
    {
      "source": "Among these",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8294
    },
    {
      "source": "Among these",
      "target": "kX8h23UG6v",
      "similarity": 0.826
    },
    {
      "source": "Bayes Hilbert spaces are frequently used due to their inherent connection to Bayes's theorem. They allow sampling from potentially intractable posterior densities",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.8343
    },
    {
      "source": "Bayes Hilbert spaces are frequently used due to their inherent connection to Bayes's theorem. They allow sampling from potentially intractable posterior densities",
      "target": "MMwaQEVsAg",
      "similarity": 0.8273
    },
    {
      "source": "Bayes Hilbert spaces are frequently used due to their inherent connection to Bayes's theorem. They allow sampling from potentially intractable posterior densities",
      "target": "latent variables",
      "similarity": 0.8235
    },
    {
      "source": "Bayes Hilbert spaces are frequently used due to their inherent connection to Bayes's theorem. They allow sampling from potentially intractable posterior densities",
      "target": "bRa4JLPzii",
      "similarity": 0.8199
    },
    {
      "source": "Bayes Hilbert spaces are frequently used due to their inherent connection to Bayes's theorem. They allow sampling from potentially intractable posterior densities",
      "target": "high-quality solutions while achieving unprecedented compression rates across",
      "similarity": 0.8191
    },
    {
      "source": "In the more general context",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.855
    },
    {
      "source": "In the more general context",
      "target": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "similarity": 0.8523
    },
    {
      "source": "In the more general context",
      "target": "memorization.",
      "similarity": 0.8489
    },
    {
      "source": "In the more general context",
      "target": "GRMfXcAAFh",
      "similarity": 0.8441
    },
    {
      "source": "In the more general context",
      "target": "EMMnAd3apQ",
      "similarity": 0.8434
    },
    {
      "source": "By applying this variational estimation framework to $f$-GANs",
      "target": "Next",
      "similarity": 0.8309
    },
    {
      "source": "By applying this variational estimation framework to $f$-GANs",
      "target": "confine RL agents to simulated environments",
      "similarity": 0.8288
    },
    {
      "source": "By applying this variational estimation framework to $f$-GANs",
      "target": "71pur4y8gs",
      "similarity": 0.8272
    },
    {
      "source": "By applying this variational estimation framework to $f$-GANs",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.8209
    },
    {
      "source": "By applying this variational estimation framework to $f$-GANs",
      "target": "2c7pfOqu9k",
      "similarity": 0.8191
    },
    {
      "source": "wSkvf2WyYz",
      "target": "4GT9uTsAJE",
      "similarity": 0.8509
    },
    {
      "source": "wSkvf2WyYz",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8482
    },
    {
      "source": "wSkvf2WyYz",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8423
    },
    {
      "source": "wSkvf2WyYz",
      "target": "4iFSBgxvIO",
      "similarity": 0.8418
    },
    {
      "source": "wSkvf2WyYz",
      "target": "{Subsequently}",
      "similarity": 0.8389
    },
    {
      "source": "Pj06mxCXPl",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8213
    },
    {
      "source": "Pj06mxCXPl",
      "target": "K5yeB4dTtS",
      "similarity": 0.8055
    },
    {
      "source": "Pj06mxCXPl",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.7988
    },
    {
      "source": "Pj06mxCXPl",
      "target": "C45YqeBDUM",
      "similarity": 0.79
    },
    {
      "source": "Pj06mxCXPl",
      "target": "VMV8gefvq8",
      "similarity": 0.7859
    },
    {
      "source": "Dl6nkKKvlX",
      "target": "To address these challenges",
      "similarity": 0.8207
    },
    {
      "source": "Dl6nkKKvlX",
      "target": "analogous kernel regression. By finding a lower bound on the smallest eigenvalue",
      "similarity": 0.8165
    },
    {
      "source": "Dl6nkKKvlX",
      "target": "FBkpCyujtS",
      "similarity": 0.8164
    },
    {
      "source": "Dl6nkKKvlX",
      "target": "However",
      "similarity": 0.8115
    },
    {
      "source": "Dl6nkKKvlX",
      "target": "wgRQ2WAORJ",
      "similarity": 0.8088
    },
    {
      "source": "wLnls9LS3x",
      "target": "yLhJYvkKA0",
      "similarity": 0.8428
    },
    {
      "source": "wLnls9LS3x",
      "target": "tXUkT709OJ",
      "similarity": 0.8332
    },
    {
      "source": "wLnls9LS3x",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8285
    },
    {
      "source": "wLnls9LS3x",
      "target": "{Subsequently}",
      "similarity": 0.8252
    },
    {
      "source": "wLnls9LS3x",
      "target": "DwqoBkj2Mw",
      "similarity": 0.8241
    },
    {
      "source": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "target": "models. However",
      "similarity": 0.8457
    },
    {
      "source": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "target": "To this end",
      "similarity": 0.8453
    },
    {
      "source": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "target": "pDDODPtpx9",
      "similarity": 0.8402
    },
    {
      "source": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "target": "Yet",
      "similarity": 0.8382
    },
    {
      "source": "$K$'s columns are indexed by a set of $n$ keys $k_1",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.838
    },
    {
      "source": "7WaRh4gCXp",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8348
    },
    {
      "source": "7WaRh4gCXp",
      "target": "This phenomenon is elucidated by insights derived from the principles of attention mechanisms.",
      "similarity": 0.8316
    },
    {
      "source": "7WaRh4gCXp",
      "target": "Subsequently",
      "similarity": 0.8299
    },
    {
      "source": "7WaRh4gCXp",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8296
    },
    {
      "source": "7WaRh4gCXp",
      "target": "solution. For $p = 1$",
      "similarity": 0.8282
    },
    {
      "source": "Previous approaches mainly predict the next best view near the agent's location",
      "target": "0T49QbSOho",
      "similarity": 0.8072
    },
    {
      "source": "Previous approaches mainly predict the next best view near the agent's location",
      "target": "te2IdORabL",
      "similarity": 0.8049
    },
    {
      "source": "Previous approaches mainly predict the next best view near the agent's location",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.7947
    },
    {
      "source": "Previous approaches mainly predict the next best view near the agent's location",
      "target": "with compression rates of 25-30%. The compression process can be completed on",
      "similarity": 0.7905
    },
    {
      "source": "Previous approaches mainly predict the next best view near the agent's location",
      "target": "Our codebase",
      "similarity": 0.79
    },
    {
      "source": "To overcome these limitations",
      "target": "This limitation could explain why RoPE performs poorly in extrapolation.",
      "similarity": 0.8592
    },
    {
      "source": "To overcome these limitations",
      "target": "R4q3cY3kQf",
      "similarity": 0.8572
    },
    {
      "source": "To overcome these limitations",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8556
    },
    {
      "source": "To overcome these limitations",
      "target": "l6QnSQizmN",
      "similarity": 0.8546
    },
    {
      "source": "To overcome these limitations",
      "target": "otW0TJOUYF",
      "similarity": 0.8541
    },
    {
      "source": "Moreover",
      "target": "traditional energy-based models",
      "similarity": 0.8537
    },
    {
      "source": "Moreover",
      "target": "vVxeFSR4fU",
      "similarity": 0.8426
    },
    {
      "source": "Moreover",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.8405
    },
    {
      "source": "Moreover",
      "target": "1CIUkpoata",
      "similarity": 0.8367
    },
    {
      "source": "Moreover",
      "target": "41uZB8bDFh",
      "similarity": 0.8333
    },
    {
      "source": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "target": "In this paper",
      "similarity": 0.8131
    },
    {
      "source": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "target": "also study the necessity of this condition via ablation studies and analytical exam-",
      "similarity": 0.8073
    },
    {
      "source": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "target": "K7xpl3LZQp",
      "similarity": 0.8069
    },
    {
      "source": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "target": "tePFpDgyqg",
      "similarity": 0.8037
    },
    {
      "source": "The model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps",
      "target": "xiQNfYl33p",
      "similarity": 0.7999
    },
    {
      "source": "By leveraging online data collection",
      "target": "standard training and",
      "similarity": 0.8487
    },
    {
      "source": "By leveraging online data collection",
      "target": "7bAjVh3CG3",
      "similarity": 0.8366
    },
    {
      "source": "By leveraging online data collection",
      "target": "In this paper",
      "similarity": 0.8202
    },
    {
      "source": "By leveraging online data collection",
      "target": "hance the LLM selection process. GraphRouter constructs a heterogeneous",
      "similarity": 0.8179
    },
    {
      "source": "By leveraging online data collection",
      "target": "a dependency parser",
      "similarity": 0.8164
    },
    {
      "source": "wCOJpXm0Me",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8347
    },
    {
      "source": "wCOJpXm0Me",
      "target": "zXCnIyX9MG",
      "similarity": 0.8154
    },
    {
      "source": "wCOJpXm0Me",
      "target": "which",
      "similarity": 0.8142
    },
    {
      "source": "wCOJpXm0Me",
      "target": "kNHVViEPWK",
      "similarity": 0.8097
    },
    {
      "source": "wCOJpXm0Me",
      "target": "sound",
      "similarity": 0.8055
    },
    {
      "source": "TvfkSyHZRA",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8047
    },
    {
      "source": "TvfkSyHZRA",
      "target": "Furthermore",
      "similarity": 0.8043
    },
    {
      "source": "TvfkSyHZRA",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.7958
    },
    {
      "source": "TvfkSyHZRA",
      "target": "The Pareto front identifies the set of policies that cannot be dominated",
      "similarity": 0.7915
    },
    {
      "source": "TvfkSyHZRA",
      "target": "Furthermore",
      "similarity": 0.7873
    },
    {
      "source": "ptjrpEGrGg",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8471
    },
    {
      "source": "ptjrpEGrGg",
      "target": "cADpvQgnqg",
      "similarity": 0.8461
    },
    {
      "source": "ptjrpEGrGg",
      "target": "otW0TJOUYF",
      "similarity": 0.8431
    },
    {
      "source": "ptjrpEGrGg",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.843
    },
    {
      "source": "ptjrpEGrGg",
      "target": "GRMfXcAAFh",
      "similarity": 0.8429
    },
    {
      "source": "With $T$ as the total number of iterations",
      "target": "show that BoneMet can be readily adopted to build versatile",
      "similarity": 0.844
    },
    {
      "source": "With $T$ as the total number of iterations",
      "target": "However",
      "similarity": 0.8413
    },
    {
      "source": "With $T$ as the total number of iterations",
      "target": "ULorFBST6X",
      "similarity": 0.8357
    },
    {
      "source": "With $T$ as the total number of iterations",
      "target": "directly in real-world settings. In this work",
      "similarity": 0.835
    },
    {
      "source": "With $T$ as the total number of iterations",
      "target": "Following these principles",
      "similarity": 0.8338
    },
    {
      "source": "AUCYptvAf3",
      "target": "To this end",
      "similarity": 0.8536
    },
    {
      "source": "AUCYptvAf3",
      "target": "To this end",
      "similarity": 0.8473
    },
    {
      "source": "AUCYptvAf3",
      "target": "Se6MgCtRhz",
      "similarity": 0.8404
    },
    {
      "source": "AUCYptvAf3",
      "target": "JSB171dSUU",
      "similarity": 0.8396
    },
    {
      "source": "AUCYptvAf3",
      "target": "Yet",
      "similarity": 0.8388
    },
    {
      "source": "8enWnd6Gp3",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8325
    },
    {
      "source": "8enWnd6Gp3",
      "target": "ogXkmugNZw",
      "similarity": 0.8163
    },
    {
      "source": "8enWnd6Gp3",
      "target": "Moreover",
      "similarity": 0.8119
    },
    {
      "source": "8enWnd6Gp3",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8106
    },
    {
      "source": "8enWnd6Gp3",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8072
    },
    {
      "source": "QowsEic1sc",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8723
    },
    {
      "source": "QowsEic1sc",
      "target": "nibeaHUEJx",
      "similarity": 0.862
    },
    {
      "source": "QowsEic1sc",
      "target": "Second",
      "similarity": 0.8603
    },
    {
      "source": "QowsEic1sc",
      "target": "stacking methods. Specifically",
      "similarity": 0.8592
    },
    {
      "source": "QowsEic1sc",
      "target": "relying on backward propagation",
      "similarity": 0.8581
    },
    {
      "source": "kxnoqaisCT",
      "target": "Zjv38dg1Hb",
      "similarity": 0.8678
    },
    {
      "source": "kxnoqaisCT",
      "target": "Here",
      "similarity": 0.8533
    },
    {
      "source": "kxnoqaisCT",
      "target": "In this paper",
      "similarity": 0.8383
    },
    {
      "source": "kxnoqaisCT",
      "target": "H0qIWXXLUR",
      "similarity": 0.838
    },
    {
      "source": "kxnoqaisCT",
      "target": "8DBTq09LgN",
      "similarity": 0.835
    },
    {
      "source": "fifXzmzeGy",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8348
    },
    {
      "source": "fifXzmzeGy",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8318
    },
    {
      "source": "fifXzmzeGy",
      "target": "object and prompt the VLM to correct deviations. To evaluate CADCodeVerify",
      "similarity": 0.8194
    },
    {
      "source": "fifXzmzeGy",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8151
    },
    {
      "source": "fifXzmzeGy",
      "target": "gVnJFY8nCM",
      "similarity": 0.8138
    },
    {
      "source": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "target": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "similarity": 0.8626
    },
    {
      "source": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "target": "GpdO9r73xT",
      "similarity": 0.8197
    },
    {
      "source": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "target": "70B-base from 8K to 128K tokens",
      "similarity": 0.8163
    },
    {
      "source": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8116
    },
    {
      "source": "_**posteriors**_ repository: https://github.com/normal-computing/posteriors\"",
      "target": "nx9Z5Kva96",
      "similarity": 0.8076
    },
    {
      "source": "jJXZvPe5z0",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8427
    },
    {
      "source": "jJXZvPe5z0",
      "target": "which",
      "similarity": 0.8315
    },
    {
      "source": "jJXZvPe5z0",
      "target": "KSLkFYHlYg",
      "similarity": 0.8307
    },
    {
      "source": "jJXZvPe5z0",
      "target": "reZKq6hjOZ",
      "similarity": 0.8268
    },
    {
      "source": "jJXZvPe5z0",
      "target": "G328D1xt4W",
      "similarity": 0.8238
    },
    {
      "source": "Regret",
      "target": "By contrast",
      "similarity": 0.7963
    },
    {
      "source": "Regret",
      "target": "ptjrpEGrGg",
      "similarity": 0.7948
    },
    {
      "source": "Regret",
      "target": "there's been a notable gap in considering layer-level information and the holistic path of information flow across layers.",
      "similarity": 0.7887
    },
    {
      "source": "Regret",
      "target": "mPdmDYIQ7f",
      "similarity": 0.7854
    },
    {
      "source": "Regret",
      "target": "K5yeB4dTtS",
      "similarity": 0.7829
    },
    {
      "source": "We prove that any proportional content ranking function with a concave activation function induces games in which no-regret learning dynamics converge.",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8402
    },
    {
      "source": "We prove that any proportional content ranking function with a concave activation function induces games in which no-regret learning dynamics converge.",
      "target": "(SWA). Samba selectively compresses a given sequence into recurrent hidden",
      "similarity": 0.8378
    },
    {
      "source": "We prove that any proportional content ranking function with a concave activation function induces games in which no-regret learning dynamics converge.",
      "target": "hoYFLRNbhc",
      "similarity": 0.8294
    },
    {
      "source": "We prove that any proportional content ranking function with a concave activation function induces games in which no-regret learning dynamics converge.",
      "target": "A1HhtITVEi",
      "similarity": 0.8248
    },
    {
      "source": "We prove that any proportional content ranking function with a concave activation function induces games in which no-regret learning dynamics converge.",
      "target": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "similarity": 0.8199
    },
    {
      "source": "Moreover",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8464
    },
    {
      "source": "Moreover",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8453
    },
    {
      "source": "Moreover",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8426
    },
    {
      "source": "Moreover",
      "target": "KzSGJy1PIf",
      "similarity": 0.8361
    },
    {
      "source": "Moreover",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8351
    },
    {
      "source": "We also study the empirical trade-offs between publishers' and users' welfare",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.8462
    },
    {
      "source": "We also study the empirical trade-offs between publishers' and users' welfare",
      "target": "hgwGi81ndj",
      "similarity": 0.8398
    },
    {
      "source": "We also study the empirical trade-offs between publishers' and users' welfare",
      "target": "Our framework",
      "similarity": 0.8392
    },
    {
      "source": "We also study the empirical trade-offs between publishers' and users' welfare",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8353
    },
    {
      "source": "We also study the empirical trade-offs between publishers' and users' welfare",
      "target": "PxlfzEePC0",
      "similarity": 0.833
    },
    {
      "source": "tRNKe2Vgqt",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.8066
    },
    {
      "source": "tRNKe2Vgqt",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.7958
    },
    {
      "source": "tRNKe2Vgqt",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.7956
    },
    {
      "source": "tRNKe2Vgqt",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.7861
    },
    {
      "source": "tRNKe2Vgqt",
      "target": "x33vSZUg0A",
      "similarity": 0.7818
    },
    {
      "source": "TKuYWeFE6S",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8672
    },
    {
      "source": "TKuYWeFE6S",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8541
    },
    {
      "source": "TKuYWeFE6S",
      "target": "First",
      "similarity": 0.8511
    },
    {
      "source": "TKuYWeFE6S",
      "target": "2pNLknCTvG",
      "similarity": 0.8507
    },
    {
      "source": "TKuYWeFE6S",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8486
    },
    {
      "source": "9qpdDiDQ2H",
      "target": "txD9llAYn9",
      "similarity": 0.8658
    },
    {
      "source": "9qpdDiDQ2H",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.8581
    },
    {
      "source": "9qpdDiDQ2H",
      "target": "A1HhtITVEi",
      "similarity": 0.8543
    },
    {
      "source": "9qpdDiDQ2H",
      "target": "9KiE3t6CsL",
      "similarity": 0.8511
    },
    {
      "source": "9qpdDiDQ2H",
      "target": "To address these challenges",
      "similarity": 0.8506
    },
    {
      "source": "wgDB1QuxIA",
      "target": "In this work",
      "similarity": 0.8233
    },
    {
      "source": "wgDB1QuxIA",
      "target": "hPWWXpCaJ7",
      "similarity": 0.8222
    },
    {
      "source": "wgDB1QuxIA",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8069
    },
    {
      "source": "wgDB1QuxIA",
      "target": "bnINPG5A32",
      "similarity": 0.8059
    },
    {
      "source": "wgDB1QuxIA",
      "target": "Adapting tools from classical sampling theory",
      "similarity": 0.8047
    },
    {
      "source": "FhTAG591Ve",
      "target": "In this paper",
      "similarity": 0.8289
    },
    {
      "source": "FhTAG591Ve",
      "target": "size in stages. We show that this approach not only generalizes prior works like",
      "similarity": 0.8158
    },
    {
      "source": "FhTAG591Ve",
      "target": "LQzN6TRFg9",
      "similarity": 0.8124
    },
    {
      "source": "FhTAG591Ve",
      "target": "L238BAx0wP",
      "similarity": 0.8079
    },
    {
      "source": "FhTAG591Ve",
      "target": "Notably",
      "similarity": 0.8075
    },
    {
      "source": "dw9VUsSHGB",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.8292
    },
    {
      "source": "dw9VUsSHGB",
      "target": "named Pacmann",
      "similarity": 0.8247
    },
    {
      "source": "dw9VUsSHGB",
      "target": "irrtPRFksw",
      "similarity": 0.8182
    },
    {
      "source": "dw9VUsSHGB",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8154
    },
    {
      "source": "dw9VUsSHGB",
      "target": "limited training data. We introduce DEPfold",
      "similarity": 0.8137
    },
    {
      "source": "Unlike traditional function-level or file-level coding tasks",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8312
    },
    {
      "source": "Unlike traditional function-level or file-level coding tasks",
      "target": "aXwukBD6M6",
      "similarity": 0.8278
    },
    {
      "source": "Unlike traditional function-level or file-level coding tasks",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8227
    },
    {
      "source": "Unlike traditional function-level or file-level coding tasks",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8219
    },
    {
      "source": "Unlike traditional function-level or file-level coding tasks",
      "target": "st7XqFgbAH",
      "similarity": 0.8172
    },
    {
      "source": "yLhJYvkKA0",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.8716
    },
    {
      "source": "yLhJYvkKA0",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8705
    },
    {
      "source": "yLhJYvkKA0",
      "target": "fNMKqyvuZT",
      "similarity": 0.8665
    },
    {
      "source": "yLhJYvkKA0",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8661
    },
    {
      "source": "yLhJYvkKA0",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8656
    },
    {
      "source": "J0qTpmbSbh",
      "target": "MxbEiFRf39",
      "similarity": 0.7931
    },
    {
      "source": "J0qTpmbSbh",
      "target": "We thoroughly assess TORCHTITAN on the Llama 3.1 family of LLMs",
      "similarity": 0.7822
    },
    {
      "source": "J0qTpmbSbh",
      "target": "AjXkRZIvjB",
      "similarity": 0.7819
    },
    {
      "source": "J0qTpmbSbh",
      "target": "This paper introduces WebRL",
      "similarity": 0.7812
    },
    {
      "source": "J0qTpmbSbh",
      "target": "Other methods have focused on the low-budget regime",
      "similarity": 0.7789
    },
    {
      "source": "XsgHl54yO7",
      "target": "b57IG6N20B",
      "similarity": 0.8159
    },
    {
      "source": "XsgHl54yO7",
      "target": "stacking methods. Specifically",
      "similarity": 0.7913
    },
    {
      "source": "XsgHl54yO7",
      "target": "zGzs5SIwT8",
      "similarity": 0.791
    },
    {
      "source": "XsgHl54yO7",
      "target": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "similarity": 0.7905
    },
    {
      "source": "XsgHl54yO7",
      "target": "jY5oml9fe9",
      "similarity": 0.7904
    },
    {
      "source": "GdbQyFOUlJ",
      "target": "Experimentally",
      "similarity": 0.8315
    },
    {
      "source": "GdbQyFOUlJ",
      "target": "jDsmB4o5S0",
      "similarity": 0.8205
    },
    {
      "source": "GdbQyFOUlJ",
      "target": "(2) The probability of preferred responses may decrease",
      "similarity": 0.8201
    },
    {
      "source": "GdbQyFOUlJ",
      "target": "8y5Uf6oEiB",
      "similarity": 0.8179
    },
    {
      "source": "GdbQyFOUlJ",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8179
    },
    {
      "source": "cC3LxGZasH",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8739
    },
    {
      "source": "cC3LxGZasH",
      "target": "We mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that",
      "similarity": 0.8718
    },
    {
      "source": "cC3LxGZasH",
      "target": "in reinforcement learning (RL)",
      "similarity": 0.87
    },
    {
      "source": "cC3LxGZasH",
      "target": "4JK2XMGUc8",
      "similarity": 0.869
    },
    {
      "source": "cC3LxGZasH",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.863
    },
    {
      "source": "based on features derived from a Joint Embedding Predictive Architecture",
      "target": "cADpvQgnqg",
      "similarity": 0.8568
    },
    {
      "source": "based on features derived from a Joint Embedding Predictive Architecture",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8524
    },
    {
      "source": "based on features derived from a Joint Embedding Predictive Architecture",
      "target": "memorization.",
      "similarity": 0.8464
    },
    {
      "source": "based on features derived from a Joint Embedding Predictive Architecture",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8459
    },
    {
      "source": "based on features derived from a Joint Embedding Predictive Architecture",
      "target": "However",
      "similarity": 0.844
    },
    {
      "source": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "target": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "similarity": 0.8422
    },
    {
      "source": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "target": "97rOQDPmk2",
      "similarity": 0.8349
    },
    {
      "source": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8331
    },
    {
      "source": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "target": "Following these principles",
      "similarity": 0.8311
    },
    {
      "source": "Project page: https://oooolga.github.io/JEDi.github.io/.\"",
      "target": "In this paper",
      "similarity": 0.8303
    },
    {
      "source": "MnJzJ2gvuf",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8261
    },
    {
      "source": "MnJzJ2gvuf",
      "target": "gFvRRCnQvX",
      "similarity": 0.8182
    },
    {
      "source": "MnJzJ2gvuf",
      "target": "Starting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data)",
      "similarity": 0.8181
    },
    {
      "source": "MnJzJ2gvuf",
      "target": "Following this new setting",
      "similarity": 0.8138
    },
    {
      "source": "MnJzJ2gvuf",
      "target": "RQz7szbVDs",
      "similarity": 0.8133
    },
    {
      "source": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "target": "TYSQYx9vwd",
      "similarity": 0.8623
    },
    {
      "source": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "target": "fXb9BbuyAD",
      "similarity": 0.8496
    },
    {
      "source": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "target": "YUYJsHOf3c",
      "similarity": 0.8424
    },
    {
      "source": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "target": "To overcome such limitations",
      "similarity": 0.8409
    },
    {
      "source": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "target": "zxO4WuVGns",
      "similarity": 0.8404
    },
    {
      "source": "First",
      "target": "TYSQYx9vwd",
      "similarity": 0.8634
    },
    {
      "source": "First",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8498
    },
    {
      "source": "First",
      "target": "rCX9l4OTCT",
      "similarity": 0.8385
    },
    {
      "source": "First",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8368
    },
    {
      "source": "First",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8367
    },
    {
      "source": "On various mathematical benchmarks",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8247
    },
    {
      "source": "On various mathematical benchmarks",
      "target": "However",
      "similarity": 0.824
    },
    {
      "source": "On various mathematical benchmarks",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8237
    },
    {
      "source": "On various mathematical benchmarks",
      "target": "Remarkably",
      "similarity": 0.8205
    },
    {
      "source": "On various mathematical benchmarks",
      "target": "h1XoHOd19I",
      "similarity": 0.8194
    },
    {
      "source": "sZQRUrvLn4",
      "target": "dTkqaCKLPp",
      "similarity": 0.8284
    },
    {
      "source": "sZQRUrvLn4",
      "target": "LLaMA-3-8B-based SFT model",
      "similarity": 0.8178
    },
    {
      "source": "sZQRUrvLn4",
      "target": "44CoQe6VCq",
      "similarity": 0.8168
    },
    {
      "source": "sZQRUrvLn4",
      "target": "uncertainty estimation. Concurrently",
      "similarity": 0.8145
    },
    {
      "source": "sZQRUrvLn4",
      "target": "(1) The probability of dispreferred (e.g.",
      "similarity": 0.8137
    },
    {
      "source": "Because of this",
      "target": "NIkfix2eDQ",
      "similarity": 0.8403
    },
    {
      "source": "Because of this",
      "target": "of order $\\tilde\\Omega(k^{s^\\star})$",
      "similarity": 0.8368
    },
    {
      "source": "Because of this",
      "target": "pDDODPtpx9",
      "similarity": 0.8344
    },
    {
      "source": "Because of this",
      "target": "We further analyze the key effects of these neurons on the image classification task",
      "similarity": 0.8322
    },
    {
      "source": "Because of this",
      "target": "BpyHIrpUOL",
      "similarity": 0.8305
    },
    {
      "source": "However",
      "target": "In doing so",
      "similarity": 0.8969
    },
    {
      "source": "However",
      "target": "in reinforcement learning (RL)",
      "similarity": 0.8892
    },
    {
      "source": "However",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8854
    },
    {
      "source": "However",
      "target": "jmN1zXMq0O",
      "similarity": 0.8629
    },
    {
      "source": "However",
      "target": "IuU0wcO0mo",
      "similarity": 0.8595
    },
    {
      "source": "Motivated by this observation",
      "target": "{Subsequently}",
      "similarity": 0.8801
    },
    {
      "source": "Motivated by this observation",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8725
    },
    {
      "source": "Motivated by this observation",
      "target": "mkDam1xIzW",
      "similarity": 0.8724
    },
    {
      "source": "Motivated by this observation",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8681
    },
    {
      "source": "Motivated by this observation",
      "target": "RAyRXQjsFl",
      "similarity": 0.8667
    },
    {
      "source": "Moreover",
      "target": "It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.",
      "similarity": 0.7984
    },
    {
      "source": "Moreover",
      "target": "4011PUI9vm",
      "similarity": 0.7943
    },
    {
      "source": "Moreover",
      "target": "To overcome these challenges",
      "similarity": 0.7895
    },
    {
      "source": "Moreover",
      "target": "as representations of instances. In this work",
      "similarity": 0.789
    },
    {
      "source": "Moreover",
      "target": "samples. However",
      "similarity": 0.7881
    },
    {
      "source": "Finally",
      "target": "4GT9uTsAJE",
      "similarity": 0.8294
    },
    {
      "source": "Finally",
      "target": "Motivated by this observation",
      "similarity": 0.8276
    },
    {
      "source": "Finally",
      "target": "We start by showing numerically that several variants used in practice",
      "similarity": 0.8185
    },
    {
      "source": "Finally",
      "target": "tj5xJInWty",
      "similarity": 0.8163
    },
    {
      "source": "Finally",
      "target": "iVMcYxTiVM",
      "similarity": 0.8088
    },
    {
      "source": "iVxxgZlXh6",
      "target": "Our models significantly improve performance in these settings",
      "similarity": 0.8413
    },
    {
      "source": "iVxxgZlXh6",
      "target": "m8yby1JfbU",
      "similarity": 0.8347
    },
    {
      "source": "iVxxgZlXh6",
      "target": "To offer practical insights",
      "similarity": 0.8229
    },
    {
      "source": "iVxxgZlXh6",
      "target": "aXwukBD6M6",
      "similarity": 0.8186
    },
    {
      "source": "iVxxgZlXh6",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8184
    },
    {
      "source": "2kGKsyhtvh",
      "target": "To this end",
      "similarity": 0.88
    },
    {
      "source": "2kGKsyhtvh",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8776
    },
    {
      "source": "2kGKsyhtvh",
      "target": "To this end",
      "similarity": 0.867
    },
    {
      "source": "2kGKsyhtvh",
      "target": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "similarity": 0.8581
    },
    {
      "source": "2kGKsyhtvh",
      "target": "VQwI055flA",
      "similarity": 0.858
    },
    {
      "source": "44CoQe6VCq",
      "target": "Our evaluation led to the following observations:",
      "similarity": 0.8323
    },
    {
      "source": "44CoQe6VCq",
      "target": "DTatjJTDl1",
      "similarity": 0.826
    },
    {
      "source": "44CoQe6VCq",
      "target": "BOQpRtI4F5",
      "similarity": 0.8257
    },
    {
      "source": "44CoQe6VCq",
      "target": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "similarity": 0.825
    },
    {
      "source": "44CoQe6VCq",
      "target": "introduce MANTRA",
      "similarity": 0.8244
    },
    {
      "source": "Y5LjYI4N6P",
      "target": "VQwI055flA",
      "similarity": 0.8549
    },
    {
      "source": "Y5LjYI4N6P",
      "target": "2mqb8bPHeb",
      "similarity": 0.8506
    },
    {
      "source": "Y5LjYI4N6P",
      "target": "bMC1t7eLRc",
      "similarity": 0.8479
    },
    {
      "source": "Y5LjYI4N6P",
      "target": "txD9llAYn9",
      "similarity": 0.8457
    },
    {
      "source": "Y5LjYI4N6P",
      "target": "bRa4JLPzii",
      "similarity": 0.8413
    },
    {
      "source": "pretraining methods. Stagewise training approaches to improve efficiency",
      "target": "FEpAUnS7f7",
      "similarity": 0.8109
    },
    {
      "source": "pretraining methods. Stagewise training approaches to improve efficiency",
      "target": "TtKN1TpvUu",
      "similarity": 0.8036
    },
    {
      "source": "pretraining methods. Stagewise training approaches to improve efficiency",
      "target": "Our approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.",
      "similarity": 0.8024
    },
    {
      "source": "pretraining methods. Stagewise training approaches to improve efficiency",
      "target": "In experiments with GPT-4",
      "similarity": 0.7996
    },
    {
      "source": "pretraining methods. Stagewise training approaches to improve efficiency",
      "target": "Finally",
      "similarity": 0.7993
    },
    {
      "source": "gradual stacking and layer dropping (Reddi et al.",
      "target": "To tackle this challenge",
      "similarity": 0.8369
    },
    {
      "source": "gradual stacking and layer dropping (Reddi et al.",
      "target": "max flow ($p = \\infty$) on undirected graphs as special cases. Our goal is to",
      "similarity": 0.8219
    },
    {
      "source": "gradual stacking and layer dropping (Reddi et al.",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8168
    },
    {
      "source": "gradual stacking and layer dropping (Reddi et al.",
      "target": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "similarity": 0.8163
    },
    {
      "source": "gradual stacking and layer dropping (Reddi et al.",
      "target": "To overcome these limitations",
      "similarity": 0.8139
    },
    {
      "source": "recently garnered attention. The prevailing view suggests that stagewise dropping",
      "target": "MyVC4X5B2X",
      "similarity": 0.8432
    },
    {
      "source": "recently garnered attention. The prevailing view suggests that stagewise dropping",
      "target": "(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;",
      "similarity": 0.8416
    },
    {
      "source": "recently garnered attention. The prevailing view suggests that stagewise dropping",
      "target": "potential algorithms to solve one task",
      "similarity": 0.8408
    },
    {
      "source": "recently garnered attention. The prevailing view suggests that stagewise dropping",
      "target": "We argue that interacting with surrogates through text",
      "similarity": 0.8403
    },
    {
      "source": "recently garnered attention. The prevailing view suggests that stagewise dropping",
      "target": "varying sequence lengths. We further provide extensive comparisons between",
      "similarity": 0.8378
    },
    {
      "source": "strategies",
      "target": "The proposed reflection-aware triplet mining loss specifically penalizes the inappropriate photometric error minimization on the localized reflective regions while preserving depth accuracy on non-reflective areas.",
      "similarity": 0.8238
    },
    {
      "source": "strategies",
      "target": "We propose Guided Strategy Discovery (GSD)",
      "similarity": 0.816
    },
    {
      "source": "strategies",
      "target": "tcsZt9ZNKD",
      "similarity": 0.815
    },
    {
      "source": "strategies",
      "target": "A1HhtITVEi",
      "similarity": 0.8069
    },
    {
      "source": "strategies",
      "target": "Our results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.",
      "similarity": 0.8062
    },
    {
      "source": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.853
    },
    {
      "source": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "target": "TYSQYx9vwd",
      "similarity": 0.8498
    },
    {
      "source": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "target": "zxO4WuVGns",
      "similarity": 0.8445
    },
    {
      "source": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "target": "cKlzKs3Nnb",
      "similarity": 0.8435
    },
    {
      "source": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "target": "ugyqNEOjoU",
      "similarity": 0.8402
    },
    {
      "source": "that",
      "target": "ULorFBST6X",
      "similarity": 0.8574
    },
    {
      "source": "that",
      "target": "x$",
      "similarity": 0.8512
    },
    {
      "source": "that",
      "target": "Additionally",
      "similarity": 0.8481
    },
    {
      "source": "that",
      "target": "Ian00SaFHg",
      "similarity": 0.8443
    },
    {
      "source": "that",
      "target": "xjKz6IxgCX",
      "similarity": 0.8411
    },
    {
      "source": "stacking methods. Specifically",
      "target": "Second",
      "similarity": 0.8688
    },
    {
      "source": "stacking methods. Specifically",
      "target": "All experimental resources",
      "similarity": 0.8611
    },
    {
      "source": "stacking methods. Specifically",
      "target": "information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology",
      "similarity": 0.8587
    },
    {
      "source": "stacking methods. Specifically",
      "target": "oYemKnlIrO",
      "similarity": 0.8581
    },
    {
      "source": "stacking methods. Specifically",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8576
    },
    {
      "source": "model and progressively increases the size of subnetworks during training",
      "target": "To enable structural learning with the language model",
      "similarity": 0.8446
    },
    {
      "source": "model and progressively increases the size of subnetworks during training",
      "target": "0e2pcSxQJS",
      "similarity": 0.8359
    },
    {
      "source": "model and progressively increases the size of subnetworks during training",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8311
    },
    {
      "source": "model and progressively increases the size of subnetworks during training",
      "target": "wide dissemination",
      "similarity": 0.8309
    },
    {
      "source": "model and progressively increases the size of subnetworks during training",
      "target": "1Njl73JKjB",
      "similarity": 0.8296
    },
    {
      "source": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "target": "JSB171dSUU",
      "similarity": 0.8578
    },
    {
      "source": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "target": "T2d0geb6y0",
      "similarity": 0.8561
    },
    {
      "source": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "target": "a pressing problem in today\u2019s cloud services and industrial operations. We propose In-Distribution Interventions (IDI)",
      "similarity": 0.8545
    },
    {
      "source": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "target": "To this end",
      "similarity": 0.8518
    },
    {
      "source": "trains the full network. We propose an instantiation of this framework \u2014 Random",
      "target": "In this paper",
      "similarity": 0.8506
    },
    {
      "source": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "target": "In practice",
      "similarity": 0.8371
    },
    {
      "source": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "target": "We repeat this on the remaining stick",
      "similarity": 0.8343
    },
    {
      "source": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "target": "4ub9gpx9xw",
      "similarity": 0.8334
    },
    {
      "source": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "target": "YFxfcQMLWX",
      "similarity": 0.8309
    },
    {
      "source": "Part Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.",
      "target": "calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically",
      "similarity": 0.829
    },
    {
      "source": "depth-wise",
      "target": "zxO4WuVGns",
      "similarity": 0.8487
    },
    {
      "source": "depth-wise",
      "target": "that allows a client to perform ANN search",
      "similarity": 0.8473
    },
    {
      "source": "depth-wise",
      "target": "GRMfXcAAFh",
      "similarity": 0.8456
    },
    {
      "source": "depth-wise",
      "target": "nrvoWOWcyg",
      "similarity": 0.841
    },
    {
      "source": "depth-wise",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8385
    },
    {
      "source": "size in stages. We show that this approach not only generalizes prior works like",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8631
    },
    {
      "source": "size in stages. We show that this approach not only generalizes prior works like",
      "target": "In this work",
      "similarity": 0.8485
    },
    {
      "source": "size in stages. We show that this approach not only generalizes prior works like",
      "target": "Qja5s0K3VX",
      "similarity": 0.8477
    },
    {
      "source": "size in stages. We show that this approach not only generalizes prior works like",
      "target": "this is a serious issue in practice.",
      "similarity": 0.8476
    },
    {
      "source": "size in stages. We show that this approach not only generalizes prior works like",
      "target": "Se6MgCtRhz",
      "similarity": 0.8454
    },
    {
      "source": "layer dropping but also fixes their key issues. Furthermore",
      "target": "iLUcsecZJp",
      "similarity": 0.8409
    },
    {
      "source": "layer dropping but also fixes their key issues. Furthermore",
      "target": "Additionally",
      "similarity": 0.8296
    },
    {
      "source": "layer dropping but also fixes their key issues. Furthermore",
      "target": "We first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results",
      "similarity": 0.8283
    },
    {
      "source": "layer dropping but also fixes their key issues. Furthermore",
      "target": "mTCbq2QssD",
      "similarity": 0.8281
    },
    {
      "source": "layer dropping but also fixes their key issues. Furthermore",
      "target": "5xSRg3eYZz",
      "similarity": 0.8276
    },
    {
      "source": "dropping",
      "target": "However",
      "similarity": 0.841
    },
    {
      "source": "dropping",
      "target": "jxMAPMqNr5",
      "similarity": 0.8365
    },
    {
      "source": "dropping",
      "target": "IuU0wcO0mo",
      "similarity": 0.8276
    },
    {
      "source": "dropping",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.827
    },
    {
      "source": "dropping",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8228
    },
    {
      "source": "comprehensive experiments",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8488
    },
    {
      "source": "comprehensive experiments",
      "target": "QowsEic1sc",
      "similarity": 0.826
    },
    {
      "source": "comprehensive experiments",
      "target": "https://github.com/Yuliang-Liu/Monkey.\"",
      "similarity": 0.8233
    },
    {
      "source": "comprehensive experiments",
      "target": "Next",
      "similarity": 0.8203
    },
    {
      "source": "comprehensive experiments",
      "target": "To develop SoundCTM",
      "similarity": 0.8196
    },
    {
      "source": "up training of standard benchmarks like BERT and UL2",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.8066
    },
    {
      "source": "up training of standard benchmarks like BERT and UL2",
      "target": "Our codebase",
      "similarity": 0.8003
    },
    {
      "source": "up training of standard benchmarks like BERT and UL2",
      "target": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "similarity": 0.793
    },
    {
      "source": "up training of standard benchmarks like BERT and UL2",
      "target": "TmCcNuo03f",
      "similarity": 0.7865
    },
    {
      "source": "up training of standard benchmarks like BERT and UL2",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.7858
    },
    {
      "source": "standard training and",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8294
    },
    {
      "source": "standard training and",
      "target": "This study highlights a major",
      "similarity": 0.8289
    },
    {
      "source": "standard training and",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8192
    },
    {
      "source": "standard training and",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8182
    },
    {
      "source": "standard training and",
      "target": "N4rYbQowE3",
      "similarity": 0.8158
    },
    {
      "source": "UL2",
      "target": "FBhKUXK7od",
      "similarity": 0.8455
    },
    {
      "source": "UL2",
      "target": "FEpAUnS7f7",
      "similarity": 0.8313
    },
    {
      "source": "UL2",
      "target": "In $\\texttt{ProAdvPrompter}$",
      "similarity": 0.8217
    },
    {
      "source": "UL2",
      "target": "Aided Design (CAD) scripting code",
      "similarity": 0.8204
    },
    {
      "source": "UL2",
      "target": "kOJf7Dklyv",
      "similarity": 0.814
    },
    {
      "source": "of better inductive bias.\"",
      "target": "sound",
      "similarity": 0.8437
    },
    {
      "source": "of better inductive bias.\"",
      "target": "of surfaces and three-dimensional manifolds",
      "similarity": 0.8408
    },
    {
      "source": "of better inductive bias.\"",
      "target": "aKJr5NnN8U",
      "similarity": 0.8389
    },
    {
      "source": "of better inductive bias.\"",
      "target": "memorized information while preserving performance on target tasks.\"",
      "similarity": 0.8384
    },
    {
      "source": "of better inductive bias.\"",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8321
    },
    {
      "source": "EEgYUccwsV",
      "target": "suz4utPr9Y",
      "similarity": 0.8795
    },
    {
      "source": "EEgYUccwsV",
      "target": "nrvoWOWcyg",
      "similarity": 0.8499
    },
    {
      "source": "EEgYUccwsV",
      "target": "K4FAFNRpko",
      "similarity": 0.8358
    },
    {
      "source": "EEgYUccwsV",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8345
    },
    {
      "source": "EEgYUccwsV",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8337
    },
    {
      "source": "st7XqFgbAH",
      "target": "We find that *in expectation* the missing mass is entirely determined by the number $f_k$ of classes that *do* appear in the training data the same number of times *and an exponentially decaying error*.",
      "similarity": 0.8312
    },
    {
      "source": "st7XqFgbAH",
      "target": "aXwukBD6M6",
      "similarity": 0.8261
    },
    {
      "source": "st7XqFgbAH",
      "target": "We conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks.",
      "similarity": 0.8172
    },
    {
      "source": "st7XqFgbAH",
      "target": "Experimental results show that no existing method can solve GeoILP tasks.",
      "similarity": 0.8081
    },
    {
      "source": "st7XqFgbAH",
      "target": "w7P92BEsb2",
      "similarity": 0.8074
    },
    {
      "source": "We evaluate LEAP on multiple decision-making benchmarks",
      "target": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "similarity": 0.8281
    },
    {
      "source": "We evaluate LEAP on multiple decision-making benchmarks",
      "target": "We start by showing numerically that several variants used in practice",
      "similarity": 0.8258
    },
    {
      "source": "We evaluate LEAP on multiple decision-making benchmarks",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8254
    },
    {
      "source": "We evaluate LEAP on multiple decision-making benchmarks",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8162
    },
    {
      "source": "We evaluate LEAP on multiple decision-making benchmarks",
      "target": "ujpAYpFDEA",
      "similarity": 0.8143
    },
    {
      "source": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "target": "ptjrpEGrGg",
      "similarity": 0.8422
    },
    {
      "source": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "target": "FBhKUXK7od",
      "similarity": 0.8312
    },
    {
      "source": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "target": "7HEMpBTb3R",
      "similarity": 0.8279
    },
    {
      "source": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "target": "GhexuBLxbO",
      "similarity": 0.8268
    },
    {
      "source": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "target": "ssRdQimeUI",
      "similarity": 0.8244
    },
    {
      "source": "wPMRwmytZe",
      "target": "hXm0Wu2U9K",
      "similarity": 0.845
    },
    {
      "source": "wPMRwmytZe",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8325
    },
    {
      "source": "wPMRwmytZe",
      "target": "EEgYUccwsV",
      "similarity": 0.8292
    },
    {
      "source": "wPMRwmytZe",
      "target": "To address these issues",
      "similarity": 0.8289
    },
    {
      "source": "wPMRwmytZe",
      "target": "Dl3MsjaIdp",
      "similarity": 0.8278
    },
    {
      "source": "TrVYEZtSQH",
      "target": "FEpAUnS7f7",
      "similarity": 0.8236
    },
    {
      "source": "TrVYEZtSQH",
      "target": "Finally",
      "similarity": 0.822
    },
    {
      "source": "TrVYEZtSQH",
      "target": "FEZOLWexPb",
      "similarity": 0.8177
    },
    {
      "source": "TrVYEZtSQH",
      "target": "In experiments with GPT-4",
      "similarity": 0.8133
    },
    {
      "source": "TrVYEZtSQH",
      "target": "This study highlights a major",
      "similarity": 0.8113
    },
    {
      "source": "NA2vUMaMOm",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8019
    },
    {
      "source": "NA2vUMaMOm",
      "target": "ANBuEJesgx",
      "similarity": 0.7972
    },
    {
      "source": "NA2vUMaMOm",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.795
    },
    {
      "source": "NA2vUMaMOm",
      "target": "To tackle this challenge",
      "similarity": 0.7918
    },
    {
      "source": "NA2vUMaMOm",
      "target": "However",
      "similarity": 0.7897
    },
    {
      "source": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "target": "{Subsequently}",
      "similarity": 0.8655
    },
    {
      "source": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "target": "fNMKqyvuZT",
      "similarity": 0.8584
    },
    {
      "source": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "target": "mkDam1xIzW",
      "similarity": 0.8582
    },
    {
      "source": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "target": "4GT9uTsAJE",
      "similarity": 0.8459
    },
    {
      "source": "Our result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency.",
      "target": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "similarity": 0.8399
    },
    {
      "source": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8877
    },
    {
      "source": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "target": "odU59TxdiB",
      "similarity": 0.8709
    },
    {
      "source": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "target": "QWunLKbBGF",
      "similarity": 0.8658
    },
    {
      "source": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "target": "3cvwO5DBZn",
      "similarity": 0.8656
    },
    {
      "source": "This consistency bound is optimal up to $\\text{poly} \\log(n)$ factors.",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.864
    },
    {
      "source": "Plugging in the offline algorithm that returns the exact optimal solution",
      "target": "To this end",
      "similarity": 0.8666
    },
    {
      "source": "Plugging in the offline algorithm that returns the exact optimal solution",
      "target": "Qja5s0K3VX",
      "similarity": 0.8602
    },
    {
      "source": "Plugging in the offline algorithm that returns the exact optimal solution",
      "target": "VpWki1v2P8",
      "similarity": 0.8562
    },
    {
      "source": "Plugging in the offline algorithm that returns the exact optimal solution",
      "target": "We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks",
      "similarity": 0.8516
    },
    {
      "source": "Plugging in the offline algorithm that returns the exact optimal solution",
      "target": "We demonstrate on this task how scaling model size and data enables compositional generalization in transformers and gives rise to a functionally structured latent space.\"",
      "similarity": 0.851
    },
    {
      "source": "we obtain the first",
      "target": "extended prediction periods exemplified by models such as Pangu and Fuxi. Despite",
      "similarity": 0.8677
    },
    {
      "source": "we obtain the first",
      "target": "In this paper",
      "similarity": 0.8624
    },
    {
      "source": "we obtain the first",
      "target": "7mlvOHL6qJ",
      "similarity": 0.862
    },
    {
      "source": "we obtain the first",
      "target": "In addition",
      "similarity": 0.8574
    },
    {
      "source": "we obtain the first",
      "target": "BpyHIrpUOL",
      "similarity": 0.857
    },
    {
      "source": "$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.",
      "target": "VQwI055flA",
      "similarity": 0.868
    },
    {
      "source": "$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.",
      "target": "F57HPKZ6KD",
      "similarity": 0.8621
    },
    {
      "source": "$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8529
    },
    {
      "source": "$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8487
    },
    {
      "source": "$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.",
      "target": "Here",
      "similarity": 0.8487
    },
    {
      "source": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "target": "fXb9BbuyAD",
      "similarity": 0.848
    },
    {
      "source": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "target": "2fojNANZSv",
      "similarity": 0.8436
    },
    {
      "source": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "target": "SFN6Wm7YBI",
      "similarity": 0.8421
    },
    {
      "source": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "target": "In addition",
      "similarity": 0.8399
    },
    {
      "source": "This simultaneously improves several previous results (Lattanzi & Vassilvitskii",
      "target": "BCP5nAHXqs",
      "similarity": 0.8328
    },
    {
      "source": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "target": "F57HPKZ6KD",
      "similarity": 0.8652
    },
    {
      "source": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "target": "In this paper",
      "similarity": 0.865
    },
    {
      "source": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.86
    },
    {
      "source": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.8573
    },
    {
      "source": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8523
    },
    {
      "source": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "target": "odU59TxdiB",
      "similarity": 0.9093
    },
    {
      "source": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "target": "3cvwO5DBZn",
      "similarity": 0.9088
    },
    {
      "source": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.9042
    },
    {
      "source": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "target": "Overall",
      "similarity": 0.8978
    },
    {
      "source": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "target": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "similarity": 0.8788
    },
    {
      "source": "rWQDzq3O5c",
      "target": "lS2SGfWizd",
      "similarity": 0.8332
    },
    {
      "source": "rWQDzq3O5c",
      "target": "reaching 90\\% quality of a state-of-the-art",
      "similarity": 0.8255
    },
    {
      "source": "rWQDzq3O5c",
      "target": "52x04chyQs",
      "similarity": 0.8229
    },
    {
      "source": "rWQDzq3O5c",
      "target": "wSkvf2WyYz",
      "similarity": 0.8206
    },
    {
      "source": "rWQDzq3O5c",
      "target": "tj5xJInWty",
      "similarity": 0.8203
    },
    {
      "source": "60GeEoG5kD",
      "target": "e0X9l4kecx",
      "similarity": 0.8527
    },
    {
      "source": "60GeEoG5kD",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.8415
    },
    {
      "source": "60GeEoG5kD",
      "target": "fvkElsJOsN",
      "similarity": 0.8313
    },
    {
      "source": "60GeEoG5kD",
      "target": "Furthermore",
      "similarity": 0.829
    },
    {
      "source": "60GeEoG5kD",
      "target": "ajSmXqgS24",
      "similarity": 0.8287
    },
    {
      "source": "KrK6zXbjfO",
      "target": "Qja5s0K3VX",
      "similarity": 0.858
    },
    {
      "source": "KrK6zXbjfO",
      "target": "JYwVijuNA7",
      "similarity": 0.8433
    },
    {
      "source": "KrK6zXbjfO",
      "target": "an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem",
      "similarity": 0.8368
    },
    {
      "source": "KrK6zXbjfO",
      "target": "Se6MgCtRhz",
      "similarity": 0.8362
    },
    {
      "source": "KrK6zXbjfO",
      "target": "p4cLtzk4oe",
      "similarity": 0.8356
    },
    {
      "source": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "target": "yIlyHJdYV3",
      "similarity": 0.8724
    },
    {
      "source": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "target": "Despite theoretically sound",
      "similarity": 0.8665
    },
    {
      "source": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8619
    },
    {
      "source": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8608
    },
    {
      "source": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "target": "78tc3EiUrN",
      "similarity": 0.8528
    },
    {
      "source": "While existing T2S distillation models address this limitation through $1$-step generation",
      "target": "1F8xTfv6ah",
      "similarity": 0.8253
    },
    {
      "source": "While existing T2S distillation models address this limitation through $1$-step generation",
      "target": "6wOmHdwCC4",
      "similarity": 0.8243
    },
    {
      "source": "While existing T2S distillation models address this limitation through $1$-step generation",
      "target": "In this work",
      "similarity": 0.8203
    },
    {
      "source": "While existing T2S distillation models address this limitation through $1$-step generation",
      "target": "Aye5wL6TCn",
      "similarity": 0.8148
    },
    {
      "source": "While existing T2S distillation models address this limitation through $1$-step generation",
      "target": "Beyond performance evaluations",
      "similarity": 0.8066
    },
    {
      "source": "Additionally",
      "target": "1F8xTfv6ah",
      "similarity": 0.8394
    },
    {
      "source": "Additionally",
      "target": "Finally",
      "similarity": 0.8366
    },
    {
      "source": "Additionally",
      "target": "98d7DLMGdt",
      "similarity": 0.83
    },
    {
      "source": "Additionally",
      "target": "GhexuBLxbO",
      "similarity": 0.8292
    },
    {
      "source": "Additionally",
      "target": "To the best of our knowledge",
      "similarity": 0.8264
    },
    {
      "source": "Thus",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8469
    },
    {
      "source": "Thus",
      "target": "zxO4WuVGns",
      "similarity": 0.833
    },
    {
      "source": "Thus",
      "target": "Our framework",
      "similarity": 0.8287
    },
    {
      "source": "Thus",
      "target": "To tackle this challenge",
      "similarity": 0.8266
    },
    {
      "source": "Thus",
      "target": "Specifically",
      "similarity": 0.8236
    },
    {
      "source": "To address these issues",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.819
    },
    {
      "source": "To address these issues",
      "target": "Ian00SaFHg",
      "similarity": 0.8141
    },
    {
      "source": "To address these issues",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8134
    },
    {
      "source": "To address these issues",
      "target": "K4FAFNRpko",
      "similarity": 0.8116
    },
    {
      "source": "To address these issues",
      "target": "Q1QTxFm0Is",
      "similarity": 0.8113
    },
    {
      "source": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "target": "nCrJD7qPJN",
      "similarity": 0.8707
    },
    {
      "source": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "target": "90DC0IvlSs",
      "similarity": 0.8688
    },
    {
      "source": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "target": "To address both challenges we augment the recently proposed",
      "similarity": 0.866
    },
    {
      "source": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "target": "BI2int5SAC",
      "similarity": 0.8645
    },
    {
      "source": "This allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention",
      "target": "For TP",
      "similarity": 0.8642
    },
    {
      "source": "To develop SoundCTM",
      "target": "xiQNfYl33p",
      "similarity": 0.8652
    },
    {
      "source": "To develop SoundCTM",
      "target": "QowsEic1sc",
      "similarity": 0.8562
    },
    {
      "source": "To develop SoundCTM",
      "target": "Progress on Spider 2.0 represents crucial steps towards developing intelligent",
      "similarity": 0.8509
    },
    {
      "source": "To develop SoundCTM",
      "target": "hjROBHstZ3",
      "similarity": 0.8495
    },
    {
      "source": "To develop SoundCTM",
      "target": "VoayJihXra",
      "similarity": 0.8393
    },
    {
      "source": "Additionally",
      "target": "Furthermore",
      "similarity": 0.8656
    },
    {
      "source": "Additionally",
      "target": "QWunLKbBGF",
      "similarity": 0.861
    },
    {
      "source": "Additionally",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.857
    },
    {
      "source": "Additionally",
      "target": "VQwI055flA",
      "similarity": 0.8562
    },
    {
      "source": "Additionally",
      "target": "in a vector database",
      "similarity": 0.8539
    },
    {
      "source": "For production-level generation",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8549
    },
    {
      "source": "For production-level generation",
      "target": "in order to be solved. In this paper",
      "similarity": 0.8539
    },
    {
      "source": "For production-level generation",
      "target": "VoayJihXra",
      "similarity": 0.8502
    },
    {
      "source": "For production-level generation",
      "target": "kwCHcaeHrf",
      "similarity": 0.8501
    },
    {
      "source": "For production-level generation",
      "target": "7mlvOHL6qJ",
      "similarity": 0.849
    },
    {
      "source": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "target": "JSB171dSUU",
      "similarity": 0.8651
    },
    {
      "source": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "target": "For example",
      "similarity": 0.8559
    },
    {
      "source": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "target": "To this end",
      "similarity": 0.854
    },
    {
      "source": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "target": "pRCOZllZdT",
      "similarity": 0.8527
    },
    {
      "source": "Audio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.\"",
      "target": "dTkqaCKLPp",
      "similarity": 0.8501
    },
    {
      "source": "r01fcKhzT5",
      "target": "0fJfVOSUra",
      "similarity": 0.8518
    },
    {
      "source": "r01fcKhzT5",
      "target": "Furthermore",
      "similarity": 0.8457
    },
    {
      "source": "r01fcKhzT5",
      "target": "(BoneMet) dataset",
      "similarity": 0.8381
    },
    {
      "source": "r01fcKhzT5",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8346
    },
    {
      "source": "r01fcKhzT5",
      "target": "and we prove that it nearly optimizes the distribution-level coverage.",
      "similarity": 0.8256
    },
    {
      "source": "Ij9ilPh36h",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.84
    },
    {
      "source": "Ij9ilPh36h",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8317
    },
    {
      "source": "Ij9ilPh36h",
      "target": "mXHTifc1Fn",
      "similarity": 0.8294
    },
    {
      "source": "Ij9ilPh36h",
      "target": "Next",
      "similarity": 0.8109
    },
    {
      "source": "Ij9ilPh36h",
      "target": "TYSQYx9vwd",
      "similarity": 0.8081
    },
    {
      "source": "Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences",
      "target": "First",
      "similarity": 0.8222
    },
    {
      "source": "Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences",
      "target": "To verify the effectiveness of our proposed method",
      "similarity": 0.7905
    },
    {
      "source": "Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences",
      "target": "TbTJJNjumY",
      "similarity": 0.7865
    },
    {
      "source": "Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences",
      "target": "hoYFLRNbhc",
      "similarity": 0.7835
    },
    {
      "source": "Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences",
      "target": "We experimentally show that SSA outperforms various baselines on real-world datasets.",
      "similarity": 0.7778
    },
    {
      "source": "41WIgfdd5o",
      "target": "unlimited streaming.\"",
      "similarity": 0.7929
    },
    {
      "source": "41WIgfdd5o",
      "target": "DpLFmc09pC",
      "similarity": 0.7922
    },
    {
      "source": "41WIgfdd5o",
      "target": "But selecting examples or writing prompts can be challenging---especially in tasks that require users to precisely articulate nebulous preferences or reason about complex edge cases. For such tasks",
      "similarity": 0.7913
    },
    {
      "source": "41WIgfdd5o",
      "target": "In this work",
      "similarity": 0.789
    },
    {
      "source": "41WIgfdd5o",
      "target": "to minimize the worst-case loss over groups. However",
      "similarity": 0.7797
    },
    {
      "source": "By contrast",
      "target": "depth-wise",
      "similarity": 0.8381
    },
    {
      "source": "By contrast",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8333
    },
    {
      "source": "By contrast",
      "target": "Furthermore",
      "similarity": 0.8255
    },
    {
      "source": "By contrast",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8225
    },
    {
      "source": "By contrast",
      "target": "memorization.",
      "similarity": 0.8212
    },
    {
      "source": "F5R0lG74Tu",
      "target": "9ca9eHNrdH",
      "similarity": 0.8227
    },
    {
      "source": "F5R0lG74Tu",
      "target": "tQ1PmLfPBL",
      "similarity": 0.8211
    },
    {
      "source": "F5R0lG74Tu",
      "target": "ptjrpEGrGg",
      "similarity": 0.8199
    },
    {
      "source": "F5R0lG74Tu",
      "target": "SG1R2H3fa1",
      "similarity": 0.8183
    },
    {
      "source": "F5R0lG74Tu",
      "target": "vbmSSIhKAM",
      "similarity": 0.8175
    },
    {
      "source": "Despite this",
      "target": "wCOJpXm0Me",
      "similarity": 0.7737
    },
    {
      "source": "Despite this",
      "target": "spDUv05cEq",
      "similarity": 0.7677
    },
    {
      "source": "Despite this",
      "target": "weights construct features. One challenge is that element-wise nonlinearities",
      "similarity": 0.766
    },
    {
      "source": "Despite this",
      "target": "UyU8ETswPg",
      "similarity": 0.7645
    },
    {
      "source": "Despite this",
      "target": "To investigate this",
      "similarity": 0.759
    },
    {
      "source": "yaQbTAD2JJ",
      "target": "JytL2MrlLT",
      "similarity": 0.8552
    },
    {
      "source": "yaQbTAD2JJ",
      "target": "41uZB8bDFh",
      "similarity": 0.8534
    },
    {
      "source": "yaQbTAD2JJ",
      "target": "present significant challenges in efficiently selecting the appropriate LLM for",
      "similarity": 0.8501
    },
    {
      "source": "yaQbTAD2JJ",
      "target": "5pd78GmXC6",
      "similarity": 0.8498
    },
    {
      "source": "yaQbTAD2JJ",
      "target": "h3wbI8Uk1Z",
      "similarity": 0.8481
    },
    {
      "source": "W0nydevOlG",
      "target": "Our codebase",
      "similarity": 0.8254
    },
    {
      "source": "W0nydevOlG",
      "target": "While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations",
      "similarity": 0.8146
    },
    {
      "source": "W0nydevOlG",
      "target": "mkuB677eMM",
      "similarity": 0.8078
    },
    {
      "source": "W0nydevOlG",
      "target": "During inference",
      "similarity": 0.8067
    },
    {
      "source": "W0nydevOlG",
      "target": "To meet real-time requirements and balance multi-task learning",
      "similarity": 0.8035
    },
    {
      "source": "gI0kPklUKS",
      "target": "QWunLKbBGF",
      "similarity": 0.8736
    },
    {
      "source": "gI0kPklUKS",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.8671
    },
    {
      "source": "gI0kPklUKS",
      "target": "jQP5o1VAVc",
      "similarity": 0.8636
    },
    {
      "source": "gI0kPklUKS",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8603
    },
    {
      "source": "gI0kPklUKS",
      "target": "In addition",
      "similarity": 0.8601
    },
    {
      "source": "works remains elusive. Current interpretability work can extract features from",
      "target": "$$",
      "similarity": 0.8337
    },
    {
      "source": "works remains elusive. Current interpretability work can extract features from",
      "target": "Fk3eod9aaD",
      "similarity": 0.8234
    },
    {
      "source": "works remains elusive. Current interpretability work can extract features from",
      "target": "8vzMLo8LDN",
      "similarity": 0.8195
    },
    {
      "source": "works remains elusive. Current interpretability work can extract features from",
      "target": "Validated using our collected college-level circuit analysis problems",
      "similarity": 0.8169
    },
    {
      "source": "works remains elusive. Current interpretability work can extract features from",
      "target": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "similarity": 0.8165
    },
    {
      "source": "hidden activations over an input dataset but generally cannot explain how MLP",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8556
    },
    {
      "source": "hidden activations over an input dataset but generally cannot explain how MLP",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8547
    },
    {
      "source": "hidden activations over an input dataset but generally cannot explain how MLP",
      "target": "real-world datasets than prior work and",
      "similarity": 0.8221
    },
    {
      "source": "hidden activations over an input dataset but generally cannot explain how MLP",
      "target": "at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.\"",
      "similarity": 0.8193
    },
    {
      "source": "hidden activations over an input dataset but generally cannot explain how MLP",
      "target": "YFxfcQMLWX",
      "similarity": 0.8174
    },
    {
      "source": "weights construct features. One challenge is that element-wise nonlinearities",
      "target": "which",
      "similarity": 0.8289
    },
    {
      "source": "weights construct features. One challenge is that element-wise nonlinearities",
      "target": "zXCnIyX9MG",
      "similarity": 0.8127
    },
    {
      "source": "weights construct features. One challenge is that element-wise nonlinearities",
      "target": "wCOJpXm0Me",
      "similarity": 0.8021
    },
    {
      "source": "weights construct features. One challenge is that element-wise nonlinearities",
      "target": "UyU8ETswPg",
      "similarity": 0.8014
    },
    {
      "source": "weights construct features. One challenge is that element-wise nonlinearities",
      "target": "Numerical experiments validate the theoretical findings and demonstrate the practical effectiveness of our proposed algorithms.\"",
      "similarity": 0.7972
    },
    {
      "source": "introduce higher-order interactions and make it difficult to trace computations",
      "target": "However",
      "similarity": 0.823
    },
    {
      "source": "introduce higher-order interactions and make it difficult to trace computations",
      "target": "output reconstruction on a larger structural scale than conventional low-rank meth-",
      "similarity": 0.8195
    },
    {
      "source": "introduce higher-order interactions and make it difficult to trace computations",
      "target": "8TBGdH3t6a",
      "similarity": 0.8135
    },
    {
      "source": "introduce higher-order interactions and make it difficult to trace computations",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.8118
    },
    {
      "source": "introduce higher-order interactions and make it difficult to trace computations",
      "target": "FEZOLWexPb",
      "similarity": 0.8101
    },
    {
      "source": "through the MLP layer. In this paper",
      "target": "KWH4UIoQKS",
      "similarity": 0.8584
    },
    {
      "source": "through the MLP layer. In this paper",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8351
    },
    {
      "source": "through the MLP layer. In this paper",
      "target": "c61unr33XA",
      "similarity": 0.8287
    },
    {
      "source": "through the MLP layer. In this paper",
      "target": "{Subsequently}",
      "similarity": 0.8278
    },
    {
      "source": "through the MLP layer. In this paper",
      "target": "When based on the Expected Information Gain (EIG)",
      "similarity": 0.823
    },
    {
      "source": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "target": "The model learns to reliably assign reward at each game state",
      "similarity": 0.8345
    },
    {
      "source": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.8286
    },
    {
      "source": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "target": "These results are a  partial confirmation of the above conjecture for rational ReLU networks",
      "similarity": 0.8222
    },
    {
      "source": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "target": "In this paper",
      "similarity": 0.8152
    },
    {
      "source": "Gated Linear Unit (GLU) without any element-wise nonlinearity that neverthe-",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8147
    },
    {
      "source": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "target": "FrFQpAgnGE",
      "similarity": 0.8706
    },
    {
      "source": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8662
    },
    {
      "source": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "target": "We release models",
      "similarity": 0.8567
    },
    {
      "source": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8539
    },
    {
      "source": "less achieves competitive performance. Bilinear MLPs can be fully expressed in",
      "target": "Kwo20MWWCb",
      "similarity": 0.8498
    },
    {
      "source": "terms of linear operations using a third-order tensor",
      "target": "Due to the high costs of setting up and running experiments",
      "similarity": 0.847
    },
    {
      "source": "terms of linear operations using a third-order tensor",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8387
    },
    {
      "source": "terms of linear operations using a third-order tensor",
      "target": "Finally",
      "similarity": 0.8372
    },
    {
      "source": "terms of linear operations using a third-order tensor",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.832
    },
    {
      "source": "terms of linear operations using a third-order tensor",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8253
    },
    {
      "source": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "target": "(e.g.",
      "similarity": 0.8473
    },
    {
      "source": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "target": "htDczodFN5",
      "similarity": 0.8401
    },
    {
      "source": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "target": "Qja5s0K3VX",
      "similarity": 0.8369
    },
    {
      "source": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "target": "To tackle this challenge",
      "similarity": 0.8307
    },
    {
      "source": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "target": "However",
      "similarity": 0.826
    },
    {
      "source": "position reveals interpretable low-rank structure across toy tasks",
      "target": "cation",
      "similarity": 0.8525
    },
    {
      "source": "position reveals interpretable low-rank structure across toy tasks",
      "target": "Consequently",
      "similarity": 0.8226
    },
    {
      "source": "position reveals interpretable low-rank structure across toy tasks",
      "target": "gfI9v7AbFg",
      "similarity": 0.8221
    },
    {
      "source": "position reveals interpretable low-rank structure across toy tasks",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.8168
    },
    {
      "source": "position reveals interpretable low-rank structure across toy tasks",
      "target": "bAFVlpFQvT",
      "similarity": 0.8148
    },
    {
      "source": "cation",
      "target": "This approach distills detoxifying representations in the form of synthetic text data",
      "similarity": 0.82
    },
    {
      "source": "cation",
      "target": "wfLuiDjQ0u",
      "similarity": 0.8167
    },
    {
      "source": "cation",
      "target": "Real-world causal structures",
      "similarity": 0.8126
    },
    {
      "source": "cation",
      "target": "2p03KljxE9",
      "similarity": 0.8107
    },
    {
      "source": "cation",
      "target": "To address this challenge",
      "similarity": 0.8107
    },
    {
      "source": "examples",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8171
    },
    {
      "source": "examples",
      "target": "MJNywBdSDy",
      "similarity": 0.8064
    },
    {
      "source": "examples",
      "target": "inherent quantization-friendly design yields small to negligible extra accuracy degradation while saving additional memory than quantization-only methods and achieving up to 2.91\u00d7 speedup for the RoPE-based attention. Moreover",
      "similarity": 0.8061
    },
    {
      "source": "examples",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.8049
    },
    {
      "source": "examples",
      "target": "edge insertion graph stream",
      "similarity": 0.8039
    },
    {
      "source": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "target": "QC2qE1tcmd",
      "similarity": 0.8756
    },
    {
      "source": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "target": "78tc3EiUrN",
      "similarity": 0.8708
    },
    {
      "source": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "target": "VQwI055flA",
      "similarity": 0.8683
    },
    {
      "source": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8627
    },
    {
      "source": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "target": "bRa4JLPzii",
      "similarity": 0.8613
    },
    {
      "source": "interpretable drop-in replacement for current activation functions and that weight-",
      "target": "To overcome this limitation",
      "similarity": 0.8385
    },
    {
      "source": "interpretable drop-in replacement for current activation functions and that weight-",
      "target": "suggesting that both SignGD and Adam requires high-quality data for real-world tasks.",
      "similarity": 0.8381
    },
    {
      "source": "interpretable drop-in replacement for current activation functions and that weight-",
      "target": "powerful expressiveness",
      "similarity": 0.8369
    },
    {
      "source": "interpretable drop-in replacement for current activation functions and that weight-",
      "target": "IQxBDLmVpT",
      "similarity": 0.8362
    },
    {
      "source": "interpretable drop-in replacement for current activation functions and that weight-",
      "target": "B5iOSxM2I0",
      "similarity": 0.8349
    },
    {
      "source": "based interpretability is viable for understanding deep-learning models.\"",
      "target": "hoYFLRNbhc",
      "similarity": 0.8591
    },
    {
      "source": "based interpretability is viable for understanding deep-learning models.\"",
      "target": "txD9llAYn9",
      "similarity": 0.8525
    },
    {
      "source": "based interpretability is viable for understanding deep-learning models.\"",
      "target": "For instance",
      "similarity": 0.8445
    },
    {
      "source": "based interpretability is viable for understanding deep-learning models.\"",
      "target": "In particular",
      "similarity": 0.844
    },
    {
      "source": "based interpretability is viable for understanding deep-learning models.\"",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.843
    },
    {
      "source": "5xwx1Myosu",
      "target": "frsg32u0rO",
      "similarity": 0.8158
    },
    {
      "source": "5xwx1Myosu",
      "target": "AUBvo4sxVL",
      "similarity": 0.8153
    },
    {
      "source": "5xwx1Myosu",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.8148
    },
    {
      "source": "5xwx1Myosu",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8128
    },
    {
      "source": "5xwx1Myosu",
      "target": "ptjrpEGrGg",
      "similarity": 0.8102
    },
    {
      "source": "YFxfcQMLWX",
      "target": "a principled framework for analyzing optimization methods in this setting.",
      "similarity": 0.8648
    },
    {
      "source": "YFxfcQMLWX",
      "target": "lOi6FtIwR8",
      "similarity": 0.859
    },
    {
      "source": "YFxfcQMLWX",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8581
    },
    {
      "source": "YFxfcQMLWX",
      "target": "FZv3kPHTtB",
      "similarity": 0.8569
    },
    {
      "source": "YFxfcQMLWX",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8561
    },
    {
      "source": "VmJdqhuTCh",
      "target": "wide dissemination",
      "similarity": 0.861
    },
    {
      "source": "VmJdqhuTCh",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8488
    },
    {
      "source": "VmJdqhuTCh",
      "target": "NWb128pSCb",
      "similarity": 0.8384
    },
    {
      "source": "VmJdqhuTCh",
      "target": "named Pacmann",
      "similarity": 0.836
    },
    {
      "source": "VmJdqhuTCh",
      "target": "in order to be solved. In this paper",
      "similarity": 0.836
    },
    {
      "source": "rfdblE10qm",
      "target": "By reformulating multi-head attention as a hypernetwork",
      "similarity": 0.8257
    },
    {
      "source": "rfdblE10qm",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8173
    },
    {
      "source": "rfdblE10qm",
      "target": "However",
      "similarity": 0.8141
    },
    {
      "source": "rfdblE10qm",
      "target": "agHddsQhsL",
      "similarity": 0.8133
    },
    {
      "source": "rfdblE10qm",
      "target": "comprehensive experiments",
      "similarity": 0.8131
    },
    {
      "source": "In this paper",
      "target": "j1tSLYKwg8",
      "similarity": 0.8775
    },
    {
      "source": "In this paper",
      "target": "ajxAJ8GUX4",
      "similarity": 0.8582
    },
    {
      "source": "In this paper",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.8518
    },
    {
      "source": "In this paper",
      "target": "learning has exhibited impressive capacities across various healthcare domains",
      "similarity": 0.8461
    },
    {
      "source": "In this paper",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.8441
    },
    {
      "source": "Despite theoretically sound",
      "target": "Our code is available at https://github.com/jiawei415/RobustDecisionTransformer\u3002\"",
      "similarity": 0.8855
    },
    {
      "source": "Despite theoretically sound",
      "target": "tu3qwNjrtw",
      "similarity": 0.8817
    },
    {
      "source": "Despite theoretically sound",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8624
    },
    {
      "source": "Despite theoretically sound",
      "target": "fAAaT826Vv",
      "similarity": 0.8534
    },
    {
      "source": "Despite theoretically sound",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8452
    },
    {
      "source": "We highlight the critical concept of *order consistency* in reward modeling and demonstrate that the BT model possesses this property.",
      "target": "vVxeFSR4fU",
      "similarity": 0.8365
    },
    {
      "source": "We highlight the critical concept of *order consistency* in reward modeling and demonstrate that the BT model possesses this property.",
      "target": "GkWA6NjePN",
      "similarity": 0.8
    },
    {
      "source": "We highlight the critical concept of *order consistency* in reward modeling and demonstrate that the BT model possesses this property.",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.7894
    },
    {
      "source": "We highlight the critical concept of *order consistency* in reward modeling and demonstrate that the BT model possesses this property.",
      "target": "NEu8wgPctU",
      "similarity": 0.7803
    },
    {
      "source": "We highlight the critical concept of *order consistency* in reward modeling and demonstrate that the BT model possesses this property.",
      "target": "MPEs often outperform them and learn representations with higher resolution and",
      "similarity": 0.7772
    },
    {
      "source": "Moreover",
      "target": "instructions",
      "similarity": 0.8639
    },
    {
      "source": "Moreover",
      "target": "Second",
      "similarity": 0.863
    },
    {
      "source": "Moreover",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8614
    },
    {
      "source": "Moreover",
      "target": "xiQNfYl33p",
      "similarity": 0.8583
    },
    {
      "source": "Moreover",
      "target": "C06kww3Qky",
      "similarity": 0.8581
    },
    {
      "source": "To offer practical insights",
      "target": "m8yby1JfbU",
      "similarity": 0.8252
    },
    {
      "source": "To offer practical insights",
      "target": "wFg0shwoRe",
      "similarity": 0.8119
    },
    {
      "source": "To offer practical insights",
      "target": "By incorporating generative models into the BOED framework",
      "similarity": 0.8025
    },
    {
      "source": "To offer practical insights",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.7992
    },
    {
      "source": "To offer practical insights",
      "target": "gsShHPxkUW",
      "similarity": 0.7986
    },
    {
      "source": "IQxBDLmVpT",
      "target": "For example",
      "similarity": 0.8619
    },
    {
      "source": "IQxBDLmVpT",
      "target": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "similarity": 0.8592
    },
    {
      "source": "IQxBDLmVpT",
      "target": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "similarity": 0.8496
    },
    {
      "source": "IQxBDLmVpT",
      "target": "XmProj9cPs",
      "similarity": 0.841
    },
    {
      "source": "IQxBDLmVpT",
      "target": "RC5FPYVQaH",
      "similarity": 0.838
    },
    {
      "source": "QfhU3ZC2g1",
      "target": "97rOQDPmk2",
      "similarity": 0.8294
    },
    {
      "source": "QfhU3ZC2g1",
      "target": "20qZK2T7fa",
      "similarity": 0.8292
    },
    {
      "source": "QfhU3ZC2g1",
      "target": "mYgoNEsUDi",
      "similarity": 0.8284
    },
    {
      "source": "QfhU3ZC2g1",
      "target": "L0evcuybH5",
      "similarity": 0.8262
    },
    {
      "source": "QfhU3ZC2g1",
      "target": "To tackle this",
      "similarity": 0.8242
    },
    {
      "source": "JCiF03qnmi",
      "target": "L14sqcrUC3",
      "similarity": 0.8084
    },
    {
      "source": "JCiF03qnmi",
      "target": "However",
      "similarity": 0.8081
    },
    {
      "source": "JCiF03qnmi",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8052
    },
    {
      "source": "JCiF03qnmi",
      "target": "aN57tSd5Us",
      "similarity": 0.8002
    },
    {
      "source": "JCiF03qnmi",
      "target": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "similarity": 0.799
    },
    {
      "source": "0iscEAo2xB",
      "target": "The code will be publicly available at https://github.com/longrongyang/STGC.\"",
      "similarity": 0.8256
    },
    {
      "source": "0iscEAo2xB",
      "target": "FCBbh0HCrF",
      "similarity": 0.8201
    },
    {
      "source": "0iscEAo2xB",
      "target": "4FVGowGzQb",
      "similarity": 0.8147
    },
    {
      "source": "0iscEAo2xB",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8145
    },
    {
      "source": "0iscEAo2xB",
      "target": "Second",
      "similarity": 0.8106
    },
    {
      "source": "KTgQGXz5xj",
      "target": "On an average of 6 diverse tasks",
      "similarity": 0.8106
    },
    {
      "source": "KTgQGXz5xj",
      "target": "paradigms show promise",
      "similarity": 0.8075
    },
    {
      "source": "KTgQGXz5xj",
      "target": "cC3LxGZasH",
      "similarity": 0.7999
    },
    {
      "source": "KTgQGXz5xj",
      "target": "r5IXBlTCGc",
      "similarity": 0.7999
    },
    {
      "source": "KTgQGXz5xj",
      "target": "gFvRRCnQvX",
      "similarity": 0.7973
    },
    {
      "source": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "target": "In this task",
      "similarity": 0.8595
    },
    {
      "source": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "target": "and propose an Adaptive and Universal Primal--Dual algorithm (AUPD) that achieves strong regret performance:",
      "similarity": 0.8582
    },
    {
      "source": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.858
    },
    {
      "source": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.856
    },
    {
      "source": "Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8514
    },
    {
      "source": "e0X9l4kecx",
      "target": "fvkElsJOsN",
      "similarity": 0.8407
    },
    {
      "source": "e0X9l4kecx",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8352
    },
    {
      "source": "e0X9l4kecx",
      "target": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "similarity": 0.821
    },
    {
      "source": "e0X9l4kecx",
      "target": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "similarity": 0.8199
    },
    {
      "source": "e0X9l4kecx",
      "target": "dmCGjPFVhF",
      "similarity": 0.8165
    },
    {
      "source": "sgbI8Pxwie",
      "target": "46xYl55hdc",
      "similarity": 0.8268
    },
    {
      "source": "sgbI8Pxwie",
      "target": "FCMpUOZkxi",
      "similarity": 0.8059
    },
    {
      "source": "sgbI8Pxwie",
      "target": "mkuB677eMM",
      "similarity": 0.8058
    },
    {
      "source": "sgbI8Pxwie",
      "target": "the same state-of-the-art long-context models (e.g.",
      "similarity": 0.8047
    },
    {
      "source": "sgbI8Pxwie",
      "target": "Extensive evaluations using MNIST",
      "similarity": 0.8045
    },
    {
      "source": "ROpY0qRUXL",
      "target": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "similarity": 0.8471
    },
    {
      "source": "ROpY0qRUXL",
      "target": "4dAgG8ma3B",
      "similarity": 0.8369
    },
    {
      "source": "ROpY0qRUXL",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8368
    },
    {
      "source": "ROpY0qRUXL",
      "target": "78tc3EiUrN",
      "similarity": 0.8343
    },
    {
      "source": "ROpY0qRUXL",
      "target": "kbm6tsICar",
      "similarity": 0.8332
    },
    {
      "source": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "target": "Vz0CWFMPUe",
      "similarity": 0.8886
    },
    {
      "source": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.8556
    },
    {
      "source": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "target": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "similarity": 0.8501
    },
    {
      "source": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "target": "nx9Z5Kva96",
      "similarity": 0.8491
    },
    {
      "source": "jective in closed form yields an indeterminate system with A and B as unknown variables",
      "target": "6ycX677p2l",
      "similarity": 0.8399
    },
    {
      "source": "8xxEBAtD7y",
      "target": "proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting",
      "similarity": 0.7863
    },
    {
      "source": "8xxEBAtD7y",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.7764
    },
    {
      "source": "8xxEBAtD7y",
      "target": "iVMcYxTiVM",
      "similarity": 0.7754
    },
    {
      "source": "8xxEBAtD7y",
      "target": "cKlzKs3Nnb",
      "similarity": 0.7728
    },
    {
      "source": "8xxEBAtD7y",
      "target": "Second",
      "similarity": 0.7714
    },
    {
      "source": "fvkElsJOsN",
      "target": "dmCGjPFVhF",
      "similarity": 0.812
    },
    {
      "source": "fvkElsJOsN",
      "target": "FJFVmeXusW",
      "similarity": 0.8044
    },
    {
      "source": "fvkElsJOsN",
      "target": "ajSmXqgS24",
      "similarity": 0.801
    },
    {
      "source": "fvkElsJOsN",
      "target": "GTcEe5fayC",
      "similarity": 0.8004
    },
    {
      "source": "fvkElsJOsN",
      "target": "PSiijdQjNU",
      "similarity": 0.7985
    },
    {
      "source": "md9qolJwLl",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8313
    },
    {
      "source": "md9qolJwLl",
      "target": "1tBvzOYTLF",
      "similarity": 0.8137
    },
    {
      "source": "md9qolJwLl",
      "target": "8sSqNntaMr",
      "similarity": 0.8132
    },
    {
      "source": "md9qolJwLl",
      "target": "Wf2ndb8nhf",
      "similarity": 0.8091
    },
    {
      "source": "md9qolJwLl",
      "target": "d8hYXbxX71",
      "similarity": 0.8087
    },
    {
      "source": "QC2qE1tcmd",
      "target": "FrFQpAgnGE",
      "similarity": 0.8705
    },
    {
      "source": "QC2qE1tcmd",
      "target": "yIlyHJdYV3",
      "similarity": 0.8705
    },
    {
      "source": "QC2qE1tcmd",
      "target": "iOMnn1hSBO",
      "similarity": 0.8583
    },
    {
      "source": "QC2qE1tcmd",
      "target": "2mqb8bPHeb",
      "similarity": 0.8545
    },
    {
      "source": "QC2qE1tcmd",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8531
    },
    {
      "source": "Zjv38dg1Hb",
      "target": "Here",
      "similarity": 0.8511
    },
    {
      "source": "Zjv38dg1Hb",
      "target": "To address this issue",
      "similarity": 0.8396
    },
    {
      "source": "Zjv38dg1Hb",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8275
    },
    {
      "source": "Zjv38dg1Hb",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.8235
    },
    {
      "source": "Zjv38dg1Hb",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8218
    },
    {
      "source": "ULorFBST6X",
      "target": "TYSQYx9vwd",
      "similarity": 0.8441
    },
    {
      "source": "ULorFBST6X",
      "target": "rCX9l4OTCT",
      "similarity": 0.8422
    },
    {
      "source": "ULorFBST6X",
      "target": "97rOQDPmk2",
      "similarity": 0.8399
    },
    {
      "source": "ULorFBST6X",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8398
    },
    {
      "source": "ULorFBST6X",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.8394
    },
    {
      "source": "Ax0i933gtp",
      "target": "U42TkrEDzb",
      "similarity": 0.8483
    },
    {
      "source": "Ax0i933gtp",
      "target": "fXb9BbuyAD",
      "similarity": 0.8469
    },
    {
      "source": "Ax0i933gtp",
      "target": "rCX9l4OTCT",
      "similarity": 0.8448
    },
    {
      "source": "Ax0i933gtp",
      "target": "This corresponds to",
      "similarity": 0.8442
    },
    {
      "source": "Ax0i933gtp",
      "target": "algorithms for this problem in the multi-armed (Wu et al.",
      "similarity": 0.842
    },
    {
      "source": "s1zO0YBEF8",
      "target": "We instead consider the inverted situation",
      "similarity": 0.7976
    },
    {
      "source": "s1zO0YBEF8",
      "target": "frsg32u0rO",
      "similarity": 0.7957
    },
    {
      "source": "s1zO0YBEF8",
      "target": "significant advancements in the field",
      "similarity": 0.7956
    },
    {
      "source": "s1zO0YBEF8",
      "target": "such events remains limited. Given the critical importance of accurately forecasting",
      "similarity": 0.7955
    },
    {
      "source": "s1zO0YBEF8",
      "target": "Remarkably",
      "similarity": 0.7855
    },
    {
      "source": "Beyond performance evaluations",
      "target": "oDbiL9CLoS",
      "similarity": 0.8348
    },
    {
      "source": "Beyond performance evaluations",
      "target": "SyVPiehSbg",
      "similarity": 0.8305
    },
    {
      "source": "Beyond performance evaluations",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.8297
    },
    {
      "source": "Beyond performance evaluations",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.829
    },
    {
      "source": "Beyond performance evaluations",
      "target": "including GPT-4-Turbo-2024-04-09",
      "similarity": 0.8288
    },
    {
      "source": "Moreover",
      "target": "such as limited view overlap or low lighting.",
      "similarity": 0.8412
    },
    {
      "source": "Moreover",
      "target": "(i) can execute searches on billion-scale corpora in less than a second",
      "similarity": 0.8372
    },
    {
      "source": "Moreover",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8279
    },
    {
      "source": "Moreover",
      "target": "MxbEiFRf39",
      "similarity": 0.8272
    },
    {
      "source": "Moreover",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.827
    },
    {
      "source": "In this paper",
      "target": "iVMcYxTiVM",
      "similarity": 0.8148
    },
    {
      "source": "In this paper",
      "target": "As a byproduct of our methods",
      "similarity": 0.8045
    },
    {
      "source": "In this paper",
      "target": "60GeEoG5kD",
      "similarity": 0.8031
    },
    {
      "source": "In this paper",
      "target": "Fortunately",
      "similarity": 0.8007
    },
    {
      "source": "In this paper",
      "target": "Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets",
      "similarity": 0.8
    },
    {
      "source": "Specifically",
      "target": "pPQPQ7Yd58",
      "similarity": 0.7954
    },
    {
      "source": "Specifically",
      "target": "fXb9BbuyAD",
      "similarity": 0.794
    },
    {
      "source": "Specifically",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.7939
    },
    {
      "source": "Specifically",
      "target": "UeVx6L59fg",
      "similarity": 0.7936
    },
    {
      "source": "Specifically",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.7911
    },
    {
      "source": "We mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that",
      "target": "To address this issue",
      "similarity": 0.8504
    },
    {
      "source": "We mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that",
      "target": "Our results challenge the traditional interpretation of how LLMs understand language",
      "similarity": 0.8372
    },
    {
      "source": "We mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that",
      "target": "uncertainty estimation. Moreover",
      "similarity": 0.8367
    },
    {
      "source": "We mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that",
      "target": "increased their demand. However",
      "similarity": 0.8327
    },
    {
      "source": "We mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that",
      "target": "ohJxgRLlLt",
      "similarity": 0.83
    },
    {
      "source": "Our theory also offers several new insights---e.g.",
      "target": "To overcome these limitations",
      "similarity": 0.849
    },
    {
      "source": "Our theory also offers several new insights---e.g.",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8465
    },
    {
      "source": "Our theory also offers several new insights---e.g.",
      "target": "n34taxF0TC",
      "similarity": 0.8369
    },
    {
      "source": "Our theory also offers several new insights---e.g.",
      "target": "iOMnn1hSBO",
      "similarity": 0.8341
    },
    {
      "source": "Our theory also offers several new insights---e.g.",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8338
    },
    {
      "source": "We validate our new predictions by training a text-conditioned diffusion model",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8501
    },
    {
      "source": "We validate our new predictions by training a text-conditioned diffusion model",
      "target": "including unnecessary activations and underutilization of experts.",
      "similarity": 0.848
    },
    {
      "source": "We validate our new predictions by training a text-conditioned diffusion model",
      "target": "TYSQYx9vwd",
      "similarity": 0.8473
    },
    {
      "source": "We validate our new predictions by training a text-conditioned diffusion model",
      "target": "zxO4WuVGns",
      "similarity": 0.8378
    },
    {
      "source": "We validate our new predictions by training a text-conditioned diffusion model",
      "target": "stacking-based approaches. This paper challenges this notion by demonstrating",
      "similarity": 0.8377
    },
    {
      "source": "Overall",
      "target": "odU59TxdiB",
      "similarity": 0.9164
    },
    {
      "source": "Overall",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.891
    },
    {
      "source": "Overall",
      "target": "3cvwO5DBZn",
      "similarity": 0.8906
    },
    {
      "source": "Overall",
      "target": "QWunLKbBGF",
      "similarity": 0.887
    },
    {
      "source": "Overall",
      "target": "counterfactual bias)",
      "similarity": 0.8775
    },
    {
      "source": "6H4jRWKFc3",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8305
    },
    {
      "source": "6H4jRWKFc3",
      "target": "In parallel",
      "similarity": 0.815
    },
    {
      "source": "6H4jRWKFc3",
      "target": "3usdM1AuI3",
      "similarity": 0.8009
    },
    {
      "source": "6H4jRWKFc3",
      "target": "In this work",
      "similarity": 0.8008
    },
    {
      "source": "6H4jRWKFc3",
      "target": "q87GUkdQBm",
      "similarity": 0.7988
    },
    {
      "source": "The child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8494
    },
    {
      "source": "The child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8475
    },
    {
      "source": "The child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets",
      "target": "wide dissemination",
      "similarity": 0.8454
    },
    {
      "source": "The child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets",
      "target": "This approach constructs a dataset suitable for off-the-shelf offline training.",
      "similarity": 0.8416
    },
    {
      "source": "The child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets",
      "target": "9QPH1YQCMn",
      "similarity": 0.8382
    },
    {
      "source": "AC5n7xHuR1",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8071
    },
    {
      "source": "AC5n7xHuR1",
      "target": "(VideoWA)",
      "similarity": 0.8048
    },
    {
      "source": "AC5n7xHuR1",
      "target": "t8fu5m8R5m",
      "similarity": 0.8017
    },
    {
      "source": "AC5n7xHuR1",
      "target": "space",
      "similarity": 0.8003
    },
    {
      "source": "AC5n7xHuR1",
      "target": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "similarity": 0.7995
    },
    {
      "source": "AEFVa6VMu1",
      "target": "xQCXInDq0m",
      "similarity": 0.8356
    },
    {
      "source": "AEFVa6VMu1",
      "target": "98d7DLMGdt",
      "similarity": 0.8195
    },
    {
      "source": "AEFVa6VMu1",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8167
    },
    {
      "source": "AEFVa6VMu1",
      "target": "kbm6tsICar",
      "similarity": 0.8102
    },
    {
      "source": "AEFVa6VMu1",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8101
    },
    {
      "source": "Oxpkn0YLG1",
      "target": "Unlike traditional multilayer perceptrons",
      "similarity": 0.8713
    },
    {
      "source": "Oxpkn0YLG1",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8656
    },
    {
      "source": "Oxpkn0YLG1",
      "target": "In online learning scenarios where data arrives sequentially",
      "similarity": 0.8624
    },
    {
      "source": "Oxpkn0YLG1",
      "target": "To this end",
      "similarity": 0.8623
    },
    {
      "source": "Oxpkn0YLG1",
      "target": "VQwI055flA",
      "similarity": 0.8606
    },
    {
      "source": "ZkFMe3OPfw",
      "target": "We provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student\u2019s realizability",
      "similarity": 0.7925
    },
    {
      "source": "ZkFMe3OPfw",
      "target": "H0qIWXXLUR",
      "similarity": 0.791
    },
    {
      "source": "ZkFMe3OPfw",
      "target": "introduce higher-order interactions and make it difficult to trace computations",
      "similarity": 0.7903
    },
    {
      "source": "ZkFMe3OPfw",
      "target": "VLM performance by providing visual feedback",
      "similarity": 0.7853
    },
    {
      "source": "ZkFMe3OPfw",
      "target": "qssVptHTPN",
      "similarity": 0.7829
    },
    {
      "source": "ERv8ptegFi",
      "target": "offering a more efficient and scalable solution for MoE-based large language models.",
      "similarity": 0.8435
    },
    {
      "source": "ERv8ptegFi",
      "target": "5pd78GmXC6",
      "similarity": 0.8385
    },
    {
      "source": "ERv8ptegFi",
      "target": "U3PBITXNG6",
      "similarity": 0.8361
    },
    {
      "source": "ERv8ptegFi",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8275
    },
    {
      "source": "ERv8ptegFi",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8232
    },
    {
      "source": "w8LMtFY97b",
      "target": "To benchmark current systems on visually rich document retrieval",
      "similarity": 0.8055
    },
    {
      "source": "w8LMtFY97b",
      "target": "200 natural language prompts paired with expert-annotated scripting code for 3D",
      "similarity": 0.8026
    },
    {
      "source": "w8LMtFY97b",
      "target": "fundamentally different from FFEs",
      "similarity": 0.7999
    },
    {
      "source": "w8LMtFY97b",
      "target": "Moreover",
      "similarity": 0.7986
    },
    {
      "source": "w8LMtFY97b",
      "target": "To integrate it with canonicalization",
      "similarity": 0.7961
    },
    {
      "source": "fN8yLc3eA7",
      "target": "named Pacmann",
      "similarity": 0.8414
    },
    {
      "source": "fN8yLc3eA7",
      "target": "hjROBHstZ3",
      "similarity": 0.841
    },
    {
      "source": "fN8yLc3eA7",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8399
    },
    {
      "source": "fN8yLc3eA7",
      "target": "each query.\"",
      "similarity": 0.8393
    },
    {
      "source": "fN8yLc3eA7",
      "target": "qFZnAC4GHR",
      "similarity": 0.8358
    },
    {
      "source": "1F8xTfv6ah",
      "target": "P6IVIoGRRg",
      "similarity": 0.8559
    },
    {
      "source": "1F8xTfv6ah",
      "target": "bounds with the first sublinear space upper bounds for this problem",
      "similarity": 0.8486
    },
    {
      "source": "1F8xTfv6ah",
      "target": "GhexuBLxbO",
      "similarity": 0.8297
    },
    {
      "source": "1F8xTfv6ah",
      "target": "In addition",
      "similarity": 0.8295
    },
    {
      "source": "1F8xTfv6ah",
      "target": "SyVPiehSbg",
      "similarity": 0.8294
    },
    {
      "source": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "target": "b57IG6N20B",
      "similarity": 0.7888
    },
    {
      "source": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "target": "Specifically",
      "similarity": 0.7798
    },
    {
      "source": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "target": "However",
      "similarity": 0.7789
    },
    {
      "source": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "target": "It relaxes the equal mass constraint",
      "similarity": 0.7767
    },
    {
      "source": "This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs).",
      "target": "We also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.",
      "similarity": 0.7731
    },
    {
      "source": "Unlike traditional multilayer perceptrons",
      "target": "Vz0CWFMPUe",
      "similarity": 0.8575
    },
    {
      "source": "Unlike traditional multilayer perceptrons",
      "target": "We release models",
      "similarity": 0.8547
    },
    {
      "source": "Unlike traditional multilayer perceptrons",
      "target": "To this end",
      "similarity": 0.8545
    },
    {
      "source": "Unlike traditional multilayer perceptrons",
      "target": "matched mask pairs between prediction and annotation respectively. Extensive",
      "similarity": 0.8539
    },
    {
      "source": "Unlike traditional multilayer perceptrons",
      "target": "4dAgG8ma3B",
      "similarity": 0.8537
    },
    {
      "source": "Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples.",
      "target": "mDKxlfraAn",
      "similarity": 0.8164
    },
    {
      "source": "Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples.",
      "target": "We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks",
      "similarity": 0.8136
    },
    {
      "source": "Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples.",
      "target": "Adapting tools from classical sampling theory",
      "similarity": 0.8128
    },
    {
      "source": "Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples.",
      "target": "This toolkit consists of 300 manually collected benign multimodal queries",
      "similarity": 0.8104
    },
    {
      "source": "Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples.",
      "target": "j1tSLYKwg8",
      "similarity": 0.8093
    },
    {
      "source": "We validate our approach on benchmarks from image and medical domains",
      "target": "Previous empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets",
      "similarity": 0.8427
    },
    {
      "source": "We validate our approach on benchmarks from image and medical domains",
      "target": "These results not only refine previous results in Stackelberg games and contract design",
      "similarity": 0.8361
    },
    {
      "source": "We validate our approach on benchmarks from image and medical domains",
      "target": "zxO4WuVGns",
      "similarity": 0.8356
    },
    {
      "source": "We validate our approach on benchmarks from image and medical domains",
      "target": "TYSQYx9vwd",
      "similarity": 0.835
    },
    {
      "source": "We validate our approach on benchmarks from image and medical domains",
      "target": "memorization.",
      "similarity": 0.8348
    },
    {
      "source": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "target": "phAlw3JPms",
      "similarity": 0.8696
    },
    {
      "source": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8693
    },
    {
      "source": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "target": "achieving a 2x acceleration in inference time and an 8x reduction of memory costs for KV cache.\"",
      "similarity": 0.8636
    },
    {
      "source": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8548
    },
    {
      "source": "These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.\"",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8511
    },
    {
      "source": "Vz0CWFMPUe",
      "target": "nx9Z5Kva96",
      "similarity": 0.8624
    },
    {
      "source": "Vz0CWFMPUe",
      "target": "Oxpkn0YLG1",
      "similarity": 0.857
    },
    {
      "source": "Vz0CWFMPUe",
      "target": "kbm6tsICar",
      "similarity": 0.8565
    },
    {
      "source": "Vz0CWFMPUe",
      "target": "MMwaQEVsAg",
      "similarity": 0.8542
    },
    {
      "source": "Vz0CWFMPUe",
      "target": "Extensive experiments demonstrate that TTR outperforms existing baselines",
      "similarity": 0.8506
    },
    {
      "source": "LPG8pPSfQD",
      "target": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "similarity": 0.824
    },
    {
      "source": "LPG8pPSfQD",
      "target": "However",
      "similarity": 0.8145
    },
    {
      "source": "LPG8pPSfQD",
      "target": "yFGR36PLDJ",
      "similarity": 0.8094
    },
    {
      "source": "LPG8pPSfQD",
      "target": "In this work",
      "similarity": 0.8094
    },
    {
      "source": "LPG8pPSfQD",
      "target": "je3GZissZc",
      "similarity": 0.8093
    },
    {
      "source": "n4wcdct43X",
      "target": "0h6v4SpLCY",
      "similarity": 0.8624
    },
    {
      "source": "n4wcdct43X",
      "target": "4JK2XMGUc8",
      "similarity": 0.856
    },
    {
      "source": "n4wcdct43X",
      "target": "In doing so",
      "similarity": 0.8481
    },
    {
      "source": "n4wcdct43X",
      "target": "increased their demand. However",
      "similarity": 0.847
    },
    {
      "source": "n4wcdct43X",
      "target": "sULAwlAWc1",
      "similarity": 0.846
    },
    {
      "source": "sIE2rI3ZPs",
      "target": "Moreover",
      "similarity": 0.8573
    },
    {
      "source": "sIE2rI3ZPs",
      "target": "methods that rely on explicit knowledge of $(L_0",
      "similarity": 0.8526
    },
    {
      "source": "sIE2rI3ZPs",
      "target": "instructions",
      "similarity": 0.8521
    },
    {
      "source": "sIE2rI3ZPs",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8494
    },
    {
      "source": "sIE2rI3ZPs",
      "target": "In particular",
      "similarity": 0.8463
    },
    {
      "source": "bAFVlpFQvT",
      "target": "A promising direction to address this limitation lies in recent advancements in foundation models",
      "similarity": 0.8535
    },
    {
      "source": "bAFVlpFQvT",
      "target": "3bcN6xlO6f",
      "similarity": 0.8469
    },
    {
      "source": "bAFVlpFQvT",
      "target": "that overcomes these limitations. MoDeGPT jointly decomposes pairs of consecu-",
      "similarity": 0.8456
    },
    {
      "source": "bAFVlpFQvT",
      "target": "Furthermore",
      "similarity": 0.8342
    },
    {
      "source": "bAFVlpFQvT",
      "target": "wUtXB43Chi",
      "similarity": 0.8331
    },
    {
      "source": "FPQzXME9NK",
      "target": "Nevertheless",
      "similarity": 0.8009
    },
    {
      "source": "FPQzXME9NK",
      "target": "Listening ability",
      "similarity": 0.798
    },
    {
      "source": "FPQzXME9NK",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.7973
    },
    {
      "source": "FPQzXME9NK",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.7962
    },
    {
      "source": "FPQzXME9NK",
      "target": "To bridge this gap",
      "similarity": 0.7947
    },
    {
      "source": "Ahlrf2HGJR",
      "target": "PQpvhUrA1C",
      "similarity": 0.8655
    },
    {
      "source": "Ahlrf2HGJR",
      "target": "bMC1t7eLRc",
      "similarity": 0.8594
    },
    {
      "source": "Ahlrf2HGJR",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8589
    },
    {
      "source": "Ahlrf2HGJR",
      "target": "yu1vqQqKkx",
      "similarity": 0.8518
    },
    {
      "source": "Ahlrf2HGJR",
      "target": "3) We train the model through compression-based auto-regression",
      "similarity": 0.85
    },
    {
      "source": "VIUisLx8lQ",
      "target": "Bpn8q40n1n",
      "similarity": 0.8133
    },
    {
      "source": "VIUisLx8lQ",
      "target": "CLIP",
      "similarity": 0.8118
    },
    {
      "source": "VIUisLx8lQ",
      "target": "L0evcuybH5",
      "similarity": 0.8106
    },
    {
      "source": "VIUisLx8lQ",
      "target": "Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.",
      "similarity": 0.8076
    },
    {
      "source": "VIUisLx8lQ",
      "target": "aWLQTbfFgV",
      "similarity": 0.8013
    },
    {
      "source": "h8yg0hT96f",
      "target": "JDm7oIcx4Y",
      "similarity": 0.8389
    },
    {
      "source": "h8yg0hT96f",
      "target": "TvGPP8i18S",
      "similarity": 0.8346
    },
    {
      "source": "h8yg0hT96f",
      "target": "cADpvQgnqg",
      "similarity": 0.8286
    },
    {
      "source": "h8yg0hT96f",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8281
    },
    {
      "source": "h8yg0hT96f",
      "target": "We validate our new predictions by training a text-conditioned diffusion model",
      "similarity": 0.8273
    },
    {
      "source": "When based on the Expected Information Gain (EIG)",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8717
    },
    {
      "source": "When based on the Expected Information Gain (EIG)",
      "target": "RAyRXQjsFl",
      "similarity": 0.8687
    },
    {
      "source": "When based on the Expected Information Gain (EIG)",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8538
    },
    {
      "source": "When based on the Expected Information Gain (EIG)",
      "target": "mkDam1xIzW",
      "similarity": 0.8478
    },
    {
      "source": "When based on the Expected Information Gain (EIG)",
      "target": "KWH4UIoQKS",
      "similarity": 0.8429
    },
    {
      "source": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "target": "{Subsequently}",
      "similarity": 0.8594
    },
    {
      "source": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "target": "fNMKqyvuZT",
      "similarity": 0.8576
    },
    {
      "source": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "target": "4GT9uTsAJE",
      "similarity": 0.8543
    },
    {
      "source": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "target": "mkDam1xIzW",
      "similarity": 0.8372
    },
    {
      "source": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "target": "RAyRXQjsFl",
      "similarity": 0.834
    },
    {
      "source": "In this work",
      "target": "xJXq6FkqEw",
      "similarity": 0.8449
    },
    {
      "source": "In this work",
      "target": "Subsequently",
      "similarity": 0.8408
    },
    {
      "source": "In this work",
      "target": "neural tangent kernel (NTK) to evaluate these encodings through the lens of an",
      "similarity": 0.8406
    },
    {
      "source": "In this work",
      "target": "In particular",
      "similarity": 0.8359
    },
    {
      "source": "In this work",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8357
    },
    {
      "source": "By incorporating generative models into the BOED framework",
      "target": "Neural networks would seem to offer a solution via data-driven amortized optimization",
      "similarity": 0.8248
    },
    {
      "source": "By incorporating generative models into the BOED framework",
      "target": "Finally",
      "similarity": 0.8178
    },
    {
      "source": "By incorporating generative models into the BOED framework",
      "target": "With $T$ as the total number of iterations",
      "similarity": 0.817
    },
    {
      "source": "By incorporating generative models into the BOED framework",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8154
    },
    {
      "source": "By incorporating generative models into the BOED framework",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8152
    },
    {
      "source": "jKcZ4hF4s5",
      "target": "uQnvYP7yX9",
      "similarity": 0.83
    },
    {
      "source": "jKcZ4hF4s5",
      "target": "mnna9LUg7P",
      "similarity": 0.8287
    },
    {
      "source": "jKcZ4hF4s5",
      "target": "rCX9l4OTCT",
      "similarity": 0.8271
    },
    {
      "source": "jKcZ4hF4s5",
      "target": "experimental evaluations show that the proposed mask-wise protocol provides a",
      "similarity": 0.8243
    },
    {
      "source": "jKcZ4hF4s5",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8231
    },
    {
      "source": "mainly because the unlabeled training data frequently contain such sensitive data.",
      "target": "1qGkuxI9UX",
      "similarity": 0.8183
    },
    {
      "source": "mainly because the unlabeled training data frequently contain such sensitive data.",
      "target": "Traditionally",
      "similarity": 0.8104
    },
    {
      "source": "mainly because the unlabeled training data frequently contain such sensitive data.",
      "target": "daUQ7vmGap",
      "similarity": 0.8093
    },
    {
      "source": "mainly because the unlabeled training data frequently contain such sensitive data.",
      "target": "h1XoHOd19I",
      "similarity": 0.808
    },
    {
      "source": "mainly because the unlabeled training data frequently contain such sensitive data.",
      "target": "hjROBHstZ3",
      "similarity": 0.8075
    },
    {
      "source": "Since labeling all sensitive data in the large-scale unlabeled training data is impractical",
      "target": "pZiyCaVuti",
      "similarity": 0.8483
    },
    {
      "source": "Since labeling all sensitive data in the large-scale unlabeled training data is impractical",
      "target": "1vrpdV9U3i",
      "similarity": 0.8272
    },
    {
      "source": "Since labeling all sensitive data in the large-scale unlabeled training data is impractical",
      "target": "74vnDs1R97",
      "similarity": 0.8261
    },
    {
      "source": "Since labeling all sensitive data in the large-scale unlabeled training data is impractical",
      "target": "Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably",
      "similarity": 0.8198
    },
    {
      "source": "Since labeling all sensitive data in the large-scale unlabeled training data is impractical",
      "target": "bilities",
      "similarity": 0.8197
    },
    {
      "source": "we address this problem by using a small amount of labeled sensitive data.",
      "target": "Excitingly",
      "similarity": 0.8134
    },
    {
      "source": "we address this problem by using a small amount of labeled sensitive data.",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.8097
    },
    {
      "source": "we address this problem by using a small amount of labeled sensitive data.",
      "target": "This helps LLMs better interpret and execute the prompts",
      "similarity": 0.8067
    },
    {
      "source": "we address this problem by using a small amount of labeled sensitive data.",
      "target": "C45YqeBDUM",
      "similarity": 0.8052
    },
    {
      "source": "we address this problem by using a small amount of labeled sensitive data.",
      "target": "eC2a2IndIt",
      "similarity": 0.7923
    },
    {
      "source": "In this paper",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.8152
    },
    {
      "source": "In this paper",
      "target": "rfdblE10qm",
      "similarity": 0.8131
    },
    {
      "source": "In this paper",
      "target": "We evaluate the proposed approach on the challenging THuman2.0",
      "similarity": 0.8058
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8038
    },
    {
      "source": "In this paper",
      "target": "4BFzTrIjPN",
      "similarity": 0.8027
    },
    {
      "source": "we propose positive-unlabeled diffusion models",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8445
    },
    {
      "source": "we propose positive-unlabeled diffusion models",
      "target": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "similarity": 0.8441
    },
    {
      "source": "we propose positive-unlabeled diffusion models",
      "target": "pZiyCaVuti",
      "similarity": 0.8402
    },
    {
      "source": "we propose positive-unlabeled diffusion models",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8388
    },
    {
      "source": "we propose positive-unlabeled diffusion models",
      "target": "A1HhtITVEi",
      "similarity": 0.8361
    },
    {
      "source": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "target": "Subsequently",
      "similarity": 0.8491
    },
    {
      "source": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "target": "ymt4crbbXh",
      "similarity": 0.8467
    },
    {
      "source": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "target": "In particular",
      "similarity": 0.8459
    },
    {
      "source": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "target": "ajxAJ8GUX4",
      "similarity": 0.845
    },
    {
      "source": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.843
    },
    {
      "source": "Our approach can approximate the evidence lower bound (ELBO) for normal (negative) data using only unlabeled and sensitive (positive) data.",
      "target": "oDbiL9CLoS",
      "similarity": 0.8148
    },
    {
      "source": "Our approach can approximate the evidence lower bound (ELBO) for normal (negative) data using only unlabeled and sensitive (positive) data.",
      "target": "In addition",
      "similarity": 0.8134
    },
    {
      "source": "Our approach can approximate the evidence lower bound (ELBO) for normal (negative) data using only unlabeled and sensitive (positive) data.",
      "target": "PbheqxnO1e",
      "similarity": 0.807
    },
    {
      "source": "Our approach can approximate the evidence lower bound (ELBO) for normal (negative) data using only unlabeled and sensitive (positive) data.",
      "target": "Beyond performance evaluations",
      "similarity": 0.8041
    },
    {
      "source": "Our approach can approximate the evidence lower bound (ELBO) for normal (negative) data using only unlabeled and sensitive (positive) data.",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.7992
    },
    {
      "source": "Therefore",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.842
    },
    {
      "source": "Therefore",
      "target": "bc2H72hGxB",
      "similarity": 0.8359
    },
    {
      "source": "Therefore",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.8294
    },
    {
      "source": "Therefore",
      "target": "memorization.",
      "similarity": 0.8225
    },
    {
      "source": "Therefore",
      "target": "5IWJBStfU7",
      "similarity": 0.8152
    },
    {
      "source": "we can maximize the ELBO for normal data and minimize it for labeled sensitive data",
      "target": "VQwI055flA",
      "similarity": 0.8742
    },
    {
      "source": "we can maximize the ELBO for normal data and minimize it for labeled sensitive data",
      "target": "To this end",
      "similarity": 0.8579
    },
    {
      "source": "we can maximize the ELBO for normal data and minimize it for labeled sensitive data",
      "target": "bRa4JLPzii",
      "similarity": 0.8574
    },
    {
      "source": "we can maximize the ELBO for normal data and minimize it for labeled sensitive data",
      "target": "4ktJJBvvUd",
      "similarity": 0.8569
    },
    {
      "source": "we can maximize the ELBO for normal data and minimize it for labeled sensitive data",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8527
    },
    {
      "source": "ensuring the generation of only normal data.",
      "target": "To this end",
      "similarity": 0.8444
    },
    {
      "source": "ensuring the generation of only normal data.",
      "target": "0fJfVOSUra",
      "similarity": 0.8436
    },
    {
      "source": "ensuring the generation of only normal data.",
      "target": "EcrdmRT99M",
      "similarity": 0.8423
    },
    {
      "source": "ensuring the generation of only normal data.",
      "target": "eHfq8Q3LeD",
      "similarity": 0.8366
    },
    {
      "source": "ensuring the generation of only normal data.",
      "target": "Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.\"",
      "similarity": 0.8362
    },
    {
      "source": "Through experiments across various datasets and settings",
      "target": "90DC0IvlSs",
      "similarity": 0.8887
    },
    {
      "source": "Through experiments across various datasets and settings",
      "target": "We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection.",
      "similarity": 0.8698
    },
    {
      "source": "Through experiments across various datasets and settings",
      "target": "4YzVF9isgD",
      "similarity": 0.8694
    },
    {
      "source": "Through experiments across various datasets and settings",
      "target": "To this end",
      "similarity": 0.8641
    },
    {
      "source": "Through experiments across various datasets and settings",
      "target": "to address these failure modes",
      "similarity": 0.858
    },
    {
      "source": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "target": "X0epAjg0hd",
      "similarity": 0.8799
    },
    {
      "source": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "target": "N4rYbQowE3",
      "similarity": 0.8096
    },
    {
      "source": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8018
    },
    {
      "source": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "target": "Beyond better performance",
      "similarity": 0.7974
    },
    {
      "source": "we demonstrated that our approach can prevent the generation of sensitive images without compromising image quality.\"",
      "target": "Previous video generation models often struggled with limited motion and short durations.",
      "similarity": 0.7938
    },
    {
      "source": "PstM8YfhvI",
      "target": "C45YqeBDUM",
      "similarity": 0.8459
    },
    {
      "source": "PstM8YfhvI",
      "target": "Our work paves the way to transform the longstanding time-consuming manual design flow of analog ICs to an automatic and massive manner powered by generative AI.",
      "similarity": 0.8444
    },
    {
      "source": "PstM8YfhvI",
      "target": "We study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.",
      "similarity": 0.8325
    },
    {
      "source": "PstM8YfhvI",
      "target": "nx9Z5Kva96",
      "similarity": 0.8199
    },
    {
      "source": "PstM8YfhvI",
      "target": "bBoetBIN2R",
      "similarity": 0.8192
    },
    {
      "source": "TYSQYx9vwd",
      "target": "In addition",
      "similarity": 0.858
    },
    {
      "source": "TYSQYx9vwd",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8508
    },
    {
      "source": "TYSQYx9vwd",
      "target": "EkfLaCJ7bk",
      "similarity": 0.85
    },
    {
      "source": "TYSQYx9vwd",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8495
    },
    {
      "source": "TYSQYx9vwd",
      "target": "fXb9BbuyAD",
      "similarity": 0.8444
    },
    {
      "source": "f7O3hITh5s",
      "target": "This work presents Physics-Informed Experimental Design (PIED)",
      "similarity": 0.8201
    },
    {
      "source": "f7O3hITh5s",
      "target": "Despite this",
      "similarity": 0.8102
    },
    {
      "source": "f7O3hITh5s",
      "target": "We then propose a novel implicitly-defined GNN architecture",
      "similarity": 0.7903
    },
    {
      "source": "f7O3hITh5s",
      "target": "To bridge this gap",
      "similarity": 0.7828
    },
    {
      "source": "f7O3hITh5s",
      "target": "I4iZmsV4HM",
      "similarity": 0.7774
    },
    {
      "source": "7IzeL0kflu",
      "target": "pB1XSj2y4X",
      "similarity": 0.8219
    },
    {
      "source": "7IzeL0kflu",
      "target": "To address these limitations",
      "similarity": 0.7841
    },
    {
      "source": "7IzeL0kflu",
      "target": "Finally",
      "similarity": 0.783
    },
    {
      "source": "7IzeL0kflu",
      "target": "L14sqcrUC3",
      "similarity": 0.7793
    },
    {
      "source": "7IzeL0kflu",
      "target": "Zjv38dg1Hb",
      "similarity": 0.779
    },
    {
      "source": "However",
      "target": "To address these issues",
      "similarity": 0.8508
    },
    {
      "source": "However",
      "target": "rCX9l4OTCT",
      "similarity": 0.8499
    },
    {
      "source": "However",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8426
    },
    {
      "source": "However",
      "target": "K4FAFNRpko",
      "similarity": 0.8423
    },
    {
      "source": "However",
      "target": "2fojNANZSv",
      "similarity": 0.8395
    },
    {
      "source": "kRoWeLTpL4",
      "target": "reZKq6hjOZ",
      "similarity": 0.7863
    },
    {
      "source": "kRoWeLTpL4",
      "target": "1H90Gb9rJ9",
      "similarity": 0.778
    },
    {
      "source": "kRoWeLTpL4",
      "target": "Pacmann shows better scalability",
      "similarity": 0.7778
    },
    {
      "source": "kRoWeLTpL4",
      "target": "lapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks",
      "similarity": 0.7768
    },
    {
      "source": "kRoWeLTpL4",
      "target": "We demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task.\"",
      "similarity": 0.7737
    },
    {
      "source": "g6v09VxgFw",
      "target": "JbRM5QKRDd",
      "similarity": 0.8379
    },
    {
      "source": "g6v09VxgFw",
      "target": "and structure of 3D objects (e.g.",
      "similarity": 0.825
    },
    {
      "source": "g6v09VxgFw",
      "target": "Second",
      "similarity": 0.8205
    },
    {
      "source": "g6v09VxgFw",
      "target": "To be specific",
      "similarity": 0.8194
    },
    {
      "source": "g6v09VxgFw",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8179
    },
    {
      "source": "Jszf4et48m",
      "target": "To this end",
      "similarity": 0.8704
    },
    {
      "source": "Jszf4et48m",
      "target": "3E8YNv1HjU",
      "similarity": 0.8666
    },
    {
      "source": "Jszf4et48m",
      "target": "eiqrnVaeIw",
      "similarity": 0.865
    },
    {
      "source": "Jszf4et48m",
      "target": "We further optimize tasks such as retrieval by sampling hard negatives",
      "similarity": 0.8632
    },
    {
      "source": "Jszf4et48m",
      "target": "LongGen builds on three key insights:",
      "similarity": 0.8592
    },
    {
      "source": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "target": "SCG generates sequences of tasks where the RL agent can be safe and performant by initially generating tasks with minimum safety violations over high-reward ones.",
      "similarity": 0.8449
    },
    {
      "source": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "target": "We also thoroughly analyzed our pre-training dataset",
      "similarity": 0.8445
    },
    {
      "source": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "target": "JvkuZZ04O7",
      "similarity": 0.8405
    },
    {
      "source": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "target": "Antib6Uovh",
      "similarity": 0.8377
    },
    {
      "source": "Instead of relying on the naive LDM concatenation conditioning mechanism to connect the different stages together",
      "target": "HN8V0flwJF",
      "similarity": 0.8337
    },
    {
      "source": "Although employing a cascaded pipeline introduces more stages",
      "target": "zigzag spaghetti (ZS)",
      "similarity": 0.851
    },
    {
      "source": "Although employing a cascaded pipeline introduces more stages",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8227
    },
    {
      "source": "Although employing a cascaded pipeline introduces more stages",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8189
    },
    {
      "source": "Although employing a cascaded pipeline introduces more stages",
      "target": "P6IVIoGRRg",
      "similarity": 0.8169
    },
    {
      "source": "Although employing a cascaded pipeline introduces more stages",
      "target": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "similarity": 0.8134
    },
    {
      "source": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "target": "WLSrq1254E",
      "similarity": 0.8448
    },
    {
      "source": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8415
    },
    {
      "source": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "target": "WCRQFlji2q",
      "similarity": 0.8378
    },
    {
      "source": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "target": "A1HhtITVEi",
      "similarity": 0.8299
    },
    {
      "source": "Modality composition not only enhances overall performance but enables emerging proprieties such as consistent editing",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8274
    },
    {
      "source": "Extensive experiments on diverse datasets",
      "target": "kxnoqaisCT",
      "similarity": 0.8147
    },
    {
      "source": "Extensive experiments on diverse datasets",
      "target": "comprehensive experiments",
      "similarity": 0.8057
    },
    {
      "source": "Extensive experiments on diverse datasets",
      "target": "a single GPU in a few hours",
      "similarity": 0.8027
    },
    {
      "source": "Extensive experiments on diverse datasets",
      "target": "Next",
      "similarity": 0.8024
    },
    {
      "source": "Extensive experiments on diverse datasets",
      "target": "ohJxgRLlLt",
      "similarity": 0.8023
    },
    {
      "source": "For instance",
      "target": "YwJkv2YqBq",
      "similarity": 0.8293
    },
    {
      "source": "For instance",
      "target": "suz4utPr9Y",
      "similarity": 0.8266
    },
    {
      "source": "For instance",
      "target": "K4FAFNRpko",
      "similarity": 0.8145
    },
    {
      "source": "For instance",
      "target": "interpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$.",
      "similarity": 0.8027
    },
    {
      "source": "For instance",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.789
    },
    {
      "source": "The project website is available at:",
      "target": "Notably",
      "similarity": 0.791
    },
    {
      "source": "The project website is available at:",
      "target": "FBhKUXK7od",
      "similarity": 0.7864
    },
    {
      "source": "The project website is available at:",
      "target": "gFvRRCnQvX",
      "similarity": 0.782
    },
    {
      "source": "The project website is available at:",
      "target": "7HEMpBTb3R",
      "similarity": 0.7756
    },
    {
      "source": "The project website is available at:",
      "target": "oDbiL9CLoS",
      "similarity": 0.7719
    },
    {
      "source": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "target": "Y2Dh8rWwlb",
      "similarity": 0.8097
    },
    {
      "source": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "target": "However",
      "similarity": 0.8044
    },
    {
      "source": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "target": "L14sqcrUC3",
      "similarity": 0.8037
    },
    {
      "source": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.8016
    },
    {
      "source": "\\href{https://toddlerdiffusion.github.io/website/}{$https://toddlerdiffusion.github.io/website/$}\"",
      "target": "nYjAzwor9R",
      "similarity": 0.7986
    },
    {
      "source": "7EhS3YBxjY",
      "target": "has difficulty in capturing the relationship and the similarity structure of a",
      "similarity": 0.8541
    },
    {
      "source": "7EhS3YBxjY",
      "target": "DTatjJTDl1",
      "similarity": 0.8355
    },
    {
      "source": "7EhS3YBxjY",
      "target": "samples from some underlying population $p^\\ast$",
      "similarity": 0.83
    },
    {
      "source": "7EhS3YBxjY",
      "target": "of distribution shifts. Then we propose an adaptive concept bottleneck framework",
      "similarity": 0.8224
    },
    {
      "source": "7EhS3YBxjY",
      "target": "We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.",
      "similarity": 0.8197
    },
    {
      "source": "Qzd4BloAjQ",
      "target": "$p\\in[2",
      "similarity": 0.8262
    },
    {
      "source": "Qzd4BloAjQ",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.8138
    },
    {
      "source": "Qzd4BloAjQ",
      "target": "magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) /",
      "similarity": 0.8094
    },
    {
      "source": "Qzd4BloAjQ",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8071
    },
    {
      "source": "Qzd4BloAjQ",
      "target": "Analyzing these high-performing models",
      "similarity": 0.8061
    },
    {
      "source": "OiQttMHwce",
      "target": "We empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks.",
      "similarity": 0.8446
    },
    {
      "source": "OiQttMHwce",
      "target": "While it is possible to correct for biases if the underlying causal graph is known",
      "similarity": 0.8414
    },
    {
      "source": "OiQttMHwce",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8406
    },
    {
      "source": "OiQttMHwce",
      "target": "implementation",
      "similarity": 0.8391
    },
    {
      "source": "OiQttMHwce",
      "target": "20qZK2T7fa",
      "similarity": 0.839
    },
    {
      "source": "P6IVIoGRRg",
      "target": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "similarity": 0.8664
    },
    {
      "source": "P6IVIoGRRg",
      "target": "WKW5TG8ItY",
      "similarity": 0.8585
    },
    {
      "source": "P6IVIoGRRg",
      "target": "Finally",
      "similarity": 0.8386
    },
    {
      "source": "P6IVIoGRRg",
      "target": "NKotdPUc3L",
      "similarity": 0.83
    },
    {
      "source": "P6IVIoGRRg",
      "target": "98d7DLMGdt",
      "similarity": 0.828
    },
    {
      "source": "3cvwO5DBZn",
      "target": "odU59TxdiB",
      "similarity": 0.8974
    },
    {
      "source": "3cvwO5DBZn",
      "target": "QWunLKbBGF",
      "similarity": 0.8877
    },
    {
      "source": "3cvwO5DBZn",
      "target": "Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically-plausible reduced Lagrangian models.\"",
      "similarity": 0.8802
    },
    {
      "source": "3cvwO5DBZn",
      "target": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "similarity": 0.8788
    },
    {
      "source": "3cvwO5DBZn",
      "target": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "similarity": 0.8758
    },
    {
      "source": "nibeaHUEJx",
      "target": "Our results show that LLMs can offer reliable self-information independent of external data in certain domains. By demonstrating this",
      "similarity": 0.847
    },
    {
      "source": "nibeaHUEJx",
      "target": "xiQNfYl33p",
      "similarity": 0.8456
    },
    {
      "source": "nibeaHUEJx",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8424
    },
    {
      "source": "nibeaHUEJx",
      "target": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "similarity": 0.8351
    },
    {
      "source": "nibeaHUEJx",
      "target": "We provide theoretical results showing that linear function approximation",
      "similarity": 0.8326
    },
    {
      "source": "2o58Mbqkd2",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8494
    },
    {
      "source": "2o58Mbqkd2",
      "target": "ii) AUPD achieves $\\tilde{O}(\\sqrt{T}+ \\frac{\\nu^*}{\\sqrt{b}}T^{\\frac{3}{4}})$ regret without strict feasibility assumption",
      "similarity": 0.8415
    },
    {
      "source": "2o58Mbqkd2",
      "target": "encodings (MPE). FFEs are seen as the standard for low dimensional mappings",
      "similarity": 0.834
    },
    {
      "source": "2o58Mbqkd2",
      "target": "TKuYWeFE6S",
      "similarity": 0.8319
    },
    {
      "source": "2o58Mbqkd2",
      "target": "AcVpLS86RT",
      "similarity": 0.8282
    },
    {
      "source": "bc2H72hGxB",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8413
    },
    {
      "source": "bc2H72hGxB",
      "target": "Kpjvm2mB0K",
      "similarity": 0.8395
    },
    {
      "source": "bc2H72hGxB",
      "target": "In this paper",
      "similarity": 0.8279
    },
    {
      "source": "bc2H72hGxB",
      "target": "ptjrpEGrGg",
      "similarity": 0.8264
    },
    {
      "source": "bc2H72hGxB",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8246
    },
    {
      "source": "However",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.849
    },
    {
      "source": "However",
      "target": "affects effectiveness in two downstream proxy model applications: data",
      "similarity": 0.8419
    },
    {
      "source": "However",
      "target": "3MnMGLctKb",
      "similarity": 0.841
    },
    {
      "source": "However",
      "target": "jxMAPMqNr5",
      "similarity": 0.8401
    },
    {
      "source": "However",
      "target": "zCZnEXF3bN",
      "similarity": 0.8384
    },
    {
      "source": "In this paper",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8287
    },
    {
      "source": "In this paper",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8245
    },
    {
      "source": "In this paper",
      "target": "Furthermore",
      "similarity": 0.8229
    },
    {
      "source": "In this paper",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.8173
    },
    {
      "source": "In this paper",
      "target": "memorization.",
      "similarity": 0.8147
    },
    {
      "source": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "target": "In offline evaluations",
      "similarity": 0.843
    },
    {
      "source": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "target": "does not necessarily improve the accuracy of the final evaluation. The inclusion of",
      "similarity": 0.8134
    },
    {
      "source": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "target": "oZkqkkvdND",
      "similarity": 0.81
    },
    {
      "source": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.8064
    },
    {
      "source": "Allie is trained on log sequences of real chess games to model the behaviors of human chess players across the skill spectrum",
      "target": "However",
      "similarity": 0.8048
    },
    {
      "source": "In offline evaluations",
      "target": "lOi6FtIwR8",
      "similarity": 0.8109
    },
    {
      "source": "In offline evaluations",
      "target": "kOJf7Dklyv",
      "similarity": 0.8078
    },
    {
      "source": "In offline evaluations",
      "target": "the weights. Analyzing the spectra of bilinear MLP weights using eigendecom-",
      "similarity": 0.8001
    },
    {
      "source": "In offline evaluations",
      "target": "While this issue is well-documented for transformers",
      "similarity": 0.799
    },
    {
      "source": "In offline evaluations",
      "target": "This increase becomes even more pronounced as the value of $p$ grows.",
      "similarity": 0.797
    },
    {
      "source": "The model learns to reliably assign reward at each game state",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.8358
    },
    {
      "source": "The model learns to reliably assign reward at each game state",
      "target": "uQnvYP7yX9",
      "similarity": 0.8306
    },
    {
      "source": "The model learns to reliably assign reward at each game state",
      "target": "cKlzKs3Nnb",
      "similarity": 0.8286
    },
    {
      "source": "The model learns to reliably assign reward at each game state",
      "target": "PxlfzEePC0",
      "similarity": 0.8244
    },
    {
      "source": "The model learns to reliably assign reward at each game state",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8209
    },
    {
      "source": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "target": "BiGR features a binary tokenizer",
      "similarity": 0.8369
    },
    {
      "source": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8361
    },
    {
      "source": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "target": "In addition",
      "similarity": 0.8339
    },
    {
      "source": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "target": "These tasks are built from geometry problems",
      "similarity": 0.8313
    },
    {
      "source": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "target": "MBBRHDuiwM",
      "similarity": 0.8202
    },
    {
      "source": "Against grandmaster-level (2500 Elo) opponents",
      "target": "In experiments with GPT-4",
      "similarity": 0.8328
    },
    {
      "source": "Against grandmaster-level (2500 Elo) opponents",
      "target": "In particular",
      "similarity": 0.8298
    },
    {
      "source": "Against grandmaster-level (2500 Elo) opponents",
      "target": "To fill this gap",
      "similarity": 0.8269
    },
    {
      "source": "Against grandmaster-level (2500 Elo) opponents",
      "target": "vVHc8bGRns",
      "similarity": 0.8229
    },
    {
      "source": "Against grandmaster-level (2500 Elo) opponents",
      "target": "layer dropping but also fixes their key issues. Furthermore",
      "similarity": 0.8204
    },
    {
      "source": "bmbRCRiNDu",
      "target": "To this end",
      "similarity": 0.8751
    },
    {
      "source": "bmbRCRiNDu",
      "target": "decision-making pipelines using high-level concept vectors. Specifically",
      "similarity": 0.8643
    },
    {
      "source": "bmbRCRiNDu",
      "target": "Qja5s0K3VX",
      "similarity": 0.8622
    },
    {
      "source": "bmbRCRiNDu",
      "target": "xPTzjpIQNp",
      "similarity": 0.8618
    },
    {
      "source": "bmbRCRiNDu",
      "target": "the best-known complexity bounds for convex objectives.",
      "similarity": 0.8614
    },
    {
      "source": "PQpvhUrA1C",
      "target": "To this end",
      "similarity": 0.8597
    },
    {
      "source": "PQpvhUrA1C",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8467
    },
    {
      "source": "PQpvhUrA1C",
      "target": "JvkuZZ04O7",
      "similarity": 0.8403
    },
    {
      "source": "PQpvhUrA1C",
      "target": "To overcome these challenges",
      "similarity": 0.8351
    },
    {
      "source": "PQpvhUrA1C",
      "target": "bMC1t7eLRc",
      "similarity": 0.8328
    },
    {
      "source": "p6ncr0eTKE",
      "target": "fn36V5qsCw",
      "similarity": 0.7969
    },
    {
      "source": "p6ncr0eTKE",
      "target": "Pj4Aid3XqL",
      "similarity": 0.7966
    },
    {
      "source": "p6ncr0eTKE",
      "target": "FEpAUnS7f7",
      "similarity": 0.7963
    },
    {
      "source": "p6ncr0eTKE",
      "target": "oYSsbY3G4o",
      "similarity": 0.7958
    },
    {
      "source": "p6ncr0eTKE",
      "target": "K3KrOsR6y9",
      "similarity": 0.7941
    },
    {
      "source": "9ca9eHNrdH",
      "target": "4iFSBgxvIO",
      "similarity": 0.8475
    },
    {
      "source": "9ca9eHNrdH",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8417
    },
    {
      "source": "9ca9eHNrdH",
      "target": "c61unr33XA",
      "similarity": 0.8417
    },
    {
      "source": "9ca9eHNrdH",
      "target": "4GT9uTsAJE",
      "similarity": 0.84
    },
    {
      "source": "9ca9eHNrdH",
      "target": "otW0TJOUYF",
      "similarity": 0.8357
    },
    {
      "source": "1Z6PSw7OL8",
      "target": "OFukl9Qg8P",
      "similarity": 0.8191
    },
    {
      "source": "1Z6PSw7OL8",
      "target": "which",
      "similarity": 0.8182
    },
    {
      "source": "1Z6PSw7OL8",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8129
    },
    {
      "source": "1Z6PSw7OL8",
      "target": "CjXaMI2kUH",
      "similarity": 0.8125
    },
    {
      "source": "1Z6PSw7OL8",
      "target": "Neural Stochastic Differential Equations for Uncertainty-aware",
      "similarity": 0.8108
    },
    {
      "source": "BiGR features a binary tokenizer",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8326
    },
    {
      "source": "BiGR features a binary tokenizer",
      "target": "x$",
      "similarity": 0.8289
    },
    {
      "source": "BiGR features a binary tokenizer",
      "target": "MBBRHDuiwM",
      "similarity": 0.8286
    },
    {
      "source": "BiGR features a binary tokenizer",
      "target": "mXHTifc1Fn",
      "similarity": 0.8282
    },
    {
      "source": "BiGR features a binary tokenizer",
      "target": "TYSQYx9vwd",
      "similarity": 0.8196
    },
    {
      "source": "Additionally",
      "target": "need for more advanced methods that can account for the reliability of individual",
      "similarity": 0.8457
    },
    {
      "source": "Additionally",
      "target": "MBBRHDuiwM",
      "similarity": 0.8396
    },
    {
      "source": "Additionally",
      "target": "jDsmB4o5S0",
      "similarity": 0.8362
    },
    {
      "source": "Additionally",
      "target": "We also analyze how the model behaves as a policy and value",
      "similarity": 0.834
    },
    {
      "source": "Additionally",
      "target": "Ian00SaFHg",
      "similarity": 0.831
    },
    {
      "source": "Extensive experiments validate BiGR's superior performance in generation quality",
      "target": "However",
      "similarity": 0.826
    },
    {
      "source": "Extensive experiments validate BiGR's superior performance in generation quality",
      "target": "In this paper",
      "similarity": 0.821
    },
    {
      "source": "Extensive experiments validate BiGR's superior performance in generation quality",
      "target": "In addition",
      "similarity": 0.8203
    },
    {
      "source": "Extensive experiments validate BiGR's superior performance in generation quality",
      "target": "WKW5TG8ItY",
      "similarity": 0.8163
    },
    {
      "source": "Extensive experiments validate BiGR's superior performance in generation quality",
      "target": "Aye5wL6TCn",
      "similarity": 0.8123
    },
    {
      "source": "Moreover",
      "target": "hXm0Wu2U9K",
      "similarity": 0.8399
    },
    {
      "source": "Moreover",
      "target": "DelTA employs a sentence-by-sentence translation strategy",
      "similarity": 0.8381
    },
    {
      "source": "Moreover",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8353
    },
    {
      "source": "Moreover",
      "target": "By directly learning to stochastically interpolate between noise and data point sets",
      "similarity": 0.8347
    },
    {
      "source": "Moreover",
      "target": "Our framework",
      "similarity": 0.8346
    },
    {
      "source": "WKW5TG8ItY",
      "target": "1F8xTfv6ah",
      "similarity": 0.8243
    },
    {
      "source": "WKW5TG8ItY",
      "target": "wsWCVrH9dv",
      "similarity": 0.8235
    },
    {
      "source": "WKW5TG8ItY",
      "target": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "similarity": 0.8224
    },
    {
      "source": "WKW5TG8ItY",
      "target": "nfKfAzkiez",
      "similarity": 0.8219
    },
    {
      "source": "WKW5TG8ItY",
      "target": "Aye5wL6TCn",
      "similarity": 0.82
    },
    {
      "source": "yZ7sn9pyqb",
      "target": "OuLgaHEmzi",
      "similarity": 0.8382
    },
    {
      "source": "yZ7sn9pyqb",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8253
    },
    {
      "source": "yZ7sn9pyqb",
      "target": "HqjRlT65WX",
      "similarity": 0.8252
    },
    {
      "source": "yZ7sn9pyqb",
      "target": "Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities",
      "similarity": 0.8232
    },
    {
      "source": "yZ7sn9pyqb",
      "target": "Our experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models",
      "similarity": 0.8231
    },
    {
      "source": "tu3qwNjrtw",
      "target": "fAAaT826Vv",
      "similarity": 0.8598
    },
    {
      "source": "tu3qwNjrtw",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8511
    },
    {
      "source": "tu3qwNjrtw",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8508
    },
    {
      "source": "tu3qwNjrtw",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.8476
    },
    {
      "source": "tu3qwNjrtw",
      "target": "zxO4WuVGns",
      "similarity": 0.8467
    },
    {
      "source": "In practice",
      "target": "8EfxjTCg2k",
      "similarity": 0.8593
    },
    {
      "source": "In practice",
      "target": "We show experimentally that our heuristic is predictive of the outcome of privacy auditing applied to various training procedures. Thus it can be used prior to training as a rough estimate of the final privacy leakage. We also probe the limitations of our heuristic by providing some artificial counterexamples where it underestimates the privacy leakage.",
      "similarity": 0.8431
    },
    {
      "source": "In practice",
      "target": "in model performance as the query vocabulary set expands",
      "similarity": 0.8429
    },
    {
      "source": "In practice",
      "target": "We identify four stages in the training dynamics",
      "similarity": 0.8426
    },
    {
      "source": "In practice",
      "target": "YFxfcQMLWX",
      "similarity": 0.8375
    },
    {
      "source": "TArmA033BU",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8681
    },
    {
      "source": "TArmA033BU",
      "target": "In our experiments",
      "similarity": 0.8369
    },
    {
      "source": "TArmA033BU",
      "target": "First",
      "similarity": 0.827
    },
    {
      "source": "TArmA033BU",
      "target": "A conjecture by Hertrich",
      "similarity": 0.8224
    },
    {
      "source": "TArmA033BU",
      "target": "IxmWIkcKs5",
      "similarity": 0.8209
    },
    {
      "source": "kOJf7Dklyv",
      "target": "However",
      "similarity": 0.8388
    },
    {
      "source": "kOJf7Dklyv",
      "target": "eNQp79A5Oz",
      "similarity": 0.8155
    },
    {
      "source": "kOJf7Dklyv",
      "target": "At its core",
      "similarity": 0.8032
    },
    {
      "source": "kOJf7Dklyv",
      "target": "(e.g.",
      "similarity": 0.8005
    },
    {
      "source": "kOJf7Dklyv",
      "target": "First",
      "similarity": 0.8003
    },
    {
      "source": "UchRjcf4z7",
      "target": "WOt1owGfuN",
      "similarity": 0.8377
    },
    {
      "source": "UchRjcf4z7",
      "target": "DKgAFfCs5F",
      "similarity": 0.818
    },
    {
      "source": "UchRjcf4z7",
      "target": "This paper proposes Preble",
      "similarity": 0.8161
    },
    {
      "source": "UchRjcf4z7",
      "target": "8sSqNntaMr",
      "similarity": 0.8153
    },
    {
      "source": "UchRjcf4z7",
      "target": "Overall",
      "similarity": 0.8151
    },
    {
      "source": "03EkqSCKuO",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8564
    },
    {
      "source": "03EkqSCKuO",
      "target": "We release models",
      "similarity": 0.8523
    },
    {
      "source": "03EkqSCKuO",
      "target": "gcouwCx7dG",
      "similarity": 0.8473
    },
    {
      "source": "03EkqSCKuO",
      "target": "This enables the network to adaptively reuse parameters across tasks",
      "similarity": 0.8396
    },
    {
      "source": "03EkqSCKuO",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8393
    },
    {
      "source": "90DC0IvlSs",
      "target": "(1) make no assumptions on the data",
      "similarity": 0.8732
    },
    {
      "source": "90DC0IvlSs",
      "target": "nCrJD7qPJN",
      "similarity": 0.869
    },
    {
      "source": "90DC0IvlSs",
      "target": "_Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images",
      "similarity": 0.8673
    },
    {
      "source": "90DC0IvlSs",
      "target": "We demonstrate the stealthiness and robustness of our method",
      "similarity": 0.8668
    },
    {
      "source": "90DC0IvlSs",
      "target": "EQgEMAD4kv",
      "similarity": 0.8623
    },
    {
      "source": "(1) make no assumptions on the data",
      "target": "nCrJD7qPJN",
      "similarity": 0.8851
    },
    {
      "source": "(1) make no assumptions on the data",
      "target": "To address both challenges we augment the recently proposed",
      "similarity": 0.8703
    },
    {
      "source": "(1) make no assumptions on the data",
      "target": "For TP",
      "similarity": 0.8657
    },
    {
      "source": "(1) make no assumptions on the data",
      "target": "fWRBheSJth",
      "similarity": 0.864
    },
    {
      "source": "(1) make no assumptions on the data",
      "target": "ngmEcEer8a",
      "similarity": 0.8603
    },
    {
      "source": "each query.\"",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8266
    },
    {
      "source": "each query.\"",
      "target": "TvGPP8i18S",
      "similarity": 0.8125
    },
    {
      "source": "each query.\"",
      "target": "k2uUeLCrQq",
      "similarity": 0.811
    },
    {
      "source": "each query.\"",
      "target": "71pur4y8gs",
      "similarity": 0.8093
    },
    {
      "source": "each query.\"",
      "target": "W2dR6rypBQ",
      "similarity": 0.8076
    },
    {
      "source": "ny8T8OuNHe",
      "target": "Moreover on large datasets with up to 100 million vectors",
      "similarity": 0.8201
    },
    {
      "source": "ny8T8OuNHe",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8189
    },
    {
      "source": "ny8T8OuNHe",
      "target": "interpretable drop-in replacement for current activation functions and that weight-",
      "similarity": 0.8154
    },
    {
      "source": "ny8T8OuNHe",
      "target": "97rOQDPmk2",
      "similarity": 0.8145
    },
    {
      "source": "ny8T8OuNHe",
      "target": "LNL7zKvm7e",
      "similarity": 0.8141
    },
    {
      "source": "aKRADWBJ1I",
      "target": "unsafe",
      "similarity": 0.8351
    },
    {
      "source": "aKRADWBJ1I",
      "target": "xI71dsS3o4",
      "similarity": 0.8083
    },
    {
      "source": "aKRADWBJ1I",
      "target": "Several subquadratic architectures have been proposed to address this computational issue. Some of them",
      "similarity": 0.8025
    },
    {
      "source": "aKRADWBJ1I",
      "target": "TrVYEZtSQH",
      "similarity": 0.8023
    },
    {
      "source": "aKRADWBJ1I",
      "target": "UN6Ik6OCx8",
      "similarity": 0.802
    },
    {
      "source": "unsafe",
      "target": "To fill this gap",
      "similarity": 0.8206
    },
    {
      "source": "unsafe",
      "target": "We present a new deep-Q algorithm that estimates the effect of both when and what to do called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for the Q-function that is compatible with flexible sequence models",
      "similarity": 0.815
    },
    {
      "source": "unsafe",
      "target": "4ytRL3HJrq",
      "similarity": 0.8136
    },
    {
      "source": "unsafe",
      "target": "yzloNYH3QN",
      "similarity": 0.801
    },
    {
      "source": "unsafe",
      "target": "UN6Ik6OCx8",
      "similarity": 0.7995
    },
    {
      "source": "confine RL agents to simulated environments",
      "target": "However",
      "similarity": 0.8115
    },
    {
      "source": "confine RL agents to simulated environments",
      "target": "To this end",
      "similarity": 0.8022
    },
    {
      "source": "confine RL agents to simulated environments",
      "target": "As such",
      "similarity": 0.7987
    },
    {
      "source": "confine RL agents to simulated environments",
      "target": "AnalogGenie addresses two key gaps in the field: building a foundational comprehensive dataset of analog circuit topology and developing a scalable sequence-based graph representation universal to analog circuits.",
      "similarity": 0.7978
    },
    {
      "source": "confine RL agents to simulated environments",
      "target": "Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention",
      "similarity": 0.7968
    },
    {
      "source": "directly in real-world settings. In this work",
      "target": "show that BoneMet can be readily adopted to build versatile",
      "similarity": 0.8436
    },
    {
      "source": "directly in real-world settings. In this work",
      "target": "target node would not have been anomalous. Prior methods of assessing the fix",
      "similarity": 0.8419
    },
    {
      "source": "directly in real-world settings. In this work",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.84
    },
    {
      "source": "directly in real-world settings. In this work",
      "target": "Code and demonstrations are available at https://mbreuss.github.io/MoDE_Diffusion_Policy.\"",
      "similarity": 0.8394
    },
    {
      "source": "directly in real-world settings. In this work",
      "target": "Pj4Aid3XqL",
      "similarity": 0.8393
    },
    {
      "source": "model-based RL algorithm for safe and efficient exploration. ActSafe learns",
      "target": "ajxAJ8GUX4",
      "similarity": 0.8334
    },
    {
      "source": "model-based RL algorithm for safe and efficient exploration. ActSafe learns",
      "target": "In this paper",
      "similarity": 0.8222
    },
    {
      "source": "model-based RL algorithm for safe and efficient exploration. ActSafe learns",
      "target": "xJXq6FkqEw",
      "similarity": 0.8219
    },
    {
      "source": "model-based RL algorithm for safe and efficient exploration. ActSafe learns",
      "target": "contextual interactions among tasks",
      "similarity": 0.8194
    },
    {
      "source": "model-based RL algorithm for safe and efficient exploration. ActSafe learns",
      "target": "prompts of 128K length",
      "similarity": 0.8161
    },
    {
      "source": "a well-calibrated probabilistic model of the system and plans optimistically",
      "target": "By investigating the geometric structure of the Pareto front in MO-MDPs",
      "similarity": 0.8181
    },
    {
      "source": "a well-calibrated probabilistic model of the system and plans optimistically",
      "target": "To overcome those challenges",
      "similarity": 0.8122
    },
    {
      "source": "a well-calibrated probabilistic model of the system and plans optimistically",
      "target": "Notably",
      "similarity": 0.8052
    },
    {
      "source": "a well-calibrated probabilistic model of the system and plans optimistically",
      "target": "wUtXB43Chi",
      "similarity": 0.8029
    },
    {
      "source": "a well-calibrated probabilistic model of the system and plans optimistically",
      "target": "eNQp79A5Oz",
      "similarity": 0.8027
    },
    {
      "source": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "target": "CkUHtnyhpY",
      "similarity": 0.8282
    },
    {
      "source": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "target": "In parallel",
      "similarity": 0.8134
    },
    {
      "source": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "target": "In this work",
      "similarity": 0.8097
    },
    {
      "source": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "target": "We propose *uncertainty coverage*",
      "similarity": 0.8047
    },
    {
      "source": "w.r.t. the epistemic uncertainty about the unknown dynamics",
      "target": "vjel3nWP2a",
      "similarity": 0.7951
    },
    {
      "source": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "target": "To address this",
      "similarity": 0.8102
    },
    {
      "source": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "target": "However",
      "similarity": 0.8078
    },
    {
      "source": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "target": "However",
      "similarity": 0.8061
    },
    {
      "source": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "target": "In this study",
      "similarity": 0.8056
    },
    {
      "source": "pessimism w.r.t. the safety constraints. Under regularity assumptions on the",
      "target": "prevent rank collapse",
      "similarity": 0.8041
    },
    {
      "source": "constraints and dynamics",
      "target": "Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term",
      "similarity": 0.8389
    },
    {
      "source": "constraints and dynamics",
      "target": "rTCJ29pkuA",
      "similarity": 0.8145
    },
    {
      "source": "constraints and dynamics",
      "target": "and ImageNet). The results show the stability and frugality of the GEV model and",
      "similarity": 0.8042
    },
    {
      "source": "constraints and dynamics",
      "target": "JDm7oIcx4Y",
      "similarity": 0.7921
    },
    {
      "source": "constraints and dynamics",
      "target": "nIEjY4a2Lf",
      "similarity": 0.7913
    },
    {
      "source": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "target": "4v4RcAODj9",
      "similarity": 0.8119
    },
    {
      "source": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "target": "WoPovNkM5h",
      "similarity": 0.8009
    },
    {
      "source": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "target": "In this paper",
      "similarity": 0.8004
    },
    {
      "source": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "target": "In contrast",
      "similarity": 0.8003
    },
    {
      "source": "learning while also obtaining a near-optimal policy in finite time. In addition",
      "target": "Nq7yKYL0Bp",
      "similarity": 0.8002
    },
    {
      "source": "propose a practical variant of ActSafe that builds on latest model-based RL advancements and enables safe exploration even in high-dimensional settings such",
      "target": "To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes",
      "similarity": 0.8161
    },
    {
      "source": "propose a practical variant of ActSafe that builds on latest model-based RL advancements and enables safe exploration even in high-dimensional settings such",
      "target": "2o58Mbqkd2",
      "similarity": 0.8131
    },
    {
      "source": "propose a practical variant of ActSafe that builds on latest model-based RL advancements and enables safe exploration even in high-dimensional settings such",
      "target": "consuming process of managing large 3D assets",
      "similarity": 0.8104
    },
    {
      "source": "propose a practical variant of ActSafe that builds on latest model-based RL advancements and enables safe exploration even in high-dimensional settings such",
      "target": "Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.",
      "similarity": 0.8052
    },
    {
      "source": "propose a practical variant of ActSafe that builds on latest model-based RL advancements and enables safe exploration even in high-dimensional settings such",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8016
    },
    {
      "source": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "target": "wide dissemination",
      "similarity": 0.8715
    },
    {
      "source": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "target": "have not been thoroughly examined for similar vulnerabilities. This paper extends",
      "similarity": 0.8518
    },
    {
      "source": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "target": "9qS3HzSDNv",
      "similarity": 0.8499
    },
    {
      "source": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "target": "These findings highlight the significant room for improvement in current reward models.\"",
      "similarity": 0.8451
    },
    {
      "source": "as visual control. We empirically show that ActSafe obtains state-of-the-art",
      "target": "m51BgoqvbP",
      "similarity": 0.8423
    },
    {
      "source": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "target": "tGYFikNONB",
      "similarity": 0.8114
    },
    {
      "source": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "target": "INyi7qUdjZ",
      "similarity": 0.7926
    },
    {
      "source": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "target": "nYjAzwor9R",
      "similarity": 0.7914
    },
    {
      "source": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "target": "comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM\u2019s complexity to demonstrate the cases where IDI\u2019s interventional approach outperforms the counterfactual approach and vice versa.",
      "similarity": 0.791
    },
    {
      "source": "performance in difficult exploration tasks on standard safe deep RL benchmarks",
      "target": "Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$",
      "similarity": 0.7902
    },
    {
      "source": "while ensuring safety during learning.\"",
      "target": "Few recent works have focused on designing a new fine-tuning scheme that can lead to small parameter interference",
      "similarity": 0.8764
    },
    {
      "source": "while ensuring safety during learning.\"",
      "target": "Essg9kb4yx",
      "similarity": 0.8761
    },
    {
      "source": "while ensuring safety during learning.\"",
      "target": "For example",
      "similarity": 0.8729
    },
    {
      "source": "while ensuring safety during learning.\"",
      "target": "ue1Tt3h1VC",
      "similarity": 0.862
    },
    {
      "source": "while ensuring safety during learning.\"",
      "target": "- In discrete image-based control (e.g.",
      "similarity": 0.8584
    },
    {
      "source": "hrOlBgHsMI",
      "target": "d8hYXbxX71",
      "similarity": 0.8188
    },
    {
      "source": "hrOlBgHsMI",
      "target": "zZ8fgXHkXi",
      "similarity": 0.7973
    },
    {
      "source": "hrOlBgHsMI",
      "target": "In our approach",
      "similarity": 0.7912
    },
    {
      "source": "hrOlBgHsMI",
      "target": "6VhDQP7WGX",
      "similarity": 0.7903
    },
    {
      "source": "hrOlBgHsMI",
      "target": "Our code",
      "similarity": 0.7858
    },
    {
      "source": "FPfCUJTsCn",
      "target": "TYSQYx9vwd",
      "similarity": 0.835
    },
    {
      "source": "FPfCUJTsCn",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8334
    },
    {
      "source": "FPfCUJTsCn",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8247
    },
    {
      "source": "FPfCUJTsCn",
      "target": "B5iOSxM2I0",
      "similarity": 0.8236
    },
    {
      "source": "FPfCUJTsCn",
      "target": "We revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances",
      "similarity": 0.8206
    },
    {
      "source": "However",
      "target": "kxnoqaisCT",
      "similarity": 0.8263
    },
    {
      "source": "However",
      "target": "First",
      "similarity": 0.8235
    },
    {
      "source": "However",
      "target": "ANBuEJesgx",
      "similarity": 0.8191
    },
    {
      "source": "However",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8187
    },
    {
      "source": "However",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8186
    },
    {
      "source": "To tackle this challenge",
      "target": "To overcome those challenges",
      "similarity": 0.8619
    },
    {
      "source": "To tackle this challenge",
      "target": "pDDODPtpx9",
      "similarity": 0.8603
    },
    {
      "source": "To tackle this challenge",
      "target": "Tn5B6Udq3E",
      "similarity": 0.8597
    },
    {
      "source": "To tackle this challenge",
      "target": "For example",
      "similarity": 0.859
    },
    {
      "source": "To tackle this challenge",
      "target": "5AtlfHYCPa",
      "similarity": 0.8573
    },
    {
      "source": "Specifically",
      "target": "works by producing ameliorative feedback by prompting a Vision-Language Model",
      "similarity": 0.8108
    },
    {
      "source": "Specifically",
      "target": "Second",
      "similarity": 0.8057
    },
    {
      "source": "Specifically",
      "target": "4GT9uTsAJE",
      "similarity": 0.8045
    },
    {
      "source": "Specifically",
      "target": "tQyh0gnfqW",
      "similarity": 0.7905
    },
    {
      "source": "Specifically",
      "target": "Furthermore",
      "similarity": 0.7895
    },
    {
      "source": "This reformulation enables DiffILO to simultaneously solve ILPs and train the model via straightforward gradient descent",
      "target": "ngmEcEer8a",
      "similarity": 0.8719
    },
    {
      "source": "This reformulation enables DiffILO to simultaneously solve ILPs and train the model via straightforward gradient descent",
      "target": "Pujt3ADZgI",
      "similarity": 0.8598
    },
    {
      "source": "This reformulation enables DiffILO to simultaneously solve ILPs and train the model via straightforward gradient descent",
      "target": "IDJUscOjM3",
      "similarity": 0.8566
    },
    {
      "source": "This reformulation enables DiffILO to simultaneously solve ILPs and train the model via straightforward gradient descent",
      "target": "90DC0IvlSs",
      "similarity": 0.8507
    },
    {
      "source": "This reformulation enables DiffILO to simultaneously solve ILPs and train the model via straightforward gradient descent",
      "target": "Through an extensive empirical study on a large selection of tasks and models",
      "similarity": 0.8452
    },
    {
      "source": "First",
      "target": "27SSnLl85x",
      "similarity": 0.8231
    },
    {
      "source": "First",
      "target": "attention mechanism. We scale Samba up to 3.8B parameters with 3.2T training",
      "similarity": 0.822
    },
    {
      "source": "First",
      "target": "4NTrco82W0",
      "similarity": 0.812
    },
    {
      "source": "First",
      "target": "Despite recent advancements in single-person motion generation",
      "similarity": 0.8057
    },
    {
      "source": "First",
      "target": "DpLFmc09pC",
      "similarity": 0.8032
    },
    {
      "source": "Second",
      "target": "tQyh0gnfqW",
      "similarity": 0.8263
    },
    {
      "source": "Second",
      "target": "1F8xTfv6ah",
      "similarity": 0.824
    },
    {
      "source": "Second",
      "target": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "similarity": 0.8224
    },
    {
      "source": "Second",
      "target": "iVMcYxTiVM",
      "similarity": 0.8216
    },
    {
      "source": "Second",
      "target": "P6IVIoGRRg",
      "similarity": 0.8188
    },
    {
      "source": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "target": "mFY0tPDWK8",
      "similarity": 0.826
    },
    {
      "source": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "target": "wkbx7BRAsM",
      "similarity": 0.8183
    },
    {
      "source": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "target": "60GeEoG5kD",
      "similarity": 0.8147
    },
    {
      "source": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "target": "PSiijdQjNU",
      "similarity": 0.8145
    },
    {
      "source": "Experiments on commonly used ILP datasets demonstrate that DiffILO not only achieves an average training speedup of $13.2$ times compared to supervised methods",
      "target": "an upper bound of excess risk on downstream classification tasks of representations",
      "similarity": 0.8135
    },
    {
      "source": "mb2ryuZ3wz",
      "target": "qn9tBYQHGi",
      "similarity": 0.8065
    },
    {
      "source": "mb2ryuZ3wz",
      "target": "a hypergraph",
      "similarity": 0.7926
    },
    {
      "source": "mb2ryuZ3wz",
      "target": "By playing against itself",
      "similarity": 0.7891
    },
    {
      "source": "mb2ryuZ3wz",
      "target": "We investigate an alternative attention mechanism based on the stick-breaking process in larger scale settings.",
      "similarity": 0.7873
    },
    {
      "source": "mb2ryuZ3wz",
      "target": "target node would not have been anomalous. Prior methods of assessing the fix",
      "similarity": 0.7859
    },
    {
      "source": "j1tSLYKwg8",
      "target": "Subsequently",
      "similarity": 0.8647
    },
    {
      "source": "j1tSLYKwg8",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8521
    },
    {
      "source": "j1tSLYKwg8",
      "target": "This study proposes \\textbf{PolyhedronNet}",
      "similarity": 0.8508
    },
    {
      "source": "j1tSLYKwg8",
      "target": "9KiE3t6CsL",
      "similarity": 0.8365
    },
    {
      "source": "j1tSLYKwg8",
      "target": "which prevent the generation of sensitive data using unlabeled and sensitive data.",
      "similarity": 0.8362
    },
    {
      "source": "xiDJaTim3P",
      "target": "We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that",
      "similarity": 0.8108
    },
    {
      "source": "xiDJaTim3P",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.8091
    },
    {
      "source": "xiDJaTim3P",
      "target": "zZ8fgXHkXi",
      "similarity": 0.8042
    },
    {
      "source": "xiDJaTim3P",
      "target": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "similarity": 0.7985
    },
    {
      "source": "xiDJaTim3P",
      "target": "In experiments with GPT-4",
      "similarity": 0.7959
    },
    {
      "source": "fAAaT826Vv",
      "target": "JYTQ6ELUVO",
      "similarity": 0.8429
    },
    {
      "source": "fAAaT826Vv",
      "target": "By balancing exploration and exploitation",
      "similarity": 0.8405
    },
    {
      "source": "fAAaT826Vv",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.8365
    },
    {
      "source": "fAAaT826Vv",
      "target": "While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion.",
      "similarity": 0.8357
    },
    {
      "source": "fAAaT826Vv",
      "target": "learning has exhibited impressive capacities across various healthcare domains",
      "similarity": 0.8339
    },
    {
      "source": "UeVx6L59fg",
      "target": "zxO4WuVGns",
      "similarity": 0.8419
    },
    {
      "source": "UeVx6L59fg",
      "target": "Drawing on findings from cognitive science about representativeness heuristics",
      "similarity": 0.8251
    },
    {
      "source": "UeVx6L59fg",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8231
    },
    {
      "source": "UeVx6L59fg",
      "target": "While recent compression methods based on low-rank matrices show potential",
      "similarity": 0.8199
    },
    {
      "source": "UeVx6L59fg",
      "target": "MRAG-Bench consists of 16",
      "similarity": 0.8183
    },
    {
      "source": "Pd7IOswRUZ",
      "target": "However",
      "similarity": 0.8571
    },
    {
      "source": "Pd7IOswRUZ",
      "target": "5IWJBStfU7",
      "similarity": 0.8474
    },
    {
      "source": "Pd7IOswRUZ",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8443
    },
    {
      "source": "Pd7IOswRUZ",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.844
    },
    {
      "source": "Pd7IOswRUZ",
      "target": "cKlzKs3Nnb",
      "similarity": 0.8421
    },
    {
      "source": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "target": "98d7DLMGdt",
      "similarity": 0.8371
    },
    {
      "source": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "target": "However",
      "similarity": 0.8329
    },
    {
      "source": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "target": "We find that pre-training with a mixture of image and text data allows models to perform better on vision-language tasks while maintaining strong performance on text-only evaluations.",
      "similarity": 0.8328
    },
    {
      "source": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "target": "We conducted a comprehensive regret analysis of our proposed framework",
      "similarity": 0.8298
    },
    {
      "source": "the ability to perform high-level abstract visual reasoning (AVR). Despite the current success of algorithms that solve this task",
      "target": "and performing sophisticated tasks",
      "similarity": 0.8264
    },
    {
      "source": "of 24 OOD scenarios. Further",
      "target": "2p03KljxE9",
      "similarity": 0.8298
    },
    {
      "source": "of 24 OOD scenarios. Further",
      "target": "Ev4iw23gdI",
      "similarity": 0.8074
    },
    {
      "source": "of 24 OOD scenarios. Further",
      "target": "1tBvzOYTLF",
      "similarity": 0.8055
    },
    {
      "source": "of 24 OOD scenarios. Further",
      "target": "While this direct impact of language-informed training on a model's visual perception is intriguing",
      "similarity": 0.8012
    },
    {
      "source": "of 24 OOD scenarios. Further",
      "target": "rEQqBZIz49",
      "similarity": 0.7896
    },
    {
      "source": "YLIsIzC74j",
      "target": "mXHTifc1Fn",
      "similarity": 0.8414
    },
    {
      "source": "YLIsIzC74j",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8167
    },
    {
      "source": "YLIsIzC74j",
      "target": "K4FAFNRpko",
      "similarity": 0.8009
    },
    {
      "source": "YLIsIzC74j",
      "target": "5z9GjHgerY",
      "similarity": 0.7969
    },
    {
      "source": "YLIsIzC74j",
      "target": "that",
      "similarity": 0.7955
    },
    {
      "source": "However",
      "target": "In this paper",
      "similarity": 0.8375
    },
    {
      "source": "However",
      "target": "7bAjVh3CG3",
      "similarity": 0.837
    },
    {
      "source": "However",
      "target": "h1XoHOd19I",
      "similarity": 0.8213
    },
    {
      "source": "However",
      "target": "We demonstrate that",
      "similarity": 0.8195
    },
    {
      "source": "However",
      "target": "Remarkably",
      "similarity": 0.8144
    },
    {
      "source": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "target": "In this paper",
      "similarity": 0.8536
    },
    {
      "source": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8404
    },
    {
      "source": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "target": "C45YqeBDUM",
      "similarity": 0.8354
    },
    {
      "source": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "target": "vQhn4wrQ6j",
      "similarity": 0.8298
    },
    {
      "source": "This is mainly because of the high computational costs associated with performing post-placement stages for evaluating such metrics",
      "target": "ogjBpZ8uSi",
      "similarity": 0.826
    },
    {
      "source": "Consequently",
      "target": "CvGqMD5OtX",
      "similarity": 0.8235
    },
    {
      "source": "Consequently",
      "target": "wxPnuFp8fZ",
      "similarity": 0.8218
    },
    {
      "source": "Consequently",
      "target": "calibration data is also crucial to post-training pruning",
      "similarity": 0.8211
    },
    {
      "source": "Consequently",
      "target": "fMTPkDEhLQ",
      "similarity": 0.8172
    },
    {
      "source": "Consequently",
      "target": "component of real-world software development.\"",
      "similarity": 0.8169
    },
    {
      "source": "To bridge this gap",
      "target": "B5iOSxM2I0",
      "similarity": 0.8366
    },
    {
      "source": "To bridge this gap",
      "target": "FPfCUJTsCn",
      "similarity": 0.8148
    },
    {
      "source": "To bridge this gap",
      "target": "03OkC0LKDD",
      "similarity": 0.8147
    },
    {
      "source": "To bridge this gap",
      "target": "GeUK3zGreN",
      "similarity": 0.8082
    },
    {
      "source": "To bridge this gap",
      "target": "hSZaCIznB2",
      "similarity": 0.807
    },
    {
      "source": "Specifically",
      "target": "cADpvQgnqg",
      "similarity": 0.8178
    },
    {
      "source": "Specifically",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8133
    },
    {
      "source": "Specifically",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8129
    },
    {
      "source": "Specifically",
      "target": "memorization.",
      "similarity": 0.8109
    },
    {
      "source": "Specifically",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.81
    },
    {
      "source": "This mask essentially acts as a fast evaluator",
      "target": "rTQNGQxm4K",
      "similarity": 0.8296
    },
    {
      "source": "This mask essentially acts as a fast evaluator",
      "target": "YvKJGYL4j7",
      "similarity": 0.8159
    },
    {
      "source": "This mask essentially acts as a fast evaluator",
      "target": "models raises the question: how does training data distribution influence model",
      "similarity": 0.8135
    },
    {
      "source": "This mask essentially acts as a fast evaluator",
      "target": "skGSOcrIj7",
      "similarity": 0.8124
    },
    {
      "source": "This mask essentially acts as a fast evaluator",
      "target": "PwxYoMvmvy",
      "similarity": 0.812
    },
    {
      "source": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.8334
    },
    {
      "source": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "target": "Fk3eod9aaD",
      "similarity": 0.8249
    },
    {
      "source": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "target": "(including gradient-based",
      "similarity": 0.8175
    },
    {
      "source": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "target": "tijmpS9Vy2",
      "similarity": 0.8118
    },
    {
      "source": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "target": "tn2mjzjSyR",
      "similarity": 0.8109
    },
    {
      "source": "KWH4UIoQKS",
      "target": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "similarity": 0.8216
    },
    {
      "source": "KWH4UIoQKS",
      "target": "fNMKqyvuZT",
      "similarity": 0.8209
    },
    {
      "source": "KWH4UIoQKS",
      "target": "c61unr33XA",
      "similarity": 0.8191
    },
    {
      "source": "KWH4UIoQKS",
      "target": "However",
      "similarity": 0.8154
    },
    {
      "source": "KWH4UIoQKS",
      "target": "{Subsequently}",
      "similarity": 0.8107
    },
    {
      "source": "9D2QvO1uWj",
      "target": "In this work",
      "similarity": 0.8365
    },
    {
      "source": "9D2QvO1uWj",
      "target": "H0qIWXXLUR",
      "similarity": 0.8141
    },
    {
      "source": "9D2QvO1uWj",
      "target": "LCPO's source code is available at https://github.com/pouyahmdn/LCPO.\"",
      "similarity": 0.8099
    },
    {
      "source": "9D2QvO1uWj",
      "target": "SFN6Wm7YBI",
      "similarity": 0.803
    },
    {
      "source": "9D2QvO1uWj",
      "target": "uL1H29dM0c",
      "similarity": 0.8013
    },
    {
      "source": "52x04chyQs",
      "target": "cADpvQgnqg",
      "similarity": 0.8324
    },
    {
      "source": "52x04chyQs",
      "target": "WJaUkwci9o",
      "similarity": 0.8266
    },
    {
      "source": "52x04chyQs",
      "target": "YcUV5apdlq",
      "similarity": 0.8193
    },
    {
      "source": "52x04chyQs",
      "target": "zxO4WuVGns",
      "similarity": 0.8178
    },
    {
      "source": "52x04chyQs",
      "target": "agents for video understanding. VideoWA consists of 2",
      "similarity": 0.8145
    },
    {
      "source": "3MnMGLctKb",
      "target": "4YzVF9isgD",
      "similarity": 0.8192
    },
    {
      "source": "3MnMGLctKb",
      "target": "that the latter is provably protected from out-of-distribution and adversarial samples. The proposed Sample-efficient Probabilistic Detection using Extreme Value",
      "similarity": 0.8154
    },
    {
      "source": "3MnMGLctKb",
      "target": "Yet",
      "similarity": 0.8143
    },
    {
      "source": "3MnMGLctKb",
      "target": "jxMAPMqNr5",
      "similarity": 0.8131
    },
    {
      "source": "3MnMGLctKb",
      "target": "However",
      "similarity": 0.8124
    },
    {
      "source": "Kpjvm2mB0K",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8691
    },
    {
      "source": "Kpjvm2mB0K",
      "target": "c61unr33XA",
      "similarity": 0.8652
    },
    {
      "source": "Kpjvm2mB0K",
      "target": "strong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD. **Third**",
      "similarity": 0.8533
    },
    {
      "source": "Kpjvm2mB0K",
      "target": "ULGbw2URE3",
      "similarity": 0.8382
    },
    {
      "source": "Kpjvm2mB0K",
      "target": "Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.",
      "similarity": 0.8377
    },
    {
      "source": "$$",
      "target": "We interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape.",
      "similarity": 0.8017
    },
    {
      "source": "$$",
      "target": "the gradient norm in nonconvex problems",
      "similarity": 0.7945
    },
    {
      "source": "$$",
      "target": "Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially",
      "similarity": 0.7944
    },
    {
      "source": "$$",
      "target": "For example",
      "similarity": 0.7926
    },
    {
      "source": "$$",
      "target": "HZgZrtIreg",
      "similarity": 0.7913
    },
    {
      "source": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "target": "rCX9l4OTCT",
      "similarity": 0.8503
    },
    {
      "source": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8404
    },
    {
      "source": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "target": "TYSQYx9vwd",
      "similarity": 0.8343
    },
    {
      "source": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "target": "4es2oO9tw1",
      "similarity": 0.8341
    },
    {
      "source": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "target": "MBBRHDuiwM",
      "similarity": 0.8315
    },
    {
      "source": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "target": "RAyRXQjsFl",
      "similarity": 0.8438
    },
    {
      "source": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "target": "way that is agnostic to whether the SAEs have learned the exact ground-truth",
      "similarity": 0.8415
    },
    {
      "source": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "target": "5IWJBStfU7",
      "similarity": 0.841
    },
    {
      "source": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "target": "yLhJYvkKA0",
      "similarity": 0.84
    },
    {
      "source": "\\text{where } \\mathbf A \\in \\mathbb R^{n \\times d} \\text{ with } n \\ll d \\",
      "target": "Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench.\"",
      "similarity": 0.8379
    },
    {
      "source": "$$",
      "target": "(including gradient-based",
      "similarity": 0.8574
    },
    {
      "source": "$$",
      "target": "Our method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model",
      "similarity": 0.8256
    },
    {
      "source": "$$",
      "target": "Validated using our collected college-level circuit analysis problems",
      "similarity": 0.8112
    },
    {
      "source": "$$",
      "target": "mDKxlfraAn",
      "similarity": 0.8103
    },
    {
      "source": "$$",
      "target": "Experiments on commonly used benchmarks demonstrate that LaMPlace significantly improves the chip quality across several key design metrics",
      "similarity": 0.81
    },
    {
      "source": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "target": "C06kww3Qky",
      "similarity": 0.8688
    },
    {
      "source": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "target": "Second",
      "similarity": 0.8669
    },
    {
      "source": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "target": "2mqb8bPHeb",
      "similarity": 0.8629
    },
    {
      "source": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "target": "hoYFLRNbhc",
      "similarity": 0.86
    },
    {
      "source": "which generalizes basis pursuit ($p = 1$) and least squares solutions to",
      "target": "TbTJJNjumY",
      "similarity": 0.8584
    },
    {
      "source": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "target": "ptjrpEGrGg",
      "similarity": 0.83
    },
    {
      "source": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8168
    },
    {
      "source": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "target": "GRMfXcAAFh",
      "similarity": 0.8155
    },
    {
      "source": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "target": "EMMnAd3apQ",
      "similarity": 0.8128
    },
    {
      "source": "underdetermined linear systems ($p = 2$). We study the column-arrival",
      "target": "IwPXYk6BV9",
      "similarity": 0.8103
    },
    {
      "source": "streaming model",
      "target": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "similarity": 0.8343
    },
    {
      "source": "streaming model",
      "target": "This paper argues that integrating length extension with a GPU-friendly KV cache reduction architecture not only reduces training overhead during length extension",
      "similarity": 0.8258
    },
    {
      "source": "streaming model",
      "target": "h0ZfDIrj7T",
      "similarity": 0.813
    },
    {
      "source": "streaming model",
      "target": "IwPXYk6BV9",
      "similarity": 0.8065
    },
    {
      "source": "streaming model",
      "target": "ERv8ptegFi",
      "similarity": 0.8019
    },
    {
      "source": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "target": "C45YqeBDUM",
      "similarity": 0.8354
    },
    {
      "source": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "target": "(VideoWA)",
      "similarity": 0.8238
    },
    {
      "source": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "target": "GpdO9r73xT",
      "similarity": 0.8187
    },
    {
      "source": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "target": "DC8bsa9bzY",
      "similarity": 0.8091
    },
    {
      "source": "stream. When $\\mathbf A$ is the incidence matrix of a graph",
      "target": "gcouwCx7dG",
      "similarity": 0.8069
    },
    {
      "source": "edge insertion graph stream",
      "target": "sound",
      "similarity": 0.8609
    },
    {
      "source": "edge insertion graph stream",
      "target": "Building on these insights",
      "similarity": 0.8482
    },
    {
      "source": "edge insertion graph stream",
      "target": "VpWki1v2P8",
      "similarity": 0.8437
    },
    {
      "source": "edge insertion graph stream",
      "target": "6GATHdOi1x",
      "similarity": 0.8433
    },
    {
      "source": "edge insertion graph stream",
      "target": "hwnObmOTrV",
      "similarity": 0.8371
    },
    {
      "source": "flows which includes transshipment ($p = 1$)",
      "target": "Our main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space",
      "similarity": 0.857
    },
    {
      "source": "flows which includes transshipment ($p = 1$)",
      "target": "In this paper",
      "similarity": 0.8501
    },
    {
      "source": "flows which includes transshipment ($p = 1$)",
      "target": "Usklli4gMc",
      "similarity": 0.8477
    },
    {
      "source": "flows which includes transshipment ($p = 1$)",
      "target": "pDDODPtpx9",
      "similarity": 0.8455
    },
    {
      "source": "flows which includes transshipment ($p = 1$)",
      "target": "For example",
      "similarity": 0.8454
    },
    {
      "source": "max flow ($p = \\infty$) on undirected graphs as special cases. Our goal is to",
      "target": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "similarity": 0.8313
    },
    {
      "source": "max flow ($p = \\infty$) on undirected graphs as special cases. Our goal is to",
      "target": "Overcooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.",
      "similarity": 0.8274
    },
    {
      "source": "max flow ($p = \\infty$) on undirected graphs as special cases. Our goal is to",
      "target": "Our code and data are publicly available at https://github.com/thu-coai/SPaR.\"",
      "similarity": 0.8269
    },
    {
      "source": "max flow ($p = \\infty$) on undirected graphs as special cases. Our goal is to",
      "target": "sampled from a distribution. We illustrate counterfactual bias certification for",
      "similarity": 0.8256
    },
    {
      "source": "max flow ($p = \\infty$) on undirected graphs as special cases. Our goal is to",
      "target": "JYTQ6ELUVO",
      "similarity": 0.825
    },
    {
      "source": "design algorithms which use space much less than the entire stream",
      "target": "other baselines across all metrics",
      "similarity": 0.8695
    },
    {
      "source": "design algorithms which use space much less than the entire stream",
      "target": "However",
      "similarity": 0.8557
    },
    {
      "source": "design algorithms which use space much less than the entire stream",
      "target": "7nyJBVCTGQ",
      "similarity": 0.8415
    },
    {
      "source": "design algorithms which use space much less than the entire stream",
      "target": "bSq0XGS3kW",
      "similarity": 0.8414
    },
    {
      "source": "design algorithms which use space much less than the entire stream",
      "target": "Following the derived guidelines",
      "similarity": 0.8329
    },
    {
      "source": "a length of $d$.",
      "target": "without access to the source dataset. Empirical evaluations with various real-world",
      "similarity": 0.8105
    },
    {
      "source": "a length of $d$.",
      "target": "YUYJsHOf3c",
      "similarity": 0.8036
    },
    {
      "source": "a length of $d$.",
      "target": "an upper bound of excess risk on downstream classification tasks of representations",
      "similarity": 0.8031
    },
    {
      "source": "a length of $d$.",
      "target": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "similarity": 0.8009
    },
    {
      "source": "a length of $d$.",
      "target": "t8fu5m8R5m",
      "similarity": 0.8004
    },
    {
      "source": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "target": "2kGKsyhtvh",
      "similarity": 0.8458
    },
    {
      "source": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8342
    },
    {
      "source": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "target": "samples. However",
      "similarity": 0.8318
    },
    {
      "source": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "target": "nx9Z5Kva96",
      "similarity": 0.8248
    },
    {
      "source": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "target": "kbm6tsICar",
      "similarity": 0.8227
    },
    {
      "source": "$p\\in[2",
      "target": "qssVptHTPN",
      "similarity": 0.8027
    },
    {
      "source": "$p\\in[2",
      "target": "For the task of estimating the cost of the $\\ell_p$ regression problem for",
      "similarity": 0.8024
    },
    {
      "source": "$p\\in[2",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8008
    },
    {
      "source": "$p\\in[2",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.7933
    },
    {
      "source": "$p\\in[2",
      "target": "While recent research has progressed in generating diagrams from text descriptions",
      "similarity": 0.7918
    },
    {
      "source": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "target": "odU59TxdiB",
      "similarity": 0.9135
    },
    {
      "source": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "target": "We show that our algorithm learns a feature representation that strongly aligns with the unknown signal $\\theta^\\star$",
      "similarity": 0.8866
    },
    {
      "source": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "target": "QWunLKbBGF",
      "similarity": 0.8803
    },
    {
      "source": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8706
    },
    {
      "source": "instance supported on $\\tilde O(\\varepsilon^{-2}n)$ columns of $\\mathbf A$",
      "target": "counterfactual bias)",
      "similarity": 0.8697
    },
    {
      "source": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "target": "1qq1QJKM5q",
      "similarity": 0.8558
    },
    {
      "source": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "target": "E4LAVLXAHW",
      "similarity": 0.8539
    },
    {
      "source": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "target": "ff2V3UR9sC",
      "similarity": 0.8431
    },
    {
      "source": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "target": "In this work",
      "similarity": 0.8355
    },
    {
      "source": "which approximates the cost up to a $(1\\pm\\varepsilon)$ factor",
      "target": "TbTJJNjumY",
      "similarity": 0.8335
    },
    {
      "source": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "target": "language-guided scene layout editing.\"",
      "similarity": 0.8401
    },
    {
      "source": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "target": "evaluate biases across LLM responses for different demographic groups (a.k.a.",
      "similarity": 0.8333
    },
    {
      "source": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "target": "These results showcase the potential for dynamic and reflective computation",
      "similarity": 0.8293
    },
    {
      "source": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "target": "lydPkW4lfz",
      "similarity": 0.8292
    },
    {
      "source": "corresponds to $\\tilde O(\\varepsilon^{-2}n^2)$ bits of space in general and",
      "target": "We provide real data examples demonstrating validity",
      "similarity": 0.8279
    },
    {
      "source": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "target": "minimum performance improvement of 12.3%. In addition",
      "similarity": 0.8404
    },
    {
      "source": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "target": "eaTqsptDPL",
      "similarity": 0.8374
    },
    {
      "source": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "target": "5.0% improvement in success rate compared to prior work.\"",
      "similarity": 0.8363
    },
    {
      "source": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "target": "JAMxRSXLFz",
      "similarity": 0.836
    },
    {
      "source": "an $\\tilde O(\\varepsilon^{-2}n)$ space semi-streaming algorithm for",
      "target": "CAssIgPN4I",
      "similarity": 0.8343
    },
    {
      "source": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "target": "otW0TJOUYF",
      "similarity": 0.8431
    },
    {
      "source": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "target": "We believe that CNL-P can bridge the gap between emerging PE and traditional SE",
      "similarity": 0.8369
    },
    {
      "source": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "target": "To this end",
      "similarity": 0.8334
    },
    {
      "source": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "target": "Towards doing so",
      "similarity": 0.826
    },
    {
      "source": "constructing $\\ell_p$ flow sparsifiers on graphs. This extends to $p\\in(1",
      "target": "by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures",
      "similarity": 0.823
    },
    {
      "source": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "target": "98d7DLMGdt",
      "similarity": 0.8356
    },
    {
      "source": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "target": "l0fn10vSyM",
      "similarity": 0.8329
    },
    {
      "source": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.8323
    },
    {
      "source": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8271
    },
    {
      "source": "2)$ with $\\tilde O(\\varepsilon^{2}n^{q/2})$ columns",
      "target": "iteratively verify and improve 3D objects generated from CAD code. Our approach",
      "similarity": 0.8266
    },
    {
      "source": "conjugate exponent of $p$. For $p = 2$",
      "target": "across a variety of benchmarks. Pretrained on sequences of 4K length",
      "similarity": 0.8246
    },
    {
      "source": "conjugate exponent of $p$. For $p = 2$",
      "target": "agHddsQhsL",
      "similarity": 0.8225
    },
    {
      "source": "conjugate exponent of $p$. For $p = 2$",
      "target": "riTiq3i21b",
      "similarity": 0.8215
    },
    {
      "source": "conjugate exponent of $p$. For $p = 2$",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8191
    },
    {
      "source": "conjugate exponent of $p$. For $p = 2$",
      "target": "rather than modifying the routing mechanism as done in previous studies",
      "similarity": 0.8188
    },
    {
      "source": "space are required in general even for outputting a constant factor",
      "target": "In response",
      "similarity": 0.8335
    },
    {
      "source": "space are required in general even for outputting a constant factor",
      "target": "Our approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment",
      "similarity": 0.8254
    },
    {
      "source": "space are required in general even for outputting a constant factor",
      "target": "while some multilingual LLMs claim to support for hundreds of languages",
      "similarity": 0.823
    },
    {
      "source": "space are required in general even for outputting a constant factor",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.8171
    },
    {
      "source": "space are required in general even for outputting a constant factor",
      "target": "hidden activations over an input dataset but generally cannot explain how MLP",
      "similarity": 0.8161
    },
    {
      "source": "solution. For $p = 1$",
      "target": "(including gradient-based",
      "similarity": 0.8397
    },
    {
      "source": "solution. For $p = 1$",
      "target": "Subsequently",
      "similarity": 0.8377
    },
    {
      "source": "solution. For $p = 1$",
      "target": "jj7b3p5kLY",
      "similarity": 0.8375
    },
    {
      "source": "solution. For $p = 1$",
      "target": "Code is available at https://github.com/XLearning-SCU/2025-ICLR-TCR.\"",
      "similarity": 0.8284
    },
    {
      "source": "solution. For $p = 1$",
      "target": "Despite the near-optimal performance of existing approaches on benchmarks with high-quality datasets",
      "similarity": 0.8281
    },
    {
      "source": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "target": "9kJperA2a4",
      "similarity": 0.8516
    },
    {
      "source": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "target": "We find empirically that this latent code is predictive of the subtasks the network performs on unseen task compositions",
      "similarity": 0.8484
    },
    {
      "source": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "target": "v1rFkElnIn",
      "similarity": 0.8457
    },
    {
      "source": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "target": "mnna9LUg7P",
      "similarity": 0.834
    },
    {
      "source": "$o(\\sqrt n)$ factor in $\\mathrm{poly}(n)$ space.",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8333
    },
    {
      "source": "On the other hand",
      "target": "ogXkmugNZw",
      "similarity": 0.8355
    },
    {
      "source": "On the other hand",
      "target": "XAjfjizaKs",
      "similarity": 0.8124
    },
    {
      "source": "On the other hand",
      "target": "To address this gap",
      "similarity": 0.8112
    },
    {
      "source": "On the other hand",
      "target": "CausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).",
      "similarity": 0.8095
    },
    {
      "source": "On the other hand",
      "target": "yVGGtsOgc7",
      "similarity": 0.8086
    },
    {
      "source": "x$",
      "target": "It contains three fundamental sub-tasks: interactive segmentation",
      "similarity": 0.8369
    },
    {
      "source": "x$",
      "target": "lS2SGfWizd",
      "similarity": 0.8235
    },
    {
      "source": "x$",
      "target": "\\min_{\\mathbf A\\mathbf x = \\mathbf b} \\lVert\\mathbf x\\rVert_p \\",
      "similarity": 0.8205
    },
    {
      "source": "x$",
      "target": "Adaptive search enables remarkable *skill calibration*; in a large-scale online evaluation against players with ratings from 1000 to 2600 Elo",
      "similarity": 0.8154
    },
    {
      "source": "x$",
      "target": "Therefore",
      "similarity": 0.8111
    },
    {
      "source": "space for $p > 1$",
      "target": "nzjSvVZBIp",
      "similarity": 0.8167
    },
    {
      "source": "space for $p > 1$",
      "target": "O6znYvxC1U",
      "similarity": 0.8165
    },
    {
      "source": "space for $p > 1$",
      "target": "yR47RmND1m",
      "similarity": 0.8164
    },
    {
      "source": "space for $p > 1$",
      "target": "In this paper",
      "similarity": 0.8164
    },
    {
      "source": "space for $p > 1$",
      "target": "entities of a sentence (subject",
      "similarity": 0.8163
    },
    {
      "source": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "target": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "similarity": 0.8645
    },
    {
      "source": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "target": "EMMnAd3apQ",
      "similarity": 0.8472
    },
    {
      "source": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "target": "YcUV5apdlq",
      "similarity": 0.8345
    },
    {
      "source": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8287
    },
    {
      "source": "$\\tilde\\Omega(d/\\kappa^{2q})$ space for $p > 1$. We complement these lower",
      "target": "Furthermore",
      "similarity": 0.8276
    },
    {
      "source": "bounds with the first sublinear space upper bounds for this problem",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.8317
    },
    {
      "source": "bounds with the first sublinear space upper bounds for this problem",
      "target": "P6IVIoGRRg",
      "similarity": 0.8187
    },
    {
      "source": "bounds with the first sublinear space upper bounds for this problem",
      "target": "nfKfAzkiez",
      "similarity": 0.8122
    },
    {
      "source": "bounds with the first sublinear space upper bounds for this problem",
      "target": "deepfake dataset comprising 1.3 million samples spanning audio-visual forgeries",
      "similarity": 0.8049
    },
    {
      "source": "bounds with the first sublinear space upper bounds for this problem",
      "target": "related solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically",
      "similarity": 0.8022
    },
    {
      "source": "that we can output a $\\kappa$-approximation using space only",
      "target": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "similarity": 0.8778
    },
    {
      "source": "that we can output a $\\kappa$-approximation using space only",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.8259
    },
    {
      "source": "that we can output a $\\kappa$-approximation using space only",
      "target": "zXCnIyX9MG",
      "similarity": 0.8129
    },
    {
      "source": "that we can output a $\\kappa$-approximation using space only",
      "target": "DTqx3iqjkz",
      "similarity": 0.8115
    },
    {
      "source": "that we can output a $\\kappa$-approximation using space only",
      "target": "Building on these insights",
      "similarity": 0.8024
    },
    {
      "source": "$\\mathrm{poly}(n) \\cdot \\tilde O(d/\\kappa^q)$ for $p > 1$",
      "target": "provable separation between model-free and model-based OPE in POMDPs.\"",
      "similarity": 0.8218
    },
    {
      "source": "$\\mathrm{poly}(n) \\cdot \\tilde O(d/\\kappa^q)$ for $p > 1$",
      "target": "Our experiments on a variety of chaotic systems",
      "similarity": 0.8208
    },
    {
      "source": "$\\mathrm{poly}(n) \\cdot \\tilde O(d/\\kappa^q)$ for $p > 1$",
      "target": "Leveraging multiple sources of information and time-series meta-data",
      "similarity": 0.8201
    },
    {
      "source": "$\\mathrm{poly}(n) \\cdot \\tilde O(d/\\kappa^q)$ for $p > 1$",
      "target": "NUD03NBDOE",
      "similarity": 0.8179
    },
    {
      "source": "$\\mathrm{poly}(n) \\cdot \\tilde O(d/\\kappa^q)$ for $p > 1$",
      "target": "We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes.",
      "similarity": 0.8159
    },
    {
      "source": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "target": "DTqx3iqjkz",
      "similarity": 0.8266
    },
    {
      "source": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "target": "Building on these insights",
      "similarity": 0.8133
    },
    {
      "source": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "target": "This leads to our proposed LongGen",
      "similarity": 0.812
    },
    {
      "source": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "target": "zXCnIyX9MG",
      "similarity": 0.8089
    },
    {
      "source": "$\\sqrt n$-approximation using $\\mathrm{poly}(n",
      "target": "OFukl9Qg8P",
      "similarity": 0.8058
    },
    {
      "source": "X0epAjg0hd",
      "target": "We find that increasing the number of experts helps solve knowledge-intensive tasks",
      "similarity": 0.8207
    },
    {
      "source": "X0epAjg0hd",
      "target": "7bAjVh3CG3",
      "similarity": 0.8135
    },
    {
      "source": "X0epAjg0hd",
      "target": "80\\% still have higher MSE than a constant-effect model; and (c) Orthogonality-based models outperform other models only 30\\% of the time",
      "similarity": 0.8072
    },
    {
      "source": "X0epAjg0hd",
      "target": "HqjRlT65WX",
      "similarity": 0.8061
    },
    {
      "source": "X0epAjg0hd",
      "target": "We empirically validate across three continuous control benchmarks for generalizing to in-distribution (interpolation) and out-of-distribution (extrapolation) factors that GSD outperforms baselines in novel behavior discovery by $\\sim$21\\%.",
      "similarity": 0.8052
    },
    {
      "source": "LqTz13JS2P",
      "target": "of mitigating gradient spikes in LLM training and introduces an effective optimization strategy that enhances both training stability and resource efficiency at scale. Code is submitted.\"",
      "similarity": 0.8491
    },
    {
      "source": "LqTz13JS2P",
      "target": "Furthermore",
      "similarity": 0.849
    },
    {
      "source": "LqTz13JS2P",
      "target": "We then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.",
      "similarity": 0.845
    },
    {
      "source": "LqTz13JS2P",
      "target": "(BoneMet) dataset",
      "similarity": 0.8436
    },
    {
      "source": "LqTz13JS2P",
      "target": "Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench",
      "similarity": 0.8421
    },
    {
      "source": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "target": "HqjRlT65WX",
      "similarity": 0.8394
    },
    {
      "source": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "target": "\\url{https://github.com/xushilin1/RAP-SAM}\"",
      "similarity": 0.8228
    },
    {
      "source": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "target": "Our results show that for LLMs with strong reasoning capabilities",
      "similarity": 0.8191
    },
    {
      "source": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "target": "(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover",
      "similarity": 0.8182
    },
    {
      "source": "We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction",
      "target": "Specifically",
      "similarity": 0.8172
    },
    {
      "source": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "target": "Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds",
      "similarity": 0.8337
    },
    {
      "source": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "target": "accuracy and computational efficiency\"",
      "similarity": 0.8285
    },
    {
      "source": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "target": "niques reveal that multiple unrelated features influence the decisions",
      "similarity": 0.8238
    },
    {
      "source": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "target": "To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks",
      "similarity": 0.8238
    },
    {
      "source": "(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$",
      "target": "MxbEiFRf39",
      "similarity": 0.8208
    },
    {
      "source": "But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret)",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8086
    },
    {
      "source": "But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret)",
      "target": "However",
      "similarity": 0.8027
    },
    {
      "source": "But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret)",
      "target": "INqLJwqUmc",
      "similarity": 0.801
    },
    {
      "source": "But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret)",
      "target": "We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions",
      "similarity": 0.7999
    },
    {
      "source": "But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret)",
      "target": "LSp4KBhAom",
      "similarity": 0.7954
    },
    {
      "source": "These results not only refine previous results in Stackelberg games and contract design",
      "target": "cADpvQgnqg",
      "similarity": 0.8549
    },
    {
      "source": "These results not only refine previous results in Stackelberg games and contract design",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8472
    },
    {
      "source": "These results not only refine previous results in Stackelberg games and contract design",
      "target": "ugyqNEOjoU",
      "similarity": 0.8452
    },
    {
      "source": "These results not only refine previous results in Stackelberg games and contract design",
      "target": "YcUV5apdlq",
      "similarity": 0.8444
    },
    {
      "source": "These results not only refine previous results in Stackelberg games and contract design",
      "target": "TYSQYx9vwd",
      "similarity": 0.8441
    },
    {
      "source": "odU59TxdiB",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8645
    },
    {
      "source": "odU59TxdiB",
      "target": "In addition",
      "similarity": 0.8643
    },
    {
      "source": "odU59TxdiB",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8628
    },
    {
      "source": "odU59TxdiB",
      "target": "jQP5o1VAVc",
      "similarity": 0.859
    },
    {
      "source": "odU59TxdiB",
      "target": "gI0kPklUKS",
      "similarity": 0.8587
    },
    {
      "source": "h7GAgbLSmC",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.87
    },
    {
      "source": "h7GAgbLSmC",
      "target": "The idea is that M1 has privileged access to its own behavioral tendencies",
      "similarity": 0.8465
    },
    {
      "source": "h7GAgbLSmC",
      "target": "FrFQpAgnGE",
      "similarity": 0.8459
    },
    {
      "source": "h7GAgbLSmC",
      "target": "A1HhtITVEi",
      "similarity": 0.8437
    },
    {
      "source": "h7GAgbLSmC",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8436
    },
    {
      "source": "agHddsQhsL",
      "target": "- In continuous image-based control (e.g.",
      "similarity": 0.8147
    },
    {
      "source": "agHddsQhsL",
      "target": "We are the first to identify these challenges in online VFL",
      "similarity": 0.8147
    },
    {
      "source": "agHddsQhsL",
      "target": "PY56Wur7S0",
      "similarity": 0.8144
    },
    {
      "source": "agHddsQhsL",
      "target": "lfPkGWXLLf",
      "similarity": 0.814
    },
    {
      "source": "agHddsQhsL",
      "target": "riTiq3i21b",
      "similarity": 0.8125
    },
    {
      "source": "lJ66m0ibQL",
      "target": "ptjrpEGrGg",
      "similarity": 0.8177
    },
    {
      "source": "lJ66m0ibQL",
      "target": "zigzag spaghetti (ZS)",
      "similarity": 0.8171
    },
    {
      "source": "lJ66m0ibQL",
      "target": "j1tSLYKwg8",
      "similarity": 0.8165
    },
    {
      "source": "lJ66m0ibQL",
      "target": "Interestingly",
      "similarity": 0.8111
    },
    {
      "source": "lJ66m0ibQL",
      "target": "GhexuBLxbO",
      "similarity": 0.8095
    },
    {
      "source": "2p03KljxE9",
      "target": "In this paper",
      "similarity": 0.8179
    },
    {
      "source": "2p03KljxE9",
      "target": "fundamentally different from FFEs",
      "similarity": 0.8062
    },
    {
      "source": "2p03KljxE9",
      "target": "In this paper",
      "similarity": 0.804
    },
    {
      "source": "2p03KljxE9",
      "target": "The code supporting this library is a public",
      "similarity": 0.7921
    },
    {
      "source": "2p03KljxE9",
      "target": "hPWWXpCaJ7",
      "similarity": 0.7921
    },
    {
      "source": "1xzqz73hvL",
      "target": "As a result",
      "similarity": 0.8177
    },
    {
      "source": "1xzqz73hvL",
      "target": "To address this",
      "similarity": 0.8151
    },
    {
      "source": "1xzqz73hvL",
      "target": "fL4qWkSmtM",
      "similarity": 0.8018
    },
    {
      "source": "1xzqz73hvL",
      "target": "such ambiguity",
      "similarity": 0.7993
    },
    {
      "source": "1xzqz73hvL",
      "target": "Fully unsupervised methods make minimal assumptions but incur high computational costs",
      "similarity": 0.7946
    },
    {
      "source": "6cQ6cBqzV3",
      "target": "RB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost.",
      "similarity": 0.7913
    },
    {
      "source": "6cQ6cBqzV3",
      "target": "KlN00vQEY2",
      "similarity": 0.7892
    },
    {
      "source": "6cQ6cBqzV3",
      "target": "model of the mixture specializes in distinct parts of the data distribution",
      "similarity": 0.7882
    },
    {
      "source": "6cQ6cBqzV3",
      "target": "tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods",
      "similarity": 0.7813
    },
    {
      "source": "6cQ6cBqzV3",
      "target": "layer on the reweighted data using influence functions. Our GSR is theoretically",
      "similarity": 0.7811
    },
    {
      "source": "HE6pJoNnFp",
      "target": "B2Fqu7Y2cd",
      "similarity": 0.8286
    },
    {
      "source": "HE6pJoNnFp",
      "target": "mUXdysoxEP",
      "similarity": 0.8271
    },
    {
      "source": "HE6pJoNnFp",
      "target": "To compute the influence ($i.e.",
      "similarity": 0.8145
    },
    {
      "source": "HE6pJoNnFp",
      "target": "we validate our findings with experiments demonstrating the crucial role of archi-",
      "similarity": 0.8078
    },
    {
      "source": "HE6pJoNnFp",
      "target": "than existing search techniques",
      "similarity": 0.8077
    },
    {
      "source": "suz4utPr9Y",
      "target": "uL1H29dM0c",
      "similarity": 0.8398
    },
    {
      "source": "suz4utPr9Y",
      "target": "cADpvQgnqg",
      "similarity": 0.8388
    },
    {
      "source": "suz4utPr9Y",
      "target": "Recent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However",
      "similarity": 0.838
    },
    {
      "source": "suz4utPr9Y",
      "target": "Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach.",
      "similarity": 0.8368
    },
    {
      "source": "suz4utPr9Y",
      "target": "Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short.",
      "similarity": 0.8351
    },
    {
      "source": "mYgoNEsUDi",
      "target": "Moreover",
      "similarity": 0.8308
    },
    {
      "source": "mYgoNEsUDi",
      "target": "mOpNrrV2zH",
      "similarity": 0.8307
    },
    {
      "source": "mYgoNEsUDi",
      "target": "However",
      "similarity": 0.8276
    },
    {
      "source": "mYgoNEsUDi",
      "target": "Additionally",
      "similarity": 0.8145
    },
    {
      "source": "mYgoNEsUDi",
      "target": "We also analyze how the model behaves as a policy and value",
      "similarity": 0.8144
    },
    {
      "source": "zigzag spaghetti (ZS)",
      "target": "The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics.",
      "similarity": 0.8598
    },
    {
      "source": "zigzag spaghetti (ZS)",
      "target": "We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting.",
      "similarity": 0.8359
    },
    {
      "source": "zigzag spaghetti (ZS)",
      "target": "h7GAgbLSmC",
      "similarity": 0.8304
    },
    {
      "source": "zigzag spaghetti (ZS)",
      "target": "by exploiting a linear factorization of the return as the inner product of successor features and a reward vector",
      "similarity": 0.8264
    },
    {
      "source": "zigzag spaghetti (ZS)",
      "target": "Furthermore",
      "similarity": 0.8217
    },
    {
      "source": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "target": "Interestingly",
      "similarity": 0.825
    },
    {
      "source": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "target": "ing on text or static image inputs. To bridge this gap",
      "similarity": 0.8228
    },
    {
      "source": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "target": "98% reduction in compute costs when compressing a 13B-parameter model. On",
      "similarity": 0.8201
    },
    {
      "source": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "target": "e5mTvjXG9u",
      "similarity": 0.8048
    },
    {
      "source": "dynamic topological information into graph diffusion models. Our extensive experiments on graph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models",
      "target": "T7bmHkwzS6",
      "similarity": 0.8038
    },
    {
      "source": "QCDdI7X3f9",
      "target": "This paper proposes",
      "similarity": 0.8524
    },
    {
      "source": "QCDdI7X3f9",
      "target": "named Pacmann",
      "similarity": 0.8429
    },
    {
      "source": "QCDdI7X3f9",
      "target": "This challenge calls for models to interact with complex SQL workflow environments",
      "similarity": 0.8336
    },
    {
      "source": "QCDdI7X3f9",
      "target": "tePFpDgyqg",
      "similarity": 0.8326
    },
    {
      "source": "QCDdI7X3f9",
      "target": "uuriavczkL",
      "similarity": 0.8304
    },
    {
      "source": "AnL6BuWzxa",
      "target": "from the weights alone. Our results demonstrate that bilinear layers serve as an",
      "similarity": 0.8412
    },
    {
      "source": "AnL6BuWzxa",
      "target": "with self-critique and significant performance gains with sound external verification.",
      "similarity": 0.8402
    },
    {
      "source": "AnL6BuWzxa",
      "target": "VQwI055flA",
      "similarity": 0.8385
    },
    {
      "source": "AnL6BuWzxa",
      "target": "FrFQpAgnGE",
      "similarity": 0.8378
    },
    {
      "source": "AnL6BuWzxa",
      "target": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "similarity": 0.8286
    },
    {
      "source": "2TIYkqieKw",
      "target": "2kGKsyhtvh",
      "similarity": 0.8503
    },
    {
      "source": "2TIYkqieKw",
      "target": "In this task",
      "similarity": 0.8381
    },
    {
      "source": "2TIYkqieKw",
      "target": "condition rely on counterfactuals inferred from a Structural Causal Model (SCM)",
      "similarity": 0.8379
    },
    {
      "source": "2TIYkqieKw",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.8291
    },
    {
      "source": "2TIYkqieKw",
      "target": "large volumes of information that cannot fit into a single prompt. We present",
      "similarity": 0.8253
    },
    {
      "source": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "target": "nYjAzwor9R",
      "similarity": 0.8156
    },
    {
      "source": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "target": "it is the only method of which we are aware that reliably works well in both low- and high-budget settings.\"",
      "similarity": 0.7999
    },
    {
      "source": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "target": "Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction.",
      "similarity": 0.7967
    },
    {
      "source": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "target": "eC2a2IndIt",
      "similarity": 0.7961
    },
    {
      "source": "Project page is available at https://raiden-zhu.github.io/blog/2025/DICE.\"",
      "target": "Our codebase",
      "similarity": 0.7862
    },
    {
      "source": "ZadnlOHsHv",
      "target": "shows improved perplexity in context lengths of up to 1M in zero-shot. When",
      "similarity": 0.8317
    },
    {
      "source": "ZadnlOHsHv",
      "target": "However",
      "similarity": 0.8287
    },
    {
      "source": "ZadnlOHsHv",
      "target": "While prior research has attempted to demystify these models through input attribution and neuron role analysis",
      "similarity": 0.8247
    },
    {
      "source": "ZadnlOHsHv",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.8242
    },
    {
      "source": "ZadnlOHsHv",
      "target": "First",
      "similarity": 0.822
    },
    {
      "source": "ScVnYBaSEw",
      "target": "27SSnLl85x",
      "similarity": 0.8329
    },
    {
      "source": "ScVnYBaSEw",
      "target": "We introduce  Explore-and-Exploit GNN ($X^2$GNN",
      "similarity": 0.8305
    },
    {
      "source": "ScVnYBaSEw",
      "target": "By playing against itself",
      "similarity": 0.8263
    },
    {
      "source": "ScVnYBaSEw",
      "target": "INqLJwqUmc",
      "similarity": 0.8151
    },
    {
      "source": "ScVnYBaSEw",
      "target": "aVfDrl7xDV",
      "similarity": 0.8138
    },
    {
      "source": "In this paper",
      "target": "We pre-train a series of LLMs from scratch to measure the impact of a potential poisoning adversary under four different attack objectives (denial-of-service",
      "similarity": 0.7932
    },
    {
      "source": "In this paper",
      "target": "Finally",
      "similarity": 0.7845
    },
    {
      "source": "In this paper",
      "target": "Subsequently",
      "similarity": 0.7725
    },
    {
      "source": "In this paper",
      "target": "gQoBw7sGAu",
      "similarity": 0.7703
    },
    {
      "source": "In this paper",
      "target": "HSi4VetQLj",
      "similarity": 0.7685
    },
    {
      "source": "9KiE3t6CsL",
      "target": "The conjecture has recently been confirmed for networks with integer weights by Haase",
      "similarity": 0.868
    },
    {
      "source": "9KiE3t6CsL",
      "target": "qZEdmyqCHF",
      "similarity": 0.8581
    },
    {
      "source": "9KiE3t6CsL",
      "target": "uxVBbSlKQ4",
      "similarity": 0.8523
    },
    {
      "source": "9KiE3t6CsL",
      "target": "We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm.",
      "similarity": 0.8482
    },
    {
      "source": "9KiE3t6CsL",
      "target": "WCRQFlji2q",
      "similarity": 0.8471
    },
    {
      "source": "Furthermore",
      "target": "To extend coding capabilities beyond function-level tasks to more challenging software-level development",
      "similarity": 0.7691
    },
    {
      "source": "Furthermore",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.7666
    },
    {
      "source": "Furthermore",
      "target": "7bAjVh3CG3",
      "similarity": 0.7588
    },
    {
      "source": "Furthermore",
      "target": "In this paper",
      "similarity": 0.7584
    },
    {
      "source": "Furthermore",
      "target": "than existing search techniques",
      "similarity": 0.7583
    },
    {
      "source": "hgwGi81ndj",
      "target": "EkfLaCJ7bk",
      "similarity": 0.8464
    },
    {
      "source": "hgwGi81ndj",
      "target": "Pd7IOswRUZ",
      "similarity": 0.8383
    },
    {
      "source": "hgwGi81ndj",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.8375
    },
    {
      "source": "hgwGi81ndj",
      "target": "Leveraging Scylla and the concept of critical complexity",
      "similarity": 0.837
    },
    {
      "source": "hgwGi81ndj",
      "target": "PxlfzEePC0",
      "similarity": 0.8341
    },
    {
      "source": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "target": "This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue.",
      "similarity": 0.8155
    },
    {
      "source": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "target": "This work not only opens a promising and orthogonal direction for improving adversarial defenses in deep learning beyond existing methods but also provides new insights into designing more resilient AI systems with robust statistics.",
      "similarity": 0.8084
    },
    {
      "source": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "target": "The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions.",
      "similarity": 0.8039
    },
    {
      "source": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "target": "To address this",
      "similarity": 0.8035
    },
    {
      "source": "We demonstrate the model's ability to (i) efficiently solve single tasks",
      "target": "https://chatqa2-project.github.io/\"",
      "similarity": 0.8028
    },
    {
      "source": "7XIkRgYjK3",
      "target": "5z9GjHgerY",
      "similarity": 0.8082
    },
    {
      "source": "7XIkRgYjK3",
      "target": "Next",
      "similarity": 0.7874
    },
    {
      "source": "7XIkRgYjK3",
      "target": "Scaling this maximization to high dimensional and complex settings has been an issue due to BOED inherent computational complexity.",
      "similarity": 0.7868
    },
    {
      "source": "7XIkRgYjK3",
      "target": "UqrFPhcmFp",
      "similarity": 0.7861
    },
    {
      "source": "7XIkRgYjK3",
      "target": "demonstrate SPADE\u2019s efficiency compared to the state-of-the-art methods.\"",
      "similarity": 0.78
    },
    {
      "source": "To address these challenges",
      "target": "gcouwCx7dG",
      "similarity": 0.8142
    },
    {
      "source": "To address these challenges",
      "target": "Oxpkn0YLG1",
      "similarity": 0.8103
    },
    {
      "source": "To address these challenges",
      "target": "much attention as a scalable unsupervised approach to this problem. However",
      "similarity": 0.8053
    },
    {
      "source": "To address these challenges",
      "target": "INyi7qUdjZ",
      "similarity": 0.8043
    },
    {
      "source": "To address these challenges",
      "target": "C45YqeBDUM",
      "similarity": 0.7997
    },
    {
      "source": "dEg5SdGaiq",
      "target": "To enable structural learning with the language model",
      "similarity": 0.862
    },
    {
      "source": "dEg5SdGaiq",
      "target": "wide dissemination",
      "similarity": 0.8586
    },
    {
      "source": "dEg5SdGaiq",
      "target": "Extensive evaluations are conducted on various long-context tasks whose lengths (e.g.",
      "similarity": 0.8494
    },
    {
      "source": "dEg5SdGaiq",
      "target": "intrinsic decomposition of shape",
      "similarity": 0.8409
    },
    {
      "source": "dEg5SdGaiq",
      "target": "mqNKiEB6pd",
      "similarity": 0.8408
    },
    {
      "source": "However",
      "target": "q5EZ7gKcnW",
      "similarity": 0.801
    },
    {
      "source": "However",
      "target": "However",
      "similarity": 0.7984
    },
    {
      "source": "However",
      "target": "we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning)",
      "similarity": 0.7947
    },
    {
      "source": "However",
      "target": "Additionally",
      "similarity": 0.7932
    },
    {
      "source": "However",
      "target": "L14sqcrUC3",
      "similarity": 0.7925
    },
    {
      "source": "In this paper",
      "target": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "similarity": 0.8788
    },
    {
      "source": "In this paper",
      "target": "To overcome this limitation",
      "similarity": 0.8455
    },
    {
      "source": "In this paper",
      "target": "For example",
      "similarity": 0.8405
    },
    {
      "source": "In this paper",
      "target": "RC5FPYVQaH",
      "similarity": 0.8398
    },
    {
      "source": "In this paper",
      "target": "However",
      "similarity": 0.8395
    },
    {
      "source": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "target": "cADpvQgnqg",
      "similarity": 0.85
    },
    {
      "source": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "target": "In the more general context",
      "similarity": 0.8417
    },
    {
      "source": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "target": "We identify the drawback of PCA projection that model performance degrades rapidly under relatively low compression rates (less than 60%).",
      "similarity": 0.8405
    },
    {
      "source": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "target": "Our framework leverages knowledge of the policy structure to solve the $\\textit{inverse problem}$",
      "similarity": 0.834
    },
    {
      "source": "Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos.",
      "target": "memorization.",
      "similarity": 0.8318
    },
    {
      "source": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "target": "INqLJwqUmc",
      "similarity": 0.8352
    },
    {
      "source": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "target": "While existing generative models can conditionally sample 3D structures with approximately correct moments",
      "similarity": 0.8336
    },
    {
      "source": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "target": "bsFWJ0Kget",
      "similarity": 0.8332
    },
    {
      "source": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "target": "DpLFmc09pC",
      "similarity": 0.831
    },
    {
      "source": "We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset",
      "target": "point in the latent representation space for each input. However",
      "similarity": 0.8263
    },
    {
      "source": "mFY0tPDWK8",
      "target": "e0X9l4kecx",
      "similarity": 0.8108
    },
    {
      "source": "mFY0tPDWK8",
      "target": "Our source code is available at https://github.com/xz-group/AnalogGenie.\"",
      "similarity": 0.7972
    },
    {
      "source": "mFY0tPDWK8",
      "target": "wkbx7BRAsM",
      "similarity": 0.7966
    },
    {
      "source": "mFY0tPDWK8",
      "target": "60GeEoG5kD",
      "similarity": 0.7966
    },
    {
      "source": "mFY0tPDWK8",
      "target": "t8fu5m8R5m",
      "similarity": 0.7948
    },
    {
      "source": "Zhdhg6n2OG",
      "target": "7bAjVh3CG3",
      "similarity": 0.7941
    },
    {
      "source": "Zhdhg6n2OG",
      "target": "Early works on clean-label attacks added triggers to a random subset of the training set",
      "similarity": 0.7897
    },
    {
      "source": "Zhdhg6n2OG",
      "target": "7d2JwGbxhA",
      "similarity": 0.7871
    },
    {
      "source": "Zhdhg6n2OG",
      "target": "Using this representation",
      "similarity": 0.7865
    },
    {
      "source": "Zhdhg6n2OG",
      "target": "Recent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts",
      "similarity": 0.7828
    },
    {
      "source": "WoPovNkM5h",
      "target": "4v4RcAODj9",
      "similarity": 0.8172
    },
    {
      "source": "WoPovNkM5h",
      "target": "space",
      "similarity": 0.8147
    },
    {
      "source": "WoPovNkM5h",
      "target": "DwqoBkj2Mw",
      "similarity": 0.8142
    },
    {
      "source": "WoPovNkM5h",
      "target": "uSz2K30RRd",
      "similarity": 0.812
    },
    {
      "source": "WoPovNkM5h",
      "target": "5IWJBStfU7",
      "similarity": 0.8086
    },
    {
      "source": "TDyE2iuvyc",
      "target": "riTiq3i21b",
      "similarity": 0.7932
    },
    {
      "source": "TDyE2iuvyc",
      "target": "IUmj2dw5se",
      "similarity": 0.7893
    },
    {
      "source": "TDyE2iuvyc",
      "target": "Inspired by these findings",
      "similarity": 0.7847
    },
    {
      "source": "TDyE2iuvyc",
      "target": "mobile devices.\"",
      "similarity": 0.7835
    },
    {
      "source": "TDyE2iuvyc",
      "target": "fMNRYBvcQN",
      "similarity": 0.7794
    },
    {
      "source": "FZv3kPHTtB",
      "target": "In response",
      "similarity": 0.8514
    },
    {
      "source": "FZv3kPHTtB",
      "target": "AcVpLS86RT",
      "similarity": 0.8389
    },
    {
      "source": "FZv3kPHTtB",
      "target": "Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images.",
      "similarity": 0.8354
    },
    {
      "source": "FZv3kPHTtB",
      "target": "In this task",
      "similarity": 0.8268
    },
    {
      "source": "FZv3kPHTtB",
      "target": "Mjn53GtMxi",
      "similarity": 0.8255
    },
    {
      "source": "IEul1M5pyk",
      "target": "To tackle this challenge",
      "similarity": 0.8549
    },
    {
      "source": "IEul1M5pyk",
      "target": "tu3qwNjrtw",
      "similarity": 0.8368
    },
    {
      "source": "IEul1M5pyk",
      "target": "JYTQ6ELUVO",
      "similarity": 0.8163
    },
    {
      "source": "IEul1M5pyk",
      "target": "szRmEM8Kx5",
      "similarity": 0.8136
    },
    {
      "source": "IEul1M5pyk",
      "target": "Without labeled calibration data for target domains",
      "similarity": 0.8121
    },
    {
      "source": "tpGkEgxMJT",
      "target": "We design the data generation process to be entirely independent of human intervention or GPT API usage",
      "similarity": 0.8403
    },
    {
      "source": "tpGkEgxMJT",
      "target": "MoDE achieves state-of-the-art performance on 134 tasks in four established imitation learning benchmarks (CALVIN and LIBERO).",
      "similarity": 0.8402
    },
    {
      "source": "tpGkEgxMJT",
      "target": "rCX9l4OTCT",
      "similarity": 0.8392
    },
    {
      "source": "tpGkEgxMJT",
      "target": "9kJperA2a4",
      "similarity": 0.8391
    },
    {
      "source": "tpGkEgxMJT",
      "target": "ugyqNEOjoU",
      "similarity": 0.8387
    },
    {
      "source": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "target": "For example",
      "similarity": 0.8383
    },
    {
      "source": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "target": "group label efficiency: utilizing the group-labeled data as a target set to optimize",
      "similarity": 0.8328
    },
    {
      "source": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "target": "4A9IdSa1ul",
      "similarity": 0.8325
    },
    {
      "source": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "target": "XmProj9cPs",
      "similarity": 0.8303
    },
    {
      "source": "Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.\"",
      "target": "While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents",
      "similarity": 0.8287
    },
    {
      "source": "phAlw3JPms",
      "target": "Then the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.",
      "similarity": 0.8459
    },
    {
      "source": "phAlw3JPms",
      "target": "To achieve computationally efficient yet high-resolution rendering",
      "similarity": 0.8416
    },
    {
      "source": "phAlw3JPms",
      "target": "NHhjczmJjo",
      "similarity": 0.8398
    },
    {
      "source": "phAlw3JPms",
      "target": "tokens and demonstrate that it significantly outperforms state-of-the-art models",
      "similarity": 0.8382
    },
    {
      "source": "phAlw3JPms",
      "target": "In this paper",
      "similarity": 0.834
    },
    {
      "source": "Extensive experiments on MuJoCo",
      "target": "based interpretability is viable for understanding deep-learning models.\"",
      "similarity": 0.8194
    },
    {
      "source": "Extensive experiments on MuJoCo",
      "target": "We instead consider the inverted situation",
      "similarity": 0.8164
    },
    {
      "source": "Extensive experiments on MuJoCo",
      "target": "v1rFkElnIn",
      "similarity": 0.8155
    },
    {
      "source": "Extensive experiments on MuJoCo",
      "target": "To develop SoundCTM",
      "similarity": 0.8147
    },
    {
      "source": "Extensive experiments on MuJoCo",
      "target": "dEg5SdGaiq",
      "similarity": 0.8127
    },
    {
      "source": "Our code is available at https://github.com/jiawei415/RobustDecisionTransformer\u3002\"",
      "target": "KOR-Bench emphasizes models' effectiveness in applying new rule descriptions to solve novel rule-driven questions. O1-Preview and O1-Mini achieve accuracies of 72.88\\% and 70.16\\%",
      "similarity": 0.8337
    },
    {
      "source": "Our code is available at https://github.com/jiawei415/RobustDecisionTransformer\u3002\"",
      "target": "tu3qwNjrtw",
      "similarity": 0.8287
    },
    {
      "source": "Our code is available at https://github.com/jiawei415/RobustDecisionTransformer\u3002\"",
      "target": "and 22\\% reduction in overall latency.\"",
      "similarity": 0.8261
    },
    {
      "source": "Our code is available at https://github.com/jiawei415/RobustDecisionTransformer\u3002\"",
      "target": "We also study the empirical trade-offs between publishers' and users' welfare",
      "similarity": 0.8209
    },
    {
      "source": "Our code is available at https://github.com/jiawei415/RobustDecisionTransformer\u3002\"",
      "target": "based on features derived from a Joint Embedding Predictive Architecture",
      "similarity": 0.8206
    },
    {
      "source": "vbmSSIhKAM",
      "target": "We also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.",
      "similarity": 0.8544
    },
    {
      "source": "vbmSSIhKAM",
      "target": "03EkqSCKuO",
      "similarity": 0.8333
    },
    {
      "source": "vbmSSIhKAM",
      "target": "Mfnh1Sqdwf",
      "similarity": 0.8323
    },
    {
      "source": "vbmSSIhKAM",
      "target": "Furthermore",
      "similarity": 0.8315
    },
    {
      "source": "vbmSSIhKAM",
      "target": "ogjBpZ8uSi",
      "similarity": 0.8296
    },
    {
      "source": "n7qGCmluZr",
      "target": "cfKZ5VrhXt",
      "similarity": 0.8089
    },
    {
      "source": "n7qGCmluZr",
      "target": "of our proposed method through a new understanding of the contrastive loss of",
      "similarity": 0.7943
    },
    {
      "source": "n7qGCmluZr",
      "target": "rJ5g8ueQaI",
      "similarity": 0.787
    },
    {
      "source": "n7qGCmluZr",
      "target": "wLmJIs1uqG",
      "similarity": 0.7867
    },
    {
      "source": "n7qGCmluZr",
      "target": "We show that DUET achieves an iteration complexity of  $O(1/T^{1-5p-\\frac{11}{4}\\tau})$ for approximate KKT-stationary point convergence under relaxed assumptions",
      "similarity": 0.7857
    }
  ],
  "threshold": 0.75,
  "top_k": 5,
  "total_papers": 3703
}